# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic
import typing_extensions
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.serialization import FieldMetadata
from ..core.unchecked_base_model import UncheckedBaseModel
from .assistant_message_judge_plan_ai import AssistantMessageJudgePlanAi
from .chat_eval_tool_response_message_evaluation_role import ChatEvalToolResponseMessageEvaluationRole


class ChatEvalToolResponseMessageEvaluation(UncheckedBaseModel):
    role: ChatEvalToolResponseMessageEvaluationRole = pydantic.Field()
    """
    This is the role of the message author.
    For a tool response message evaluation, the role is always 'tool'
    @default 'tool'
    """

    judge_plan: typing_extensions.Annotated[AssistantMessageJudgePlanAi, FieldMetadata(alias="judgePlan")] = (
        pydantic.Field()
    )
    """
    This is the judge plan that instructs how to evaluate the tool response message.
    The tool response message can be evaluated with an LLM-as-judge by defining the evaluation criteria in a prompt.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
