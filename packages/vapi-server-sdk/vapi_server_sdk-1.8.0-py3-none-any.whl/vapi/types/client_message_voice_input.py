# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations

import typing

import pydantic
import typing_extensions
from ..core.pydantic_utilities import IS_PYDANTIC_V2, update_forward_refs
from ..core.serialization import FieldMetadata
from ..core.unchecked_base_model import UncheckedBaseModel
from .call import Call
from .client_message_voice_input_phone_number import ClientMessageVoiceInputPhoneNumber
from .client_message_voice_input_type import ClientMessageVoiceInputType
from .create_customer_dto import CreateCustomerDto


class ClientMessageVoiceInput(UncheckedBaseModel):
    phone_number: typing_extensions.Annotated[
        typing.Optional[ClientMessageVoiceInputPhoneNumber], FieldMetadata(alias="phoneNumber")
    ] = pydantic.Field(default=None)
    """
    This is the phone number that the message is associated with.
    """

    type: ClientMessageVoiceInputType = pydantic.Field()
    """
    This is the type of the message. "voice-input" is sent when a generation is requested from voice provider.
    """

    timestamp: typing.Optional[float] = pydantic.Field(default=None)
    """
    This is the timestamp of the message.
    """

    call: typing.Optional[Call] = pydantic.Field(default=None)
    """
    This is the call that the message is associated with.
    """

    customer: typing.Optional[CreateCustomerDto] = pydantic.Field(default=None)
    """
    This is the customer that the message is associated with.
    """

    assistant: typing.Optional["CreateAssistantDto"] = pydantic.Field(default=None)
    """
    This is the assistant that the message is associated with.
    """

    input: str = pydantic.Field()
    """
    This is the voice input content
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


from .anthropic_model import AnthropicModel  # noqa: E402, F401, I001
from .anyscale_model import AnyscaleModel  # noqa: E402, F401, I001
from .assistant_overrides import AssistantOverrides  # noqa: E402, F401, I001
from .call_hook_assistant_speech_interrupted import CallHookAssistantSpeechInterrupted  # noqa: E402, F401, I001
from .call_hook_call_ending import CallHookCallEnding  # noqa: E402, F401, I001
from .call_hook_customer_speech_interrupted import CallHookCustomerSpeechInterrupted  # noqa: E402, F401, I001
from .call_hook_customer_speech_timeout import CallHookCustomerSpeechTimeout  # noqa: E402, F401, I001
from .cerebras_model import CerebrasModel  # noqa: E402, F401, I001
from .create_assistant_dto import CreateAssistantDto  # noqa: E402, F401, I001
from .create_handoff_tool_dto import CreateHandoffToolDto  # noqa: E402, F401, I001
from .custom_llm_model import CustomLlmModel  # noqa: E402, F401, I001
from .deep_infra_model import DeepInfraModel  # noqa: E402, F401, I001
from .deep_seek_model import DeepSeekModel  # noqa: E402, F401, I001
from .google_model import GoogleModel  # noqa: E402, F401, I001
from .groq_model import GroqModel  # noqa: E402, F401, I001
from .group_condition import GroupCondition  # noqa: E402, F401, I001
from .handoff_destination_assistant import HandoffDestinationAssistant  # noqa: E402, F401, I001
from .inflection_ai_model import InflectionAiModel  # noqa: E402, F401, I001
from .open_ai_model import OpenAiModel  # noqa: E402, F401, I001
from .open_router_model import OpenRouterModel  # noqa: E402, F401, I001
from .perplexity_ai_model import PerplexityAiModel  # noqa: E402, F401, I001
from .together_ai_model import TogetherAiModel  # noqa: E402, F401, I001
from .tool_call_hook_action import ToolCallHookAction  # noqa: E402, F401, I001
from .xai_model import XaiModel  # noqa: E402, F401, I001

update_forward_refs(ClientMessageVoiceInput)
