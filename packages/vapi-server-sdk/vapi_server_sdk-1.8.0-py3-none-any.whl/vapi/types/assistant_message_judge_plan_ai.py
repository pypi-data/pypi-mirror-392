# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.unchecked_base_model import UncheckedBaseModel
from .assistant_message_judge_plan_ai_model import AssistantMessageJudgePlanAiModel
from .assistant_message_judge_plan_ai_type import AssistantMessageJudgePlanAiType


class AssistantMessageJudgePlanAi(UncheckedBaseModel):
    model: AssistantMessageJudgePlanAiModel = pydantic.Field()
    """
    This is the model to use for the LLM-as-a-judge.
    If not provided, will default to the assistant's model.
    
    The instructions on how to evaluate the model output with this LLM-Judge must be passed as a system message in the messages array of the model.
    
    The Mock conversation can be passed to the LLM-Judge to evaluate using the prompt {{messages}} and will be evaluated as a LiquidJS Variable. To access and judge only the last message, use {{messages[-1]}}
    
    The LLM-Judge must respond with "pass" or "fail" and only those two responses are allowed.
    """

    type: AssistantMessageJudgePlanAiType = pydantic.Field()
    """
    This is the type of the judge plan.
    Use 'ai' to evaluate the assistant message content using LLM-as-a-judge.
    @default 'ai'
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
