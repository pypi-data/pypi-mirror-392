{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: LLM Output Processing with Complex Pydantic Models\n",
    "\n",
    "**Category**: ln Utilities  \n",
    "**Difficulty**: Intermediate  \n",
    "**Time**: 15-20 minutes\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "When processing LLM outputs with structured extraction (using Pydantic models), you often receive nested container models like `TaskList(tasks: list[Task])`. Extracting specific fields from these nested structures for downstream processing requires handling:\n",
    "\n",
    "- **Nested model hierarchies** - Container models wrapping lists of child models\n",
    "- **Variable output quality** - LLM outputs with inconsistent completeness\n",
    "- **Null value handling** - Missing fields, optional attributes, partial extraction failures\n",
    "\n",
    "**Why This Matters**:\n",
    "- **Data Pipeline Robustness**: LLM outputs fail unpredictably - extraction logic must handle partial results\n",
    "- **Analytics Integration**: Downstream systems expect flat lists of primitives (task titles, IDs), not nested models\n",
    "\n",
    "**What You'll Build**:\n",
    "A field extraction pipeline using lionherd-core's `to_list()` that processes nested Pydantic models from LLM outputs and produces clean flat lists for analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Prior Knowledge**:\n",
    "- Pydantic BaseModel basics\n",
    "- List comprehensions and basic Python data manipulation\n",
    "\n",
    "**Required Packages**:\n",
    "```bash\n",
    "pip install lionherd-core  # >=0.1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "from enum import Enum\n",
    "\n",
    "# Third-party\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# lionherd-core\n",
    "from lionherd_core.ln import to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Overview\n",
    "\n",
    "We'll implement field extraction using `to_list()` with progressive sophistication:\n",
    "\n",
    "1. **Model Definition**: Define realistic LLM output models (TaskList containing Task[])\n",
    "2. **Basic Extraction**: Extract fields from nested models\n",
    "3. **Data Cleaning**: Handle nulls, duplicates, and quality filtering\n",
    "\n",
    "**Key lionherd-core Components**:\n",
    "- `to_list()`: Universal list conversion with flattening, null removal, deduplication\n",
    "- `flatten=True`: Recursively flattens nested iterables\n",
    "- `dropna=True`: Filters None/Undefined/Unset values\n",
    "- `unique=True`: Deduplicates results\n",
    "\n",
    "**Expected Outcome**: Robust extraction of flat field lists from nested Pydantic models.\n",
    "\n",
    "**Pattern**: Extract objects first (with `to_list`), then access fields (with comprehension)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define LLM Output Models and Sample Data\n",
    "\n",
    "Define Pydantic models representing typical LLM structured outputs with variable quality (some complete, some partial, some empty).\n",
    "\n",
    "**Key Point**: This pattern (container model with list of child models) is ubiquitous in LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 LLM outputs\n",
      "Output 1: 3 tasks\n",
      "Output 2: 2 tasks\n",
      "Output 3: 0 tasks (empty)\n"
     ]
    }
   ],
   "source": [
    "# Define realistic LLM output models\n",
    "\n",
    "\n",
    "class Priority(Enum):\n",
    "    \"\"\"Task priority levels.\"\"\"\n",
    "\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    URGENT = \"urgent\"\n",
    "\n",
    "\n",
    "class Task(BaseModel):\n",
    "    \"\"\"Individual task extracted from document.\"\"\"\n",
    "\n",
    "    title: str\n",
    "    description: str | None = None\n",
    "    priority: Priority | None = None\n",
    "    assignee: str | None = None\n",
    "\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    \"\"\"Container for extracted tasks (typical LLM output structure).\"\"\"\n",
    "\n",
    "    source_document: str\n",
    "    tasks: list[Task] = Field(default_factory=list)\n",
    "    confidence: float | None = None\n",
    "\n",
    "\n",
    "# Create sample LLM outputs with variable quality\n",
    "output1 = TaskList(\n",
    "    source_document=\"meeting_notes.txt\",\n",
    "    tasks=[\n",
    "        Task(title=\"Review PR #123\", priority=Priority.HIGH, assignee=\"Alice\"),\n",
    "        Task(title=\"Update documentation\", priority=Priority.MEDIUM),\n",
    "        Task(title=\"Fix bug in auth\", priority=Priority.URGENT, assignee=\"Bob\"),\n",
    "    ],\n",
    "    confidence=0.92,\n",
    ")\n",
    "\n",
    "output2 = TaskList(\n",
    "    source_document=\"email_thread.txt\",\n",
    "    tasks=[\n",
    "        Task(title=\"Schedule team sync\"),  # Missing fields\n",
    "        Task(title=\"Review goals\", priority=Priority.MEDIUM, assignee=\"Charlie\"),\n",
    "    ],\n",
    "    confidence=0.78,\n",
    ")\n",
    "\n",
    "output3 = TaskList(\n",
    "    source_document=\"slack_messages.txt\",\n",
    "    tasks=[],  # Empty extraction\n",
    "    confidence=0.45,\n",
    ")\n",
    "\n",
    "batch_outputs = [output1, output2, output3]\n",
    "\n",
    "print(f\"Created {len(batch_outputs)} LLM outputs\")\n",
    "print(f\"Output 1: {len(output1.tasks)} tasks\")\n",
    "print(f\"Output 2: {len(output2.tasks)} tasks\")\n",
    "print(f\"Output 3: {len(output3.tasks)} tasks (empty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extract Fields from Nested Models\n",
    "\n",
    "Extract task titles using the two-step pattern: extract objects with `to_list()`, then access fields.\n",
    "\n",
    "**Key Point**: `to_list()` provides consistent handling of edge cases (None values, empty lists) that list comprehensions don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks extracted: 5 tasks\n",
      "\n",
      "Titles: ['Review PR #123', 'Update documentation', 'Fix bug in auth', 'Schedule team sync', 'Review goals']\n",
      "\n",
      "Priorities raw (with None): [<Priority.HIGH: 'high'>, <Priority.MEDIUM: 'medium'>, <Priority.URGENT: 'urgent'>, None, <Priority.MEDIUM: 'medium'>]\n",
      "Priorities clean: [<Priority.HIGH: 'high'>, <Priority.MEDIUM: 'medium'>, <Priority.URGENT: 'urgent'>, <Priority.MEDIUM: 'medium'>]\n"
     ]
    }
   ],
   "source": [
    "# Extract all tasks from batch outputs\n",
    "all_tasks = to_list(\n",
    "    [output.tasks for output in batch_outputs],\n",
    "    flatten=True,  # Flatten nested lists\n",
    "    dropna=True,  # Remove None values\n",
    ")\n",
    "\n",
    "print(f\"All tasks extracted: {len(all_tasks)} tasks\")\n",
    "\n",
    "# Extract titles from tasks\n",
    "titles = [task.title for task in all_tasks]\n",
    "print(f\"\\nTitles: {titles}\")\n",
    "\n",
    "# Extract priorities (optional field - may be None)\n",
    "priorities_raw = [task.priority for task in all_tasks]\n",
    "print(f\"\\nPriorities raw (with None): {priorities_raw}\")\n",
    "\n",
    "# Clean priorities (remove None values)\n",
    "priorities_clean = to_list(\n",
    "    priorities_raw,\n",
    "    flatten=True,\n",
    "    dropna=True,\n",
    ")\n",
    "print(f\"Priorities clean: {priorities_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Quality Filtering and Deduplication\n",
    "\n",
    "Filter by confidence threshold and extract unique values.\n",
    "\n",
    "**Key Point**: Filter outputs before extraction (preserves context); use `unique=True` for deduplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch outputs confidence:\n",
      "  Output 1: 0.92 ✓ PASS\n",
      "  Output 2: 0.78 ✓ PASS\n",
      "  Output 3: 0.45 ✗ FAIL\n",
      "\n",
      "High quality outputs: 2/3\n",
      "Tasks from high-quality outputs: 5\n",
      "Unique assignees: ['Alice', 'Bob', 'Charlie']\n"
     ]
    }
   ],
   "source": [
    "# Quality-aware extraction with confidence filtering\n",
    "CONFIDENCE_THRESHOLD = 0.75\n",
    "\n",
    "print(\"Batch outputs confidence:\")\n",
    "for i, output in enumerate(batch_outputs, 1):\n",
    "    conf = output.confidence or 0.0\n",
    "    status = \"✓ PASS\" if conf >= CONFIDENCE_THRESHOLD else \"✗ FAIL\"\n",
    "    print(f\"  Output {i}: {conf:.2f} {status}\")\n",
    "\n",
    "# Filter high-confidence outputs\n",
    "high_quality = [\n",
    "    output\n",
    "    for output in batch_outputs\n",
    "    if output.confidence and output.confidence >= CONFIDENCE_THRESHOLD\n",
    "]\n",
    "\n",
    "print(f\"\\nHigh quality outputs: {len(high_quality)}/{len(batch_outputs)}\")\n",
    "\n",
    "# Extract tasks from high-quality outputs only\n",
    "quality_tasks = to_list(\n",
    "    [output.tasks for output in high_quality],\n",
    "    flatten=True,\n",
    "    dropna=True,\n",
    ")\n",
    "\n",
    "# Get unique assignees\n",
    "assignees = to_list(\n",
    "    [task.assignee for task in quality_tasks],\n",
    "    flatten=True,\n",
    "    dropna=True,\n",
    "    unique=True,\n",
    ")\n",
    "\n",
    "print(f\"Tasks from high-quality outputs: {len(quality_tasks)}\")\n",
    "print(f\"Unique assignees: {assignees}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Working Example\n",
    "\n",
    "Production-ready field extraction with quality filtering and enum value handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All titles: ['Review PR #123', 'Update documentation', 'Fix bug in auth', 'Schedule team sync', 'Review goals']\n",
      "\n",
      "Unique priorities (strings): ['high', 'medium', 'urgent']\n",
      "\n",
      "Unique assignees: ['Alice', 'Bob', 'Charlie']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Production field extraction from LLM outputs.\n",
    "\"\"\"\n",
    "from enum import Enum\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from lionherd_core.ln import to_list\n",
    "\n",
    "\n",
    "def extract_field(\n",
    "    batch_outputs: list[TaskList],\n",
    "    field_name: str,\n",
    "    *,\n",
    "    min_confidence: float = 0.75,\n",
    "    unique: bool = False,\n",
    "    extract_enum_values: bool = True,\n",
    ") -> list:\n",
    "    \"\"\"Extract field from batch LLM outputs with quality filtering.\n",
    "\n",
    "    Args:\n",
    "        batch_outputs: List of TaskList outputs from LLM\n",
    "        field_name: Field to extract from Task objects\n",
    "        min_confidence: Minimum confidence threshold\n",
    "        unique: If True, deduplicate results\n",
    "        extract_enum_values: If True, extract .value from enums\n",
    "\n",
    "    Returns:\n",
    "        Clean list of field values (nulls removed, optionally deduplicated)\n",
    "    \"\"\"\n",
    "    # Filter by confidence\n",
    "    quality_outputs = [\n",
    "        output\n",
    "        for output in batch_outputs\n",
    "        if output.confidence and output.confidence >= min_confidence\n",
    "    ]\n",
    "\n",
    "    # Extract all tasks\n",
    "    all_tasks = to_list(\n",
    "        [output.tasks for output in quality_outputs],\n",
    "        flatten=True,\n",
    "        dropna=True,\n",
    "    )\n",
    "\n",
    "    if not all_tasks:\n",
    "        return []\n",
    "\n",
    "    # Extract field values\n",
    "    field_values = []\n",
    "    for task in all_tasks:\n",
    "        value = getattr(task, field_name, None)\n",
    "\n",
    "        # Handle enum values\n",
    "        if extract_enum_values and isinstance(value, Enum):\n",
    "            value = value.value\n",
    "\n",
    "        field_values.append(value)\n",
    "\n",
    "    # Clean and optionally deduplicate\n",
    "    return to_list(\n",
    "        field_values,\n",
    "        flatten=True,\n",
    "        dropna=True,\n",
    "        unique=unique,\n",
    "    )\n",
    "\n",
    "\n",
    "# Usage examples\n",
    "titles = extract_field(batch_outputs, \"title\")\n",
    "print(f\"All titles: {titles}\")\n",
    "\n",
    "priorities = extract_field(\n",
    "    batch_outputs,\n",
    "    \"priority\",\n",
    "    min_confidence=0.75,\n",
    "    unique=True,\n",
    ")\n",
    "print(f\"\\nUnique priorities (strings): {priorities}\")\n",
    "\n",
    "assignees = extract_field(\n",
    "    batch_outputs,\n",
    "    \"assignee\",\n",
    "    min_confidence=0.75,\n",
    "    unique=True,\n",
    ")\n",
    "print(f\"\\nUnique assignees: {assignees}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Considerations\n",
    "\n",
    "### Error Handling\n",
    "\n",
    "```python\n",
    "def safe_extract(batch_outputs, field_name):\n",
    "    \"\"\"Extract with error handling and diagnostics.\"\"\"\n",
    "    try:\n",
    "        # Validate field exists\n",
    "        if not hasattr(Task, field_name):\n",
    "            raise ValueError(f\"Field '{field_name}' not found\")\n",
    "        \n",
    "        results = extract_field(batch_outputs, field_name)\n",
    "        \n",
    "        # Check pass rate\n",
    "        quality_count = len([o for o in batch_outputs if o.confidence and o.confidence >= 0.75])\n",
    "        pass_rate = quality_count / len(batch_outputs)\n",
    "        \n",
    "        if pass_rate < 0.5:\n",
    "            logger.warning(f\"Low pass rate: {pass_rate:.1%}\")\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Extraction failed: {e}\")\n",
    "        return []\n",
    "```\n",
    "\n",
    "### Performance\n",
    "\n",
    "- Field extraction: O(n) where n = total child models across batch\n",
    "- Deduplication: O(n) for hashable types\n",
    "- Total overhead: < 5% of extraction time\n",
    "\n",
    "**Benchmarks**:\n",
    "- 1,000 items: ~1-2ms (flatten + dropna)\n",
    "- 10,000 items: ~10-15ms\n",
    "- 100,000 items: ~100-150ms\n",
    "\n",
    "### Testing\n",
    "\n",
    "```python\n",
    "def test_extraction_empty_batch():\n",
    "    \"\"\"Test handling of empty batch.\"\"\"\n",
    "    results = extract_field([], 'title')\n",
    "    assert results == []\n",
    "\n",
    "def test_extraction_enum_values():\n",
    "    \"\"\"Test enum value extraction.\"\"\"\n",
    "    outputs = [TaskList(\n",
    "        source_document=\"test\",\n",
    "        tasks=[Task(title=\"t\", priority=Priority.HIGH)],\n",
    "        confidence=0.9\n",
    "    )]\n",
    "    results = extract_field(outputs, 'priority')\n",
    "    assert results == [\"high\"]  # String value, not enum\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations\n",
    "\n",
    "### Multi-Level Nesting\n",
    "\n",
    "```python\n",
    "# Extract from Report → Section → Finding → Evidence (3 levels)\n",
    "def extract_deep(reports: list[Report]) -> list[str]:\n",
    "    # Level 1: Extract sections\n",
    "    sections = to_list(\n",
    "        [r.sections for r in reports],\n",
    "        flatten=True, dropna=True,\n",
    "    )\n",
    "    \n",
    "    # Level 2: Extract findings\n",
    "    findings = to_list(\n",
    "        [s.findings for s in sections],\n",
    "        flatten=True, dropna=True,\n",
    "    )\n",
    "    \n",
    "    # Level 3: Extract evidence text\n",
    "    return [e.text for e in findings]\n",
    "```\n",
    "\n",
    "### Selective Fields (Multiple at Once)\n",
    "\n",
    "```python\n",
    "def extract_multiple(batch_outputs, fields: list[str]) -> dict[str, list]:\n",
    "    \"\"\"Extract multiple fields in single pass.\"\"\"\n",
    "    # Extract tasks once\n",
    "    all_tasks = to_list(\n",
    "        [o.tasks for o in batch_outputs],\n",
    "        flatten=True, dropna=True,\n",
    "    )\n",
    "    \n",
    "    # Extract all fields\n",
    "    results = {}\n",
    "    for field in fields:\n",
    "        values = [getattr(t, field, None) for t in all_tasks]\n",
    "        results[field] = to_list(values, flatten=True, dropna=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 3x faster for 3 fields (process once)\n",
    "data = extract_multiple(batch_outputs, ['title', 'priority', 'assignee'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What You Accomplished**:\n",
    "- ✅ Built field extractor for nested Pydantic LLM outputs\n",
    "- ✅ Implemented confidence-based quality filtering\n",
    "- ✅ Used `to_list()` for robust flatten/dropna/unique operations\n",
    "- ✅ Handled optional fields, enum values, and null removal\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. **Two-step extraction**: Extract child models first (with `to_list`), then access fields\n",
    "2. **Quality filtering upfront**: Filter by confidence before extraction\n",
    "3. **to_list() for cleaning**: Combines flatten/dropna/unique in single operation\n",
    "4. **Enum value extraction**: Use `.value` for serialization-ready primitives\n",
    "\n",
    "**When to Use**:\n",
    "- ✅ Processing batch LLM outputs with structured extraction\n",
    "- ✅ Building analytics pipelines needing flat field lists\n",
    "- ✅ Handling variable quality outputs (some complete, some partial)\n",
    "- ❌ Single-level flat models (use direct field access)\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "- [to_list API](../../docs/api/ln/to_list.md)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
