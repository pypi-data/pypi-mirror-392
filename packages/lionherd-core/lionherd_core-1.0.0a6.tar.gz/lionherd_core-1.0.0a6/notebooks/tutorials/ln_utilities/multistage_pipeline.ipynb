{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Multi-Stage Data Processing Pipeline\n",
    "\n",
    "**Category**: ln Utilities  \n",
    "**Difficulty**: Intermediate  \n",
    "**Time**: 15-20 minutes\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Real-world data processing often requires multiple transformation steps: parse raw input, validate and clean, transform values, and deduplicate results. Each stage has different requirements—some need to flatten nested data, others must filter nulls or remove duplicates.\n",
    "\n",
    "Traditional approaches chain list comprehensions or multiple map operations, resulting in verbose code with intermediate variables. Each stage requires manual null handling, flattening logic, and deduplication checks.\n",
    "\n",
    "**Why This Matters**:\n",
    "- **Clarity**: Pipeline intent obscured by implementation details (null checks, flattening loops)\n",
    "- **Efficiency**: Intermediate list allocations for each transformation stage\n",
    "- **Maintenance**: Scattered processing logic across multiple comprehensions\n",
    "\n",
    "**What You'll Build**:\n",
    "A 3-stage data cleaning pipeline using `lcall` that parses CSV data, validates/transforms values, and deduplicates results—using input/output flags for concise, declarative processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Prior Knowledge**:\n",
    "- Python lists and basic transformations\n",
    "- Understanding of map/filter operations\n",
    "- Familiarity with None handling\n",
    "\n",
    "**Required Packages**:\n",
    "```bash\n",
    "pip install lionherd-core  # >=0.1.0\n",
    "```\n",
    "\n",
    "**Optional Reading**:\n",
    "- [API Reference: lcall](../../docs/api/ln/list_call.md)\n",
    "- [Reference Notebook: to_list](../references/ln_to_list.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lionherd-core\n",
    "from lionherd_core.ln import lcall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Overview\n",
    "\n",
    "We'll build a data cleaning pipeline using chained `lcall` operations:\n",
    "\n",
    "1. **Stage 1 (Parse)**: Parse CSV strings, flatten nested results, remove nulls\n",
    "2. **Stage 2 (Transform)**: Apply transformations, filter nulls, deduplicate\n",
    "3. **Stage 3 (Format)**: Final formatting with output processing\n",
    "\n",
    "**Key lionherd-core Features**:\n",
    "- `lcall`: Apply function to each element with configurable input/output processing\n",
    "- `input_*` flags: Process data BEFORE function application (flatten, dropna, unique)\n",
    "- `output_*` flags: Process results AFTER function application\n",
    "\n",
    "**Flow**:\n",
    "```\n",
    "Raw CSV Strings → lcall(parse, output_flatten, output_dropna) → \n",
    "  Parsed Values → lcall(transform, input_dropna, input_unique) → \n",
    "    Transformed → lcall(format) → \n",
    "      Final Results\n",
    "```\n",
    "\n",
    "**Expected Outcome**: Clean, deduplicated data from messy CSV input using declarative processing flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Single Stage - Basic Transformation\n",
    "\n",
    "Start with a simple `lcall` operation: apply a function to each element in a list.\n",
    "\n",
    "**Key Concept**: `lcall` maps a function over elements—like `map()` but returns a list directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  ['hello', 'world', 'pipeline']\n",
      "Output: ['HELLO', 'WORLD', 'PIPELINE']\n",
      "\n",
      "Squares: [1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "# Simple transformation: convert strings to uppercase\n",
    "words = [\"hello\", \"world\", \"pipeline\"]\n",
    "\n",
    "result = lcall(words, str.upper)\n",
    "print(f\"Input:  {words}\")\n",
    "print(f\"Output: {result}\")\n",
    "# Output: ['HELLO', 'WORLD', 'PIPELINE']\n",
    "\n",
    "# With additional arguments\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "result = lcall(numbers, pow, 2)  # pow(x, 2) for each x\n",
    "print(f\"\\nSquares: {result}\")\n",
    "# Output: [1, 4, 9, 16, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Chaining Stages - Pipeline Composition\n",
    "\n",
    "Chain multiple `lcall` operations: output of first stage becomes input of second stage.\n",
    "\n",
    "**Key Concept**: Pass `lcall` result directly to next `lcall`—no intermediate variables needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After split: [['data', 'processing'], ['pipeline', 'example']]\n",
      "After uppercase (flattened): ['DATA', 'PROCESSING', 'PIPELINE', 'EXAMPLE']\n",
      "\n",
      "Chained result: ['DATA', 'PROCESSING', 'PIPELINE', 'EXAMPLE']\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: Split sentences into words\n",
    "sentences = [\"data processing\", \"pipeline example\"]\n",
    "\n",
    "# Stage 1: split each sentence\n",
    "stage1 = lcall(sentences, str.split)\n",
    "print(f\"After split: {stage1}\")\n",
    "# [['data', 'processing'], ['pipeline', 'example']]\n",
    "\n",
    "# Stage 2: flatten and uppercase each word\n",
    "# Need to flatten first to get individual words\n",
    "stage2 = lcall(stage1, str.upper, input_flatten=True)\n",
    "print(f\"After uppercase (flattened): {stage2}\")\n",
    "# ['DATA', 'PROCESSING', 'PIPELINE', 'EXAMPLE']\n",
    "\n",
    "# Or chain in one expression:\n",
    "result = lcall(lcall(sentences, str.split, output_flatten=True), str.upper)\n",
    "print(f\"\\nChained result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Input Processing Flags\n",
    "\n",
    "Use `input_*` flags to process data BEFORE applying the function.\n",
    "\n",
    "**Key Flags**:\n",
    "- `input_flatten`: Flatten nested structures before processing\n",
    "- `input_dropna`: Remove `None` values before processing\n",
    "- `input_unique`: Deduplicate inputs (requires flatten or dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[1, 2, None], [3, None, 4], [2, 5], None]\n",
      "Output: [10, 20, 30, 40, 50]\n"
     ]
    }
   ],
   "source": [
    "# Messy data with nesting and nulls\n",
    "messy_data = [\n",
    "    [1, 2, None],\n",
    "    [3, None, 4],\n",
    "    [2, 5],  # Note: 2 is duplicate\n",
    "    None,\n",
    "]\n",
    "\n",
    "# Without input processing - would need manual handling\n",
    "# With input processing - automatic cleanup\n",
    "result = lcall(\n",
    "    messy_data,\n",
    "    lambda x: x * 10,\n",
    "    input_flatten=True,  # Flatten [[1,2], [3,4]] → [1,2,3,4]\n",
    "    input_dropna=True,  # Remove None values\n",
    "    input_unique=True,  # Remove duplicates (requires flatten or dropna)\n",
    ")\n",
    "\n",
    "print(f\"Input:  {messy_data}\")\n",
    "print(f\"Output: {result}\")\n",
    "# Input processed: [1, 2, None, 3, None, 4, 2, 5, None]\n",
    "# After dropna:   [1, 2, 3, 4, 2, 5]\n",
    "# After unique:   [1, 2, 3, 4, 5]\n",
    "# After transform: [10, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Output Processing Flags\n",
    "\n",
    "Use `output_*` flags to process results AFTER applying the function.\n",
    "\n",
    "**Key Flags**:\n",
    "- `output_flatten`: Flatten nested results\n",
    "- `output_dropna`: Remove `None` from results\n",
    "- `output_unique`: Deduplicate results (requires flatten or dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without output flags: [1, [2, 1], None, 3, [4, 2], None, [6, 3]]\n",
      "With output flags:    [1, 2, 1, 3, 4, 2, 6, 3]\n"
     ]
    }
   ],
   "source": [
    "# Function that returns nested results or None\n",
    "def process_number(x):\n",
    "    if x == 0:\n",
    "        return None  # Invalid, will be filtered\n",
    "    if x % 2 == 0:\n",
    "        return [x, x // 2]  # Even: return [value, half]\n",
    "    return x  # Odd: return as-is\n",
    "\n",
    "\n",
    "numbers = [1, 2, 0, 3, 4, 0, 6]\n",
    "\n",
    "# Without output processing\n",
    "raw_result = lcall(numbers, process_number)\n",
    "print(f\"Without output flags: {raw_result}\")\n",
    "# [1, [2, 1], None, 3, [4, 2], None, [6, 3]]\n",
    "\n",
    "# With output processing\n",
    "clean_result = lcall(\n",
    "    numbers,\n",
    "    process_number,\n",
    "    output_flatten=True,  # Flatten nested lists\n",
    "    output_dropna=True,  # Remove None values\n",
    ")\n",
    "print(f\"With output flags:    {clean_result}\")\n",
    "# [1, 2, 1, 3, 4, 2, 6, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Complete 3-Stage Pipeline\n",
    "\n",
    "Combine everything: chain multiple `lcall` operations with different input/output flags for each stage.\n",
    "\n",
    "**Real-World Example**: Parse CSV data → validate/transform → deduplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 (Parse):     [1, 2, 3, 4, None, 5, 6, 7, 2, 8, 9]\n",
      "Stage 2 (Transform): [2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "Stage 3 (Format):    ['val_2', 'val_4', 'val_6', 'val_8', 'val_10', 'val_12', 'val_14', 'val_16', 'val_18']\n"
     ]
    }
   ],
   "source": [
    "# Messy CSV data from various sources\n",
    "raw_csv = [\n",
    "    \"1,2,3\",\n",
    "    \"4,,5\",  # Empty value (becomes None)\n",
    "    \"6,7\",\n",
    "    None,  # Invalid row\n",
    "    \"2,8,9\",  # Note: 2 is duplicate\n",
    "]\n",
    "\n",
    "\n",
    "# Stage 1: Parse CSV strings to integers\n",
    "def parse_csv(line):\n",
    "    \"\"\"Parse CSV line, return list of ints (None for empty values).\"\"\"\n",
    "    if line is None:\n",
    "        return None\n",
    "    return [int(x) if x else None for x in line.split(\",\")]\n",
    "\n",
    "\n",
    "stage1 = lcall(\n",
    "    raw_csv,\n",
    "    parse_csv,\n",
    "    input_dropna=True,  # Remove None rows before parsing\n",
    "    output_flatten=True,  # Flatten [[1,2,3], [4,None,5]] → [1,2,3,4,None,5]\n",
    ")\n",
    "print(f\"Stage 1 (Parse):     {stage1}\")\n",
    "# [1, 2, 3, 4, None, 5, 6, 7, 2, 8, 9]\n",
    "\n",
    "# Stage 2: Transform (double values), remove nulls and duplicates\n",
    "stage2 = lcall(\n",
    "    stage1,\n",
    "    lambda x: x * 2,\n",
    "    input_flatten=True,  # Required for input_unique\n",
    "    input_dropna=True,  # Remove None values before doubling\n",
    "    input_unique=True,  # Remove duplicates (2 appears twice)\n",
    ")\n",
    "print(f\"Stage 2 (Transform): {stage2}\")\n",
    "# Input after dropna+unique: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# After transform: [2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "\n",
    "# Stage 3: Format as strings with prefix\n",
    "stage3 = lcall(stage2, lambda x: f\"val_{x}\")\n",
    "print(f\"Stage 3 (Format):    {stage3}\")\n",
    "# ['val_2', 'val_4', 'val_6', 'val_8', 'val_10', 'val_12', 'val_14', 'val_16', 'val_18']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Working Example\n",
    "\n",
    "Here's a copy-paste ready 3-stage pipeline that handles real-world data cleaning.\n",
    "\n",
    "**Features**:\n",
    "- ✅ Parse CSV with error handling\n",
    "- ✅ Flatten nested results automatically\n",
    "- ✅ Remove nulls and duplicates declaratively\n",
    "- ✅ Transform and format in clear stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Results:\n",
      "  Raw input:   6 rows\n",
      "  After parse: 10 values\n",
      "  After valid: 9 values\n",
      "  Final:       ['$100.00', '$200.00', '$300.00', '$400.00', '$500.00', '$600.00', '$700.00', '$800.00', '$900.00']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Production-ready 3-stage data pipeline using lcall.\n",
    "\n",
    "Demonstrates: CSV parsing → validation/transform → formatting\n",
    "\"\"\"\n",
    "from lionherd_core.ln import lcall\n",
    "\n",
    "# Sample data: messy CSV from various sources\n",
    "raw_data = [\n",
    "    \"100,200,300\",\n",
    "    \"400,,500\",  # Missing value\n",
    "    \"600,700\",\n",
    "    None,  # Invalid row\n",
    "    \"200,800,900\",  # Duplicate: 200\n",
    "    \"\",  # Empty row\n",
    "]\n",
    "\n",
    "\n",
    "# Stage 1: Parse CSV lines\n",
    "def parse_csv_line(line):\n",
    "    \"\"\"Parse CSV, return ints (None for empty values).\"\"\"\n",
    "    if not line:\n",
    "        return None\n",
    "    return [int(x) if x else None for x in line.split(\",\")]\n",
    "\n",
    "\n",
    "parsed = lcall(\n",
    "    raw_data,\n",
    "    parse_csv_line,\n",
    "    input_dropna=True,  # Skip None/empty rows\n",
    "    output_flatten=True,  # Flatten nested lists\n",
    "    output_dropna=True,  # Remove None from parsed values\n",
    ")\n",
    "\n",
    "\n",
    "# Stage 2: Validate and transform\n",
    "def validate_and_transform(value):\n",
    "    \"\"\"Keep values >= 100, convert to float.\"\"\"\n",
    "    return float(value) if value >= 100 else None\n",
    "\n",
    "\n",
    "transformed = lcall(\n",
    "    parsed,\n",
    "    validate_and_transform,\n",
    "    output_flatten=True,  # Required for output_unique\n",
    "    output_dropna=True,  # Remove invalid values (< 100)\n",
    "    output_unique=True,  # Remove duplicates\n",
    ")\n",
    "\n",
    "\n",
    "# Stage 3: Format output\n",
    "def format_currency(value):\n",
    "    \"\"\"Format as currency string.\"\"\"\n",
    "    return f\"${value:,.2f}\"\n",
    "\n",
    "\n",
    "final = lcall(transformed, format_currency)\n",
    "\n",
    "print(\"Pipeline Results:\")\n",
    "print(f\"  Raw input:   {len(raw_data)} rows\")\n",
    "print(f\"  After parse: {len(parsed)} values\")\n",
    "print(f\"  After valid: {len(transformed)} values\")\n",
    "print(f\"  Final:       {final}\")\n",
    "# Final: ['$100.00', '$200.00', '$300.00', '$400.00', '$500.00', '$600.00', '$700.00', '$800.00', '$900.00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Considerations\n",
    "\n",
    "### When to Use Input vs Output Flags\n",
    "\n",
    "**Input Processing** (`input_*`):\n",
    "- Use when data needs normalization BEFORE function sees it\n",
    "- Example: Flatten nested API responses before validation\n",
    "- Benefit: Function doesn't need to handle nesting/nulls\n",
    "\n",
    "**Output Processing** (`output_*`):\n",
    "- Use when function produces nested/nullable results\n",
    "- Example: Function returns `[value, metadata]` pairs, need flat list\n",
    "- Benefit: Declarative result transformation\n",
    "\n",
    "### Performance\n",
    "\n",
    "- **Chaining overhead**: Each `lcall` creates intermediate list\n",
    "- **For large datasets (>10K items)**: Consider single-pass processing\n",
    "- **For small-medium (< 10K)**: Clarity > micro-optimization\n",
    "\n",
    "### Error Handling\n",
    "\n",
    "```python\n",
    "# Wrap stages in try/except for production\n",
    "try:\n",
    "    stage1 = lcall(data, parse, input_dropna=True)\n",
    "    stage2 = lcall(stage1, transform, output_dropna=True)\n",
    "except ValueError as e:\n",
    "    # Handle parsing errors\n",
    "    print(f\"Pipeline failed: {e}\")\n",
    "```\n",
    "\n",
    "### Testing\n",
    "\n",
    "Test each stage independently:\n",
    "\n",
    "```python\n",
    "def test_parse_stage():\n",
    "    result = lcall([\"1,2\", \"3,4\"], parse_csv_line, output_flatten=True)\n",
    "    assert result == [1, 2, 3, 4]\n",
    "\n",
    "def test_transform_stage():\n",
    "    result = lcall([1, None, 2], lambda x: x * 2, input_dropna=True)\n",
    "    assert result == [2, 4]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations\n",
    "\n",
    "### 1. Conditional Transformation\n",
    "\n",
    "Apply different logic based on input values:\n",
    "\n",
    "```python\n",
    "def conditional_transform(x):\n",
    "    if x < 100:\n",
    "        return None  # Filter out\n",
    "    elif x < 1000:\n",
    "        return [x, \"small\"]  # Tag as small\n",
    "    else:\n",
    "        return [x, \"large\"]  # Tag as large\n",
    "\n",
    "result = lcall(\n",
    "    [50, 200, 1500],\n",
    "    conditional_transform,\n",
    "    output_dropna=True,\n",
    "    output_flatten=True\n",
    ")\n",
    "# [200, 'small', 1500, 'large']\n",
    "```\n",
    "\n",
    "### 2. Parallel Processing with Shared Config\n",
    "\n",
    "Pass configuration to each function call:\n",
    "\n",
    "```python\n",
    "def scale(value, factor, offset=0):\n",
    "    return value * factor + offset\n",
    "\n",
    "result = lcall(\n",
    "    [1, 2, 3],\n",
    "    scale,\n",
    "    10,           # factor=10 passed to each call\n",
    "    offset=5      # offset=5 as kwarg\n",
    ")\n",
    "# [15, 25, 35]  (each value: x*10 + 5)\n",
    "```\n",
    "\n",
    "### 3. Enum Value Extraction\n",
    "\n",
    "Process enum values directly:\n",
    "\n",
    "```python\n",
    "from enum import Enum\n",
    "\n",
    "class Status(Enum):\n",
    "    ACTIVE = \"active\"\n",
    "    INACTIVE = \"inactive\"\n",
    "\n",
    "statuses = [Status.ACTIVE, Status.INACTIVE]\n",
    "result = lcall(\n",
    "    statuses,\n",
    "    str.upper,\n",
    "    input_use_values=True  # Extract .value before processing\n",
    ")\n",
    "# ['ACTIVE', 'INACTIVE']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What You Accomplished**:\n",
    "- ✅ Chained multiple `lcall` operations for multi-stage pipelines\n",
    "- ✅ Used `input_*` flags for pre-processing (flatten, dropna, unique)\n",
    "- ✅ Used `output_*` flags for post-processing results\n",
    "- ✅ Built production-ready CSV cleaning pipeline in ~30 lines\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. **Declarative processing**: Use flags instead of manual loops for flatten/filter/dedupe\n",
    "2. **Pipeline composition**: Chain `lcall` outputs as inputs for multi-stage transforms\n",
    "3. **Input vs Output flags**: Process data before function (`input_*`) or after (`output_*`)\n",
    "4. **Unique requires flatten/dropna**: Can't deduplicate without normalization\n",
    "\n",
    "**When to Use This Pattern**:\n",
    "- ✅ Multi-step data transformations (parse → validate → format)\n",
    "- ✅ Cleaning messy data with nesting and nulls\n",
    "- ✅ API response processing with nested/optional fields\n",
    "- ❌ Single-step transformations (use list comprehension)\n",
    "- ❌ Very large datasets needing streaming (use generators)\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**lionherd-core API Reference**:\n",
    "- [lcall](../../docs/api/ln/list_call.md) - Synchronous list processing with input/output flags\n",
    "- [to_list](../../docs/api/ln/to_list.md) - Underlying list conversion utility\n",
    "\n",
    "**Reference Notebooks**:\n",
    "- [to_list Patterns](../references/ln_to_list.ipynb) - Deep dive into flatten/dropna/unique\n",
    "\n",
    "**External Resources**:\n",
    "- [Python map() Documentation](https://docs.python.org/3/library/functions.html#map) - Built-in mapping alternative\n",
    "- [itertools Documentation](https://docs.python.org/3/library/itertools.html) - Standard library iteration tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
