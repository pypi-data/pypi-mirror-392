{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tutorial: Dynamic Schema Selection with Schema Dict Pattern\n",
    "\n",
    "**Category**: Schema Handlers  \n",
    "**Difficulty**: Intermediate  \n",
    "**Time**: 15-25 minutes\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "When building MCP servers or multi-tool systems, each tool requires its own schema for validation. Hardcoding validation logic for each tool creates maintenance burden and code duplication. You need a scalable pattern that routes tool invocations to the correct schema dynamically.\n",
    "\n",
    "Consider an MCP server with tools like `search()`, `create()`, and `update()`. Each has different parameter structures. Manual dispatch logic becomes unwieldy:\n",
    "\n",
    "```python\n",
    "# ❌ Manual dispatch - doesn't scale\n",
    "if tool == \"search\":\n",
    "    schema = SearchSchema\n",
    "elif tool == \"create\":\n",
    "    schema = CreateSchema\n",
    "elif tool == \"update\":\n",
    "    schema = UpdateSchema\n",
    "# ... 50 more tools\n",
    "```\n",
    "\n",
    "**Why This Matters**:\n",
    "- **Scalability**: Adding new tools shouldn't require modifying dispatch logic\n",
    "- **Type Safety**: Each tool's parameters should be validated against its specific schema\n",
    "- **Code Reuse**: Generic processing pipeline should work for all tools\n",
    "\n",
    "**What You'll Build**:\n",
    "A production-ready schema registry pattern using a simple dict mapping (`{tool_name: schema}`) that enables dynamic schema selection, parameter mapping, and validation for multi-tool systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Prior Knowledge**:\n",
    "- Python dictionaries and Pydantic models\n",
    "- Basic understanding of function call parsing\n",
    "- Familiarity with tool/API dispatch patterns\n",
    "\n",
    "**Required Packages**:\n",
    "```bash\n",
    "pip install lionherd-core  # >=0.1.0\n",
    "```\n",
    "\n",
    "**Optional Reading**:\n",
    "- [API Reference: function_call_parser](../../../docs/api/libs/schema_handlers/function_call_parser.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "\n",
    "# Third-party\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# lionherd-core - schema handlers\n",
    "from lionherd_core.libs.schema_handlers import (\n",
    "    map_positional_args,\n",
    "    nest_arguments_by_schema,\n",
    "    parse_function_call,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution-overview",
   "metadata": {},
   "source": [
    "## Solution Overview\n",
    "\n",
    "We'll implement a schema dict pattern for dynamic tool routing:\n",
    "\n",
    "1. **Define Tool Schemas**: Create Pydantic models for each tool's parameters\n",
    "2. **Build Schema Dict**: Map tool names to schemas (`{'search': SearchSchema}`)\n",
    "3. **Parse Function Calls**: Extract tool name and arguments from call syntax\n",
    "4. **Dynamic Selection**: Use tool name to select schema from dict\n",
    "5. **Process with Schema**: Map args, nest structure, validate\n",
    "\n",
    "**Key lionherd-core Components**:\n",
    "- `parse_function_call()`: Parses Python function syntax into tool + arguments\n",
    "- `map_positional_args()`: Maps positional args to parameter names\n",
    "- `nest_arguments_by_schema()`: Restructures flat args into nested format\n",
    "\n",
    "**Flow**:\n",
    "```\n",
    "Function Call String → Parse → Extract Tool Name → Select Schema → Map Args → Validate\n",
    "   search(\"AI\", 10)       ↓         \"search\"           SearchSchema    {query, limit}   ✓\n",
    "```\n",
    "\n",
    "**Expected Outcome**: A reusable pattern where adding a new tool only requires defining its schema and adding one entry to the schema dict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-title",
   "metadata": {},
   "source": [
    "### Step 1: Define Tool Schemas\n",
    "\n",
    "Start by defining Pydantic schemas for different tools. Each schema represents the expected parameters for that tool.\n",
    "\n",
    "**Why Separate Schemas**: Different tools have different parameter structures. `search()` needs `query` and `limit`, while `create()` needs `title` and `content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "step1-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 3 tool schemas:\n",
      "  SearchSchema: ['query', 'limit', 'category']\n",
      "  CreateSchema: ['title', 'content', 'tags']\n",
      "  UpdateSchema: ['item_id', 'title', 'content']\n"
     ]
    }
   ],
   "source": [
    "# Schema 1: Search tool\n",
    "class SearchSchema(BaseModel):\n",
    "    \"\"\"Schema for search tool - finds items matching query.\"\"\"\n",
    "\n",
    "    query: str = Field(description=\"Search query string\")\n",
    "    limit: int = Field(default=10, description=\"Maximum results to return\")\n",
    "    category: str | None = Field(default=None, description=\"Filter by category\")\n",
    "\n",
    "\n",
    "# Schema 2: Create tool\n",
    "class CreateSchema(BaseModel):\n",
    "    \"\"\"Schema for create tool - creates new items.\"\"\"\n",
    "\n",
    "    title: str = Field(description=\"Item title\")\n",
    "    content: str = Field(description=\"Item content/body\")\n",
    "    tags: list[str] = Field(default_factory=list, description=\"Item tags\")\n",
    "\n",
    "\n",
    "# Schema 3: Update tool\n",
    "class UpdateSchema(BaseModel):\n",
    "    \"\"\"Schema for update tool - updates existing items.\"\"\"\n",
    "\n",
    "    item_id: str = Field(description=\"ID of item to update\")\n",
    "    title: str | None = Field(default=None, description=\"New title\")\n",
    "    content: str | None = Field(default=None, description=\"New content\")\n",
    "\n",
    "\n",
    "print(\"Defined 3 tool schemas:\")\n",
    "print(f\"  SearchSchema: {list(SearchSchema.model_fields.keys())}\")\n",
    "print(f\"  CreateSchema: {list(CreateSchema.model_fields.keys())}\")\n",
    "print(f\"  UpdateSchema: {list(UpdateSchema.model_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-notes",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- **Field descriptions**: Help with auto-generated documentation and LLM prompting\n",
    "- **Optional fields**: Use `| None` with defaults for parameters that aren't always required\n",
    "- **Validation**: Pydantic automatically validates types, constraints, and provides error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-title",
   "metadata": {},
   "source": [
    "### Step 2: Create Schema Dict (Registry)\n",
    "\n",
    "The core pattern: a simple dictionary mapping tool names to their schemas. This is your \"schema registry\" - simple yet powerful.\n",
    "\n",
    "**Pattern**: `{tool_name: schema_class}` enables dynamic schema lookup in O(1) time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "step2-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema Registry:\n",
      "  'search' → SearchSchema (3 fields)\n",
      "  'create' → CreateSchema (3 fields)\n",
      "  'update' → UpdateSchema (3 fields)\n",
      "\n",
      "Adding a new tool:\n",
      "  1. Define schema (e.g., DeleteSchema)\n",
      "  2. Add to dict: TOOL_SCHEMAS['delete'] = DeleteSchema\n",
      "  3. Add params: TOOL_PARAM_NAMES['delete'] = ['item_id']\n",
      "  4. Done! Generic processing handles the rest.\n"
     ]
    }
   ],
   "source": [
    "# Schema registry - the core pattern\n",
    "TOOL_SCHEMAS = {\n",
    "    \"search\": SearchSchema,\n",
    "    \"create\": CreateSchema,\n",
    "    \"update\": UpdateSchema,\n",
    "}\n",
    "\n",
    "# Also store parameter order for each tool (used for positional arg mapping)\n",
    "TOOL_PARAM_NAMES = {\n",
    "    \"search\": [\"query\", \"limit\", \"category\"],\n",
    "    \"create\": [\"title\", \"content\", \"tags\"],\n",
    "    \"update\": [\"item_id\", \"title\", \"content\"],\n",
    "}\n",
    "\n",
    "print(\"Schema Registry:\")\n",
    "for tool_name, schema_cls in TOOL_SCHEMAS.items():\n",
    "    param_count = len(schema_cls.model_fields)\n",
    "    print(f\"  '{tool_name}' → {schema_cls.__name__} ({param_count} fields)\")\n",
    "\n",
    "print(\"\\nAdding a new tool:\")\n",
    "print(\"  1. Define schema (e.g., DeleteSchema)\")\n",
    "print(\"  2. Add to dict: TOOL_SCHEMAS['delete'] = DeleteSchema\")\n",
    "print(\"  3. Add params: TOOL_PARAM_NAMES['delete'] = ['item_id']\")\n",
    "print(\"  4. Done! Generic processing handles the rest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-notes",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- **Scalability**: Adding 100 tools is just 100 dict entries - no logic changes\n",
    "- **Type safety**: Each tool gets validated against its specific schema\n",
    "- **Parameter names**: Needed for mapping positional args (e.g., `search(\"AI\")` → `{query: \"AI\"}`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-title",
   "metadata": {},
   "source": [
    "### Step 3: Parse Function Calls\n",
    "\n",
    "Function calls come in as strings (from LLMs, user input, config files). Parse them to extract the tool name and arguments.\n",
    "\n",
    "**Parsing**: Converts `search(\"AI news\", 10)` → `{tool: \"search\", arguments: {_pos_0: \"AI news\", _pos_1: 10}}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "step3-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing function calls:\n",
      "\n",
      "Input:  search(\"AI trends\", 20)\n",
      "Tool:   search\n",
      "Args:   {'_pos_0': 'AI trends', '_pos_1': 20}\n",
      "\n",
      "Input:  create(\"My Title\", \"Content here\", tags=[\"ai\", \"ml\"])\n",
      "Tool:   create\n",
      "Args:   {'_pos_0': 'My Title', '_pos_1': 'Content here', 'tags': ['ai', 'ml']}\n",
      "\n",
      "Input:  update(item_id=\"123\", title=\"New Title\")\n",
      "Tool:   update\n",
      "Args:   {'item_id': '123', 'title': 'New Title'}\n",
      "\n",
      "Note: Positional args are labeled _pos_0, _pos_1, etc.\n",
      "      These will be mapped to actual param names next.\n"
     ]
    }
   ],
   "source": [
    "# Example function call strings (from LLM, user, config)\n",
    "call_examples = [\n",
    "    'search(\"AI trends\", 20)',  # Positional args\n",
    "    'create(\"My Title\", \"Content here\", tags=[\"ai\", \"ml\"])',  # Mixed\n",
    "    'update(item_id=\"123\", title=\"New Title\")',  # Keyword args\n",
    "]\n",
    "\n",
    "print(\"Parsing function calls:\\n\")\n",
    "for call_str in call_examples:\n",
    "    # Parse the call\n",
    "    parsed = parse_function_call(call_str)\n",
    "\n",
    "    print(f\"Input:  {call_str}\")\n",
    "    print(f\"Tool:   {parsed['tool']}\")\n",
    "    print(f\"Args:   {parsed['arguments']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Note: Positional args are labeled _pos_0, _pos_1, etc.\")\n",
    "print(\"      These will be mapped to actual param names next.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-notes",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- **Positional args**: Labeled `_pos_0`, `_pos_1` because we don't know parameter names yet\n",
    "- **Keyword args**: Already have correct names, kept as-is\n",
    "- **Complex types**: Lists, dicts, nested structures are parsed automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-title",
   "metadata": {},
   "source": [
    "### Step 4: Dynamic Schema Selection and Processing\n",
    "\n",
    "Now use the tool name to select the correct schema from the registry and process the arguments.\n",
    "\n",
    "**Pattern**: `schema = TOOL_SCHEMAS[tool_name]` → map args → validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "step4-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tool calls with dynamic schema selection:\n",
      "\n",
      "Call:   search(\"AI trends\", 20)\n",
      "Schema: SearchSchema\n",
      "Valid:  query='AI trends' limit=20 category=None\n",
      "\n",
      "Call:   create(\"Tutorial\", \"Content about schemas\")\n",
      "Schema: CreateSchema\n",
      "Valid:  title='Tutorial' content='Content about schemas' tags=[]\n",
      "\n",
      "Call:   update(\"item-123\", title=\"Updated Title\")\n",
      "Schema: UpdateSchema\n",
      "Valid:  item_id='item-123' title='Updated Title' content=None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_tool_call(call_str: str) -> BaseModel:\n",
    "    \"\"\"Process function call with dynamic schema selection.\"\"\"\n",
    "    # Step 1: Parse call → get tool name and arguments\n",
    "    parsed = parse_function_call(call_str)\n",
    "    tool_name = parsed[\"tool\"]\n",
    "    arguments = parsed[\"arguments\"]\n",
    "\n",
    "    # Step 2: Select schema from registry\n",
    "    if tool_name not in TOOL_SCHEMAS:\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "\n",
    "    schema_cls = TOOL_SCHEMAS[tool_name]\n",
    "    param_names = TOOL_PARAM_NAMES[tool_name]\n",
    "\n",
    "    # Step 3: Map positional args to parameter names\n",
    "    mapped_args = map_positional_args(arguments, param_names)\n",
    "\n",
    "    # Step 4: Nest arguments by schema structure (if needed)\n",
    "    nested_args = nest_arguments_by_schema(mapped_args, schema_cls)\n",
    "\n",
    "    # Step 5: Validate with schema\n",
    "    validated = schema_cls(**nested_args)\n",
    "\n",
    "    return validated\n",
    "\n",
    "\n",
    "# Test with different tools\n",
    "print(\"Processing tool calls with dynamic schema selection:\\n\")\n",
    "\n",
    "test_calls = [\n",
    "    'search(\"AI trends\", 20)',\n",
    "    'create(\"Tutorial\", \"Content about schemas\")',\n",
    "    'update(\"item-123\", title=\"Updated Title\")',\n",
    "]\n",
    "\n",
    "for call_str in test_calls:\n",
    "    result = process_tool_call(call_str)\n",
    "    print(f\"Call:   {call_str}\")\n",
    "    print(f\"Schema: {type(result).__name__}\")\n",
    "    print(f\"Valid:  {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-notes",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- **Generic processing**: Same code handles all tools - no tool-specific logic\n",
    "- **Type safety**: Each result is properly typed (SearchSchema, CreateSchema, etc.)\n",
    "- **Validation**: Pydantic ensures all required fields present and types correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-title",
   "metadata": {},
   "source": [
    "### Step 5: Nested Schema Handling\n",
    "\n",
    "For complex tools with nested structures (e.g., filters, metadata), the nesting function automatically restructures flat arguments.\n",
    "\n",
    "**Pattern**: Flat args → detect nested fields in schema → restructure automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "step5-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat call: advanced_search(\"AI\", 15, \"2024-01-01\", \"2024-12-31\", \"tech\")\n",
      "\n",
      "Step 1 - Parsed (positional):\n",
      "  {'_pos_0': 'AI', '_pos_1': 15, '_pos_2': '2024-01-01', '_pos_3': '2024-12-31', '_pos_4': 'tech'}\n",
      "\n",
      "Step 2 - Mapped to param names:\n",
      "  {'query': 'AI', 'limit': 15, 'date_from': '2024-01-01', 'date_to': '2024-12-31', 'category': 'tech'}\n",
      "\n",
      "Step 3 - Nested by schema:\n",
      "  {'query': 'AI', 'limit': 15, 'filters': {'date_from': '2024-01-01', 'date_to': '2024-12-31', 'category': 'tech'}}\n",
      "\n",
      "Step 4 - Validated:\n",
      "  query='AI' limit=15 filters=FilterOptions(date_from='2024-01-01', date_to='2024-12-31', category='tech')\n",
      "  Filters: date_from='2024-01-01' date_to='2024-12-31' category='tech'\n"
     ]
    }
   ],
   "source": [
    "# Define a tool with nested structure\n",
    "class FilterOptions(BaseModel):\n",
    "    \"\"\"Filter options for advanced search.\"\"\"\n",
    "\n",
    "    date_from: str | None = None\n",
    "    date_to: str | None = None\n",
    "    category: str | None = None\n",
    "\n",
    "\n",
    "class AdvancedSearchSchema(BaseModel):\n",
    "    \"\"\"Advanced search with nested filter options.\"\"\"\n",
    "\n",
    "    query: str\n",
    "    limit: int = 10\n",
    "    filters: FilterOptions  # Nested structure\n",
    "\n",
    "\n",
    "# Add to registry\n",
    "TOOL_SCHEMAS[\"advanced_search\"] = AdvancedSearchSchema\n",
    "TOOL_PARAM_NAMES[\"advanced_search\"] = [\"query\", \"limit\", \"date_from\", \"date_to\", \"category\"]\n",
    "\n",
    "# Call with flat arguments\n",
    "flat_call = 'advanced_search(\"AI\", 15, \"2024-01-01\", \"2024-12-31\", \"tech\")'\n",
    "print(f\"Flat call: {flat_call}\\n\")\n",
    "\n",
    "# Parse and show argument transformation\n",
    "parsed = parse_function_call(flat_call)\n",
    "print(\"Step 1 - Parsed (positional):\")\n",
    "print(f\"  {parsed['arguments']}\\n\")\n",
    "\n",
    "mapped = map_positional_args(parsed[\"arguments\"], TOOL_PARAM_NAMES[\"advanced_search\"])\n",
    "print(\"Step 2 - Mapped to param names:\")\n",
    "print(f\"  {mapped}\\n\")\n",
    "\n",
    "nested = nest_arguments_by_schema(mapped, AdvancedSearchSchema)\n",
    "print(\"Step 3 - Nested by schema:\")\n",
    "print(f\"  {nested}\\n\")\n",
    "\n",
    "validated = AdvancedSearchSchema(**nested)\n",
    "print(\"Step 4 - Validated:\")\n",
    "print(f\"  {validated}\")\n",
    "print(f\"  Filters: {validated.filters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-notes",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- **Automatic nesting**: `date_from`, `date_to`, `category` automatically grouped under `filters`\n",
    "- **Schema detection**: Nesting logic inspects schema structure to determine grouping\n",
    "- **Flat call syntax**: Users can call with flat args, system handles nesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-example",
   "metadata": {},
   "source": [
    "## Complete Working Example\n",
    "\n",
    "Here's a production-ready implementation showing the schema dict pattern in a complete 30-line snippet. This is copy-paste ready for your MCP server or multi-tool system.\n",
    "\n",
    "**Features**:\n",
    "- ✅ Schema dict registry for dynamic selection\n",
    "- ✅ Generic processing pipeline\n",
    "- ✅ Handles positional and keyword args\n",
    "- ✅ Automatic nested structure handling\n",
    "- ✅ Type-safe validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complete-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search result: query='AI trends' limit=20\n",
      "Create result: title='My Post' content='Content here'\n",
      "\n",
      "✅ Complete pattern in ~30 lines!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Production-ready schema dict pattern for dynamic tool routing.\n",
    "Copy this cell for a complete working system.\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from lionherd_core.libs.schema_handlers import (\n",
    "    map_positional_args,\n",
    "    nest_arguments_by_schema,\n",
    "    parse_function_call,\n",
    ")\n",
    "\n",
    "\n",
    "# Define tool schemas\n",
    "class SearchSchema(BaseModel):\n",
    "    query: str\n",
    "    limit: int = 10\n",
    "\n",
    "\n",
    "class CreateSchema(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "# Schema registry - the core pattern\n",
    "SCHEMAS = {\"search\": SearchSchema, \"create\": CreateSchema}\n",
    "PARAMS = {\"search\": [\"query\", \"limit\"], \"create\": [\"title\", \"content\"]}\n",
    "\n",
    "\n",
    "def process_call(call_str: str) -> BaseModel:\n",
    "    \"\"\"Process any tool call with dynamic schema selection.\"\"\"\n",
    "    parsed = parse_function_call(call_str)\n",
    "    tool = parsed[\"tool\"]\n",
    "\n",
    "    # Dynamic schema selection\n",
    "    schema = SCHEMAS[tool]\n",
    "    params = PARAMS[tool]\n",
    "\n",
    "    # Process arguments\n",
    "    args = map_positional_args(parsed[\"arguments\"], params)\n",
    "    args = nest_arguments_by_schema(args, schema)\n",
    "\n",
    "    return schema(**args)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result1 = process_call('search(\"AI trends\", 20)')\n",
    "result2 = process_call('create(\"My Post\", \"Content here\")')\n",
    "\n",
    "print(f\"Search result: {result1}\")\n",
    "print(f\"Create result: {result2}\")\n",
    "\n",
    "print(\"\\n✅ Complete pattern in ~30 lines!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908f69e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "production-considerations",
   "metadata": {},
   "source": [
    "## Production Considerations\n",
    "\n",
    "### Error Handling\n",
    "\n",
    "**What Can Go Wrong**:\n",
    "1. **Unknown tool**: User calls a tool not in registry\n",
    "2. **Validation errors**: Arguments don't match schema (wrong types, missing required fields)\n",
    "3. **Parse errors**: Malformed function call syntax\n",
    "4. **Too many positional args**: More positional args than parameters\n",
    "\n",
    "**Handling**:\n",
    "```python\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def safe_process_call(call_str: str) -> tuple[bool, BaseModel | str]:\n",
    "    \"\"\"Process call with comprehensive error handling.\"\"\"\n",
    "    try:\n",
    "        # Parse\n",
    "        parsed = parse_function_call(call_str)\n",
    "        tool = parsed[\"tool\"]\n",
    "        \n",
    "        # Check if tool exists\n",
    "        if tool not in TOOL_SCHEMAS:\n",
    "            return (False, f\"Unknown tool: {tool}. Available: {list(TOOL_SCHEMAS.keys())}\")\n",
    "        \n",
    "        # Process\n",
    "        schema = TOOL_SCHEMAS[tool]\n",
    "        params = TOOL_PARAM_NAMES[tool]\n",
    "        args = map_positional_args(parsed[\"arguments\"], params)\n",
    "        args = nest_arguments_by_schema(args, schema)\n",
    "        \n",
    "        # Validate\n",
    "        result = schema(**args)\n",
    "        return (True, result)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        # Parse errors or positional arg errors\n",
    "        return (False, f\"Parse error: {e}\")\n",
    "    except ValidationError as e:\n",
    "        # Pydantic validation errors\n",
    "        return (False, f\"Validation error: {e}\")\n",
    "    except Exception as e:\n",
    "        # Unexpected errors\n",
    "        return (False, f\"Unexpected error: {e}\")\n",
    "```\n",
    "\n",
    "### Performance\n",
    "\n",
    "**Scalability**:\n",
    "- **Registry lookup**: O(1) dict lookup per tool call\n",
    "- **Parsing**: O(n) where n = argument count (typically < 20)\n",
    "- **Validation**: O(n) field validation\n",
    "- **Total overhead**: < 1ms per call for typical tools\n",
    "\n",
    "**Benchmarks** (approximate, 5 parameters):\n",
    "- Parse function call: ~0.1-0.3ms\n",
    "- Map positional args: ~0.05ms\n",
    "- Nest arguments: ~0.1ms\n",
    "- Pydantic validation: ~0.2-0.5ms\n",
    "- **Total**: ~0.5-1.0ms per tool call\n",
    "\n",
    "**Optimization**:\n",
    "```python\n",
    "# Cache parameter names if calling same tool repeatedly\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def get_param_names(tool: str) -> list[str]:\n",
    "    \"\"\"Cached parameter name lookup.\"\"\"\n",
    "    return TOOL_PARAM_NAMES[tool]\n",
    "```\n",
    "\n",
    "### Testing\n",
    "\n",
    "**Unit Tests**:\n",
    "```python\n",
    "def test_schema_registry_lookup():\n",
    "    \"\"\"Test that all registered tools have schemas.\"\"\"\n",
    "    for tool in TOOL_SCHEMAS:\n",
    "        assert tool in TOOL_PARAM_NAMES\n",
    "        assert len(TOOL_PARAM_NAMES[tool]) > 0\n",
    "\n",
    "def test_dynamic_selection():\n",
    "    \"\"\"Test dynamic schema selection.\"\"\"\n",
    "    result = process_call('search(\"test\", 5)')\n",
    "    assert isinstance(result, SearchSchema)\n",
    "    assert result.query == \"test\"\n",
    "    assert result.limit == 5\n",
    "\n",
    "def test_validation_errors():\n",
    "    \"\"\"Test that validation errors are caught.\"\"\"\n",
    "    success, _ = safe_process_call('search()')\n",
    "    assert not success  # Missing required 'query' field\n",
    "```\n",
    "\n",
    "**Integration Tests**:\n",
    "- Test all registered tools have valid schemas\n",
    "- Test parameter count matches schema field count\n",
    "- Test nested schema handling for complex tools\n",
    "- Test error messages are helpful for debugging\n",
    "\n",
    "### Monitoring\n",
    "\n",
    "**Key Metrics**:\n",
    "- **Tool usage**: Track which tools are called most (optimize hot paths)\n",
    "- **Validation failures**: % of calls that fail validation (indicates schema issues or user errors)\n",
    "- **Unknown tools**: Track attempts to call unregistered tools (indicates missing features)\n",
    "\n",
    "**Observability**:\n",
    "```python\n",
    "import time\n",
    "\n",
    "def process_call_with_metrics(call_str: str) -> BaseModel:\n",
    "    \"\"\"Process call with metric emission.\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    try:\n",
    "        parsed = parse_function_call(call_str)\n",
    "        tool = parsed[\"tool\"]\n",
    "        \n",
    "        # Emit tool usage metric\n",
    "        metrics.increment(f\"tool.call.{tool}\")\n",
    "        \n",
    "        result = process_call(call_str)\n",
    "        \n",
    "        metrics.increment(f\"tool.success.{tool}\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        metrics.increment(f\"tool.error.{tool}\")\n",
    "        raise\n",
    "    finally:\n",
    "        duration = time.time() - start\n",
    "        metrics.timing(\"tool.duration\", duration)\n",
    "```\n",
    "\n",
    "### Configuration Management\n",
    "\n",
    "**Registry Organization**:\n",
    "```python\n",
    "# For large systems, organize by category\n",
    "SEARCH_TOOLS = {\"search\": SearchSchema, \"advanced_search\": AdvancedSearchSchema}\n",
    "CRUD_TOOLS = {\"create\": CreateSchema, \"update\": UpdateSchema, \"delete\": DeleteSchema}\n",
    "ADMIN_TOOLS = {\"backup\": BackupSchema, \"restore\": RestoreSchema}\n",
    "\n",
    "# Combine into main registry\n",
    "TOOL_SCHEMAS = {**SEARCH_TOOLS, **CRUD_TOOLS, **ADMIN_TOOLS}\n",
    "```\n",
    "\n",
    "**Schema Versioning**:\n",
    "```python\n",
    "# Version schemas for backward compatibility\n",
    "TOOL_SCHEMAS = {\n",
    "    \"search\": SearchSchemaV2,  # Current version\n",
    "    \"search_v1\": SearchSchemaV1,  # Legacy support\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variations",
   "metadata": {},
   "source": [
    "## Variations\n",
    "\n",
    "### 1. Class-Based Registry\n",
    "\n",
    "**When to Use**: Large systems with many tools, need validation and tooling support\n",
    "\n",
    "**Approach**:\n",
    "```python\n",
    "class ToolRegistry:\n",
    "    \"\"\"Type-safe tool registry with validation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._schemas: dict[str, type[BaseModel]] = {}\n",
    "        self._params: dict[str, list[str]] = {}\n",
    "    \n",
    "    def register(self, name: str, schema: type[BaseModel], params: list[str]):\n",
    "        \"\"\"Register a tool with validation.\"\"\"\n",
    "        # Validate param count matches schema fields\n",
    "        if len(params) != len(schema.model_fields):\n",
    "            raise ValueError(f\"Param count mismatch for {name}\")\n",
    "        \n",
    "        self._schemas[name] = schema\n",
    "        self._params[name] = params\n",
    "    \n",
    "    def process(self, call_str: str) -> BaseModel:\n",
    "        \"\"\"Process call using registered schemas.\"\"\"\n",
    "        parsed = parse_function_call(call_str)\n",
    "        tool = parsed[\"tool\"]\n",
    "        \n",
    "        if tool not in self._schemas:\n",
    "            raise ValueError(f\"Unregistered tool: {tool}\")\n",
    "        \n",
    "        schema = self._schemas[tool]\n",
    "        params = self._params[tool]\n",
    "        \n",
    "        args = map_positional_args(parsed[\"arguments\"], params)\n",
    "        args = nest_arguments_by_schema(args, schema)\n",
    "        \n",
    "        return schema(**args)\n",
    "\n",
    "# Usage\n",
    "registry = ToolRegistry()\n",
    "registry.register(\"search\", SearchSchema, [\"query\", \"limit\"])\n",
    "registry.register(\"create\", CreateSchema, [\"title\", \"content\"])\n",
    "\n",
    "result = registry.process('search(\"AI\", 10)')\n",
    "```\n",
    "\n",
    "**Trade-offs**:\n",
    "- ✅ Type safety and validation at registration time\n",
    "- ✅ Encapsulation and better tooling support\n",
    "- ✅ Easier testing (mock registry)\n",
    "- ❌ More boilerplate than simple dict\n",
    "- ❌ Slightly more complex for small systems\n",
    "\n",
    "### 2. Auto-Generate Param Names from Schema\n",
    "\n",
    "**When to Use**: Want to avoid manually maintaining TOOL_PARAM_NAMES\n",
    "\n",
    "**Approach**:\n",
    "```python\n",
    "def get_param_names(schema: type[BaseModel]) -> list[str]:\n",
    "    \"\"\"Extract parameter names from schema field order.\"\"\"\n",
    "    return list(schema.model_fields.keys())\n",
    "\n",
    "# Simplified registry - only schemas needed\n",
    "TOOL_SCHEMAS = {\"search\": SearchSchema, \"create\": CreateSchema}\n",
    "\n",
    "def process_call(call_str: str) -> BaseModel:\n",
    "    parsed = parse_function_call(call_str)\n",
    "    tool = parsed[\"tool\"]\n",
    "    schema = TOOL_SCHEMAS[tool]\n",
    "    \n",
    "    # Auto-generate param names\n",
    "    params = get_param_names(schema)\n",
    "    \n",
    "    args = map_positional_args(parsed[\"arguments\"], params)\n",
    "    args = nest_arguments_by_schema(args, schema)\n",
    "    return schema(**args)\n",
    "```\n",
    "\n",
    "**Trade-offs**:\n",
    "- ✅ Less maintenance (single source of truth)\n",
    "- ✅ Impossible for param names to get out of sync\n",
    "- ❌ Relies on Python 3.7+ dict ordering guarantee\n",
    "- ❌ Can't customize param order (must match schema field order)\n",
    "\n",
    "### 3. Decorator-Based Registration\n",
    "\n",
    "**When to Use**: Want declarative, Django/Flask-style tool registration\n",
    "\n",
    "**Approach**:\n",
    "```python\n",
    "TOOL_REGISTRY = {}\n",
    "\n",
    "def tool(name: str, params: list[str]):\n",
    "    \"\"\"Decorator to register tool schema.\"\"\"\n",
    "    def decorator(schema_cls: type[BaseModel]):\n",
    "        TOOL_REGISTRY[name] = {\"schema\": schema_cls, \"params\": params}\n",
    "        return schema_cls\n",
    "    return decorator\n",
    "\n",
    "# Declarative registration\n",
    "@tool(\"search\", [\"query\", \"limit\"])\n",
    "class SearchSchema(BaseModel):\n",
    "    query: str\n",
    "    limit: int = 10\n",
    "\n",
    "@tool(\"create\", [\"title\", \"content\"])\n",
    "class CreateSchema(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "\n",
    "# Process using registry\n",
    "def process_call(call_str: str) -> BaseModel:\n",
    "    parsed = parse_function_call(call_str)\n",
    "    tool = parsed[\"tool\"]\n",
    "    \n",
    "    tool_info = TOOL_REGISTRY[tool]\n",
    "    schema = tool_info[\"schema\"]\n",
    "    params = tool_info[\"params\"]\n",
    "    \n",
    "    args = map_positional_args(parsed[\"arguments\"], params)\n",
    "    args = nest_arguments_by_schema(args, schema)\n",
    "    return schema(**args)\n",
    "```\n",
    "\n",
    "**Trade-offs**:\n",
    "- ✅ Clean, declarative syntax\n",
    "- ✅ Schema definition and registration in one place\n",
    "- ❌ Magic (less explicit than dict)\n",
    "- ❌ Harder to see full registry at a glance\n",
    "\n",
    "## Choosing the Right Variation\n",
    "\n",
    "| Scenario | Recommended Variation |\n",
    "|----------|----------------------|\n",
    "| < 10 tools, simple system | Base implementation (dict) |\n",
    "| 10-50 tools, need validation | Class-Based Registry |\n",
    "| Want minimal maintenance | Auto-Generate Param Names |\n",
    "| Large codebase, want declarative style | Decorator-Based Registration |\n",
    "| MCP server (production) | Class-Based Registry + Auto-Generate |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What You Accomplished**:\n",
    "- ✅ Built a schema dict registry for dynamic tool routing\n",
    "- ✅ Implemented generic processing pipeline that works for any tool\n",
    "- ✅ Handled positional args, keyword args, and nested structures\n",
    "- ✅ Created a 30-line production-ready pattern\n",
    "- ✅ Learned error handling, testing, and monitoring strategies\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. **Schema dict is the core pattern**: `{tool_name: schema}` enables O(1) dynamic selection\n",
    "2. **Generic processing scales**: Same code handles 5 tools or 500 tools\n",
    "3. **Positional arg mapping**: Requires parameter name list per tool\n",
    "4. **Nested structures are automatic**: `nest_arguments_by_schema()` detects and restructures\n",
    "5. **Adding tools is trivial**: Define schema + add dict entry = done\n",
    "\n",
    "**When to Use This Pattern**:\n",
    "- ✅ Building MCP servers with multiple tools\n",
    "- ✅ Multi-tool API dispatchers\n",
    "- ✅ LLM function calling systems\n",
    "- ✅ Config-driven command processors\n",
    "- ✅ Any system where tools are added/removed frequently\n",
    "- ❌ Single-tool systems (overkill - use schema directly)\n",
    "- ❌ Fixed tool set that never changes (consider hardcoded dispatch)\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**lionherd-core API Reference**:\n",
    "- [function_call_parser](../../../docs/api/libs/schema_handlers/function_call_parser.md) - Complete API documentation\n",
    "\n",
    "**Reference Notebooks**:\n",
    "- [Schema Handlers Patterns](../references/schema_handlers.ipynb) - Additional schema handling techniques\n",
    "\n",
    "**Related Tutorials**:\n",
    "- [Fuzzy Validation](../ln_utilities/fuzzy_validation.ipynb) - Handle schema field name variations\n",
    "\n",
    "**External Resources**:\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/) - Schema validation and models\n",
    "- [MCP Specification](https://spec.modelcontextprotocol.io/) - Model Context Protocol for tool servers\n",
    "- [Python AST Module](https://docs.python.org/3/library/ast.html) - Abstract syntax tree parsing (used by parser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
