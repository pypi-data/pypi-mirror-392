{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Service Lifecycle Management with TaskGroups\n",
    "\n",
    "**Category**: Concurrency\n",
    "**Difficulty**: Advanced\n",
    "**Time**: 25-35 minutes\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Building production services often requires coordinating multiple components with complex dependencies. Consider an HTTP API service that needs:\n",
    "\n",
    "- A database connection pool that must be ready before anything else\n",
    "- A cache layer that depends on the database\n",
    "- An HTTP server that depends on both database and cache\n",
    "- Background workers processing tasks from a queue\n",
    "- A health monitoring system that checks all components\n",
    "\n",
    "The challenge isn't just running these concurrently - it's managing their lifecycle: **initialization order**, **readiness signaling**, **health monitoring**, and **graceful shutdown**. If the database takes 2 seconds to connect, the API shouldn't start serving requests. If a component fails health checks, the service should shut down cleanly.\n",
    "\n",
    "Traditional approaches like spawning independent tasks lead to race conditions: the API starts before the database is ready, health checks run before components initialize, or shutdown leaves orphaned background workers.\n",
    "\n",
    "**Why This Matters**:\n",
    "- **Correctness**: Components accessing uninitialized dependencies cause crashes or data corruption\n",
    "- **Observability**: Without coordinated health checks, you can't tell if the service is actually ready\n",
    "- **Reliability**: Uncoordinated shutdown leaves connections open, jobs incomplete, or resources leaked\n",
    "\n",
    "**What You'll Build**:\n",
    "A production-ready service manager using lionherd-core's `create_task_group()`, `task_status.started()`, and Event coordination that manages multi-component initialization, dependency ordering, health monitoring, and graceful shutdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Prior Knowledge**:\n",
    "- Python async/await fundamentals (asyncio basics)\n",
    "- Understanding of context managers (async with)\n",
    "- Structured concurrency concepts (task groups, cancellation)\n",
    "\n",
    "**Required Packages**:\n",
    "```bash\n",
    "pip install lionherd-core  # >=1.0.0a3\n",
    "```\n",
    "\n",
    "**Optional Reading**:\n",
    "- [API Reference: Task Groups](../../docs/api/libs/concurrency/task.md)\n",
    "- [Reference Notebook: Task Groups](../references/concurrency_task.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from typing import Any\n",
    "\n",
    "# Third-party\n",
    "import anyio\n",
    "from anyio.abc import TaskStatus\n",
    "\n",
    "# lionherd-core\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    Event,\n",
    "    create_task_group,\n",
    "    get_cancelled_exc_class,\n",
    "    sleep,\n",
    ")\n",
    "\n",
    "# Configure logging for examples\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"[%(asctime)s.%(msecs)03d] %(name)s: %(message)s\", datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Overview\n",
    "\n",
    "Service manager using structured concurrency handles complete lifecycle:\n",
    "\n",
    "1. **Initialization Protocol**: Services signal readiness via `task_status.started()`\n",
    "2. **Dependency Ordering**: Parent waits for dependencies before starting dependents\n",
    "3. **Event Coordination**: Health checks use Events to signal between components\n",
    "4. **Graceful Shutdown**: Cancel scope triggers coordinated cleanup\n",
    "\n",
    "**Key APIs**: `create_task_group()`, `TaskGroup.start()`, `TaskGroup.start_soon()`, `Event`, `cancel_scope`\n",
    "\n",
    "**Flow**: Database ‚Üí started() ‚Üí Cache ‚Üí started() ‚Üí API ‚Üí started() ‚Üí Health Monitor ‚Üí Workers ‚Üí Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database] Starting...\n",
      "[Database] Running\n",
      "‚úì Database ready\n",
      "[Database] Stopped\n",
      "‚úì Lifecycle complete\n"
     ]
    }
   ],
   "source": [
    "# Quick Start: Service Lifecycle in 30 Seconds\n",
    "\n",
    "\n",
    "async def service(name: str, events: Event, *, task_status: TaskStatus = anyio.TASK_STATUS_IGNORED):\n",
    "    \"\"\"Minimal service with lifecycle.\"\"\"\n",
    "    print(f\"[{name}] Starting...\")\n",
    "    await sleep(0.1)  # Simulate startup\n",
    "\n",
    "    task_status.started(f\"{name} ready\")\n",
    "    events.set()  # Signal ready\n",
    "    print(f\"[{name}] Running\")\n",
    "\n",
    "    await events.wait()  # Wait for shutdown\n",
    "    print(f\"[{name}] Stopped\")\n",
    "\n",
    "\n",
    "# Try it:\n",
    "shutdown = Event()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start service and wait for ready\n",
    "    status = await tg.start(service, \"Database\", shutdown)\n",
    "    print(f\"‚úì {status}\")\n",
    "\n",
    "    await sleep(0.2)\n",
    "\n",
    "    # Trigger shutdown\n",
    "    shutdown.set()\n",
    "\n",
    "print(\"‚úì Lifecycle complete\")\n",
    "\n",
    "# üëá Now read below to understand coordinated multi-service lifecycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Service States and Event Coordination\n",
    "\n",
    "Before implementing services, we need clear state definitions and event signaling mechanisms. Services transition through states (Initializing ‚Üí Running ‚Üí Stopping ‚Üí Stopped), and components coordinate via Events.\n",
    "\n",
    "**Why Events**: Events provide thread-safe signaling between tasks. A health monitor can wait for a \"database_ready\" event before checking database health, avoiding race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Database: initializing\n",
      "Events ready: False\n",
      "Events shutdown: False\n"
     ]
    }
   ],
   "source": [
    "class ServiceState(Enum):\n",
    "    \"\"\"Service lifecycle states.\"\"\"\n",
    "\n",
    "    INITIALIZING = \"initializing\"\n",
    "    RUNNING = \"running\"\n",
    "    STOPPING = \"stopping\"\n",
    "    STOPPED = \"stopped\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ServiceStatus:\n",
    "    \"\"\"Service status with state and metadata.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    state: ServiceState\n",
    "    details: dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}: {self.state.value}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ServiceEvents:\n",
    "    \"\"\"Coordination events for service lifecycle.\"\"\"\n",
    "\n",
    "    ready: Event = field(default_factory=Event)\n",
    "    shutdown: Event = field(default_factory=Event)\n",
    "    health_check: Event = field(default_factory=Event)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "status = ServiceStatus(name=\"Database\", state=ServiceState.INITIALIZING)\n",
    "events = ServiceEvents()\n",
    "\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Events ready: {events.ready.is_set()}\")\n",
    "print(f\"Events shutdown: {events.shutdown.is_set()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- `ServiceState` enum ensures type safety and clear transitions\n",
    "- `ServiceEvents` groups related events (ready, shutdown, health_check) for easier management\n",
    "- Events are created once and shared across tasks - don't create new Event instances for coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Basic Service with Lifecycle\n",
    "\n",
    "A service needs initialization, operation, and cleanup phases. The `task_status.started()` protocol signals when initialization completes, allowing dependents to proceed.\n",
    "\n",
    "**Why task_status.started()**: Without it, parent tasks can't distinguish \"still initializing\" from \"ready\". Using `start()` instead of `start_soon()` provides synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:20.447] __main__: [Database] Initializing connection pool...\n",
      "[00:03:20.648] __main__: [Database] Ready (10 connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Service started: Database: running\n",
      "  Details: {'connections': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:20.950] __main__: [Database] Shutting down...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Service lifecycle complete\n"
     ]
    }
   ],
   "source": [
    "async def database_service(\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Simulated database service with lifecycle management.\"\"\"\n",
    "    name = \"Database\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        # Initialize (simulate connection pool setup)\n",
    "        logger.info(f\"[{name}] Initializing connection pool...\")\n",
    "        await sleep(0.2)  # Simulate startup time\n",
    "\n",
    "        # Signal ready\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"connections\"] = 10\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (10 connections)\")\n",
    "\n",
    "        # Run (keep-alive, health checks)\n",
    "        while True:\n",
    "            await sleep(1.0)  # Simulate periodic maintenance\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        # Graceful shutdown\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.1)  # Simulate cleanup (close connections)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        status.state = ServiceState.FAILED\n",
    "        logger.error(f\"[{name}] Failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Test the service lifecycle\n",
    "async with create_task_group() as tg:\n",
    "    # Wait for database to initialize\n",
    "    status = await tg.start(database_service)\n",
    "    print(f\"\\n‚úì Service started: {status}\")\n",
    "    print(f\"  Details: {status.details}\")\n",
    "\n",
    "    # Let it run briefly\n",
    "    await sleep(0.3)\n",
    "\n",
    "    # Trigger shutdown\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Service lifecycle complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- `task_status.started(status)` returns ServiceStatus to caller - useful for passing connection info\n",
    "- Cancellation triggers graceful shutdown - always catch `get_cancelled_exc_class()` for cleanup\n",
    "- State transitions (INITIALIZING ‚Üí RUNNING ‚Üí STOPPING ‚Üí STOPPED) provide observability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add Multi-Service Coordination with Dependencies\n",
    "\n",
    "Real services have dependencies: cache needs database, API needs both. We use `await tg.start()` sequentially to enforce ordering.\n",
    "\n",
    "**Why Sequential start()**: Each `await tg.start()` blocks until `task_status.started()` is called, ensuring dependencies are ready before dependents start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:20.958] __main__: [Database] Initializing connection pool...\n",
      "[00:03:21.160] __main__: [Database] Ready (10 connections)\n",
      "[00:03:21.161] __main__: [Cache] Connecting to Database...\n",
      "[00:03:21.312] __main__: [Cache] Ready (cache_size: 100MB)\n",
      "[00:03:21.313] __main__: [API] Starting HTTP server (port: 8000)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Database: running\n",
      "‚úì Cache: running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:21.414] __main__: [API] Ready (port: 8000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì API: running\n",
      "  Dependencies: ['Database', 'Cache']\n",
      "\n",
      "‚úì All services ready\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:21.716] __main__: [Database] Shutting down...\n",
      "[00:03:21.717] __main__: [API] Shutting down...\n",
      "[00:03:21.718] __main__: [Cache] Shutting down...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating shutdown...\n",
      "\n",
      "\n",
      "‚úì Coordinated lifecycle complete\n"
     ]
    }
   ],
   "source": [
    "async def cache_service(\n",
    "    db_status: ServiceStatus,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Cache service that depends on database.\"\"\"\n",
    "    name = \"Cache\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        # Use database connection from db_status\n",
    "        logger.info(f\"[{name}] Connecting to {db_status.name}...\")\n",
    "        await sleep(0.15)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"cache_size\"] = \"100MB\"\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (cache_size: 100MB)\")\n",
    "\n",
    "        while True:\n",
    "            await sleep(1.0)\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "\n",
    "async def api_service(\n",
    "    db_status: ServiceStatus,\n",
    "    cache_status: ServiceStatus,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"HTTP API service that depends on database and cache.\"\"\"\n",
    "    name = \"API\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Starting HTTP server (port: 8000)...\")\n",
    "        await sleep(0.1)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"port\"] = 8000\n",
    "        status.details[\"dependencies\"] = [db_status.name, cache_status.name]\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (port: 8000)\")\n",
    "\n",
    "        while True:\n",
    "            await sleep(1.0)\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Test coordinated startup\n",
    "async with create_task_group() as tg:\n",
    "    # Start in dependency order\n",
    "    db_status = await tg.start(database_service)\n",
    "    print(f\"‚úì {db_status}\")\n",
    "\n",
    "    cache_status = await tg.start(cache_service, db_status)\n",
    "    print(f\"‚úì {cache_status}\")\n",
    "\n",
    "    api_status = await tg.start(api_service, db_status, cache_status)\n",
    "    print(f\"‚úì {api_status}\")\n",
    "    print(f\"  Dependencies: {api_status.details['dependencies']}\")\n",
    "\n",
    "    # All services running\n",
    "    print(\"\\n‚úì All services ready\\n\")\n",
    "    await sleep(0.3)\n",
    "\n",
    "    # Coordinated shutdown\n",
    "    print(\"Initiating shutdown...\\n\")\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Coordinated lifecycle complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Passing `db_status` to `cache_service` provides connection info (not just signaling)\n",
    "- Services start sequentially but run concurrently after initialization\n",
    "- Shutdown happens in reverse (cancel propagates to all tasks simultaneously)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add Health Monitoring with Event Signaling\n",
    "\n",
    "Health monitors need to coordinate with services: wait for services to be ready, check them periodically, signal failures.\n",
    "\n",
    "**Why Events**: Health monitor waits for `ready` event before checking. Services set events after initialization. This avoids polling or sleep-based coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:21.726] __main__: [HealthMonitor(TestService)] Waiting for TestService ready...\n",
      "[00:03:21.726] __main__: [TestService] Initializing...\n",
      "[00:03:21.877] __main__: [TestService] Ready (ready event set)\n",
      "[00:03:21.877] __main__: [HealthMonitor(TestService)] TestService is ready, starting checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TestService: running\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:22.078] __main__: [HealthMonitor(TestService)] Health check #1: OK\n",
      "[00:03:22.280] __main__: [HealthMonitor(TestService)] Health check #2: OK\n",
      "[00:03:22.379] __main__: [HealthMonitor(TestService)] Stopped (performed 2 checks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initiating shutdown...\n",
      "\n",
      "\n",
      "‚úì Health monitoring complete\n"
     ]
    }
   ],
   "source": [
    "async def monitored_service(\n",
    "    name: str,\n",
    "    startup_time: float,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Service with health monitoring integration.\"\"\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing...\")\n",
    "        await sleep(startup_time)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()  # Signal health monitor\n",
    "        logger.info(f\"[{name}] Ready (ready event set)\")\n",
    "\n",
    "        # Wait for shutdown signal\n",
    "        await events.shutdown.wait()\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "\n",
    "async def health_monitor(\n",
    "    service_name: str,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    \"\"\"Health monitoring task that waits for service readiness.\"\"\"\n",
    "    monitor_name = f\"HealthMonitor({service_name})\"\n",
    "\n",
    "    try:\n",
    "        # Wait for service to be ready\n",
    "        logger.info(f\"[{monitor_name}] Waiting for {service_name} ready...\")\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{monitor_name}] {service_name} is ready, starting checks\")\n",
    "\n",
    "        # Periodic health checks\n",
    "        check_count = 0\n",
    "        while True:\n",
    "            await sleep(0.2)  # Check every 200ms\n",
    "            check_count += 1\n",
    "            logger.info(f\"[{monitor_name}] Health check #{check_count}: OK\")\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{monitor_name}] Stopped (performed {check_count} checks)\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Test health monitoring\n",
    "service_events = ServiceEvents()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start health monitor first (it will wait)\n",
    "    tg.start_soon(health_monitor, \"TestService\", service_events)\n",
    "\n",
    "    # Start service (will signal ready)\n",
    "    status = await tg.start(monitored_service, \"TestService\", 0.15, service_events)\n",
    "    print(f\"‚úì {status}\\n\")\n",
    "\n",
    "    # Let health checks run\n",
    "    await sleep(0.5)\n",
    "\n",
    "    # Shutdown\n",
    "    print(\"\\nInitiating shutdown...\\n\")\n",
    "    service_events.shutdown.set()\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Health monitoring complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Health monitor uses `start_soon()` (fire-and-forget) since it doesn't need initialization protocol\n",
    "- Service sets `ready` event after initialization - monitor waits for this before checking\n",
    "- `shutdown` event provides clean termination signal (alternative to cancellation for some scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:22.388] __main__: [TaskService] Initializing...\n",
      "[00:03:22.489] __main__: [TaskService] Ready\n",
      "[00:03:22.490] __main__: [Worker-0] Started\n",
      "[00:03:22.490] __main__: [Worker-1] Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TaskService: running\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:22.641] __main__: [TaskService] Enqueued task-0\n",
      "[00:03:22.642] __main__: [Worker-0] Processing task: task-0\n",
      "[00:03:22.743] __main__: [Worker-0] Completed task: task-0\n",
      "[00:03:22.793] __main__: [TaskService] Enqueued task-1\n",
      "[00:03:22.793] __main__: [Worker-1] Processing task: task-1\n",
      "[00:03:22.895] __main__: [Worker-1] Completed task: task-1\n",
      "[00:03:22.944] __main__: [TaskService] Enqueued task-2\n",
      "[00:03:22.945] __main__: [Worker-0] Processing task: task-2\n",
      "[00:03:23.046] __main__: [Worker-0] Completed task: task-2\n",
      "[00:03:23.096] __main__: [TaskService] Enqueued task-3\n",
      "[00:03:23.097] __main__: [Worker-1] Processing task: task-3\n",
      "[00:03:23.198] __main__: [Worker-1] Completed task: task-3\n",
      "[00:03:23.248] __main__: [TaskService] Enqueued task-4\n",
      "[00:03:23.249] __main__: [Worker-0] Processing task: task-4\n",
      "[00:03:23.351] __main__: [Worker-0] Completed task: task-4\n",
      "[00:03:23.492] __main__: [Worker-0] Shutting down\n",
      "[00:03:23.492] __main__: [Worker-1] Shutting down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initiating shutdown...\n",
      "\n",
      "\n",
      "‚úì Workers shutdown complete\n"
     ]
    }
   ],
   "source": [
    "from lionherd_core.libs.concurrency import Queue\n",
    "\n",
    "\n",
    "async def background_worker(\n",
    "    worker_id: int,\n",
    "    queue: Queue,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    \"\"\"Background worker that processes tasks from queue.\"\"\"\n",
    "    name = f\"Worker-{worker_id}\"\n",
    "\n",
    "    try:\n",
    "        # Wait for service ready\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{name}] Started\")\n",
    "\n",
    "        # Process tasks\n",
    "        while True:\n",
    "            task = await queue.get()\n",
    "            logger.info(f\"[{name}] Processing task: {task}\")\n",
    "            await sleep(0.1)  # Simulate work\n",
    "            logger.info(f\"[{name}] Completed task: {task}\")\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down\")\n",
    "        raise\n",
    "\n",
    "\n",
    "async def service_with_workers(\n",
    "    task_queue: Queue,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Service that produces tasks for workers.\"\"\"\n",
    "    name = \"TaskService\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing...\")\n",
    "        await sleep(0.1)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "\n",
    "        # Produce tasks\n",
    "        for i in range(5):\n",
    "            await sleep(0.15)\n",
    "            await task_queue.put(f\"task-{i}\")\n",
    "            logger.info(f\"[{name}] Enqueued task-{i}\")\n",
    "\n",
    "        # Wait for shutdown\n",
    "        await events.shutdown.wait()\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Test service with background workers\n",
    "task_queue = Queue.with_maxsize(10)\n",
    "worker_events = ServiceEvents()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start workers (they wait for ready event)\n",
    "    for i in range(2):\n",
    "        tg.start_soon(background_worker, i, task_queue, worker_events)\n",
    "\n",
    "    # Start service (signals ready, produces tasks)\n",
    "    status = await tg.start(service_with_workers, task_queue, worker_events)\n",
    "    print(f\"‚úì {status}\\n\")\n",
    "\n",
    "    # Let workers process\n",
    "    await sleep(1.0)\n",
    "\n",
    "    # Shutdown\n",
    "    print(\"\\nInitiating shutdown...\\n\")\n",
    "    worker_events.shutdown.set()\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Workers shutdown complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Workers use `while True: task = await queue.get()` pattern to process tasks\n",
    "- `await queue.close()` signals queue closure - `queue.get()` raises `anyio.EndOfStream`\n",
    "- Catch `anyio.EndOfStream` for graceful worker shutdown when queue closes\n",
    "- Workers wait for `ready` event before processing - ensures service is initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Considerations\n",
    "\n",
    "Here's the full production-ready implementation combining all patterns: multi-service dependencies, health monitoring, background workers, and coordinated lifecycle management.\n",
    "\n",
    "**Features**:\n",
    "- ‚úÖ Multi-component initialization (Database ‚Üí Cache ‚Üí API)\n",
    "- ‚úÖ Dependency ordering with `task_status.started()`\n",
    "- ‚úÖ Health monitoring with event coordination\n",
    "- ‚úÖ Background workers with queue processing\n",
    "- ‚úÖ Graceful shutdown with cleanup\n",
    "- ‚úÖ Production-ready error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: Parallel Service Initialization\n",
    "\n",
    "Independent services can initialize concurrently for faster startup:\n",
    "\n",
    "```python\n",
    "async with create_task_group() as tg:\n",
    "    # Start independent services concurrently\n",
    "    db_task = tg.start(database_service, events_db)\n",
    "    metrics_task = tg.start(metrics_service, events_metrics)\n",
    "    \n",
    "    # Wait for all\n",
    "    db_status, metrics_status = await db_task, await metrics_task\n",
    "    \n",
    "    # Start dependent services\n",
    "    await tg.start(api_service, db_status, events_api)\n",
    "```\n",
    "\n",
    "**Trade-offs**: Faster startup | More complex, harder to debug concurrent failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Patterns**:\n",
    "- Structured concurrency: TaskGroups ensure all tasks complete/cancel together\n",
    "- Initialization protocol: `await tg.start()` + `task_status.started()` for dependencies\n",
    "- Event coordination: Signal between tasks without polling\n",
    "- Graceful shutdown: Cancellation + cleanup in `except get_cancelled_exc_class()`\n",
    "\n",
    "**Use Cases**:\n",
    "- ‚úÖ Multi-component services (HTTP API + database + cache)\n",
    "- ‚úÖ Long-running services with health monitoring\n",
    "- ‚úÖ Background task processing with queues\n",
    "- ‚ùå Simple single-task operations (use asyncio.create_task)\n",
    "\n",
    "**Related**: [Task Groups API](../../docs/api/libs/concurrency/task.md), [Primitives API](../../docs/api/libs/concurrency/primitives.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What You Accomplished**:\n",
    "- ‚úÖ Built multi-component service manager with coordinated initialization\n",
    "- ‚úÖ Implemented dependency ordering using `task_status.started()` protocol\n",
    "- ‚úÖ Integrated health monitoring with Event-based coordination\n",
    "- ‚úÖ Added background workers with queue-based task processing\n",
    "- ‚úÖ Implemented graceful shutdown with cleanup protocols\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. **Structured Concurrency**: TaskGroups ensure all tasks complete or cancel before exit - no orphaned tasks\n",
    "2. **Initialization Protocol**: `await tg.start()` + `task_status.started()` provides type-safe dependency ordering\n",
    "3. **Event Coordination**: Events signal between tasks without polling or sleep-based synchronization\n",
    "4. **Graceful Shutdown**: Cancellation propagates to all tasks, each handles cleanup in `except get_cancelled_exc_class()`\n",
    "5. **Production Readiness**: Error handling, monitoring, and configuration tuning are essential - not optional\n",
    "\n",
    "**When to Use This Pattern**:\n",
    "- ‚úÖ Multi-component services with dependencies (HTTP API + database + cache)\n",
    "- ‚úÖ Long-running services needing health monitoring\n",
    "- ‚úÖ Background task processing with queues\n",
    "- ‚úÖ Coordinated startup and shutdown requirements\n",
    "- ‚ùå Simple single-task operations (use asyncio.create_task instead)\n",
    "- ‚ùå Fire-and-forget tasks with no lifecycle management (use start_soon only)\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**lionherd-core API Reference**:\n",
    "- [Task Groups](../../docs/api/libs/concurrency/task.md) - create_task_group, start, start_soon\n",
    "- [Primitives](../../docs/api/libs/concurrency/primitives.md) - Event, Queue, Lock\n",
    "- [Cancellation](../../docs/api/libs/concurrency/cancel.md) - Cancel scopes, timeouts\n",
    "\n",
    "**Reference Notebooks**:\n",
    "- [Task Groups Patterns](../references/concurrency_task.ipynb) - Overview of task group capabilities\n",
    "- [Primitives](../references/concurrency_primitives.ipynb) - Event, Queue, Lock usage\n",
    "- [Cancellation](../references/concurrency_cancel.ipynb) - Timeout and cancellation patterns\n",
    "\n",
    "**External Resources**:\n",
    "- [AnyIO Documentation: Task Groups](https://anyio.readthedocs.io/en/stable/tasks.html) - Underlying implementation\n",
    "- [Structured Concurrency (Nathaniel Smith)](https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/) - Conceptual foundation\n",
    "- [Production Service Patterns (AWS)](https://aws.amazon.com/builders-library/implementing-health-checks/) - Health monitoring best practices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
