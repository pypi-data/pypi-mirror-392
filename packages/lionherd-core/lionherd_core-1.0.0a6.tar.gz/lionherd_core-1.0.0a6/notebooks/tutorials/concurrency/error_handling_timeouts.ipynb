{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Concurrency Error Handling & Timeouts\n",
    "\n",
    "**Category**: Concurrency  \n",
    "**Difficulty**: Beginner to Intermediate  \n",
    "**Time**: 20 minutes\n",
    "\n",
    "## Overview\n",
    "\n",
    "Learn lionherd-core's three essential concurrency utilities for handling errors and timeouts:\n",
    "\n",
    "1. **`fail_after()`** - Hard timeout that raises `TimeoutError`\n",
    "2. **`move_on_after()`** - Soft timeout with silent cancellation\n",
    "3. **`bounded_map()`** - Parallel execution with concurrency limits\n",
    "\n",
    "**What You'll Learn**:\n",
    "- When to use hard vs soft timeouts\n",
    "- How to handle partial failures in parallel operations\n",
    "- Controlling concurrency to avoid overwhelming resources\n",
    "\n",
    "**Prerequisites**:\n",
    "```bash\n",
    "pip install lionherd-core\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lionherd-core concurrency utilities\n",
    "# Standard library\n",
    "\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    bounded_map,\n",
    "    fail_after,\n",
    "    move_on_after,\n",
    "    sleep,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: `fail_after()` - Hard Timeouts\n",
    "\n",
    "**Use Case**: Critical operations that MUST complete within a deadline or fail explicitly.\n",
    "\n",
    "**API**:\n",
    "```python\n",
    "with fail_after(seconds):\n",
    "    await operation()  # Raises TimeoutError if exceeds seconds\n",
    "```\n",
    "\n",
    "**When to Use**:\n",
    "- ✅ API requests with SLA requirements\n",
    "- ✅ Database queries that shouldn't hang\n",
    "- ✅ User-facing operations (prevent indefinite waiting)\n",
    "- ❌ Optional operations (use `move_on_after` instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Completed: success\n",
      "✗ TimeoutError: Operation took too long\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Successful operation within timeout\n",
    "async def quick_operation():\n",
    "    \"\"\"Completes in 0.5 seconds.\"\"\"\n",
    "    await sleep(0.5)\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "# This succeeds (0.5s < 2s timeout)\n",
    "with fail_after(2.0):\n",
    "    result = await quick_operation()\n",
    "    print(f\"✓ Completed: {result}\")\n",
    "\n",
    "\n",
    "# Example 2: Operation exceeds timeout\n",
    "async def slow_operation():\n",
    "    \"\"\"Takes 3 seconds (too slow).\"\"\"\n",
    "    await sleep(3.0)\n",
    "    return \"too late\"\n",
    "\n",
    "\n",
    "# This raises TimeoutError (3s > 1s timeout)\n",
    "try:\n",
    "    with fail_after(1.0):\n",
    "        result = await slow_operation()\n",
    "except TimeoutError:\n",
    "    print(\"✗ TimeoutError: Operation took too long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points**:\n",
    "- **Raises exception**: `TimeoutError` is raised, operation is cancelled\n",
    "- **Caller handles failure**: Use try/except to handle timeout\n",
    "- **Resource cleanup**: Cancelled tasks are properly cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: {'url': 'https://api.example.com/data', 'data': 'response'}\n",
      "Error: Request to https://slow-api.example.com/data timed out after 1.0s\n"
     ]
    }
   ],
   "source": [
    "# Practical Example: HTTP-like request with timeout\n",
    "async def fetch_data(url: str, timeout: float = 2.0) -> dict:\n",
    "    \"\"\"Fetch data with enforced timeout.\"\"\"\n",
    "    try:\n",
    "        with fail_after(timeout):\n",
    "            # Simulate network request\n",
    "            await sleep(1.5)  # Realistic latency\n",
    "            return {\"url\": url, \"data\": \"response\"}\n",
    "    except TimeoutError:\n",
    "        # Timeout is treated as an error\n",
    "        raise RuntimeError(f\"Request to {url} timed out after {timeout}s\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "result = await fetch_data(\"https://api.example.com/data\")\n",
    "print(f\"Success: {result}\")\n",
    "\n",
    "# This will raise RuntimeError (wrapping TimeoutError)\n",
    "try:\n",
    "    await fetch_data(\"https://slow-api.example.com/data\", timeout=1.0)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: `move_on_after()` - Soft Timeouts\n",
    "\n",
    "**Use Case**: Optional operations that shouldn't block the main flow.\n",
    "\n",
    "**API**:\n",
    "```python\n",
    "with move_on_after(seconds) as scope:\n",
    "    await optional_operation()\n",
    "    \n",
    "if scope.cancel_called:\n",
    "    # Operation timed out (no exception raised)\n",
    "```\n",
    "\n",
    "**When to Use**:\n",
    "- ✅ Optional cache lookups\n",
    "- ✅ Best-effort enrichment\n",
    "- ✅ Graceful degradation (show partial data)\n",
    "- ❌ Critical operations (use `fail_after` instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Operation completed\n",
      "Timed out: False\n",
      "Timed out: True\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Operation completes within timeout\n",
    "with move_on_after(2.0) as scope:\n",
    "    await sleep(0.5)\n",
    "    print(\"✓ Operation completed\")\n",
    "\n",
    "print(f\"Timed out: {scope.cancel_called}\")  # False\n",
    "\n",
    "# Example 2: Operation times out silently\n",
    "with move_on_after(1.0) as scope:\n",
    "    await sleep(3.0)  # This gets cancelled\n",
    "    print(\"This won't print\")  # Never reached\n",
    "\n",
    "print(f\"Timed out: {scope.cancel_called}\")  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points**:\n",
    "- **No exception**: Operation is silently cancelled\n",
    "- **Check `scope.cancel_called`**: Detect if timeout occurred\n",
    "- **Execution continues**: Code after `with` block runs normally\n",
    "- **Common pattern**: Cache-with-fallback - try fast source first, use slow reliable source if timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fast cache: {'id': 123, 'name': 'Cached User', 'source': 'cache'}\n",
      "⏱ Cache timeout for user 456, fetching from DB\n",
      "✓ Slow cache (timeout): {'id': 456, 'name': 'DB User', 'source': 'database'}\n"
     ]
    }
   ],
   "source": [
    "# Practical Example: Optional cache with fallback\n",
    "async def get_user_data(user_id: int, cache_latency: float = 0.2) -> dict:\n",
    "    \"\"\"Get user data with optional cache lookup.\n",
    "\n",
    "    Pattern: Try fast cache first (with timeout), fall back to reliable database.\n",
    "    This prevents slow caches from degrading user experience.\n",
    "\n",
    "    Args:\n",
    "        user_id: User identifier\n",
    "        cache_latency: Simulated cache response time (default: 0.2s fast cache)\n",
    "    \"\"\"\n",
    "    cache_data = None\n",
    "\n",
    "    # Try cache with 0.5s timeout (optional operation)\n",
    "    with move_on_after(0.5) as scope:\n",
    "        await sleep(cache_latency)  # Simulate cache lookup\n",
    "        cache_data = {\"id\": user_id, \"name\": \"Cached User\", \"source\": \"cache\"}\n",
    "\n",
    "    # Check if timeout occurred\n",
    "    if scope.cancel_called:\n",
    "        print(f\"⏱ Cache timeout for user {user_id}, fetching from DB\")\n",
    "\n",
    "    # Use cache result if available, otherwise fall back to database\n",
    "    if cache_data:\n",
    "        return cache_data\n",
    "    else:\n",
    "        # Fallback: reliable database query (slower but always available)\n",
    "        await sleep(0.3)\n",
    "        return {\"id\": user_id, \"name\": \"DB User\", \"source\": \"database\"}\n",
    "\n",
    "\n",
    "# Scenario 1: Fast cache (0.2s < 0.5s timeout) - cache succeeds\n",
    "user1 = await get_user_data(123, cache_latency=0.2)\n",
    "print(f\"✓ Fast cache: {user1}\")\n",
    "\n",
    "# Scenario 2: Slow cache (2.0s > 0.5s timeout) - timeout triggers, DB fallback\n",
    "user2 = await get_user_data(456, cache_latency=2.0)\n",
    "print(f\"✓ Slow cache (timeout): {user2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: `bounded_map()` - Parallel with Concurrency Limits\n",
    "\n",
    "**Use Case**: Process many items in parallel without overwhelming resources.\n",
    "\n",
    "**API**:\n",
    "```python\n",
    "results = await bounded_map(\n",
    "    async_function,\n",
    "    items,\n",
    "    limit=10,  # Max concurrent operations\n",
    "    return_exceptions=False  # Collect exceptions or raise on first\n",
    ")\n",
    "```\n",
    "\n",
    "**When to Use**:\n",
    "- ✅ Batch API calls (rate limiting)\n",
    "- ✅ Parallel file processing\n",
    "- ✅ Database bulk operations\n",
    "- ❌ Unlimited concurrency OK (use `asyncio.gather`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "Processed 10 items\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Basic parallel processing with concurrency limit\n",
    "async def process_item(item: int) -> int:\n",
    "    \"\"\"Simulate processing (I/O-bound work).\"\"\"\n",
    "    await sleep(0.1)\n",
    "    return item * 2\n",
    "\n",
    "\n",
    "items = list(range(10))\n",
    "\n",
    "# Process with max 3 concurrent operations\n",
    "results = await bounded_map(process_item, items, limit=3)\n",
    "print(f\"Results: {results}\")\n",
    "print(f\"Processed {len(results)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points**:\n",
    "- **Concurrency control**: Max `limit` operations run simultaneously\n",
    "- **Order preserved**: Results match input order\n",
    "- **Automatic batching**: Processes items in batches of size `limit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successes: [2, 4, 8, 10, 14, 16]\n",
      "Failures: 4 items failed\n",
      "Success rate: 6/10 (60%)\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Handling partial failures with return_exceptions=True\n",
    "async def unreliable_operation(item: int) -> int:\n",
    "    \"\"\"Sometimes fails.\"\"\"\n",
    "    await sleep(0.05)\n",
    "    if item % 3 == 0:\n",
    "        raise ValueError(f\"Item {item} failed\")\n",
    "    return item * 2\n",
    "\n",
    "\n",
    "items = list(range(10))\n",
    "\n",
    "# Collect both successes and failures\n",
    "results = await bounded_map(\n",
    "    unreliable_operation,\n",
    "    items,\n",
    "    limit=5,\n",
    "    return_exceptions=True,  # Don't halt on first error\n",
    ")\n",
    "\n",
    "# Separate successes from failures\n",
    "successes = [r for r in results if not isinstance(r, Exception)]\n",
    "failures = [r for r in results if isinstance(r, Exception)]\n",
    "\n",
    "print(f\"Successes: {successes}\")\n",
    "print(f\"Failures: {len(failures)} items failed\")\n",
    "print(f\"Success rate: {len(successes)}/{len(items)} ({len(successes) / len(items) * 100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`return_exceptions` Behavior**:\n",
    "- **`False` (default)**: Raises on first error, cancels remaining\n",
    "- **`True`**: Collects all results, exceptions included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 users in 0.80s\n",
      "Average: 40ms per user\n",
      "First 3 users: [{'id': 1, 'name': 'User 1'}, {'id': 2, 'name': 'User 2'}, {'id': 3, 'name': 'User 3'}]\n"
     ]
    }
   ],
   "source": [
    "# Practical Example: Rate-limited API calls\n",
    "async def fetch_user(user_id: int) -> dict:\n",
    "    \"\"\"Simulate API call with realistic latency.\"\"\"\n",
    "    await sleep(0.2)  # 200ms per request\n",
    "    return {\"id\": user_id, \"name\": f\"User {user_id}\"}\n",
    "\n",
    "\n",
    "# Fetch 20 users with max 5 concurrent requests (respect rate limit)\n",
    "user_ids = list(range(1, 21))\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "users = await bounded_map(fetch_user, user_ids, limit=5)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Fetched {len(users)} users in {elapsed:.2f}s\")\n",
    "print(f\"Average: {elapsed / len(users) * 1000:.0f}ms per user\")\n",
    "print(f\"First 3 users: {users[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Insight**:\n",
    "- Sequential: 20 users × 200ms = 4 seconds\n",
    "- `bounded_map(limit=5)`: ~800ms (5× speedup)\n",
    "- Unlimited (`asyncio.gather`): ~200ms but may overwhelm API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Techniques\n",
    "\n",
    "Use all three together for robust parallel processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successful: 10/10\n",
      "✗ Failed/Timeout: 0\n",
      "Data: [{'source': 0, 'data': 'data_0'}, {'source': 1, 'data': 'data_1'}, {'source': 2, 'data': 'data_2'}]...\n"
     ]
    }
   ],
   "source": [
    "# Real-world scenario: Fetch data from multiple sources with timeouts and concurrency control\n",
    "async def fetch_with_timeout(source_id: int) -> dict | None:\n",
    "    \"\"\"Fetch from source with hard timeout, return None on failure.\"\"\"\n",
    "    try:\n",
    "        # Hard timeout for critical operation\n",
    "        with fail_after(1.0):\n",
    "            # Simulate variable latency\n",
    "            await sleep(0.3 + (source_id % 3) * 0.2)\n",
    "            return {\"source\": source_id, \"data\": f\"data_{source_id}\"}\n",
    "    except TimeoutError:\n",
    "        return None  # Graceful degradation\n",
    "\n",
    "\n",
    "# Process 10 sources with max 3 concurrent fetches\n",
    "source_ids = list(range(10))\n",
    "results = await bounded_map(\n",
    "    fetch_with_timeout,\n",
    "    source_ids,\n",
    "    limit=3,\n",
    "    return_exceptions=True,  # Don't fail entire batch on error\n",
    ")\n",
    "\n",
    "# Filter out None and exceptions\n",
    "successful = [r for r in results if r is not None and not isinstance(r, Exception)]\n",
    "failed_count = len([r for r in results if r is None or isinstance(r, Exception)])\n",
    "\n",
    "print(f\"✓ Successful: {len(successful)}/{len(source_ids)}\")\n",
    "print(f\"✗ Failed/Timeout: {failed_count}\")\n",
    "print(f\"Data: {successful[:3]}...\")  # Show first 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Function | Timeout Behavior | Use Case | Exception |\n",
    "|----------|-----------------|----------|------------|\n",
    "| `fail_after(t)` | Raises `TimeoutError` | Critical operations | ✅ Raises |\n",
    "| `move_on_after(t)` | Silent cancellation | Optional operations | ❌ Silent |\n",
    "| `bounded_map(..., limit=N)` | Concurrency control | Batch processing | Configurable |\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "**Need timeout?**\n",
    "- Operation is critical → `fail_after()` (raises error)\n",
    "- Operation is optional → `move_on_after()` (graceful degradation)\n",
    "\n",
    "**Processing multiple items?**\n",
    "- Unlimited concurrency OK → `asyncio.gather()`\n",
    "- Need rate limiting → `bounded_map(limit=N)`\n",
    "- Partial failures acceptable → `bounded_map(..., return_exceptions=True)`\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **`fail_after()`**: Hard timeouts for critical paths\n",
    "2. **`move_on_after()`**: Soft timeouts for graceful degradation\n",
    "3. **`bounded_map()`**: Parallel execution with resource control\n",
    "4. **Combine them**: Build robust error-tolerant systems\n",
    "\n",
    "### Related Resources\n",
    "\n",
    "- [API Reference: Concurrency](../../docs/api/libs/concurrency/)\n",
    "- [Reference Notebooks: Concurrency](../references/concurrency.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
