{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Concurrency Error Handling - Backend-Agnostic Utilities\n",
    "\n",
    "The `concurrency._errors` module provides utilities for handling cancellation and exceptions in async code that works across asyncio and trio backends.\n",
    "\n",
    "**Core Features:**\n",
    "- **Backend Detection**: Auto-detect cancellation exception class (asyncio.CancelledError vs trio.Cancelled)\n",
    "- **Cancellation Testing**: Check if exceptions are cancellations\n",
    "- **Shielding**: Protect critical code from cancellation\n",
    "- **Exception Groups**: Split and filter cancellations from other errors (Python 3.11+)\n",
    "- **Clean Error Handling**: Separate cancellation from actual failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import anyio\n",
    "\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    get_cancelled_exc_class,\n",
    "    is_cancelled,\n",
    "    non_cancel_subgroup,\n",
    "    shield,\n",
    "    sleep,\n",
    ")\n",
    "\n",
    "# Note: split_cancellation not in public API, import from private module\n",
    "from lionherd_core.libs.concurrency._errors import split_cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Backend-Native Cancellation Detection\n",
    "\n",
    "Different async backends use different cancellation exceptions. These utilities detect the correct class automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend cancellation class: CancelledError\n",
      "Module: asyncio.exceptions\n"
     ]
    }
   ],
   "source": [
    "# Get the cancellation exception class for current backend\n",
    "cancel_class = get_cancelled_exc_class()\n",
    "print(f\"Backend cancellation class: {cancel_class.__name__}\")\n",
    "print(f\"Module: {cancel_class.__module__}\")\n",
    "\n",
    "# In asyncio backend, this will be asyncio.CancelledError\n",
    "# In trio backend, this would be trio.Cancelled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Testing for Cancellation\n",
    "\n",
    "Use `is_cancelled()` to distinguish cancellation from other exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CancelledError is cancellation: True\n",
      "ValueError is cancellation: False\n",
      "RuntimeError is cancellation: False\n"
     ]
    }
   ],
   "source": [
    "# Create different exception types\n",
    "cancel_exc = asyncio.CancelledError(\"Task cancelled\")\n",
    "value_exc = ValueError(\"Invalid input\")\n",
    "runtime_exc = RuntimeError(\"Something went wrong\")\n",
    "\n",
    "print(f\"CancelledError is cancellation: {is_cancelled(cancel_exc)}\")\n",
    "print(f\"ValueError is cancellation: {is_cancelled(value_exc)}\")\n",
    "print(f\"RuntimeError is cancellation: {is_cancelled(runtime_exc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation failed: ZeroDivisionError: division by zero\n",
      "Result: None\n"
     ]
    }
   ],
   "source": [
    "# Practical use: distinguish failure types\n",
    "async def robust_operation():\n",
    "    \"\"\"Handle cancellation differently from errors.\"\"\"\n",
    "    try:\n",
    "        await sleep(1)\n",
    "        result = 42 / 0  # Will raise ZeroDivisionError\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        if is_cancelled(e):\n",
    "            print(\"Operation was cancelled - cleanup gracefully\")\n",
    "            raise  # Re-raise to propagate cancellation\n",
    "        else:\n",
    "            print(f\"Operation failed: {type(e).__name__}: {e}\")\n",
    "            # Handle error, maybe retry or return default\n",
    "            return None\n",
    "\n",
    "\n",
    "# Test with actual error\n",
    "result = await robust_operation()\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Shielding from Cancellation\n",
    "\n",
    "Use `shield()` to protect critical operations from being cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 42...\n",
      "Saved to database: processed_42\n",
      "Cleanup guaranteed!\n"
     ]
    }
   ],
   "source": [
    "# Critical operation that must complete\n",
    "async def save_to_database(data):\n",
    "    \"\"\"Simulate database write.\"\"\"\n",
    "    await sleep(0.1)\n",
    "    print(f\"Saved to database: {data}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "async def process_with_cleanup(value):\n",
    "    \"\"\"Process data with guaranteed cleanup.\"\"\"\n",
    "    print(f\"Processing {value}...\")\n",
    "    await sleep(0.05)\n",
    "\n",
    "    # Even if this function gets cancelled, cleanup will complete\n",
    "    await shield(save_to_database, f\"processed_{value}\")\n",
    "    print(\"Cleanup guaranteed!\")\n",
    "\n",
    "\n",
    "# Test normal execution\n",
    "await process_with_cleanup(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 99...\n",
      "Task was cancelled, but shielded operation completed\n"
     ]
    }
   ],
   "source": [
    "# Test with cancellation\n",
    "async def cancelled_scenario():\n",
    "    \"\"\"Simulate cancellation during processing.\"\"\"\n",
    "    with anyio.CancelScope() as scope:\n",
    "        async with anyio.create_task_group() as tg:\n",
    "            tg.start_soon(process_with_cleanup, 99)  # Callable, not coroutine\n",
    "            await sleep(0.01)  # Let it start\n",
    "            scope.cancel()  # Cancel the scope\n",
    "\n",
    "    print(\"Task was cancelled, but shielded operation completed\")\n",
    "\n",
    "\n",
    "await cancelled_scenario()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Exception Group Splitting (Python 3.11+)\n",
    "\n",
    "When running multiple tasks concurrently, separate cancellations from real errors using `split_cancellation()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original group has 4 exceptions\n",
      "\n",
      "Cancellation group: Multiple failures (2 sub-exceptions)\n",
      "  - 2 cancellations\n",
      "    • Task 1 cancelled\n",
      "    • Task 3 cancelled\n",
      "\n",
      "Error group: Multiple failures (2 sub-exceptions)\n",
      "  - 2 actual errors\n",
      "    • ValueError: Invalid data\n",
      "    • RuntimeError: Connection failed\n"
     ]
    }
   ],
   "source": [
    "# Create mixed exception group\n",
    "exceptions = [\n",
    "    asyncio.CancelledError(\"Task 1 cancelled\"),\n",
    "    ValueError(\"Invalid data\"),\n",
    "    asyncio.CancelledError(\"Task 3 cancelled\"),\n",
    "    RuntimeError(\"Connection failed\"),\n",
    "]\n",
    "\n",
    "exc_group = BaseExceptionGroup(\"Multiple failures\", exceptions)\n",
    "print(f\"Original group has {len(exc_group.exceptions)} exceptions\")\n",
    "\n",
    "# Split into cancellations and errors\n",
    "cancel_group, error_group = split_cancellation(exc_group)\n",
    "\n",
    "print(f\"\\nCancellation group: {cancel_group}\")\n",
    "if cancel_group:\n",
    "    print(f\"  - {len(cancel_group.exceptions)} cancellations\")\n",
    "    for exc in cancel_group.exceptions:\n",
    "        print(f\"    • {exc}\")\n",
    "\n",
    "print(f\"\\nError group: {error_group}\")\n",
    "if error_group:\n",
    "    print(f\"  - {len(error_group.exceptions)} actual errors\")\n",
    "    for exc in error_group.exceptions:\n",
    "        print(f\"    • {type(exc).__name__}: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Filtering Non-Cancellation Errors\n",
    "\n",
    "Use `non_cancel_subgroup()` to get only the actual errors, ignoring cancellations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real errors to handle: 2\n",
      "  • ValueError: Bad value\n",
      "  • TypeError: Wrong type\n"
     ]
    }
   ],
   "source": [
    "# Same exception group\n",
    "exc_group = BaseExceptionGroup(\n",
    "    \"Multiple failures\",\n",
    "    [\n",
    "        asyncio.CancelledError(\"Cancelled\"),\n",
    "        ValueError(\"Bad value\"),\n",
    "        asyncio.CancelledError(\"Also cancelled\"),\n",
    "        TypeError(\"Wrong type\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Get only real errors\n",
    "errors_only = non_cancel_subgroup(exc_group)\n",
    "\n",
    "if errors_only:\n",
    "    print(f\"Real errors to handle: {len(errors_only.exceptions)}\")\n",
    "    for exc in errors_only.exceptions:\n",
    "        print(f\"  • {type(exc).__name__}: {exc}\")\n",
    "else:\n",
    "    print(\"No real errors - all were cancellations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result when all cancelled: None\n",
      "✓ Returns None when no real errors\n"
     ]
    }
   ],
   "source": [
    "# All cancellations - returns None\n",
    "all_cancelled = BaseExceptionGroup(\n",
    "    \"All cancelled\",\n",
    "    [\n",
    "        asyncio.CancelledError(\"Task 1\"),\n",
    "        asyncio.CancelledError(\"Task 2\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "errors_only = non_cancel_subgroup(all_cancelled)\n",
    "print(f\"Result when all cancelled: {errors_only}\")\n",
    "print(\"✓ Returns None when no real errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Real-World Example: Task Runner with Error Handling\n",
    "\n",
    "Combine these utilities to build robust concurrent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  2 tasks failed:\n",
      "   • Task 2 failed\n",
      "   • Task 4 failed\n",
      "Saved to database: completed_2_of_4\n",
      "\n",
      "✓ Completed 2 successful tasks\n",
      "Results: ['Result 1', 'Result 3']\n"
     ]
    }
   ],
   "source": [
    "async def flaky_task(task_id: int, should_fail: bool = False):\n",
    "    \"\"\"Simulate a task that might fail or be cancelled.\"\"\"\n",
    "    await sleep(0.05)\n",
    "\n",
    "    if should_fail:\n",
    "        raise ValueError(f\"Task {task_id} failed\")\n",
    "\n",
    "    return f\"Result {task_id}\"\n",
    "\n",
    "\n",
    "async def run_tasks_with_cleanup(task_configs):\n",
    "    \"\"\"Run multiple tasks with proper error handling and cleanup.\"\"\"\n",
    "    results = []\n",
    "    errors = []\n",
    "\n",
    "    async def task_wrapper(task_id, should_fail):\n",
    "        \"\"\"Wrapper that captures results or errors.\"\"\"\n",
    "        try:\n",
    "            result = await flaky_task(task_id, should_fail)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            errors.append(e)\n",
    "\n",
    "    # Start all tasks in TaskGroup\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        for task_id, should_fail in task_configs:\n",
    "            # Pass callable and arguments separately\n",
    "            tg.start_soon(task_wrapper, task_id, should_fail)\n",
    "\n",
    "    # After TaskGroup exits, all tasks are complete\n",
    "\n",
    "    # Analyze errors\n",
    "    if errors:\n",
    "        exc_group = BaseExceptionGroup(\"Task failures\", errors)\n",
    "\n",
    "        # Separate cancellations from real errors\n",
    "        real_errors = non_cancel_subgroup(exc_group)\n",
    "\n",
    "        if real_errors:\n",
    "            print(f\"⚠️  {len(real_errors.exceptions)} tasks failed:\")\n",
    "            for exc in real_errors.exceptions:\n",
    "                print(f\"   • {exc}\")\n",
    "\n",
    "        cancel_group, _ = split_cancellation(exc_group)\n",
    "        if cancel_group:\n",
    "            print(f\"ℹ️  {len(cancel_group.exceptions)} tasks cancelled\")  # noqa: RUF001\n",
    "\n",
    "    # Always cleanup (shielded from cancellation)\n",
    "    await shield(save_to_database, f\"completed_{len(results)}_of_{len(task_configs)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test with mixed success/failure\n",
    "configs = [\n",
    "    (1, False),  # Success\n",
    "    (2, True),  # Fail\n",
    "    (3, False),  # Success\n",
    "    (4, True),  # Fail\n",
    "]\n",
    "\n",
    "results = await run_tasks_with_cleanup(configs)\n",
    "print(f\"\\n✓ Completed {len(results)} successful tasks\")\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Pattern: Graceful Shutdown\n",
    "\n",
    "Shield cleanup operations during application shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DatabasePool started\n",
      "✓ DatabasePool stopped cleanly\n",
      "✓ Service shutdown complete\n",
      "Final state - running: False\n"
     ]
    }
   ],
   "source": [
    "class Service:\n",
    "    \"\"\"Example service with guaranteed cleanup.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.running = False\n",
    "\n",
    "    async def start(self):\n",
    "        self.running = True\n",
    "        print(f\"✓ {self.name} started\")\n",
    "\n",
    "    async def stop(self):\n",
    "        \"\"\"Critical cleanup - must complete.\"\"\"\n",
    "        await sleep(0.05)  # Simulate cleanup work\n",
    "        self.running = False\n",
    "        print(f\"✓ {self.name} stopped cleanly\")\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"Main service loop with guaranteed cleanup.\"\"\"\n",
    "        await self.start()\n",
    "\n",
    "        try:\n",
    "            # Simulate work\n",
    "            while True:\n",
    "                await sleep(0.1)\n",
    "        except Exception as e:\n",
    "            if is_cancelled(e):\n",
    "                print(f\"ℹ️  {self.name} received cancellation\")  # noqa: RUF001\n",
    "            else:\n",
    "                print(f\"⚠️  {self.name} error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Cleanup is shielded - will complete even if cancelled\n",
    "            await shield(self.stop)\n",
    "\n",
    "\n",
    "# Test graceful shutdown\n",
    "async def test_graceful_shutdown():\n",
    "    service = Service(\"DatabasePool\")\n",
    "\n",
    "    with anyio.CancelScope() as scope:\n",
    "        async with anyio.create_task_group() as tg:\n",
    "            tg.start_soon(service.run)  # Pass callable, not coroutine\n",
    "            await sleep(0.15)  # Let it run\n",
    "            scope.cancel()  # Initiate shutdown\n",
    "\n",
    "    print(\"✓ Service shutdown complete\")\n",
    "    print(f\"Final state - running: {service.running}\")\n",
    "\n",
    "\n",
    "await test_graceful_shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "**Concurrency Error Handling Essentials:**\n",
    "- ✅ `get_cancelled_exc_class()` - Auto-detect backend cancellation exception\n",
    "- ✅ `is_cancelled(exc)` - Test if exception is cancellation\n",
    "- ✅ `shield(func, *args, **kwargs)` - Protect critical code from cancellation\n",
    "- ✅ `split_cancellation(eg)` - Separate cancellations from errors in exception groups\n",
    "- ✅ `non_cancel_subgroup(eg)` - Filter out cancellations, keep only real errors\n",
    "- ✅ Backend-agnostic (works with asyncio and trio)\n",
    "- ✅ Python 3.11+ ExceptionGroup support\n",
    "- ✅ Preserves exception structure, tracebacks, and metadata\n",
    "\n",
    "**Best Practices:**\n",
    "- Shield cleanup operations (database commits, file closes, resource releases)\n",
    "- Distinguish cancellation from failure in error handling\n",
    "- Use `non_cancel_subgroup()` to focus on actionable errors\n",
    "- Always re-raise cancellation after cleanup\n",
    "- Combine with `TaskGroup` for robust concurrent operations\n",
    "\n",
    "**Next Steps:**\n",
    "- See `concurrency.throttle` for rate limiting\n",
    "- See `concurrency.gather` for parallel task execution\n",
    "- See `Event` for async event handling patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
