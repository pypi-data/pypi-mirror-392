{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency Primitives - Async Synchronization Tools\n",
    "\n",
    "Lionherd provides async-first concurrency primitives built on AnyIO. These tools enable safe coordination between concurrent tasks:\n",
    "\n",
    "**Core Primitives:**\n",
    "- **Lock**: Mutual exclusion for critical sections\n",
    "- **Semaphore**: Limit concurrent access to N resources\n",
    "- **Event**: Signal completion or state changes across tasks\n",
    "- **CapacityLimiter**: Fine-grained resource capacity management\n",
    "- **Queue**: Producer-consumer communication\n",
    "- **Condition**: Wait for complex conditions with notifications\n",
    "\n",
    "**Key Features:**\n",
    "- Context manager support (`async with`)\n",
    "- AnyIO-compatible (works with asyncio, trio, etc.)\n",
    "- Type-safe with generics (Queue)\n",
    "- Statistics and observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:50.603630Z",
     "iopub.status.busy": "2025-11-09T06:18:50.603555Z",
     "iopub.status.idle": "2025-11-09T06:18:50.697810Z",
     "shell.execute_reply": "2025-11-09T06:18:50.697303Z"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    CapacityLimiter,\n",
    "    Condition,\n",
    "    Event,\n",
    "    Lock,\n",
    "    Queue,\n",
    "    Semaphore,\n",
    "    create_task_group,\n",
    "    sleep,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lock - Mutual Exclusion\n",
    "\n",
    "Lock ensures only one task accesses a critical section at a time. Essential for protecting shared state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:50.699206Z",
     "iopub.status.busy": "2025-11-09T06:18:50.699123Z",
     "iopub.status.idle": "2025-11-09T06:18:50.716276Z",
     "shell.execute_reply": "2025-11-09T06:18:50.715959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsafe counter (expected 3000): 1000\n",
      "Lost updates: 2000\n"
     ]
    }
   ],
   "source": [
    "# Shared counter without protection (race condition)\n",
    "counter = 0\n",
    "\n",
    "\n",
    "async def increment_unsafe():\n",
    "    global counter\n",
    "    for _ in range(1000):\n",
    "        # Read-modify-write is NOT atomic\n",
    "        temp = counter\n",
    "        await sleep(0)  # Simulate context switch\n",
    "        counter = temp + 1\n",
    "\n",
    "\n",
    "# Run 3 concurrent tasks\n",
    "async def race_condition_demo():\n",
    "    global counter\n",
    "    counter = 0\n",
    "    async with create_task_group() as tg:\n",
    "        for _ in range(3):\n",
    "            tg.start_soon(increment_unsafe)\n",
    "    return counter\n",
    "\n",
    "\n",
    "result = await race_condition_demo()\n",
    "print(f\"Unsafe counter (expected 3000): {result}\")\n",
    "print(f\"Lost updates: {3000 - result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:50.732386Z",
     "iopub.status.busy": "2025-11-09T06:18:50.732266Z",
     "iopub.status.idle": "2025-11-09T06:18:50.826151Z",
     "shell.execute_reply": "2025-11-09T06:18:50.825616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe counter: 3000\n",
      "✓ No lost updates!\n"
     ]
    }
   ],
   "source": [
    "# Safe version with Lock\n",
    "lock = Lock()\n",
    "counter = 0\n",
    "\n",
    "\n",
    "async def increment_safe():\n",
    "    global counter\n",
    "    for _ in range(1000):\n",
    "        async with lock:  # Only one task in critical section\n",
    "            temp = counter\n",
    "            await sleep(0)\n",
    "            counter = temp + 1\n",
    "\n",
    "\n",
    "async def safe_counter_demo():\n",
    "    global counter\n",
    "    counter = 0\n",
    "    async with create_task_group() as tg:\n",
    "        for _ in range(3):\n",
    "            tg.start_soon(increment_safe)\n",
    "    return counter\n",
    "\n",
    "\n",
    "result = await safe_counter_demo()\n",
    "print(f\"Safe counter: {result}\")\n",
    "print(\"✓ No lost updates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Semaphore - Limited Concurrency\n",
    "\n",
    "Semaphore allows up to N tasks to access a resource simultaneously. Perfect for rate limiting or resource pools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:50.827403Z",
     "iopub.status.busy": "2025-11-09T06:18:50.827309Z",
     "iopub.status.idle": "2025-11-09T06:18:52.336418Z",
     "shell.execute_reply": "2025-11-09T06:18:52.335624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 started (max 2 concurrent)\n",
      "Task 1 started (max 2 concurrent)\n",
      "Task 0 finished\n",
      "Task 1 finished\n",
      "Task 2 started (max 2 concurrent)\n",
      "Task 3 started (max 2 concurrent)\n",
      "Task 2 finished\n",
      "Task 3 finished\n",
      "Task 4 started (max 2 concurrent)\n",
      "Task 4 finished\n",
      "\n",
      "All results: ['Result 0', 'Result 1', 'Result 2', 'Result 3', 'Result 4']\n"
     ]
    }
   ],
   "source": [
    "# Limit to 2 concurrent API calls\n",
    "api_semaphore = Semaphore(2)\n",
    "\n",
    "\n",
    "async def api_call(task_id: int):\n",
    "    async with api_semaphore:\n",
    "        print(f\"Task {task_id} started (max 2 concurrent)\")\n",
    "        await sleep(0.5)  # Simulate API latency\n",
    "        print(f\"Task {task_id} finished\")\n",
    "        return f\"Result {task_id}\"\n",
    "\n",
    "\n",
    "# Launch 5 tasks - only 2 run at once\n",
    "async def semaphore_demo():\n",
    "    # start_soon() returns None, so we use shared results list\n",
    "    results = []\n",
    "\n",
    "    async def wrapper(task_id: int):\n",
    "        result = await api_call(task_id)\n",
    "        results.append(result)\n",
    "\n",
    "    async with create_task_group() as tg:\n",
    "        for i in range(5):\n",
    "            tg.start_soon(wrapper, i)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = await semaphore_demo()\n",
    "print(f\"\\nAll results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Event - Cross-Task Signaling\n",
    "\n",
    "Event allows tasks to wait for a signal from another task. Useful for initialization, checkpoints, or shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:52.338752Z",
     "iopub.status.busy": "2025-11-09T06:18:52.338595Z",
     "iopub.status.idle": "2025-11-09T06:18:53.847988Z",
     "shell.execute_reply": "2025-11-09T06:18:53.847042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer: Loading resources...\n",
      "Worker 0: Waiting for initialization...\n",
      "Worker 1: Waiting for initialization...\n",
      "Worker 2: Waiting for initialization...\n",
      "Initializer: Ready!\n",
      "Worker 0: Starting work!\n",
      "Worker 1: Starting work!\n",
      "Worker 2: Starting work!\n",
      "\n",
      "Results: ['Worker 0 done', 'Worker 1 done', 'Worker 2 done']\n",
      "Event is set: True\n"
     ]
    }
   ],
   "source": [
    "ready_event = Event()\n",
    "\n",
    "\n",
    "async def initializer():\n",
    "    print(\"Initializer: Loading resources...\")\n",
    "    await sleep(1)  # Simulate startup time\n",
    "    print(\"Initializer: Ready!\")\n",
    "    ready_event.set()  # Signal waiting tasks\n",
    "\n",
    "\n",
    "async def worker(worker_id: int):\n",
    "    print(f\"Worker {worker_id}: Waiting for initialization...\")\n",
    "    await ready_event.wait()  # Block until event is set\n",
    "    print(f\"Worker {worker_id}: Starting work!\")\n",
    "    await sleep(0.5)\n",
    "    return f\"Worker {worker_id} done\"\n",
    "\n",
    "\n",
    "async def event_demo():\n",
    "    # start_soon() returns None, so we use shared results list\n",
    "    results = []\n",
    "\n",
    "    async def worker_wrapper(worker_id: int):\n",
    "        result = await worker(worker_id)\n",
    "        results.append(result)\n",
    "\n",
    "    async with create_task_group() as tg:\n",
    "        # Start initializer\n",
    "        tg.start_soon(initializer)\n",
    "        # Start workers (will wait for event)\n",
    "        for i in range(3):\n",
    "            tg.start_soon(worker_wrapper, i)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = await event_demo()\n",
    "print(f\"\\nResults: {results}\")\n",
    "print(f\"Event is set: {ready_event.is_set()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CapacityLimiter - Resource Management\n",
    "\n",
    "CapacityLimiter manages integer capacity with fine-grained control. Track available/borrowed tokens and adjust limits dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:53.849937Z",
     "iopub.status.busy": "2025-11-09T06:18:53.849758Z",
     "iopub.status.idle": "2025-11-09T06:18:53.852807Z",
     "shell.execute_reply": "2025-11-09T06:18:53.852245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "  Total tokens: 3\n",
      "  Available: 3\n",
      "  Borrowed: 0\n"
     ]
    }
   ],
   "source": [
    "# Create limiter with 3 total capacity\n",
    "limiter = CapacityLimiter(3)\n",
    "\n",
    "print(\"Initial state:\")\n",
    "print(f\"  Total tokens: {limiter.total_tokens}\")\n",
    "print(f\"  Available: {limiter.available_tokens}\")\n",
    "print(f\"  Borrowed: {limiter.borrowed_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:53.854285Z",
     "iopub.status.busy": "2025-11-09T06:18:53.854182Z",
     "iopub.status.idle": "2025-11-09T06:18:54.460250Z",
     "shell.execute_reply": "2025-11-09T06:18:54.459809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 waiting for capacity...\n",
      "Task 1 waiting for capacity...\n",
      "Task 2 waiting for capacity...\n",
      "Task 3 waiting for capacity...\n",
      "Task 4 waiting for capacity...\n",
      "  Task 0 acquired (available: 0)\n",
      "  Task 1 acquired (available: 0)\n",
      "  Task 2 acquired (available: 0)\n",
      "  Task 0 released (available: 1)\n",
      "  Task 1 released (available: 2)\n",
      "  Task 2 released (available: 3)\n",
      "  Task 3 acquired (available: 2)\n",
      "  Task 4 acquired (available: 1)\n",
      "  Task 3 released (available: 2)\n",
      "  Task 4 released (available: 3)\n",
      "\n",
      "Final state: 3/3 available\n"
     ]
    }
   ],
   "source": [
    "async def task_with_capacity(task_id: int):\n",
    "    print(f\"Task {task_id} waiting for capacity...\")\n",
    "    async with limiter:  # Acquire 1 token by default\n",
    "        print(f\"  Task {task_id} acquired (available: {limiter.available_tokens})\")\n",
    "        await sleep(0.3)\n",
    "    print(f\"  Task {task_id} released (available: {limiter.available_tokens})\")\n",
    "\n",
    "\n",
    "# Launch 5 tasks - only 3 tokens available\n",
    "async def capacity_demo():\n",
    "    async with create_task_group() as tg:\n",
    "        for i in range(5):\n",
    "            tg.start_soon(task_with_capacity, i)\n",
    "\n",
    "\n",
    "await capacity_demo()\n",
    "print(f\"\\nFinal state: {limiter.available_tokens}/{limiter.total_tokens} available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:54.461784Z",
     "iopub.status.busy": "2025-11-09T06:18:54.461678Z",
     "iopub.status.idle": "2025-11-09T06:18:54.464636Z",
     "shell.execute_reply": "2025-11-09T06:18:54.464088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increased capacity to 5\n",
      "Worker 1 acquired capacity\n",
      "  Borrowed: 1\n",
      "Worker 1 released capacity\n",
      "  Borrowed: 0\n"
     ]
    }
   ],
   "source": [
    "# Dynamic capacity adjustment\n",
    "limiter.total_tokens = 5  # Increase capacity\n",
    "print(f\"Increased capacity to {limiter.total_tokens}\")\n",
    "\n",
    "\n",
    "# Borrower-tracked capacity\n",
    "class Worker:\n",
    "    def __init__(self, worker_id: int):\n",
    "        self.id = worker_id\n",
    "\n",
    "\n",
    "async def tracked_capacity_demo():\n",
    "    worker = Worker(1)\n",
    "\n",
    "    await limiter.acquire_on_behalf_of(worker)\n",
    "    print(f\"Worker {worker.id} acquired capacity\")\n",
    "    print(f\"  Borrowed: {limiter.borrowed_tokens}\")\n",
    "\n",
    "    limiter.release_on_behalf_of(worker)\n",
    "    print(f\"Worker {worker.id} released capacity\")\n",
    "    print(f\"  Borrowed: {limiter.borrowed_tokens}\")\n",
    "\n",
    "\n",
    "await tracked_capacity_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Queue - Producer-Consumer Pattern\n",
    "\n",
    "Queue enables safe communication between producer and consumer tasks. Supports backpressure via maxsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:54.466061Z",
     "iopub.status.busy": "2025-11-09T06:18:54.465953Z",
     "iopub.status.idle": "2025-11-09T06:18:56.479223Z",
     "shell.execute_reply": "2025-11-09T06:18:56.478862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer 1 produced: P1-Item0\n",
      "Producer 2 produced: P2-Item0\n",
      "  Consumer 1 consumed: P1-Item0\n",
      "  Consumer 2 consumed: P2-Item0\n",
      "Producer 1 produced: P1-Item1\n",
      "Producer 2 produced: P2-Item1\n",
      "Producer 1 produced: P1-Item2\n",
      "Producer 2 produced: P2-Item2\n",
      "  Consumer 1 consumed: P1-Item1\n",
      "  Consumer 2 consumed: P2-Item1\n",
      "  Consumer 1 consumed: P1-Item2\n",
      "  Consumer 2 consumed: P2-Item2\n",
      "  Consumer 1 timed out (queue empty)\n",
      "  Consumer 2 timed out (queue empty)\n"
     ]
    }
   ],
   "source": [
    "# Create queue with max 3 items\n",
    "work_queue = Queue[str].with_maxsize(3)\n",
    "\n",
    "\n",
    "async def producer(producer_id: int, count: int):\n",
    "    for i in range(count):\n",
    "        item = f\"P{producer_id}-Item{i}\"\n",
    "        await work_queue.put(item)  # Blocks when queue is full\n",
    "        print(f\"Producer {producer_id} produced: {item}\")\n",
    "        await sleep(0.2)\n",
    "\n",
    "\n",
    "async def consumer(consumer_id: int):\n",
    "    while True:\n",
    "        try:\n",
    "            # Try to get with timeout\n",
    "            item = await asyncio.wait_for(work_queue.get(), timeout=1.0)\n",
    "            print(f\"  Consumer {consumer_id} consumed: {item}\")\n",
    "            await sleep(0.3)  # Simulate processing\n",
    "        except TimeoutError:\n",
    "            print(f\"  Consumer {consumer_id} timed out (queue empty)\")\n",
    "            break\n",
    "\n",
    "\n",
    "async def queue_demo():\n",
    "    async with create_task_group() as tg:\n",
    "        # 2 producers, 2 consumers\n",
    "        tg.start_soon(producer, 1, 3)\n",
    "        tg.start_soon(producer, 2, 3)\n",
    "        await sleep(0.1)  # Let producers start\n",
    "        tg.start_soon(consumer, 1)\n",
    "        tg.start_soon(consumer, 2)\n",
    "\n",
    "\n",
    "await queue_demo()\n",
    "await work_queue.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Condition - Coordinated Waiting\n",
    "\n",
    "Condition allows tasks to wait for complex conditions and be notified when state changes. More flexible than Event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:56.480554Z",
     "iopub.status.busy": "2025-11-09T06:18:56.480471Z",
     "iopub.status.idle": "2025-11-09T06:18:57.484227Z",
     "shell.execute_reply": "2025-11-09T06:18:57.483767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer 0: Waiting for data...\n",
      "Consumer 1: Waiting for data...\n",
      "Consumer 2: Waiting for data...\n",
      "Producer: Data ready, notifying all waiters\n",
      "Consumer 0: Got data: Important Data\n",
      "Consumer 1: Got data: Important Data\n",
      "Consumer 2: Got data: Important Data\n",
      "\n",
      "All consumers got: ['Important Data', 'Important Data', 'Important Data']\n"
     ]
    }
   ],
   "source": [
    "# Shared state protected by condition\n",
    "condition = Condition()\n",
    "data_ready = False\n",
    "data_value = None\n",
    "\n",
    "\n",
    "async def data_producer():\n",
    "    global data_ready, data_value\n",
    "    await sleep(1)  # Simulate data collection\n",
    "\n",
    "    async with condition:\n",
    "        data_value = \"Important Data\"\n",
    "        data_ready = True\n",
    "        print(\"Producer: Data ready, notifying all waiters\")\n",
    "        condition.notify_all()  # Wake all waiting tasks\n",
    "\n",
    "\n",
    "async def data_consumer(consumer_id: int):\n",
    "    print(f\"Consumer {consumer_id}: Waiting for data...\")\n",
    "    async with condition:\n",
    "        while not data_ready:  # Wait for condition\n",
    "            await condition.wait()\n",
    "        print(f\"Consumer {consumer_id}: Got data: {data_value}\")\n",
    "        return data_value\n",
    "\n",
    "\n",
    "async def condition_demo():\n",
    "    global data_ready, data_value\n",
    "    data_ready = False\n",
    "    data_value = None\n",
    "\n",
    "    # start_soon() returns None, so we use shared results list\n",
    "    results = []\n",
    "\n",
    "    async def consumer_wrapper(consumer_id: int):\n",
    "        result = await data_consumer(consumer_id)\n",
    "        results.append(result)\n",
    "\n",
    "    async with create_task_group() as tg:\n",
    "        # Start consumers first (will wait)\n",
    "        for i in range(3):\n",
    "            tg.start_soon(consumer_wrapper, i)\n",
    "        # Start producer\n",
    "        tg.start_soon(data_producer)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = await condition_demo()\n",
    "print(f\"\\nAll consumers got: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistics and Observability\n",
    "\n",
    "Event and Condition provide statistics for monitoring and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:57.485501Z",
     "iopub.status.busy": "2025-11-09T06:18:57.485416Z",
     "iopub.status.idle": "2025-11-09T06:18:57.590355Z",
     "shell.execute_reply": "2025-11-09T06:18:57.589899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before set:\n",
      "  Tasks waiting: 5\n",
      "\n",
      "After set:\n",
      "  Tasks waiting: 0\n",
      "  Event is set: True\n"
     ]
    }
   ],
   "source": [
    "# Create event with multiple waiters\n",
    "monitored_event = Event()\n",
    "\n",
    "\n",
    "async def monitored_waiter(waiter_id: int):\n",
    "    await monitored_event.wait()\n",
    "    return waiter_id\n",
    "\n",
    "\n",
    "async def statistics_demo():\n",
    "    # Start waiters\n",
    "    async with create_task_group() as tg:\n",
    "        # start_soon() returns None, results not needed here\n",
    "        for i in range(5):\n",
    "            tg.start_soon(monitored_waiter, i)\n",
    "\n",
    "        # Check statistics before setting\n",
    "        await sleep(0.1)\n",
    "        stats_before = monitored_event.statistics()\n",
    "        print(\"Before set:\")\n",
    "        print(f\"  Tasks waiting: {stats_before.tasks_waiting}\")\n",
    "\n",
    "        # Set event\n",
    "        monitored_event.set()\n",
    "\n",
    "    # After all waiters complete\n",
    "    stats_after = monitored_event.statistics()\n",
    "    print(\"\\nAfter set:\")\n",
    "    print(f\"  Tasks waiting: {stats_after.tasks_waiting}\")\n",
    "    print(f\"  Event is set: {monitored_event.is_set()}\")\n",
    "\n",
    "\n",
    "await statistics_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-World Pattern: Bounded Task Executor\n",
    "\n",
    "Combine primitives for a practical pattern: execute tasks with bounded concurrency and progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:18:57.591483Z",
     "iopub.status.busy": "2025-11-09T06:18:57.591413Z",
     "iopub.status.idle": "2025-11-09T06:18:58.803184Z",
     "shell.execute_reply": "2025-11-09T06:18:58.802645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/10\n",
      "Progress: 2/10\n",
      "Progress: 3/10\n",
      "Progress: 4/10\n",
      "Progress: 5/10\n",
      "Progress: 6/10\n",
      "Progress: 7/10\n",
      "Progress: 8/10\n",
      "Progress: 9/10\n",
      "Progress: 10/10\n",
      "\n",
      "All results: 10 tasks completed\n"
     ]
    }
   ],
   "source": [
    "class BoundedExecutor:\n",
    "    def __init__(self, max_concurrent: int):\n",
    "        self.semaphore = Semaphore(max_concurrent)\n",
    "        self.lock = Lock()\n",
    "        self.completed = 0\n",
    "        self.total = 0\n",
    "\n",
    "    async def execute(self, coro):\n",
    "        async with self.semaphore:  # Limit concurrency\n",
    "            result = await coro\n",
    "            async with self.lock:  # Protect counter\n",
    "                self.completed += 1\n",
    "                print(f\"Progress: {self.completed}/{self.total}\")\n",
    "            return result\n",
    "\n",
    "    async def map(self, tasks):\n",
    "        self.total = len(tasks)\n",
    "        self.completed = 0\n",
    "\n",
    "        # start_soon() returns None, so we use shared results list\n",
    "        results = []\n",
    "\n",
    "        async def wrapper(task):\n",
    "            result = await self.execute(task)\n",
    "            results.append(result)\n",
    "\n",
    "        async with create_task_group() as tg:\n",
    "            for task in tasks:\n",
    "                tg.start_soon(wrapper, task)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# Use executor\n",
    "async def slow_task(task_id: int):\n",
    "    await sleep(0.3)\n",
    "    return f\"Task {task_id} result\"\n",
    "\n",
    "\n",
    "executor = BoundedExecutor(max_concurrent=3)\n",
    "tasks = [slow_task(i) for i in range(10)]\n",
    "results = await executor.map(tasks)\n",
    "print(f\"\\nAll results: {len(results)} tasks completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "**Concurrency Primitives:**\n",
    "- ✅ **Lock**: Mutual exclusion for critical sections (race condition protection)\n",
    "- ✅ **Semaphore**: Limit N concurrent operations (rate limiting, resource pools)\n",
    "- ✅ **Event**: Signal state changes across tasks (initialization, checkpoints)\n",
    "- ✅ **CapacityLimiter**: Fine-grained capacity management (fractional tokens, dynamic limits)\n",
    "- ✅ **Queue**: Producer-consumer communication (backpressure via maxsize)\n",
    "- ✅ **Condition**: Wait for complex conditions (coordinated state changes)\n",
    "\n",
    "**Best Practices:**\n",
    "- ✅ Use `async with` for automatic acquire/release\n",
    "- ✅ Lock protects shared state, Semaphore limits access\n",
    "- ✅ Event for one-time signals, Condition for repeated notifications\n",
    "- ✅ Queue maxsize provides backpressure (prevents memory issues)\n",
    "- ✅ Monitor statistics for debugging and observability\n",
    "- ✅ Combine primitives for complex patterns (executor example)\n",
    "\n",
    "**Common Patterns:**\n",
    "- Lock + counter: Safe shared state\n",
    "- Semaphore: API rate limiting, connection pools\n",
    "- Event: Startup coordination, shutdown signals\n",
    "- Queue: Task distribution, pipeline processing\n",
    "- Condition: Producer-consumer with state checks\n",
    "\n",
    "**Next Steps:**\n",
    "- See `TaskGroup` for structured concurrency\n",
    "- See `ExecutorPool` for parallel execution\n",
    "- See AnyIO docs for cross-library compatibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
