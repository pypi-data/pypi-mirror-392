{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Groups - Structured Concurrency Primitives\n",
    "\n",
    "Task groups provide structured concurrency primitives for managing async tasks with proper lifecycle management:\n",
    "\n",
    "**Core Components:**\n",
    "- **TaskGroup**: Wrapper around anyio task groups with structured concurrency\n",
    "- **create_task_group()**: Context manager for task group creation\n",
    "- **start_soon()**: Start task without waiting for initialization\n",
    "- **start()**: Start task and wait for initialization signal\n",
    "\n",
    "**Key Features:**\n",
    "- Structured concurrency (all tasks complete or cancel before exit)\n",
    "- Automatic cleanup on cancellation or exception\n",
    "- Cancel scope integration for timeout and cancellation\n",
    "- Initialization protocol for service startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:07.306888Z",
     "iopub.status.busy": "2025-11-09T06:19:07.306820Z",
     "iopub.status.idle": "2025-11-09T06:19:07.411346Z",
     "shell.execute_reply": "2025-11-09T06:19:07.410763Z"
    }
   },
   "outputs": [],
   "source": [
    "from lionherd_core.libs.concurrency import (\n",
    "    create_task_group,\n",
    "    current_time,\n",
    "    get_cancelled_exc_class,\n",
    "    sleep,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Task Group Usage\n",
    "\n",
    "`create_task_group()` provides a context manager that ensures all spawned tasks complete before exiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:07.412903Z",
     "iopub.status.busy": "2025-11-09T06:19:07.412806Z",
     "iopub.status.idle": "2025-11-09T06:19:07.568618Z",
     "shell.execute_reply": "2025-11-09T06:19:07.568011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks spawned\n",
      "[Task-1] Starting work (duration: 0.1s)\n",
      "[Task-2] Starting work (duration: 0.05s)\n",
      "[Task-3] Starting work (duration: 0.15s)\n",
      "[Task-2] Completed\n",
      "[Task-1] Completed\n",
      "[Task-3] Completed\n",
      "✓ All tasks completed (task group exited)\n"
     ]
    }
   ],
   "source": [
    "# Simple worker task\n",
    "async def worker(name: str, duration: float) -> None:\n",
    "    print(f\"[{name}] Starting work (duration: {duration}s)\")\n",
    "    await sleep(duration)\n",
    "    print(f\"[{name}] Completed\")\n",
    "\n",
    "\n",
    "# Task group ensures all tasks complete\n",
    "async with create_task_group() as tg:\n",
    "    tg.start_soon(worker, \"Task-1\", 0.1)\n",
    "    tg.start_soon(worker, \"Task-2\", 0.05)\n",
    "    tg.start_soon(worker, \"Task-3\", 0.15)\n",
    "    print(\"All tasks spawned\")\n",
    "\n",
    "print(\"✓ All tasks completed (task group exited)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. start_soon() - Fire and Forget\n",
    "\n",
    "`start_soon()` spawns tasks without waiting for them to initialize. Use for background work that doesn't need coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:07.589908Z",
     "iopub.status.busy": "2025-11-09T06:19:07.589749Z",
     "iopub.status.idle": "2025-11-09T06:19:07.635083Z",
     "shell.execute_reply": "2025-11-09T06:19:07.634646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawned 5 tasks, results so far: []\n",
      "Processed item 0 -> 0\n",
      "Processed item 1 -> 2\n",
      "Processed item 2 -> 4\n",
      "Processed item 3 -> 6\n",
      "Processed item 4 -> 8\n",
      "✓ All tasks done, results: [0, 2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "# Background processing\n",
    "results = []\n",
    "\n",
    "\n",
    "async def process_item(item: int) -> None:\n",
    "    await sleep(0.01 * item)  # Simulate work\n",
    "    results.append(item * 2)\n",
    "    print(f\"Processed item {item} -> {item * 2}\")\n",
    "\n",
    "\n",
    "# Clear results\n",
    "results = []\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Spawn tasks immediately, don't wait\n",
    "    for i in range(5):\n",
    "        tg.start_soon(process_item, i)\n",
    "    print(f\"Spawned 5 tasks, results so far: {results}\")\n",
    "    # Tasks still running...\n",
    "\n",
    "print(f\"✓ All tasks done, results: {sorted(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Tasks\n",
    "\n",
    "Use the `name` parameter for better debugging and observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:07.636521Z",
     "iopub.status.busy": "2025-11-09T06:19:07.636441Z",
     "iopub.status.idle": "2025-11-09T06:19:07.691020Z",
     "shell.execute_reply": "2025-11-09T06:19:07.690641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named tasks spawned\n",
      "Task 1 executing\n",
      "Task 2 executing\n",
      "Task 3 executing\n",
      "✓ All named tasks completed\n"
     ]
    }
   ],
   "source": [
    "async def monitored_task(task_id: int) -> None:\n",
    "    await sleep(0.05)\n",
    "    print(f\"Task {task_id} executing\")\n",
    "\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    tg.start_soon(monitored_task, 1, name=\"worker-1\")\n",
    "    tg.start_soon(monitored_task, 2, name=\"worker-2\")\n",
    "    tg.start_soon(monitored_task, 3, name=\"worker-3\")\n",
    "    print(\"Named tasks spawned\")\n",
    "\n",
    "print(\"✓ All named tasks completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. start() - Initialization Protocol\n",
    "\n",
    "`start()` waits for a task to signal it has initialized. The task must call `task_status.started()` to signal readiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:07.692399Z",
     "iopub.status.busy": "2025-11-09T06:19:07.692324Z",
     "iopub.status.idle": "2025-11-09T06:19:08.000626Z",
     "shell.execute_reply": "2025-11-09T06:19:08.000081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database] Initialized\n",
      "Service started with status: Database ready\n",
      "[Dependent-Task] Starting work (duration: 0.1s)\n",
      "[Dependent-Task] Completed\n",
      "[Database] Shutting down\n",
      "✓ Service lifecycle complete\n"
     ]
    }
   ],
   "source": [
    "# Service that needs startup coordination\n",
    "async def service_task(\n",
    "    service_name: str,\n",
    "    *,\n",
    "    task_status=...,  # anyio injects this\n",
    ") -> None:\n",
    "    # Initialize service\n",
    "    await sleep(0.1)  # Simulate startup\n",
    "    print(f\"[{service_name}] Initialized\")\n",
    "\n",
    "    # Signal ready\n",
    "    task_status.started(f\"{service_name} ready\")\n",
    "\n",
    "    # Continue running\n",
    "    await sleep(0.2)\n",
    "    print(f\"[{service_name}] Shutting down\")\n",
    "\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Wait for service to initialize\n",
    "    status = await tg.start(service_task, \"Database\")\n",
    "    print(f\"Service started with status: {status}\")\n",
    "\n",
    "    # Can safely spawn dependent tasks now\n",
    "    tg.start_soon(worker, \"Dependent-Task\", 0.1)\n",
    "\n",
    "print(\"✓ Service lifecycle complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Services with Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:08.002739Z",
     "iopub.status.busy": "2025-11-09T06:19:08.002531Z",
     "iopub.status.idle": "2025-11-09T06:19:08.614562Z",
     "shell.execute_reply": "2025-11-09T06:19:08.613883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database] Ready\n",
      "Database ready, starting cache...\n",
      "[Cache] Ready\n",
      "Cache ready, starting API...\n",
      "[API] Ready\n",
      "API ready, all services running\n",
      "✓ Startup order: ['Database', 'Cache', 'API']\n"
     ]
    }
   ],
   "source": [
    "# Coordinated startup\n",
    "startup_order = []\n",
    "\n",
    "\n",
    "async def layered_service(\n",
    "    name: str,\n",
    "    startup_time: float,\n",
    "    *,\n",
    "    task_status=...,\n",
    ") -> None:\n",
    "    await sleep(startup_time)\n",
    "    startup_order.append(name)\n",
    "    print(f\"[{name}] Ready\")\n",
    "    task_status.started()\n",
    "\n",
    "    # Keep running\n",
    "    await sleep(0.5)\n",
    "\n",
    "\n",
    "# Clear\n",
    "startup_order = []\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start services in dependency order\n",
    "    await tg.start(layered_service, \"Database\", 0.05)\n",
    "    print(\"Database ready, starting cache...\")\n",
    "\n",
    "    await tg.start(layered_service, \"Cache\", 0.03)\n",
    "    print(\"Cache ready, starting API...\")\n",
    "\n",
    "    await tg.start(layered_service, \"API\", 0.02)\n",
    "    print(\"API ready, all services running\")\n",
    "\n",
    "print(f\"✓ Startup order: {startup_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cancel Scope - Timeout and Cancellation\n",
    "\n",
    "Task groups have a cancel scope for implementing timeouts and coordinated cancellation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:08.616624Z",
     "iopub.status.busy": "2025-11-09T06:19:08.616475Z",
     "iopub.status.idle": "2025-11-09T06:19:08.822696Z",
     "shell.execute_reply": "2025-11-09T06:19:08.822058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 starting\n",
      "Task 2 starting\n",
      "Task 3 starting\n",
      "Task 3 cancelled\n",
      "Task 2 cancelled\n",
      "Task 1 cancelled\n"
     ]
    }
   ],
   "source": [
    "# Timeout for task group\n",
    "async def slow_task(task_id: int) -> None:\n",
    "    try:\n",
    "        print(f\"Task {task_id} starting\")\n",
    "        await sleep(5.0)  # Too slow\n",
    "        print(f\"Task {task_id} completed\")\n",
    "    except get_cancelled_exc_class():\n",
    "        print(f\"Task {task_id} cancelled\")\n",
    "        raise\n",
    "\n",
    "\n",
    "try:\n",
    "    async with create_task_group() as tg:\n",
    "        # Set timeout on the task group\n",
    "        tg.cancel_scope.deadline = current_time() + 0.2\n",
    "\n",
    "        tg.start_soon(slow_task, 1)\n",
    "        tg.start_soon(slow_task, 2)\n",
    "        tg.start_soon(slow_task, 3)\n",
    "except TimeoutError:\n",
    "    print(\"✓ Task group cancelled due to timeout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:08.824779Z",
     "iopub.status.busy": "2025-11-09T06:19:08.824646Z",
     "iopub.status.idle": "2025-11-09T06:19:08.918487Z",
     "shell.execute_reply": "2025-11-09T06:19:08.918081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 found target!\n",
      "Cancelling remaining tasks...\n",
      "Task 1 cancelled\n",
      "Task 3 cancelled\n",
      "✓ Result: Task 2 found target!\n"
     ]
    }
   ],
   "source": [
    "# Conditional cancellation\n",
    "found_result = None\n",
    "\n",
    "\n",
    "async def search_task(task_id: int) -> None:\n",
    "    global found_result\n",
    "    try:\n",
    "        for i in range(10):\n",
    "            await sleep(0.02)\n",
    "            if task_id == 2 and i == 3:\n",
    "                found_result = f\"Task {task_id} found target!\"\n",
    "                print(found_result)\n",
    "                return\n",
    "    except get_cancelled_exc_class():\n",
    "        print(f\"Task {task_id} cancelled\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Clear\n",
    "found_result = None\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    tg.start_soon(search_task, 1)\n",
    "    tg.start_soon(search_task, 2)\n",
    "    tg.start_soon(search_task, 3)\n",
    "\n",
    "    # Monitor for result\n",
    "    while not found_result:\n",
    "        await sleep(0.01)\n",
    "\n",
    "    # Cancel all tasks once we have result\n",
    "    print(\"Cancelling remaining tasks...\")\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(f\"✓ Result: {found_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exception Handling\n",
    "\n",
    "If any task raises an exception, all tasks in the group are cancelled and the exception propagates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:08.919803Z",
     "iopub.status.busy": "2025-11-09T06:19:08.919732Z",
     "iopub.status.idle": "2025-11-09T06:19:08.974117Z",
     "shell.execute_reply": "2025-11-09T06:19:08.973808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 completed\n",
      "Task 3 completed\n",
      "\n",
      "✓ Task group aborted, caught 1 exception(s):\n",
      "  - Task 2 failed\n"
     ]
    }
   ],
   "source": [
    "# Task that fails\n",
    "async def failing_task(task_id: int, should_fail: bool) -> None:\n",
    "    try:\n",
    "        await sleep(0.05)\n",
    "        if should_fail:\n",
    "            raise ValueError(f\"Task {task_id} failed\")\n",
    "        print(f\"Task {task_id} completed\")\n",
    "    except get_cancelled_exc_class():\n",
    "        print(f\"Task {task_id} cancelled due to sibling failure\")\n",
    "        raise\n",
    "\n",
    "\n",
    "try:\n",
    "    async with create_task_group() as tg:\n",
    "        tg.start_soon(failing_task, 1, False)\n",
    "        tg.start_soon(failing_task, 2, True)  # This will fail\n",
    "        tg.start_soon(failing_task, 3, False)\n",
    "except* ValueError as eg:\n",
    "    print(f\"\\n✓ Task group aborted, caught {len(eg.exceptions)} exception(s):\")\n",
    "    for exc in eg.exceptions:\n",
    "        print(f\"  - {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:08.975745Z",
     "iopub.status.busy": "2025-11-09T06:19:08.975666Z",
     "iopub.status.idle": "2025-11-09T06:19:09.000495Z",
     "shell.execute_reply": "2025-11-09T06:19:09.000151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Caught multiple exception types (2 total):\n",
      "  - ValueError: Task 1 error\n",
      "  - TypeError: Task 2 error\n"
     ]
    }
   ],
   "source": [
    "# Multiple tasks fail simultaneously\n",
    "async def multi_fail_task(task_id: int, error_type: type[Exception] | None) -> None:\n",
    "    await sleep(0.02)\n",
    "    if error_type:\n",
    "        raise error_type(f\"Task {task_id} error\")\n",
    "\n",
    "\n",
    "try:\n",
    "    async with create_task_group() as tg:\n",
    "        tg.start_soon(multi_fail_task, 1, ValueError)\n",
    "        tg.start_soon(multi_fail_task, 2, TypeError)\n",
    "        tg.start_soon(multi_fail_task, 3, None)  # Succeeds but cancelled\n",
    "except* (ValueError, TypeError) as eg:\n",
    "    print(f\"✓ Caught multiple exception types ({len(eg.exceptions)} total):\")\n",
    "    for exc in eg.exceptions:\n",
    "        print(f\"  - {type(exc).__name__}: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Patterns\n",
    "\n",
    "Common patterns using task groups in real applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Worker Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:09.001867Z",
     "iopub.status.busy": "2025-11-09T06:19:09.001785Z",
     "iopub.status.idle": "2025-11-09T06:19:09.091313Z",
     "shell.execute_reply": "2025-11-09T06:19:09.090924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 processed: item-0\n",
      "Worker 1 processed: item-4\n",
      "Worker 2 processed: item-8\n",
      "Worker 0 processed: item-1\n",
      "Worker 1 processed: item-5\n",
      "Worker 2 processed: item-9\n",
      "Worker 0 processed: item-2\n",
      "Worker 1 processed: item-6\n",
      "Worker 2 processed: item-10\n",
      "Worker 0 processed: item-3\n",
      "Worker 1 processed: item-7\n",
      "Worker 2 processed: item-11\n",
      "✓ All work processed (12 items)\n"
     ]
    }
   ],
   "source": [
    "# Fixed-size worker pool with simple queue pattern\n",
    "async def worker_pool_example() -> None:\n",
    "    processed_items = []\n",
    "\n",
    "    async def worker(worker_id: int, items: list[str]) -> None:\n",
    "        for item in items:\n",
    "            await sleep(0.02)  # Process item\n",
    "            processed_items.append(f\"Worker {worker_id} processed: {item}\")\n",
    "            print(f\"Worker {worker_id} processed: {item}\")\n",
    "\n",
    "    # Distribute work among workers\n",
    "    items = [f\"item-{i}\" for i in range(12)]\n",
    "    chunk_size = 4\n",
    "\n",
    "    async with create_task_group() as tg:\n",
    "        # Spawn workers with their assigned items\n",
    "        for i in range(3):\n",
    "            start = i * chunk_size\n",
    "            end = start + chunk_size\n",
    "            tg.start_soon(worker, i, items[start:end])\n",
    "\n",
    "    print(f\"✓ All work processed ({len(processed_items)} items)\")\n",
    "\n",
    "\n",
    "await worker_pool_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Service Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:09.092876Z",
     "iopub.status.busy": "2025-11-09T06:19:09.092782Z",
     "iopub.status.idle": "2025-11-09T06:19:09.457159Z",
     "shell.execute_reply": "2025-11-09T06:19:09.455763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database] Started\n",
      "[Cache] Started\n",
      "[API] Started\n",
      "All services ready: ['Database', 'Cache', 'API']\n",
      "Initiating shutdown...\n",
      "[Database] Shutting down gracefully\n",
      "[API] Shutting down gracefully\n",
      "[Cache] Shutting down gracefully\n",
      "✓ All services stopped\n"
     ]
    }
   ],
   "source": [
    "# Manage multiple long-running services\n",
    "class ServiceManager:\n",
    "    def __init__(self) -> None:\n",
    "        self.services_ready: list[str] = []\n",
    "\n",
    "    async def run_service(\n",
    "        self,\n",
    "        name: str,\n",
    "        *,\n",
    "        task_status=...,\n",
    "    ) -> None:\n",
    "        # Startup\n",
    "        await sleep(0.05)\n",
    "        self.services_ready.append(name)\n",
    "        print(f\"[{name}] Started\")\n",
    "        task_status.started()\n",
    "\n",
    "        # Run until cancelled\n",
    "        try:\n",
    "            while True:\n",
    "                await sleep(0.1)\n",
    "        except get_cancelled_exc_class():\n",
    "            print(f\"[{name}] Shutting down gracefully\")\n",
    "            raise\n",
    "\n",
    "    async def run(self) -> None:\n",
    "        async with create_task_group() as tg:\n",
    "            # Start all services\n",
    "            await tg.start(self.run_service, \"Database\")\n",
    "            await tg.start(self.run_service, \"Cache\")\n",
    "            await tg.start(self.run_service, \"API\")\n",
    "\n",
    "            print(f\"All services ready: {self.services_ready}\")\n",
    "\n",
    "            # Run for a bit\n",
    "            await sleep(0.2)\n",
    "\n",
    "            # Graceful shutdown\n",
    "            print(\"Initiating shutdown...\")\n",
    "            tg.cancel_scope.cancel()\n",
    "\n",
    "\n",
    "manager = ServiceManager()\n",
    "await manager.run()\n",
    "print(\"✓ All services stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern: Nested Task Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:09.459392Z",
     "iopub.status.busy": "2025-11-09T06:19:09.459295Z",
     "iopub.status.idle": "2025-11-09T06:19:09.484209Z",
     "shell.execute_reply": "2025-11-09T06:19:09.483811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 spawning subtasks...\n",
      "Task 2 spawning subtasks...\n",
      "  [Task-1] Subtask 1 done\n",
      "  [Task-1] Subtask 2 done\n",
      "  [Task-1] Subtask 3 done\n",
      "  [Task-2] Subtask 1 done\n",
      "  [Task-2] Subtask 2 done\n",
      "  [Task-2] Subtask 3 done\n",
      "Task 1 completed all subtasks\n",
      "Task 2 completed all subtasks\n",
      "✓ All tasks and subtasks completed\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical task organization\n",
    "async def subtask(group: str, task_id: int) -> None:\n",
    "    await sleep(0.02)\n",
    "    print(f\"  [{group}] Subtask {task_id} done\")\n",
    "\n",
    "\n",
    "async def task_with_subtasks(task_id: int) -> None:\n",
    "    print(f\"Task {task_id} spawning subtasks...\")\n",
    "    async with create_task_group() as subtg:\n",
    "        subtg.start_soon(subtask, f\"Task-{task_id}\", 1)\n",
    "        subtg.start_soon(subtask, f\"Task-{task_id}\", 2)\n",
    "        subtg.start_soon(subtask, f\"Task-{task_id}\", 3)\n",
    "    print(f\"Task {task_id} completed all subtasks\")\n",
    "\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    tg.start_soon(task_with_subtasks, 1)\n",
    "    tg.start_soon(task_with_subtasks, 2)\n",
    "\n",
    "print(\"✓ All tasks and subtasks completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with asyncio.TaskGroup\n",
    "\n",
    "lionherd's TaskGroup wraps anyio for cross-platform async compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:19:09.485445Z",
     "iopub.status.busy": "2025-11-09T06:19:09.485377Z",
     "iopub.status.idle": "2025-11-09T06:19:09.540881Z",
     "shell.execute_reply": "2025-11-09T06:19:09.540065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task completed\n",
      "✓ Cross-platform structured concurrency\n"
     ]
    }
   ],
   "source": [
    "# Key differences:\n",
    "\n",
    "# asyncio.TaskGroup (Python 3.11+):\n",
    "# - create_task() method\n",
    "# - asyncio-specific\n",
    "# - No start() protocol\n",
    "\n",
    "# lionherd TaskGroup:\n",
    "# - start_soon() method (anyio naming)\n",
    "# - Cross-platform (asyncio, trio)\n",
    "# - start() protocol for initialization\n",
    "# - Direct cancel_scope access\n",
    "\n",
    "\n",
    "async def demo_task() -> None:\n",
    "    await sleep(0.05)\n",
    "    print(\"Task completed\")\n",
    "\n",
    "\n",
    "# lionherd pattern (cross-platform)\n",
    "async with create_task_group() as tg:\n",
    "    tg.start_soon(demo_task)\n",
    "    # Works on asyncio, trio, etc.\n",
    "\n",
    "print(\"✓ Cross-platform structured concurrency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "**Task Group Essentials:**\n",
    "- ✅ `create_task_group()` for structured concurrency context\n",
    "- ✅ `start_soon()` spawns tasks without waiting (fire-and-forget)\n",
    "- ✅ `start()` waits for task initialization via `task_status.started()`\n",
    "- ✅ `cancel_scope` property for timeout and cancellation control\n",
    "- ✅ Named tasks via `name` parameter for debugging\n",
    "\n",
    "**Lifecycle Guarantees:**\n",
    "- ✅ All tasks complete or cancel before context exit\n",
    "- ✅ Exception in any task cancels all siblings\n",
    "- ✅ Automatic cleanup on cancellation\n",
    "- ✅ ExceptionGroup for multiple task failures\n",
    "\n",
    "**Practical Patterns:**\n",
    "- ✅ Worker pools with shared queues\n",
    "- ✅ Service managers with coordinated startup/shutdown\n",
    "- ✅ Nested task groups for hierarchical organization\n",
    "- ✅ Timeout and deadline management\n",
    "- ✅ Conditional cancellation based on results\n",
    "\n",
    "**Next Steps:**\n",
    "- See `_patterns` for high-level concurrency patterns (gather, race, bounded_map)\n",
    "- See `_primitives` for CapacityLimiter and other synchronization primitives\n",
    "- See `_cancel` for deadline and cancellation utilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
