{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ln._utils - Core Utility Functions\n",
    "\n",
    "Essential utilities for lionherd operations:\n",
    "\n",
    "**Time Management:**\n",
    "- **now_utc()**: Current UTC timestamp\n",
    "\n",
    "**Async Path Operations:**\n",
    "- **acreate_path()**: Async file path creation with timestamps, random hashes, and timeouts\n",
    "\n",
    "**Data Organization:**\n",
    "- **get_bins()**: Bin packing for strings by cumulative length\n",
    "\n",
    "**Dynamic Imports:**\n",
    "- **import_module()**: Flexible module importing by path\n",
    "- **is_import_installed()**: Check package availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.068414Z",
     "iopub.status.busy": "2025-11-09T05:59:26.068273Z",
     "iopub.status.idle": "2025-11-09T05:59:26.155710Z",
     "shell.execute_reply": "2025-11-09T05:59:26.155252Z"
    }
   },
   "outputs": [],
   "source": "import tempfile\n\nfrom lionherd_core.ln._utils import (\n    acreate_path,\n    get_bins,\n    import_module,\n    is_import_installed,\n    now_utc,\n)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. UTC Timestamps with now_utc()\n",
    "\n",
    "Simple utility to get timezone-aware UTC datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.157040Z",
     "iopub.status.busy": "2025-11-09T05:59:26.156967Z",
     "iopub.status.idle": "2025-11-09T05:59:26.159027Z",
     "shell.execute_reply": "2025-11-09T05:59:26.158642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current UTC: 2025-11-09 15:36:53.390652+00:00\n",
      "Timezone: UTC\n",
      "ISO format: 2025-11-09T15:36:53.390652+00:00\n"
     ]
    }
   ],
   "source": [
    "# Get current UTC time\n",
    "timestamp = now_utc()\n",
    "print(f\"Current UTC: {timestamp}\")\n",
    "print(f\"Timezone: {timestamp.tzinfo}\")\n",
    "print(f\"ISO format: {timestamp.isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.159990Z",
     "iopub.status.busy": "2025-11-09T05:59:26.159925Z",
     "iopub.status.idle": "2025-11-09T05:59:26.271146Z",
     "shell.execute_reply": "2025-11-09T05:59:26.270550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.10s\n",
      "Both have UTC timezone: True\n"
     ]
    }
   ],
   "source": [
    "# Use for consistent timestamps\n",
    "import time\n",
    "\n",
    "t1 = now_utc()\n",
    "time.sleep(0.1)\n",
    "t2 = now_utc()\n",
    "\n",
    "print(f\"Time elapsed: {(t2 - t1).total_seconds():.2f}s\")\n",
    "print(f\"Both have UTC timezone: {t1.tzinfo == t2.tzinfo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Async Path Creation with acreate_path()\n",
    "\n",
    "Flexible async file path generation with:\n",
    "- Subdirectory support via `/` in filename\n",
    "- Optional timestamps\n",
    "- Random hash suffixes\n",
    "- Timeout protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.272788Z",
     "iopub.status.busy": "2025-11-09T05:59:26.272657Z",
     "iopub.status.idle": "2025-11-09T05:59:26.280457Z",
     "shell.execute_reply": "2025-11-09T05:59:26.279699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /var/folders/5p/rcbw097d29j3s2qt861tsjfh0000gn/T/tmp6aczjedl/test.txt\n",
      "Type: Path\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Basic usage - simple filename\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(tmpdir, \"test\", \"txt\")\n",
    "    print(f\"Created: {path}\")\n",
    "    print(f\"Type: {type(path).__name__}\")\n",
    "    print(f\"Exists: {await path.parent.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.281786Z",
     "iopub.status.busy": "2025-11-09T05:59:26.281664Z",
     "iopub.status.idle": "2025-11-09T05:59:26.285681Z",
     "shell.execute_reply": "2025-11-09T05:59:26.285130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /var/folders/5p/rcbw097d29j3s2qt861tsjfh0000gn/T/tmpng6k8nnj/logs/2025/report.txt\n",
      "Parent exists: True\n",
      "Parent name: 2025\n"
     ]
    }
   ],
   "source": [
    "# Subdirectory support - filename with slashes\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(tmpdir, \"logs/2025/report.txt\")\n",
    "    print(f\"Path: {path}\")\n",
    "    print(f\"Parent exists: {await path.parent.exists()}\")\n",
    "    print(f\"Parent name: {path.parent.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.286953Z",
     "iopub.status.busy": "2025-11-09T05:59:26.286810Z",
     "iopub.status.idle": "2025-11-09T05:59:26.290832Z",
     "shell.execute_reply": "2025-11-09T05:59:26.290349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix: report_20251109103653.txt\n",
      "Prefix: 20251109103653_report.txt\n",
      "Custom format: report_2025-11-09.txt\n"
     ]
    }
   ],
   "source": [
    "# Timestamp options\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Timestamp suffix (default)\n",
    "    path1 = await acreate_path(tmpdir, \"report\", \"txt\", timestamp=True)\n",
    "    print(f\"Suffix: {path1.name}\")\n",
    "\n",
    "    # Timestamp prefix\n",
    "    path2 = await acreate_path(tmpdir, \"report\", \"txt\", timestamp=True, time_prefix=True)\n",
    "    print(f\"Prefix: {path2.name}\")\n",
    "\n",
    "    # Custom timestamp format\n",
    "    path3 = await acreate_path(tmpdir, \"report\", \"txt\", timestamp=True, timestamp_format=\"%Y-%m-%d\")\n",
    "    print(f\"Custom format: {path3.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.292140Z",
     "iopub.status.busy": "2025-11-09T05:59:26.292039Z",
     "iopub.status.idle": "2025-11-09T05:59:26.295200Z",
     "shell.execute_reply": "2025-11-09T05:59:26.294843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 1: session-809a118e.log\n",
      "Path 2: session-c6fe3a3f.log\n",
      "Unique: True\n"
     ]
    }
   ],
   "source": [
    "# Random hash suffix for uniqueness\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path1 = await acreate_path(tmpdir, \"session\", \"log\", random_hash_digits=8)\n",
    "    path2 = await acreate_path(tmpdir, \"session\", \"log\", random_hash_digits=8)\n",
    "\n",
    "    print(f\"Path 1: {path1.name}\")\n",
    "    print(f\"Path 2: {path2.name}\")\n",
    "    print(f\"Unique: {path1.name != path2.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.296413Z",
     "iopub.status.busy": "2025-11-09T05:59:26.296326Z",
     "iopub.status.idle": "2025-11-09T05:59:26.299678Z",
     "shell.execute_reply": "2025-11-09T05:59:26.299241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path: /var/folders/5p/rcbw097d29j3s2qt861tsjfh0000gn/T/tmpnmhzvm2h/output/results_20251109-ad34ba.csv\n",
      "Filename: results_20251109-ad34ba.csv\n"
     ]
    }
   ],
   "source": [
    "# Combining timestamp + random hash\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(\n",
    "        tmpdir,\n",
    "        \"output/results.csv\",\n",
    "        timestamp=True,\n",
    "        random_hash_digits=6,\n",
    "        timestamp_format=\"%Y%m%d\",\n",
    "    )\n",
    "    print(f\"Full path: {path}\")\n",
    "    print(f\"Filename: {path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.300796Z",
     "iopub.status.busy": "2025-11-09T05:59:26.300713Z",
     "iopub.status.idle": "2025-11-09T05:59:26.304384Z",
     "shell.execute_reply": "2025-11-09T05:59:26.303970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ File exists error caught: FileExistsError\n",
      "✓ file_exist_ok=True allows existing: True\n"
     ]
    }
   ],
   "source": [
    "# File existence control\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = await acreate_path(tmpdir, \"unique\", \"txt\")\n",
    "\n",
    "    # Create the file\n",
    "    await path.touch()\n",
    "\n",
    "    # Try creating again with file_exist_ok=False (default)\n",
    "    try:\n",
    "        await acreate_path(tmpdir, \"unique.txt\", file_exist_ok=False)\n",
    "    except FileExistsError as e:\n",
    "        print(f\"✓ File exists error caught: {type(e).__name__}\")\n",
    "\n",
    "    # Allow existing file\n",
    "    path2 = await acreate_path(tmpdir, \"unique.txt\", file_exist_ok=True)\n",
    "    print(f\"✓ file_exist_ok=True allows existing: {path == path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.305486Z",
     "iopub.status.busy": "2025-11-09T05:59:26.305407Z",
     "iopub.status.idle": "2025-11-09T05:59:26.308119Z",
     "shell.execute_reply": "2025-11-09T05:59:26.307700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Completed within timeout: fast.txt\n"
     ]
    }
   ],
   "source": [
    "# Timeout protection for slow I/O\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Normal operation completes quickly\n",
    "    path = await acreate_path(tmpdir, \"fast\", \"txt\", timeout=1.0)\n",
    "    print(f\"✓ Completed within timeout: {path.name}\")\n",
    "\n",
    "    # Note: Actual timeout demonstration would require slow filesystem\n",
    "    # In practice, typical operations complete in <100ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 3. Bin Packing with get_bins()\n",
    "\n",
    "Organize string indices into bins by cumulative length - useful for batching within token limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.309125Z",
     "iopub.status.busy": "2025-11-09T05:59:26.309056Z",
     "iopub.status.idle": "2025-11-09T05:59:26.311644Z",
     "shell.execute_reply": "2025-11-09T05:59:26.311293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings: ['short', 'a bit longer', 'tiny', 'this is a much longer string', 'mid']\n",
      "\n",
      "Bins (max 20 chars cumulative):\n",
      "\n",
      "  Bin 0: indices [0, 1]\n",
      "    Strings: ['short', 'a bit longer']\n",
      "    Total length: 17\n",
      "  Bin 1: indices [2]\n",
      "    Strings: ['tiny']\n",
      "    Total length: 4\n",
      "  Bin 2: indices [3]\n",
      "    Strings: ['this is a much longer string']\n",
      "    Total length: 28\n",
      "  Bin 3: indices [4]\n",
      "    Strings: ['mid']\n",
      "    Total length: 3\n"
     ]
    }
   ],
   "source": [
    "# Basic binning\n",
    "strings = [\"short\", \"a bit longer\", \"tiny\", \"this is a much longer string\", \"mid\"]\n",
    "bins = get_bins(strings, upper=20)\n",
    "\n",
    "print(\"Strings:\", strings)\n",
    "print(\"\\nBins (max 20 chars cumulative):\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    bin_strings = [strings[idx] for idx in bin_indices]\n",
    "    total_len = sum(len(s) for s in bin_strings)\n",
    "    print(f\"  Bin {i}: indices {bin_indices}\")\n",
    "    print(f\"    Strings: {bin_strings}\")\n",
    "    print(f\"    Total length: {total_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.312756Z",
     "iopub.status.busy": "2025-11-09T05:59:26.312685Z",
     "iopub.status.idle": "2025-11-09T05:59:26.314848Z",
     "shell.execute_reply": "2025-11-09T05:59:26.314474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing messages into batches:\n",
      "\n",
      "Batch 1: ['Hello', 'How are you?']\n",
      "Batch 2: [\"I'm doing great!\"]\n",
      "Batch 3: [\"What's the weather like?\", 'Sunny']\n",
      "Batch 4: ['Perfect!']\n"
     ]
    }
   ],
   "source": [
    "# Token limit simulation\n",
    "messages = [\n",
    "    \"Hello\",\n",
    "    \"How are you?\",\n",
    "    \"I'm doing great!\",\n",
    "    \"What's the weather like?\",\n",
    "    \"Sunny\",\n",
    "    \"Perfect!\",\n",
    "]\n",
    "\n",
    "# Bin by 30-character chunks\n",
    "bins = get_bins(messages, upper=30)\n",
    "\n",
    "print(\"Organizing messages into batches:\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    batch = [messages[idx] for idx in bin_indices]\n",
    "    print(f\"Batch {i + 1}: {batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.315754Z",
     "iopub.status.busy": "2025-11-09T05:59:26.315686Z",
     "iopub.status.idle": "2025-11-09T05:59:26.317698Z",
     "shell.execute_reply": "2025-11-09T05:59:26.317433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When item > limit, it gets its own bin:\n",
      "\n",
      "Bin 0: ['a']\n",
      "Bin 1: ['this exceeds the limit by far']\n",
      "Bin 2: ['b', 'c']\n"
     ]
    }
   ],
   "source": [
    "# Edge case: String longer than limit\n",
    "items = [\"a\", \"this exceeds the limit by far\", \"b\", \"c\"]\n",
    "bins = get_bins(items, upper=10)\n",
    "\n",
    "print(\"When item > limit, it gets its own bin:\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    print(f\"Bin {i}: {[items[idx] for idx in bin_indices]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 4. Dynamic Imports with import_module()\n",
    "\n",
    "Import modules, packages, and specific objects dynamically by path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.318660Z",
     "iopub.status.busy": "2025-11-09T05:59:26.318591Z",
     "iopub.status.idle": "2025-11-09T05:59:26.320446Z",
     "shell.execute_reply": "2025-11-09T05:59:26.320096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: json\n",
      "Has dumps: True\n"
     ]
    }
   ],
   "source": [
    "# Import entire module\n",
    "json_module = import_module(\"json\")\n",
    "print(f\"Imported: {json_module.__name__}\")\n",
    "print(f\"Has dumps: {hasattr(json_module, 'dumps')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.321407Z",
     "iopub.status.busy": "2025-11-09T05:59:26.321345Z",
     "iopub.status.idle": "2025-11-09T05:59:26.323336Z",
     "shell.execute_reply": "2025-11-09T05:59:26.322954Z"
    }
   },
   "outputs": [],
   "source": "# Import specific object from module\nPathClass = import_module(\"pathlib\", import_name=\"Path\")\nprint(f\"Imported: {PathClass.__name__}\")\nprint(f\"Type: {type(PathClass)}\")\n\n# Use it\np = PathClass(\"/tmp/test\")\nprint(f\"Created path: {p}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.324223Z",
     "iopub.status.busy": "2025-11-09T05:59:26.324145Z",
     "iopub.status.idle": "2025-11-09T05:59:26.326357Z",
     "shell.execute_reply": "2025-11-09T05:59:26.325966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: dumps, loads\n",
      "Roundtrip: {'test': 123} -> '{\"test\": 123}' -> {'test': 123}\n"
     ]
    }
   ],
   "source": [
    "# Import multiple objects at once\n",
    "dumps, loads = import_module(\"json\", import_name=[\"dumps\", \"loads\"])\n",
    "print(f\"Imported: {dumps.__name__}, {loads.__name__}\")\n",
    "\n",
    "# Use them\n",
    "data = {\"test\": 123}\n",
    "json_str = dumps(data)\n",
    "restored = loads(json_str)\n",
    "print(f\"Roundtrip: {data} -> '{json_str}' -> {restored}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.327313Z",
     "iopub.status.busy": "2025-11-09T05:59:26.327251Z",
     "iopub.status.idle": "2025-11-09T05:59:26.329563Z",
     "shell.execute_reply": "2025-11-09T05:59:26.329179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: Element\n",
      "Created: Element with ID 9881ec82-a8da-4e07-a270-19b50e600ce4\n"
     ]
    }
   ],
   "source": [
    "# Import from nested package\n",
    "Element = import_module(\"lionherd_core.base\", import_name=\"Element\")\n",
    "print(f\"Imported: {Element.__name__}\")\n",
    "\n",
    "# Create instance\n",
    "elem = Element()\n",
    "print(f\"Created: {type(elem).__name__} with ID {elem.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.330474Z",
     "iopub.status.busy": "2025-11-09T05:59:26.330411Z",
     "iopub.status.idle": "2025-11-09T05:59:26.332452Z",
     "shell.execute_reply": "2025-11-09T05:59:26.332139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Import error caught: Failed to import module nonexistent_package_xyz: N...\n"
     ]
    }
   ],
   "source": [
    "# Error handling for missing modules\n",
    "try:\n",
    "    import_module(\"nonexistent_package_xyz\")\n",
    "except ImportError as e:\n",
    "    print(f\"✓ Import error caught: {str(e)[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 5. Package Detection with is_import_installed()\n",
    "\n",
    "Check if packages are available before attempting imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.333641Z",
     "iopub.status.busy": "2025-11-09T05:59:26.333558Z",
     "iopub.status.idle": "2025-11-09T05:59:26.335538Z",
     "shell.execute_reply": "2025-11-09T05:59:26.335183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json installed: True\n",
      "pathlib installed: True\n",
      "asyncio installed: True\n"
     ]
    }
   ],
   "source": [
    "# Check standard library\n",
    "print(f\"json installed: {is_import_installed('json')}\")\n",
    "print(f\"pathlib installed: {is_import_installed('pathlib')}\")\n",
    "print(f\"asyncio installed: {is_import_installed('asyncio')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.336392Z",
     "iopub.status.busy": "2025-11-09T05:59:26.336332Z",
     "iopub.status.idle": "2025-11-09T05:59:26.338178Z",
     "shell.execute_reply": "2025-11-09T05:59:26.337844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydantic installed: True\n",
      "anyio installed: True\n"
     ]
    }
   ],
   "source": [
    "# Check third-party packages\n",
    "print(f\"pydantic installed: {is_import_installed('pydantic')}\")\n",
    "print(f\"anyio installed: {is_import_installed('anyio')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.339116Z",
     "iopub.status.busy": "2025-11-09T05:59:26.339050Z",
     "iopub.status.idle": "2025-11-09T05:59:26.341006Z",
     "shell.execute_reply": "2025-11-09T05:59:26.340651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_package_xyz installed: False\n"
     ]
    }
   ],
   "source": [
    "# Check non-existent package\n",
    "print(f\"fake_package_xyz installed: {is_import_installed('fake_package_xyz')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.341814Z",
     "iopub.status.busy": "2025-11-09T05:59:26.341755Z",
     "iopub.status.idle": "2025-11-09T05:59:26.343658Z",
     "shell.execute_reply": "2025-11-09T05:59:26.343310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pydantic available, using BaseModel\n"
     ]
    }
   ],
   "source": [
    "# Conditional import pattern\n",
    "if is_import_installed(\"pydantic\"):\n",
    "    print(\"✓ Pydantic available, using BaseModel\")\n",
    "else:\n",
    "    print(\"⚠ Pydantic not available, using alternative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 6. Real-World Use Cases\n",
    "\n",
    "Combining utilities for common patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.344550Z",
     "iopub.status.busy": "2025-11-09T05:59:26.344489Z",
     "iopub.status.idle": "2025-11-09T05:59:26.347710Z",
     "shell.execute_reply": "2025-11-09T05:59:26.347377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file: session_20251109_103653-6123.log\n",
      "Content: [2025-11-09T15:36:53.584205+00:00] Session started\n"
     ]
    }
   ],
   "source": [
    "# Timestamped log file creation\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    log_path = await acreate_path(\n",
    "        tmpdir,\n",
    "        \"sessions/session\",\n",
    "        \"log\",\n",
    "        timestamp=True,\n",
    "        random_hash_digits=4,\n",
    "        timestamp_format=\"%Y%m%d_%H%M%S\",\n",
    "    )\n",
    "\n",
    "    # Write timestamped entry\n",
    "    await log_path.write_text(f\"[{now_utc().isoformat()}] Session started\\n\")\n",
    "\n",
    "    content = await log_path.read_text()\n",
    "    print(f\"Log file: {log_path.name}\")\n",
    "    print(f\"Content: {content.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.348643Z",
     "iopub.status.busy": "2025-11-09T05:59:26.348580Z",
     "iopub.status.idle": "2025-11-09T05:59:26.350956Z",
     "shell.execute_reply": "2025-11-09T05:59:26.350614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing message batches:\n",
      "\n",
      "[15:36:53] Batch 1: 2 messages\n",
      "  - User: Hello\n",
      "  - Assistant: Hi there!\n",
      "[15:36:53] Batch 2: 1 messages\n",
      "  - User: How's the weather?\n",
      "[15:36:53] Batch 3: 2 messages\n",
      "  - Assistant: Sunny and warm!\n",
      "  - User: Great for a walk\n",
      "[15:36:53] Batch 4: 1 messages\n",
      "  - Assistant: Absolutely!\n"
     ]
    }
   ],
   "source": [
    "# Batch message processing with token limits\n",
    "messages = [\n",
    "    \"User: Hello\",\n",
    "    \"Assistant: Hi there!\",\n",
    "    \"User: How's the weather?\",\n",
    "    \"Assistant: Sunny and warm!\",\n",
    "    \"User: Great for a walk\",\n",
    "    \"Assistant: Absolutely!\",\n",
    "]\n",
    "\n",
    "# Organize into batches (simulate 50-char token limit)\n",
    "bins = get_bins(messages, upper=50)\n",
    "\n",
    "print(\"Processing message batches:\\n\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    batch = [messages[idx] for idx in bin_indices]\n",
    "    timestamp = now_utc()\n",
    "    print(f\"[{timestamp.strftime('%H:%M:%S')}] Batch {i + 1}: {len(batch)} messages\")\n",
    "    for msg in batch:\n",
    "        print(f\"  - {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T05:59:26.351810Z",
     "iopub.status.busy": "2025-11-09T05:59:26.351752Z",
     "iopub.status.idle": "2025-11-09T05:59:26.354115Z",
     "shell.execute_reply": "2025-11-09T05:59:26.353763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using serializer: orjson\n",
      "Serialized: b'{\"timestamp\":\"2025-11-09T15:36:53.592065+00:00\",\"status\":\"ok\"}'\n"
     ]
    }
   ],
   "source": [
    "# Optional feature loading with graceful fallback\n",
    "def get_serializer():\n",
    "    \"\"\"Get best available JSON serializer.\"\"\"\n",
    "    if is_import_installed(\"orjson\"):\n",
    "        orjson = import_module(\"orjson\")\n",
    "        return \"orjson\", orjson.dumps, orjson.loads\n",
    "    else:\n",
    "        json = import_module(\"json\")\n",
    "        return \"json\", json.dumps, json.loads\n",
    "\n",
    "\n",
    "name, dumps, loads = get_serializer()\n",
    "print(f\"Using serializer: {name}\")\n",
    "\n",
    "# Test it\n",
    "data = {\"timestamp\": now_utc().isoformat(), \"status\": \"ok\"}\n",
    "serialized = dumps(data)\n",
    "print(f\"Serialized: {serialized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "**Time Utilities:**\n",
    "- ✅ `now_utc()` for consistent UTC timestamps\n",
    "- ✅ Timezone-aware datetime objects\n",
    "\n",
    "**Path Management:**\n",
    "- ✅ `acreate_path()` for async file path creation\n",
    "- ✅ Subdirectory support via `/` in filename\n",
    "- ✅ Optional timestamps (prefix/suffix, custom format)\n",
    "- ✅ Random hash suffixes for uniqueness\n",
    "- ✅ File existence control\n",
    "- ✅ Timeout protection for I/O operations\n",
    "\n",
    "**Data Organization:**\n",
    "- ✅ `get_bins()` for batching strings by cumulative length\n",
    "- ✅ Useful for token limits, message batching\n",
    "\n",
    "**Dynamic Imports:**\n",
    "- ✅ `import_module()` for runtime imports\n",
    "- ✅ Import entire modules or specific objects\n",
    "- ✅ Multiple object imports in one call\n",
    "- ✅ `is_import_installed()` for availability checks\n",
    "- ✅ Graceful fallbacks for optional dependencies\n",
    "\n",
    "**Common Patterns:**\n",
    "- ✅ Timestamped log files with unique IDs\n",
    "- ✅ Batch processing with size limits\n",
    "- ✅ Optional feature loading with fallbacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
