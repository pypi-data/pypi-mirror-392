{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# ln Module - lionherd Utility Toolkit\n\nThe `ln` module provides essential utilities for lionherd operations organized into functional categories:\n\n**Async Operations:**\n- **alcall / bcall**: Concurrent function mapping with retry, throttling, and error handling\n- **lcall**: List comprehension-style function application\n\n**Fuzzy Matching & Validation:**\n- **fuzzy_match_keys**: Dictionary key validation with typo correction\n- **fuzzy_validate_mapping / fuzzy_validate_pydantic**: Schema validation with fuzzy matching\n\n**JSON Utilities (orjson-based):**\n- **json_dumps / json_dumpb**: Fast JSON serialization with custom handlers\n- **json_dict / json_lines_iter**: Parsing and NDJSON generation utilities\n- **get_orjson_default / make_options**: Serialization configuration\n\n**Data Conversion:**\n- **to_dict**: Flexible object → dict conversion\n- **to_list**: Normalize iterables to lists\n\n**Hashing:**\n- **hash_dict**: Stable hashing for dicts, lists, Pydantic models\n\n**General Utilities:**\n- **now_utc**: UTC timestamps\n- **acreate_path**: Async path creation with timestamps/hashes\n- **get_bins**: Bin packing for strings\n- **import_module / is_import_installed**: Dynamic imports and checks"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.545402Z",
     "iopub.status.busy": "2025-11-09T06:10:45.545239Z",
     "iopub.status.idle": "2025-11-09T06:10:45.648432Z",
     "shell.execute_reply": "2025-11-09T06:10:45.648024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln module exports:\n",
      "['AlcallParams', 'BcallParams', 'FuzzyMatchKeysParams', 'acreate_path', 'alcall', 'bcall', 'fuzzy_match_keys', 'fuzzy_validate_mapping', 'fuzzy_validate_pydantic', 'get_bins', 'get_orjson_default', 'hash_dict', 'import_module', 'is_import_installed', 'json_dict', 'json_dumpb', 'json_dumps', 'json_lines_iter', 'lcall', 'make_options', 'now_utc', 'to_dict', 'to_list']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from lionherd_core import ln\n",
    "\n",
    "# Show all exports\n",
    "print(\"ln module exports:\")\n",
    "print(sorted([name for name in dir(ln) if not name.startswith(\"_\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Async Operations - Concurrent Processing\n",
    "\n",
    "Apply functions to lists with comprehensive control over concurrency, retries, and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.649562Z",
     "iopub.status.busy": "2025-11-09T06:10:45.649495Z",
     "iopub.status.idle": "2025-11-09T06:10:45.687378Z",
     "shell.execute_reply": "2025-11-09T06:10:45.687021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 5 users:\n",
      "  {'id': 1, 'name': 'User1'}\n",
      "  {'id': 2, 'name': 'User2'}\n"
     ]
    }
   ],
   "source": [
    "# alcall - async list map with full control\n",
    "async def api_fetch(user_id):\n",
    "    await asyncio.sleep(0.01)  # Simulate API call\n",
    "    return {\"id\": user_id, \"name\": f\"User{user_id}\"}\n",
    "\n",
    "\n",
    "# Concurrent execution with limits\n",
    "results = await ln.alcall(\n",
    "    [1, 2, 3, 4, 5],\n",
    "    api_fetch,\n",
    "    max_concurrent=2,  # Limit concurrent requests\n",
    "    retry_attempts=2,  # Retry failures\n",
    "    retry_timeout=1.0,  # Per-call timeout\n",
    ")\n",
    "\n",
    "print(f\"Fetched {len(results)} users:\")\n",
    "for user in results[:2]:\n",
    "    print(f\"  {user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.688597Z",
     "iopub.status.busy": "2025-11-09T06:10:45.688522Z",
     "iopub.status.idle": "2025-11-09T06:10:45.715241Z",
     "shell.execute_reply": "2025-11-09T06:10:45.714932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: [2, 4, 6]\n",
      "Batch 2: [8, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "# bcall - batch processing with incremental results\n",
    "async def process_item(x):\n",
    "    await asyncio.sleep(0.01)\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "batch_num = 0\n",
    "async for batch in ln.bcall(list(range(1, 11)), process_item, batch_size=3):\n",
    "    batch_num += 1\n",
    "    print(f\"Batch {batch_num}: {batch}\")\n",
    "    if batch_num >= 2:  # Show first 2 batches\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.716465Z",
     "iopub.status.busy": "2025-11-09T06:10:45.716394Z",
     "iopub.status.idle": "2025-11-09T06:10:45.719104Z",
     "shell.execute_reply": "2025-11-09T06:10:45.718694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squares: [1, 4, 9, 16, 25]\n",
      "Flattened and doubled: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# lcall - simple synchronous list mapping\n",
    "from lionherd_core.ln import lcall\n",
    "\n",
    "# Apply function to each element\n",
    "result = lcall([1, 2, 3, 4, 5], lambda x: x**2)\n",
    "print(f\"Squares: {result}\")\n",
    "\n",
    "# With input/output processing\n",
    "nested = [[1, 2], [3, 4], [5]]\n",
    "flat_doubled = lcall(nested, lambda x: x * 2, input_flatten=True)\n",
    "print(f\"Flattened and doubled: {flat_doubled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Fuzzy Matching & Validation - Robust Schema Handling\n",
    "\n",
    "Handle typos and variations in data with intelligent string similarity matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.720592Z",
     "iopub.status.busy": "2025-11-09T06:10:45.720420Z",
     "iopub.status.idle": "2025-11-09T06:10:45.723051Z",
     "shell.execute_reply": "2025-11-09T06:10:45.722733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original keys: ['usrname', 'emal', 'age']\n",
      "Corrected: {'age': 30, 'email': 'alice@example.com', 'username': 'Alice', 'created_at': None}\n"
     ]
    }
   ],
   "source": [
    "# fuzzy_match_keys - correct typos in dictionary keys\n",
    "user_input = {\n",
    "    \"usrname\": \"Alice\",  # typo: username\n",
    "    \"emal\": \"alice@example.com\",  # typo: email\n",
    "    \"age\": 30,\n",
    "}\n",
    "\n",
    "expected_schema = [\"username\", \"email\", \"age\", \"created_at\"]\n",
    "\n",
    "# Correct keys and fill missing fields\n",
    "corrected = ln.fuzzy_match_keys(\n",
    "    user_input,\n",
    "    expected_schema,\n",
    "    similarity_threshold=0.85,\n",
    "    handle_unmatched=\"force\",  # Drop unmatched, fill missing\n",
    "    fill_value=None,\n",
    ")\n",
    "\n",
    "print(\"Original keys:\", list(user_input.keys()))\n",
    "print(\"Corrected:\", corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.724199Z",
     "iopub.status.busy": "2025-11-09T06:10:45.724098Z",
     "iopub.status.idle": "2025-11-09T06:10:45.726769Z",
     "shell.execute_reply": "2025-11-09T06:10:45.726365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated: {'age': '25', 'email': 'bob@example.com', 'username': 'Bob'}\n",
      "Types: username=str, age=str\n"
     ]
    }
   ],
   "source": [
    "# fuzzy_validate_mapping - validate dict against schema\n",
    "from lionherd_core.ln import fuzzy_validate_mapping\n",
    "\n",
    "schema = {\"username\": str, \"age\": int, \"email\": str}\n",
    "data = {\"usrname\": \"Bob\", \"age\": \"25\", \"emal\": \"bob@example.com\"}  # typos + wrong type\n",
    "\n",
    "# Fuzzy match keys and coerce types\n",
    "validated = fuzzy_validate_mapping(\n",
    "    data,\n",
    "    schema,\n",
    "    fuzzy_match=True,\n",
    "    similarity_threshold=0.8,\n",
    "    handle_unmatched=\"force\",\n",
    ")\n",
    "\n",
    "print(\"Validated:\", validated)\n",
    "print(\n",
    "    f\"Types: username={type(validated['username']).__name__}, age={type(validated['age']).__name__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.727745Z",
     "iopub.status.busy": "2025-11-09T06:10:45.727663Z",
     "iopub.status.idle": "2025-11-09T06:10:45.730592Z",
     "shell.execute_reply": "2025-11-09T06:10:45.730247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User model: username='Charlie' age=30 email='charlie@example.com'\n",
      "Type: User\n"
     ]
    }
   ],
   "source": [
    "# fuzzy_validate_pydantic - validate against Pydantic model\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from lionherd_core.ln import FuzzyMatchKeysParams, fuzzy_validate_pydantic\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str\n",
    "    age: int\n",
    "    email: str\n",
    "\n",
    "\n",
    "# Data with typos\n",
    "messy_data = {\"usrname\": \"Charlie\", \"age\": \"30\", \"emal\": \"charlie@example.com\"}\n",
    "\n",
    "# Fuzzy validate and create model instance\n",
    "user = fuzzy_validate_pydantic(\n",
    "    messy_data,\n",
    "    User,\n",
    "    fuzzy_match=True,\n",
    "    fuzzy_match_params=FuzzyMatchKeysParams(similarity_threshold=0.8),\n",
    ")\n",
    "\n",
    "print(f\"User model: {user}\")\n",
    "print(f\"Type: {type(user).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 3. JSON Utilities - Fast Serialization with orjson\n",
    "\n",
    "High-performance JSON operations with support for custom types (UUID, datetime, Pydantic models, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.731746Z",
     "iopub.status.busy": "2025-11-09T06:10:45.731648Z",
     "iopub.status.idle": "2025-11-09T06:10:45.735332Z",
     "shell.execute_reply": "2025-11-09T06:10:45.735033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON string: {\"id\":\"b39e4fbf-8b8f-4e21-9d7a-cd8b9f6a82ba\",\"timestamp\":\"2025-11-09T15:36:35.366594+00:00\",\"data\":{\"status\":\"active\",\"count\":42}}\n",
      "JSON bytes: b'{\"id\":\"b39e4fbf-8b8f-4e21-9d7a-cd8b9f6a82ba\",\"timestamp\":\"2025-11-09T15:36:35.36'...\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from uuid import uuid4\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Custom types that need special handling\n",
    "class Event(BaseModel):\n",
    "    id: str\n",
    "    timestamp: dt.datetime\n",
    "    data: dict\n",
    "\n",
    "\n",
    "event = Event(id=str(uuid4()), timestamp=ln.now_utc(), data={\"status\": \"active\", \"count\": 42})\n",
    "\n",
    "# json_dumps - serialize to string\n",
    "json_str = ln.json_dumps(event)\n",
    "print(f\"JSON string: {json_str}\")\n",
    "\n",
    "# json_dumpb - serialize to bytes (faster)\n",
    "json_bytes = ln.json_dumpb(event)\n",
    "print(f\"JSON bytes: {json_bytes[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.736373Z",
     "iopub.status.busy": "2025-11-09T06:10:45.736305Z",
     "iopub.status.idle": "2025-11-09T06:10:45.738750Z",
     "shell.execute_reply": "2025-11-09T06:10:45.738339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pydantic → dict: {'host': 'localhost', 'port': 8000}\n",
      "Type: dict\n"
     ]
    }
   ],
   "source": [
    "# json_dict - convert object to dict via JSON roundtrip\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Config(BaseModel):\n",
    "    host: str\n",
    "    port: int\n",
    "\n",
    "\n",
    "config = Config(host=\"localhost\", port=8000)\n",
    "\n",
    "# Convert Pydantic model to plain dict via JSON\n",
    "plain_dict = ln.json_dict(config)\n",
    "print(f\"Pydantic → dict: {plain_dict}\")\n",
    "print(f\"Type: {type(plain_dict).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.739835Z",
     "iopub.status.busy": "2025-11-09T06:10:45.739755Z",
     "iopub.status.idle": "2025-11-09T06:10:45.742006Z",
     "shell.execute_reply": "2025-11-09T06:10:45.741680Z"
    }
   },
   "outputs": [],
   "source": [
    "# json_lines_iter - generate JSON Lines format\n",
    "records = [{\"id\": 1, \"name\": \"Alice\"}, {\"id\": 2, \"name\": \"Bob\"}, {\"id\": 3, \"name\": \"Charlie\"}]\n",
    "\n",
    "# Iterate to generate NDJSON lines (bytes)\n",
    "for line in ln.json_lines_iter(records):\n",
    "    print(f\"  {line.decode('utf-8')}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 4. Data Conversion - Flexible Type Handling\n",
    "\n",
    "Convert objects to dictionaries and normalize iterables to lists with extensive options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.743040Z",
     "iopub.status.busy": "2025-11-09T06:10:45.742983Z",
     "iopub.status.idle": "2025-11-09T06:10:45.745642Z",
     "shell.execute_reply": "2025-11-09T06:10:45.745290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Pydantic: {'name': 'Alice', 'age': 30}\n",
      "From dict: {'a': 1, 'b': 2}\n",
      "From JSON string: {'username': 'Bob', 'age': 25}\n"
     ]
    }
   ],
   "source": [
    "# to_dict - convert various types to dict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "# From Pydantic model\n",
    "person = Person(name=\"Alice\", age=30)\n",
    "dict1 = ln.to_dict(person)\n",
    "print(f\"From Pydantic: {dict1}\")\n",
    "\n",
    "# From dict-like object\n",
    "dict2 = ln.to_dict({\"a\": 1, \"b\": 2})\n",
    "print(f\"From dict: {dict2}\")\n",
    "\n",
    "# From JSON string\n",
    "dict3 = ln.to_dict('{\"username\": \"Bob\", \"age\": 25}')\n",
    "print(f\"From JSON string: {dict3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.746585Z",
     "iopub.status.busy": "2025-11-09T06:10:45.746526Z",
     "iopub.status.idle": "2025-11-09T06:10:45.748871Z",
     "shell.execute_reply": "2025-11-09T06:10:45.748524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened: [1, 2, 3, 4, 5, 6]\n",
      "Unique: [1, 2, 3, 4]\n",
      "Clean: [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# to_list - normalize to list with filtering\n",
    "from lionherd_core.ln import to_list\n",
    "\n",
    "# Flatten nested structures\n",
    "nested = [[1, 2], [3, None], 4, None, [5, 6]]\n",
    "flat = to_list(nested, flatten=True, dropna=True)\n",
    "print(f\"Flattened: {flat}\")\n",
    "\n",
    "# Remove duplicates (requires flatten=True)\n",
    "with_dupes = [1, 2, 2, 3, 1, 4, 3]\n",
    "unique = to_list(with_dupes, flatten=True, unique=True)\n",
    "print(f\"Unique: {unique}\")\n",
    "\n",
    "# Combine all options\n",
    "messy = [[1, None, 2], None, [2, 3], 3, [4, None]]\n",
    "clean = to_list(messy, flatten=True, dropna=True, unique=True)\n",
    "print(f\"Clean: {clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 5. Hashing - Stable Content-Based Hashing\n",
    "\n",
    "Generate consistent hashes for dicts, lists, sets, and Pydantic models (order-independent for dicts/sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.749739Z",
     "iopub.status.busy": "2025-11-09T06:10:45.749680Z",
     "iopub.status.idle": "2025-11-09T06:10:45.751701Z",
     "shell.execute_reply": "2025-11-09T06:10:45.751372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict 1 hash: 8599943207739827362\n",
      "Dict 2 hash: 8599943207739827362\n",
      "Hashes equal (order-independent): True\n"
     ]
    }
   ],
   "source": [
    "# hash_dict - stable hashing for data structures\n",
    "\n",
    "# Order-independent for dicts\n",
    "dict1 = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "dict2 = {\"c\": 3, \"a\": 1, \"b\": 2}  # Different order\n",
    "\n",
    "hash1 = ln.hash_dict(dict1)\n",
    "hash2 = ln.hash_dict(dict2)\n",
    "\n",
    "print(f\"Dict 1 hash: {hash1}\")\n",
    "print(f\"Dict 2 hash: {hash2}\")\n",
    "print(f\"Hashes equal (order-independent): {hash1 == hash2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.752580Z",
     "iopub.status.busy": "2025-11-09T06:10:45.752522Z",
     "iopub.status.idle": "2025-11-09T06:10:45.754914Z",
     "shell.execute_reply": "2025-11-09T06:10:45.754662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex structure hash: -7655103619936329721\n",
      "Same structure hash: -7655103619936329721\n",
      "Hashes equal: True\n"
     ]
    }
   ],
   "source": [
    "# Works with nested structures\n",
    "complex_data = {\n",
    "    \"users\": [{\"name\": \"Alice\", \"id\": 1}, {\"name\": \"Bob\", \"id\": 2}],\n",
    "    \"metadata\": {\"version\": \"1.0\", \"created\": \"2025-01-01\"},\n",
    "    \"tags\": {\"important\", \"reviewed\"},  # Set - order independent\n",
    "}\n",
    "\n",
    "hash_complex = ln.hash_dict(complex_data)\n",
    "print(f\"Complex structure hash: {hash_complex}\")\n",
    "\n",
    "# Same structure, different tag order → same hash\n",
    "complex_data2 = {\n",
    "    \"users\": [{\"name\": \"Alice\", \"id\": 1}, {\"name\": \"Bob\", \"id\": 2}],\n",
    "    \"metadata\": {\"created\": \"2025-01-01\", \"version\": \"1.0\"},  # Different order\n",
    "    \"tags\": {\"reviewed\", \"important\"},  # Different order\n",
    "}\n",
    "\n",
    "hash_complex2 = ln.hash_dict(complex_data2)\n",
    "print(f\"Same structure hash: {hash_complex2}\")\n",
    "print(f\"Hashes equal: {hash_complex == hash_complex2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.755880Z",
     "iopub.status.busy": "2025-11-09T06:10:45.755822Z",
     "iopub.status.idle": "2025-11-09T06:10:45.758284Z",
     "shell.execute_reply": "2025-11-09T06:10:45.758004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 1 hash: -3676016240202627472\n",
      "Config 2 hash: -3676016240202627472\n",
      "Pydantic models match: True\n"
     ]
    }
   ],
   "source": [
    "# Works with Pydantic models\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Config(BaseModel):\n",
    "    host: str\n",
    "    port: int\n",
    "    tags: set[str]\n",
    "\n",
    "\n",
    "config1 = Config(host=\"localhost\", port=8000, tags={\"dev\", \"test\"})\n",
    "config2 = Config(host=\"localhost\", port=8000, tags={\"test\", \"dev\"})  # Different tag order\n",
    "\n",
    "print(f\"Config 1 hash: {ln.hash_dict(config1)}\")\n",
    "print(f\"Config 2 hash: {ln.hash_dict(config2)}\")\n",
    "print(f\"Pydantic models match: {ln.hash_dict(config1) == ln.hash_dict(config2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 6. General Utilities - Time, Paths, Imports\n",
    "\n",
    "Essential utilities for timestamps, async path operations, data organization, and dynamic imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.759279Z",
     "iopub.status.busy": "2025-11-09T06:10:45.759214Z",
     "iopub.status.idle": "2025-11-09T06:10:45.761047Z",
     "shell.execute_reply": "2025-11-09T06:10:45.760727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current UTC: 2025-11-09 15:36:35.400821+00:00\n",
      "Timezone: UTC\n",
      "ISO format: 2025-11-09T15:36:35.400821+00:00\n"
     ]
    }
   ],
   "source": [
    "# now_utc - UTC timestamps\n",
    "timestamp = ln.now_utc()\n",
    "print(f\"Current UTC: {timestamp}\")\n",
    "print(f\"Timezone: {timestamp.tzinfo}\")\n",
    "print(f\"ISO format: {timestamp.isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.761960Z",
     "iopub.status.busy": "2025-11-09T06:10:45.761888Z",
     "iopub.status.idle": "2025-11-09T06:10:45.765122Z",
     "shell.execute_reply": "2025-11-09T06:10:45.764774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created path: /var/folders/5p/rcbw097d29j3s2qt861tsjfh0000gn/T/tmpdqxz8hip/logs/session_20251109_103635-b6ad14.log\n",
      "Filename: session_20251109_103635-b6ad14.log\n",
      "Parent exists: True\n"
     ]
    }
   ],
   "source": [
    "# acreate_path - async path creation with timestamps/hashes\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    # Create path with timestamp and random hash\n",
    "    path = await ln.acreate_path(\n",
    "        tmpdir,\n",
    "        \"logs/session\",\n",
    "        \"log\",\n",
    "        timestamp=True,\n",
    "        random_hash_digits=6,\n",
    "        timestamp_format=\"%Y%m%d_%H%M%S\",\n",
    "    )\n",
    "\n",
    "    print(f\"Created path: {path}\")\n",
    "    print(f\"Filename: {path.name}\")\n",
    "    print(f\"Parent exists: {await path.parent.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.765999Z",
     "iopub.status.busy": "2025-11-09T06:10:45.765939Z",
     "iopub.status.idle": "2025-11-09T06:10:45.768056Z",
     "shell.execute_reply": "2025-11-09T06:10:45.767720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message batches (max 30 chars):\n",
      "  Batch 1: ['Hello world', 'How are you?']\n",
      "  Batch 2: [\"I'm great!\", \"What's the weather?\"]\n",
      "  Batch 3: ['Sunny', 'Perfect!']\n"
     ]
    }
   ],
   "source": [
    "# get_bins - bin packing by cumulative string length\n",
    "messages = [\n",
    "    \"Hello world\",\n",
    "    \"How are you?\",\n",
    "    \"I'm great!\",\n",
    "    \"What's the weather?\",\n",
    "    \"Sunny\",\n",
    "    \"Perfect!\",\n",
    "]\n",
    "\n",
    "# Organize into 30-character bins\n",
    "bins = ln.get_bins(messages, upper=30)\n",
    "\n",
    "print(\"Message batches (max 30 chars):\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    batch = [messages[idx] for idx in bin_indices]\n",
    "    print(f\"  Batch {i + 1}: {batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.768919Z",
     "iopub.status.busy": "2025-11-09T06:10:45.768862Z",
     "iopub.status.idle": "2025-11-09T06:10:45.771035Z",
     "shell.execute_reply": "2025-11-09T06:10:45.770715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pydantic installed: True\n",
      "Imported: json\n",
      "Imported Path: Path\n",
      "Imported: dumps, loads\n"
     ]
    }
   ],
   "source": [
    "# import_module - dynamic imports\n",
    "from lionherd_core.ln import import_module, is_import_installed\n",
    "\n",
    "# Check if package is available\n",
    "has_pydantic = is_import_installed(\"pydantic\")\n",
    "print(f\"Pydantic installed: {has_pydantic}\")\n",
    "\n",
    "# Import module\n",
    "json_mod = import_module(\"json\")\n",
    "print(f\"Imported: {json_mod.__name__}\")\n",
    "\n",
    "# Import specific object\n",
    "Path = import_module(\"pathlib\", import_name=\"Path\")\n",
    "print(f\"Imported Path: {Path.__name__}\")\n",
    "\n",
    "# Import multiple objects\n",
    "dumps, loads = import_module(\"json\", import_name=[\"dumps\", \"loads\"])\n",
    "print(f\"Imported: {dumps.__name__}, {loads.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 7. Integration Patterns - Common Workflows\n",
    "\n",
    "Real-world combinations of ln utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.771994Z",
     "iopub.status.busy": "2025-11-09T06:10:45.771939Z",
     "iopub.status.idle": "2025-11-09T06:10:45.774236Z",
     "shell.execute_reply": "2025-11-09T06:10:45.773956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized API responses:\n",
      "  {'email': 'alice@example.com', 'user_id': 1, 'username': 'Alice'}\n",
      "  {'user_id': 2, 'username': None, 'email': None}\n",
      "  {'username': 'Charlie', 'email': 'charlie@example.com', 'user_id': None}\n"
     ]
    }
   ],
   "source": [
    "# Pattern 1: API response normalization with fuzzy matching\n",
    "from lionherd_core.ln import FuzzyMatchKeysParams\n",
    "\n",
    "# Define reusable normalizer\n",
    "api_normalizer = FuzzyMatchKeysParams(\n",
    "    similarity_threshold=0.8,\n",
    "    handle_unmatched=\"force\",\n",
    "    fill_value=None,\n",
    ")\n",
    "\n",
    "# Simulate messy API responses\n",
    "api_responses = [\n",
    "    {\"usr_id\": 1, \"usrname\": \"Alice\", \"emal\": \"alice@example.com\"},\n",
    "    {\"user_id\": 2, \"name\": \"Bob\"},  # Missing email\n",
    "    {\"id\": 3, \"username\": \"Charlie\", \"email\": \"charlie@example.com\"},\n",
    "]\n",
    "\n",
    "expected = [\"user_id\", \"username\", \"email\"]\n",
    "\n",
    "print(\"Normalized API responses:\")\n",
    "for resp in api_responses:\n",
    "    normalized = api_normalizer(resp, expected)\n",
    "    print(f\"  {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.775088Z",
     "iopub.status.busy": "2025-11-09T06:10:45.775031Z",
     "iopub.status.idle": "2025-11-09T06:10:45.861567Z",
     "shell.execute_reply": "2025-11-09T06:10:45.861113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch of 3 users\n",
      "Processed batch of 3 users\n",
      "Processed batch of 3 users\n",
      "Processed batch of 1 users\n",
      "\n",
      "Total fetched: 10 users\n",
      "Sample: [{'id': 1, 'name': 'User1', 'status': 'active'}, {'id': 2, 'name': 'User2', 'status': 'active'}]\n"
     ]
    }
   ],
   "source": [
    "# Pattern 2: Concurrent API fetching with retry and batching\n",
    "async def fetch_user(user_id):\n",
    "    \"\"\"Simulate API fetch.\"\"\"\n",
    "    await asyncio.sleep(0.01)\n",
    "    return {\"id\": user_id, \"name\": f\"User{user_id}\", \"status\": \"active\"}\n",
    "\n",
    "\n",
    "# Fetch users in controlled batches\n",
    "user_ids = list(range(1, 11))\n",
    "\n",
    "all_users = []\n",
    "async for batch in ln.bcall(\n",
    "    user_ids,\n",
    "    fetch_user,\n",
    "    batch_size=3,\n",
    "    max_concurrent=2,  # Respect rate limits\n",
    "    retry_attempts=2,\n",
    "):\n",
    "    all_users.extend(batch)\n",
    "    print(f\"Processed batch of {len(batch)} users\")\n",
    "\n",
    "print(f\"\\nTotal fetched: {len(all_users)} users\")\n",
    "print(f\"Sample: {all_users[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.862961Z",
     "iopub.status.busy": "2025-11-09T06:10:45.862859Z",
     "iopub.status.idle": "2025-11-09T06:10:45.866291Z",
     "shell.execute_reply": "2025-11-09T06:10:45.865879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 4 records\n",
      "Unique: 2 records\n",
      "Deduplicated: [{'name': 'Alice', 'age': 30, 'tags': {'senior', 'dev'}}, {'name': 'Bob', 'age': 25, 'tags': {'junior'}}]\n"
     ]
    }
   ],
   "source": [
    "# Pattern 3: Data deduplication with stable hashing\n",
    "records = [\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"tags\": {\"dev\", \"senior\"}},\n",
    "    {\"age\": 30, \"name\": \"Alice\", \"tags\": {\"senior\", \"dev\"}},  # Duplicate (different order)\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"tags\": {\"junior\"}},\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"tags\": {\"dev\", \"senior\"}},  # Another duplicate\n",
    "]\n",
    "\n",
    "# Deduplicate using stable hashing\n",
    "seen_hashes = set()\n",
    "unique_records = []\n",
    "\n",
    "for record in records:\n",
    "    record_hash = ln.hash_dict(record)\n",
    "    if record_hash not in seen_hashes:\n",
    "        seen_hashes.add(record_hash)\n",
    "        unique_records.append(record)\n",
    "\n",
    "print(f\"Original: {len(records)} records\")\n",
    "print(f\"Unique: {len(unique_records)} records\")\n",
    "print(f\"Deduplicated: {unique_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.867516Z",
     "iopub.status.busy": "2025-11-09T06:10:45.867431Z",
     "iopub.status.idle": "2025-11-09T06:10:45.870336Z",
     "shell.execute_reply": "2025-11-09T06:10:45.869900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing message batches:\n",
      "[15:36:35] Batch 1:\n",
      "  - User logged in\n",
      "  - Fetched profile data\n",
      "[15:36:35] Batch 2:\n",
      "  - Updated preferences\n",
      "  - Saved changes to database\n",
      "[15:36:35] Batch 3:\n",
      "  - Logged out\n"
     ]
    }
   ],
   "source": [
    "# Pattern 4: Message batching and timestamping\n",
    "# Organize messages into batches for processing\n",
    "messages = [\n",
    "    \"User logged in\",\n",
    "    \"Fetched profile data\",\n",
    "    \"Updated preferences\",\n",
    "    \"Saved changes to database\",\n",
    "    \"Logged out\",\n",
    "]\n",
    "\n",
    "# Batch by length (max 50 chars)\n",
    "bins = ln.get_bins(messages, upper=50)\n",
    "\n",
    "print(\"Processing message batches:\")\n",
    "for i, bin_indices in enumerate(bins):\n",
    "    batch = [messages[idx] for idx in bin_indices]\n",
    "    timestamp = ln.now_utc()\n",
    "    print(f\"[{timestamp.strftime('%H:%M:%S')}] Batch {i + 1}:\")\n",
    "    for msg in batch:\n",
    "        print(f\"  - {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 8. Parameter Objects - Reusable Configurations\n",
    "\n",
    "Use parameter dataclasses for consistent behavior across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.871416Z",
     "iopub.status.busy": "2025-11-09T06:10:45.871335Z",
     "iopub.status.idle": "2025-11-09T06:10:45.898681Z",
     "shell.execute_reply": "2025-11-09T06:10:45.898241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (double): [2, 4, 6]\n",
      "Result 2 (square): [1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "# AlcallParams - reusable async call configuration\n",
    "from lionherd_core.ln import AlcallParams\n",
    "\n",
    "# Define standard API client config\n",
    "api_client_params = AlcallParams(\n",
    "    max_concurrent=5,\n",
    "    retry_attempts=3,\n",
    "    retry_initial_delay=0.1,\n",
    "    retry_backoff=2.0,\n",
    "    retry_timeout=5.0,\n",
    ")\n",
    "\n",
    "\n",
    "# Use with different functions/inputs\n",
    "async def api_call_1(x):\n",
    "    await asyncio.sleep(0.01)\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "async def api_call_2(x):\n",
    "    await asyncio.sleep(0.01)\n",
    "    return x**2\n",
    "\n",
    "\n",
    "result1 = await api_client_params([1, 2, 3], api_call_1)\n",
    "result2 = await api_client_params([1, 2, 3], api_call_2)\n",
    "\n",
    "print(f\"Result 1 (double): {result1}\")\n",
    "print(f\"Result 2 (square): {result2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T06:10:45.899765Z",
     "iopub.status.busy": "2025-11-09T06:10:45.899692Z",
     "iopub.status.idle": "2025-11-09T06:10:45.902022Z",
     "shell.execute_reply": "2025-11-09T06:10:45.901612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenient normalization: {'age': 30, 'username': 'Alice', 'email': None}\n"
     ]
    }
   ],
   "source": [
    "# FuzzyMatchKeysParams - reusable fuzzy matching config\n",
    "from lionherd_core.ln import FuzzyMatchKeysParams\n",
    "\n",
    "# Strict validator for API inputs\n",
    "strict_validator = FuzzyMatchKeysParams(\n",
    "    similarity_threshold=0.9,\n",
    "    handle_unmatched=\"raise\",\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "# Lenient normalizer for user inputs\n",
    "lenient_normalizer = FuzzyMatchKeysParams(\n",
    "    similarity_threshold=0.7,\n",
    "    handle_unmatched=\"force\",\n",
    "    fill_value=None,\n",
    ")\n",
    "\n",
    "# Use them\n",
    "user_data = {\"usrname\": \"Alice\", \"age\": 30}\n",
    "schema = [\"username\", \"age\", \"email\"]\n",
    "\n",
    "normalized = lenient_normalizer(user_data, schema)\n",
    "print(f\"Lenient normalization: {normalized}\")\n",
    "\n",
    "# Strict would raise (uncomment to test)\n",
    "# strict_validator(user_data, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": "## Summary Checklist\n\n**ln Module Essentials:**\n\n**Async Operations:**\n- ✅ `alcall` for concurrent function mapping with retry/throttle/error handling\n- ✅ `bcall` for batch processing with incremental results\n- ✅ `lcall` for simple list comprehension-style operations\n\n**Fuzzy Matching:**\n- ✅ `fuzzy_match_keys` for typo-tolerant dictionary validation\n- ✅ `fuzzy_validate_mapping` for schema validation with type coercion\n- ✅ `fuzzy_validate_pydantic` for Pydantic model validation\n\n**JSON Utilities:**\n- ✅ `json_dumps/json_dumpb` for fast serialization with custom handlers\n- ✅ `json_dict` for parsing with fuzzy matching\n- ✅ `json_lines_iter` for generating NDJSON format\n\n**Data Conversion:**\n- ✅ `to_dict` for flexible object → dict conversion\n- ✅ `to_list` for normalizing iterables with flatten/dropna/unique\n\n**Hashing:**\n- ✅ `hash_dict` for stable, order-independent hashing\n\n**General Utilities:**\n- ✅ `now_utc` for UTC timestamps\n- ✅ `acreate_path` for async path creation with timestamps/hashes\n- ✅ `get_bins` for bin packing by string length\n- ✅ `import_module/is_import_installed` for dynamic imports\n\n**Next Steps:**\n- See individual notebooks for deep dives: `ln_async_call`, `ln_fuzzy_match`, `ln_utils`, etc.\n- See `base.Element` for integration with lionherd's serialization\n- See `types.Spec` for structured data with fuzzy validation\n- Use in production for robust data processing, API integration, and workflow orchestration"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
