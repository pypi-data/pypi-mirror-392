{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Async Call Utilities - Concurrent Function Mapping with Retry and Control\n",
    "\n",
    "The `ln` module provides powerful async utilities for applying functions to lists with comprehensive control:\n",
    "\n",
    "**Core Functions:**\n",
    "- **`alcall`**: Async list map with retry, concurrency control, and error handling\n",
    "- **`bcall`**: Batch processing generator yielding results incrementally\n",
    "\n",
    "**Key Features:**\n",
    "- **Input/Output Processing**: Flatten, filter, deduplicate collections\n",
    "- **Retry Logic**: Exponential backoff with configurable attempts\n",
    "- **Timeout Control**: Per-call timeouts with cancellation\n",
    "- **Concurrency Limits**: Semaphore-based max concurrent execution\n",
    "- **Throttling**: Delay between task starts for rate limiting\n",
    "- **Exception Handling**: Return or raise exceptions with proper grouping\n",
    "- **Order Preservation**: Results maintain input order regardless of completion time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from lionherd_core.ln import AlcallParams, alcall, bcall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Basic Usage - Async Mapping\n",
    "\n",
    "`alcall` applies a function to each list element concurrently, handling both sync and async functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync function: [2, 4, 6, 8]\n",
      "Async function: [2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "# Sync function\n",
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Async function\n",
    "async def async_double(x):\n",
    "    await asyncio.sleep(0.01)  # Simulate async work\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Apply sync function\n",
    "result_sync = await alcall([1, 2, 3, 4], double)\n",
    "print(f\"Sync function: {result_sync}\")\n",
    "\n",
    "# Apply async function\n",
    "result_async = await alcall([1, 2, 3, 4], async_double)\n",
    "print(f\"Async function: {result_async}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Input Processing - Clean and Transform Input\n",
    "\n",
    "Process input before applying the function: flatten nested structures, remove None values, deduplicate.\n",
    "\n",
    "**Note:** When flattening without `dropna`, None values are included and may cause errors unless handled with `return_exceptions=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten: [2, 4, 6, TypeError(\"unsupported operand type(s) for *: 'NoneType' and 'int'\"), 2, 8, TypeError(\"unsupported operand type(s) for *: 'NoneType' and 'int'\"), 10]\n",
      "Flatten + dropna: [2, 4, 6, 2, 8, 10]\n",
      "Flatten + dropna + unique: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Nested list with duplicates and None\n",
    "nested_input = [[1, 2], [3, None], [1, 4], None, 5]\n",
    "\n",
    "# Flatten only - Note: None values cause errors unless handled\n",
    "result_flatten = await alcall(nested_input, double, input_flatten=True, return_exceptions=True)\n",
    "print(f\"Flatten: {result_flatten}\")\n",
    "\n",
    "# Flatten + drop None - this removes None values before processing\n",
    "result_dropna = await alcall(nested_input, double, input_flatten=True, input_dropna=True)\n",
    "print(f\"Flatten + dropna: {result_dropna}\")\n",
    "\n",
    "# Flatten + drop None + unique\n",
    "result_unique = await alcall(\n",
    "    nested_input, double, input_flatten=True, input_dropna=True, input_unique=True\n",
    ")\n",
    "print(f\"Flatten + dropna + unique: {result_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 3. Output Processing - Transform Results\n",
    "\n",
    "Same processing options available for output: flatten nested results, filter None, deduplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: [[[1, 1], [10]], None, [[3, 3], [30]]]\n",
      "Flatten output: [1, 1, 10, None, 3, 3, 30]\n",
      "Flatten + dropna output: [1, 1, 10, 3, 3, 30]\n"
     ]
    }
   ],
   "source": [
    "# Function that returns nested lists\n",
    "def make_nested(x):\n",
    "    if x == 2:\n",
    "        return None  # Some items return None\n",
    "    return [[x, x], [x * 10]]\n",
    "\n",
    "\n",
    "# Raw output\n",
    "result_raw = await alcall([1, 2, 3], make_nested)\n",
    "print(f\"Raw: {result_raw}\")\n",
    "\n",
    "# Flatten output\n",
    "result_flatten_out = await alcall([1, 2, 3], make_nested, output_flatten=True)\n",
    "print(f\"Flatten output: {result_flatten_out}\")\n",
    "\n",
    "# Flatten + drop None\n",
    "result_clean = await alcall([1, 2, 3], make_nested, output_flatten=True, output_dropna=True)\n",
    "print(f\"Flatten + dropna output: {result_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 4. Retry Mechanism - Handle Transient Failures\n",
    "\n",
    "Configure retry attempts with exponential backoff for resilient operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [2, 4, 6]\n",
      "Attempts per item: {1: 3, 2: 3, 3: 3}\n"
     ]
    }
   ],
   "source": [
    "# Flaky function that fails first 2 attempts\n",
    "attempt_count = {}\n",
    "\n",
    "\n",
    "def flaky_func(x):\n",
    "    attempt_count[x] = attempt_count.get(x, 0) + 1\n",
    "    if attempt_count[x] < 3:  # Fail first 2 attempts\n",
    "        raise ValueError(f\"Attempt {attempt_count[x]} failed for {x}\")\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Reset counter\n",
    "attempt_count.clear()\n",
    "\n",
    "# Retry up to 3 times with 0.01s initial delay, 2x backoff\n",
    "result = await alcall(\n",
    "    [1, 2, 3],\n",
    "    flaky_func,\n",
    "    retry_attempts=3,\n",
    "    retry_initial_delay=0.01,\n",
    "    retry_backoff=2.0,\n",
    ")\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"Attempts per item: {attempt_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With retry_default: [-1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "# Use retry_default to return value instead of raising on exhaustion\n",
    "def always_fails(x):\n",
    "    raise ValueError(f\"Always fails for {x}\")\n",
    "\n",
    "\n",
    "result_default = await alcall(\n",
    "    [1, 2, 3],\n",
    "    always_fails,\n",
    "    retry_attempts=2,\n",
    "    retry_default=-1,  # Return -1 instead of raising\n",
    ")\n",
    "print(f\"With retry_default: {result_default}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 5. Timeout Control - Limit Execution Time\n",
    "\n",
    "Set per-call timeouts to prevent hanging operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With timeout (item 2 timed out): [2, -1, 6]\n"
     ]
    }
   ],
   "source": [
    "async def slow_func(x):\n",
    "    if x == 2:\n",
    "        await asyncio.sleep(1.0)  # This will timeout\n",
    "    else:\n",
    "        await asyncio.sleep(0.01)\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Timeout after 0.1 seconds, return -1 on timeout\n",
    "result_timeout = await alcall(\n",
    "    [1, 2, 3],\n",
    "    slow_func,\n",
    "    retry_timeout=0.1,\n",
    "    retry_default=-1,  # TimeoutError → -1\n",
    ")\n",
    "print(f\"With timeout (item 2 timed out): {result_timeout}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 6. Concurrency Control - Limit Parallel Execution\n",
    "\n",
    "Use `max_concurrent` to limit simultaneous executions (e.g., API rate limits, resource constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [1, 2, 3, 4, 5]\n",
      "Max concurrent executions: 2 (limit was 2)\n"
     ]
    }
   ],
   "source": [
    "# Track concurrent executions\n",
    "concurrent_count = 0\n",
    "max_seen = 0\n",
    "\n",
    "\n",
    "async def track_concurrent(x):\n",
    "    global concurrent_count, max_seen\n",
    "    concurrent_count += 1\n",
    "    max_seen = max(max_seen, concurrent_count)\n",
    "    await asyncio.sleep(0.05)\n",
    "    concurrent_count -= 1\n",
    "    return x\n",
    "\n",
    "\n",
    "# Reset counters\n",
    "concurrent_count = 0\n",
    "max_seen = 0\n",
    "\n",
    "# Limit to 2 concurrent executions\n",
    "result_limited = await alcall([1, 2, 3, 4, 5], track_concurrent, max_concurrent=2)\n",
    "print(f\"Result: {result_limited}\")\n",
    "print(f\"Max concurrent executions: {max_seen} (limit was 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 7. Throttling - Rate Limit Task Starts\n",
    "\n",
    "Add delay between starting tasks to control burst rate (different from max_concurrent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time intervals: ['0.051s', '0.050s', '0.051s']\n",
      "All intervals >= 0.05s: True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_times = []\n",
    "\n",
    "\n",
    "async def record_start(x):\n",
    "    start_times.append(time.time())\n",
    "    return x\n",
    "\n",
    "\n",
    "# Reset\n",
    "start_times.clear()\n",
    "\n",
    "# 0.05s delay between starting each task\n",
    "result_throttle = await alcall([1, 2, 3, 4], record_start, throttle_period=0.05)\n",
    "\n",
    "# Calculate intervals\n",
    "intervals = [start_times[i] - start_times[i - 1] for i in range(1, len(start_times))]\n",
    "print(f\"Start time intervals: {[f'{x:.3f}s' for x in intervals]}\")\n",
    "print(f\"All intervals >= 0.05s: {all(x >= 0.04 for x in intervals)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 8. Exception Handling - Control Error Behavior\n",
    "\n",
    "Choose to return exceptions as values or raise them as ExceptionGroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results (with exception): [2, ValueError('Failed on 2'), 6]\n",
      "Exception at index 1: True\n",
      "Exception message: Failed on 2\n"
     ]
    }
   ],
   "source": [
    "def selective_fail(x):\n",
    "    if x == 2:\n",
    "        raise ValueError(f\"Failed on {x}\")\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Return exceptions as values\n",
    "result_exceptions = await alcall([1, 2, 3], selective_fail, return_exceptions=True)\n",
    "print(f\"Results (with exception): {result_exceptions}\")\n",
    "print(f\"Exception at index 1: {isinstance(result_exceptions[1], ValueError)}\")\n",
    "print(f\"Exception message: {result_exceptions[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught ExceptionGroup with 1 exception(s)\n",
      "First exception: Failed on 2\n"
     ]
    }
   ],
   "source": [
    "# Raise exceptions (default behavior)\n",
    "try:\n",
    "    result_raise = await alcall([1, 2, 3], selective_fail, return_exceptions=False)\n",
    "except ExceptionGroup as eg:\n",
    "    print(f\"Caught ExceptionGroup with {len(eg.exceptions)} exception(s)\")\n",
    "    print(f\"First exception: {eg.exceptions[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 9. Order Preservation - Results Match Input Order\n",
    "\n",
    "Results are returned in input order regardless of completion time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input order: [1, 2, 3, 4]\n",
      "Result (preserved order): [10, 20, 30, 40]\n",
      "Matches expected [10, 20, 30, 40]: True\n"
     ]
    }
   ],
   "source": [
    "async def variable_delay(x):\n",
    "    # Later items finish first (reverse order completion)\n",
    "    await asyncio.sleep(0.05 * (5 - x))\n",
    "    return x * 10\n",
    "\n",
    "\n",
    "result_ordered = await alcall([1, 2, 3, 4], variable_delay)\n",
    "print(\"Input order: [1, 2, 3, 4]\")\n",
    "print(f\"Result (preserved order): {result_ordered}\")\n",
    "print(f\"Matches expected [10, 20, 30, 40]: {result_ordered == [10, 20, 30, 40]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 10. Batch Processing - bcall for Incremental Results\n",
    "\n",
    "`bcall` processes input in batches, yielding results incrementally (useful for large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: [2, 4, 6]\n",
      "Batch 2: [8, 10, 12]\n",
      "Batch 3: [14, 16, 18]\n",
      "Batch 4: [20]\n",
      "\n",
      "All results: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
      "Total items: 10\n"
     ]
    }
   ],
   "source": [
    "async def process_item(x):\n",
    "    await asyncio.sleep(0.01)\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Process 10 items in batches of 3\n",
    "all_results = []\n",
    "batch_num = 0\n",
    "\n",
    "async for batch_result in bcall(list(range(1, 11)), process_item, batch_size=3):\n",
    "    batch_num += 1\n",
    "    print(f\"Batch {batch_num}: {batch_result}\")\n",
    "    all_results.extend(batch_result)\n",
    "\n",
    "print(f\"\\nAll results: {all_results}\")\n",
    "print(f\"Total items: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 11. Parameter Objects - Reusable Configurations\n",
    "\n",
    "Use `AlcallParams` to define reusable parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: [2, 4, 6]\n",
      "Result 2: [8, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "# Create reusable parameter configuration\n",
    "params = AlcallParams(\n",
    "    retry_attempts=2,\n",
    "    retry_initial_delay=0.01,\n",
    "    retry_backoff=2.0,\n",
    "    max_concurrent=3,\n",
    ")\n",
    "\n",
    "# Use params with different inputs/functions\n",
    "# Additional parameters like return_exceptions can be passed as keyword arguments\n",
    "result1 = await params([1, 2, 3], double, return_exceptions=True)\n",
    "result2 = await params([4, 5, 6], async_double, return_exceptions=True)\n",
    "\n",
    "print(f\"Result 1: {result1}\")\n",
    "print(f\"Result 2: {result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 12. Complex Example - Real-World API Simulation\n",
    "\n",
    "Combine multiple features for robust API-like operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total API calls: 8\n",
      "Attempts per user: {1: 1, 2: 1, 3: 2, 4: 1, 5: 2, 6: 1}\n",
      "\n",
      "Results:\n",
      "  User 1: {'user_id': 1, 'name': 'User1', 'score': 10}\n",
      "  User 2: {'user_id': 2, 'name': 'User2', 'score': 20}\n",
      "  User 3: {'user_id': 3, 'name': 'User3', 'score': 30}\n",
      "  User 4: {'user_id': 4, 'name': 'User4', 'score': 40}\n",
      "  User 5: {'user_id': 5, 'name': 'User5', 'score': 50}\n",
      "  User 6: {'user_id': 6, 'name': 'User6', 'score': 60}\n"
     ]
    }
   ],
   "source": [
    "# Simulate API with rate limits and transient failures\n",
    "api_call_count = 0\n",
    "failure_ids = {3, 5}  # These IDs fail first attempt\n",
    "attempt_tracker = {}\n",
    "\n",
    "\n",
    "async def api_fetch(user_id):\n",
    "    global api_call_count\n",
    "    api_call_count += 1\n",
    "    attempt_tracker[user_id] = attempt_tracker.get(user_id, 0) + 1\n",
    "\n",
    "    # Simulate transient failures\n",
    "    if user_id in failure_ids and attempt_tracker[user_id] == 1:\n",
    "        raise ConnectionError(f\"Network error for user {user_id}\")\n",
    "\n",
    "    # Simulate API delay\n",
    "    await asyncio.sleep(0.02)\n",
    "    return {\"user_id\": user_id, \"name\": f\"User{user_id}\", \"score\": user_id * 10}\n",
    "\n",
    "\n",
    "# Reset tracking\n",
    "api_call_count = 0\n",
    "attempt_tracker.clear()\n",
    "\n",
    "# Fetch user data with:\n",
    "# - Max 3 concurrent requests (rate limit)\n",
    "# - Retry transient failures (up to 2 retries)\n",
    "# - 0.5s timeout per request\n",
    "# - Return exceptions instead of crashing\n",
    "user_ids = [1, 2, 3, 4, 5, 6]\n",
    "results = await alcall(\n",
    "    user_ids,\n",
    "    api_fetch,\n",
    "    max_concurrent=3,\n",
    "    retry_attempts=2,\n",
    "    retry_initial_delay=0.01,\n",
    "    retry_timeout=0.5,\n",
    "    return_exceptions=True,\n",
    ")\n",
    "\n",
    "print(f\"Total API calls: {api_call_count}\")\n",
    "print(f\"Attempts per user: {attempt_tracker}\")\n",
    "print(\"\\nResults:\")\n",
    "for i, result in enumerate(results):\n",
    "    if isinstance(result, Exception):\n",
    "        print(f\"  User {user_ids[i]}: ERROR - {result}\")\n",
    "    else:\n",
    "        print(f\"  User {user_ids[i]}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "**Async Call Utilities Essentials:**\n",
    "- ✅ Apply functions to lists concurrently with `alcall`\n",
    "- ✅ Process batches incrementally with `bcall` generator\n",
    "- ✅ Clean input: flatten, dropna, unique\n",
    "- ✅ Transform output: same processing options\n",
    "- ✅ Retry failed operations with exponential backoff\n",
    "- ✅ Set per-call timeouts to prevent hanging\n",
    "- ✅ Limit concurrent execution with semaphores\n",
    "- ✅ Throttle task starts for rate limiting\n",
    "- ✅ Handle exceptions: return as values or raise as group\n",
    "- ✅ Preserve input order regardless of completion time\n",
    "- ✅ Support both sync and async functions transparently\n",
    "- ✅ Reuse configurations with `AlcallParams`\n",
    "\n",
    "**Next Steps:**\n",
    "- See `to_list` for input/output processing details\n",
    "- See `concurrency` module for underlying primitives\n",
    "- Use in production for robust API calls, data processing, and parallel workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
