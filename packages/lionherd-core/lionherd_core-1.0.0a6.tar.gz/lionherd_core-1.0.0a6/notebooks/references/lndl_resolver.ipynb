{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LNDL Resolver - Tool Resolution & Registry Management\n",
    "\n",
    "The LNDL (Lion Directive Language) resolver is the core validation and execution engine that:\n",
    "\n",
    "**Core Features:**\n",
    "- **Reference Resolution**: Maps variable/action names to values using namespace-prefixed declarations\n",
    "- **Type Validation**: Validates outputs against Operable specs (strict type checking)\n",
    "- **Action Lifecycle**: Manages three-phase action execution (parse → execute → revalidate)\n",
    "- **Mixed Inputs**: Supports combining static lvars with dynamic lacts in BaseModel construction\n",
    "- **Error Aggregation**: Collects validation errors into ExceptionGroups for batch reporting\n",
    "\n",
    "**Key Functions:**\n",
    "- `parse_lndl()`: High-level API - parses full LLM response and validates\n",
    "- `resolve_references_prefixed()`: Low-level resolver - validates OUT{} block against specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from lionherd_core.lndl import (\n",
    "    ActionCall,\n",
    "    ensure_no_action_calls,\n",
    "    has_action_calls,\n",
    "    parse_lndl,\n",
    "    resolve_references_prefixed,\n",
    "    revalidate_with_action_results,\n",
    ")\n",
    "from lionherd_core.lndl.errors import MissingFieldError, TypeMismatchError\n",
    "from lionherd_core.types import Operable, Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Resolution - Static Variables Only\n",
    "\n",
    "Start with the simplest case: resolving static lvar declarations without actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: title='Quarterly Analysis' score=0.92\n",
      "Title: Quarterly Analysis\n",
      "Score: 0.92\n",
      "Type: Report\n"
     ]
    }
   ],
   "source": [
    "# Define a simple model\n",
    "class Report(BaseModel):\n",
    "    title: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "# Create Operable with Report spec\n",
    "operable = Operable(specs=[Spec(name=\"report\", base_type=Report)])\n",
    "\n",
    "# Mock LNDL response with lvars\n",
    "response = \"\"\"\n",
    "<lvar Report.title t>Quarterly Analysis</lvar>\n",
    "<lvar Report.score s>0.92</lvar>\n",
    "\n",
    "OUT{\n",
    "    report: [t, s]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Parse and resolve\n",
    "output = parse_lndl(response, operable)\n",
    "\n",
    "print(f\"Report: {output.report}\")\n",
    "print(f\"Title: {output.report.title}\")\n",
    "print(f\"Score: {output.report.score}\")\n",
    "print(f\"Type: {type(output.report).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LNDLOutput Structure\n",
    "\n",
    "Understanding the output object's structure and access patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access patterns:\n",
      "1. Attribute: title='Quarterly Analysis' score=0.92\n",
      "2. Dict-style: title='Quarterly Analysis' score=0.92\n",
      "3. Fields dict: title='Quarterly Analysis' score=0.92\n",
      "\n",
      "Lvars declared: ['t', 's']\n",
      "Lacts declared: []\n",
      "Actions referenced in OUT{}: []\n",
      "\n",
      "Lvar 't' metadata:\n",
      "  Model: Report\n",
      "  Field: title\n",
      "  Value: Quarterly Analysis\n"
     ]
    }
   ],
   "source": [
    "# Access fields multiple ways\n",
    "print(\"Access patterns:\")\n",
    "print(f\"1. Attribute: {output.report}\")\n",
    "print(f\"2. Dict-style: {output['report']}\")\n",
    "print(f\"3. Fields dict: {output.fields['report']}\")\n",
    "\n",
    "# Inspect metadata\n",
    "print(f\"\\nLvars declared: {list(output.lvars.keys())}\")\n",
    "print(f\"Lacts declared: {list(output.lacts.keys())}\")\n",
    "print(f\"Actions referenced in OUT{{}}: {list(output.actions.keys())}\")\n",
    "\n",
    "# Check lvar metadata\n",
    "lvar_t = output.lvars[\"t\"]\n",
    "print(\"\\nLvar 't' metadata:\")\n",
    "print(f\"  Model: {lvar_t.model}\")\n",
    "print(f\"  Field: {lvar_t.field}\")\n",
    "print(f\"  Value: {lvar_t.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scalar Field Resolution\n",
    "\n",
    "Scalar fields (str, int, float, bool) have special handling - single variable or literal assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Direct Literal (type: str)\n",
      "Count: 42 (type: int)\n",
      "Ratio: 0.75 (type: float)\n",
      "Active: True (type: bool)\n"
     ]
    }
   ],
   "source": [
    "# Operable with scalar specs\n",
    "operable_scalars = Operable(\n",
    "    specs=[\n",
    "        Spec(name=\"title\", base_type=str),\n",
    "        Spec(name=\"count\", base_type=int),\n",
    "        Spec(name=\"ratio\", base_type=float),\n",
    "        Spec(name=\"active\", base_type=bool),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = \"\"\"\n",
    "OUT{\n",
    "    title: \"Direct Literal\",\n",
    "    count: 42,\n",
    "    ratio: 0.75,\n",
    "    active: true\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output = parse_lndl(response, operable_scalars)\n",
    "\n",
    "print(f\"Title: {output.title} (type: {type(output.title).__name__})\")\n",
    "print(f\"Count: {output.count} (type: {type(output.count).__name__})\")\n",
    "print(f\"Ratio: {output.ratio} (type: {type(output.ratio).__name__})\")\n",
    "print(f\"Active: {output.active} (type: {type(output.active).__name__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Required vs Optional Fields\n",
    "\n",
    "Specs can be marked as required (default) or optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: required_field = Present\n",
      "Optional field in output: False\n",
      "\n",
      "✓ Missing required field caught: Required field 'required_field' missing from OUT{}\n"
     ]
    }
   ],
   "source": [
    "# Operable with required and optional fields\n",
    "operable_mixed = Operable(\n",
    "    specs=[\n",
    "        Spec(name=\"required_field\", base_type=str, required=True),\n",
    "        Spec(name=\"optional_field\", base_type=str, required=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Valid: required field present, optional missing\n",
    "response_valid = \"\"\"\n",
    "OUT{\n",
    "    required_field: \"Present\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output = parse_lndl(response_valid, operable_mixed)\n",
    "print(f\"Valid: required_field = {output.required_field}\")\n",
    "print(f\"Optional field in output: {'optional_field' in output.fields}\")\n",
    "\n",
    "# Invalid: required field missing\n",
    "response_invalid = \"\"\"\n",
    "OUT{\n",
    "    optional_field: \"Only optional\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    parse_lndl(response_invalid, operable_mixed)\n",
    "except MissingFieldError as e:\n",
    "    print(f\"\\n✓ Missing required field caught: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Action Lifecycle - Three Phases\n",
    "\n",
    "Actions follow a strict lifecycle: **Parse → Execute → Revalidate**\n",
    "\n",
    "Phase 1 (Parse): ActionCall objects created, partial validation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Parse complete\n",
      "Search result type: SearchResult\n",
      "Query (static): AI research\n",
      "Results (ActionCall): ActionCall(name='r', function='search_api', arguments={'query': 'AI', 'limit': 10}, raw_call='search_api(query=\"AI\", limit=10)')\n",
      "Results type: ActionCall\n",
      "\n",
      "Has action calls: True\n",
      "Actions to execute: ['r']\n"
     ]
    }
   ],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    query: str\n",
    "    results: int = Field(gt=0)  # Must be positive\n",
    "\n",
    "\n",
    "operable_action = Operable(specs=[Spec(name=\"search\", base_type=SearchResult)])\n",
    "\n",
    "response_with_action = \"\"\"\n",
    "<lvar SearchResult.query q>AI research</lvar>\n",
    "<lact SearchResult.results r>search_api(query=\"AI\", limit=10)</lact>\n",
    "\n",
    "OUT{\n",
    "    search: [q, r]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Phase 1: Parse - creates ActionCall placeholders\n",
    "output = parse_lndl(response_with_action, operable_action)\n",
    "\n",
    "print(\"Phase 1: Parse complete\")\n",
    "print(f\"Search result type: {type(output.search).__name__}\")\n",
    "print(f\"Query (static): {output.search.query}\")\n",
    "print(f\"Results (ActionCall): {output.search.results}\")\n",
    "print(f\"Results type: {type(output.search.results).__name__}\")\n",
    "\n",
    "# Check for actions\n",
    "print(f\"\\nHas action calls: {has_action_calls(output.search)}\")\n",
    "print(f\"Actions to execute: {list(output.actions.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase 2 (Execute)**: Caller executes actions using the `.actions` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: search_api({'query': 'AI', 'limit': 10})\n",
      "\n",
      "Phase 2: Execution complete\n",
      "Action results: {'r': 10}\n"
     ]
    }
   ],
   "source": [
    "# Mock action execution\n",
    "def execute_action(action: ActionCall) -> int:\n",
    "    \"\"\"Mock tool executor - returns count based on limit.\"\"\"\n",
    "    print(f\"Executing: {action.function}({action.arguments})\")\n",
    "    limit = action.arguments.get(\"limit\", 5)\n",
    "    return limit  # Simulate API returning result count\n",
    "\n",
    "\n",
    "# Execute all actions\n",
    "action_results = {}\n",
    "for name, action in output.actions.items():\n",
    "    result = execute_action(action)\n",
    "    action_results[name] = result\n",
    "\n",
    "print(\"\\nPhase 2: Execution complete\")\n",
    "print(f\"Action results: {action_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase 3 (Revalidate)**: Replace ActionCall objects with results and run full Pydantic validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3: Revalidation complete\n",
      "Query: AI research\n",
      "Results: 10 (type: int)\n",
      "Has action calls: False\n",
      "\n",
      "✓ Safe for database: query='AI research' results=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lion/projects/open-source/lionherd-core/.venv/lib/python3.11/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [field_name='results', input_value=ActionCall(name='r', func...(query=\"AI\", limit=10)'), input_type=ActionCall])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Revalidate with action results\n",
    "validated_search = revalidate_with_action_results(output.search, action_results)\n",
    "\n",
    "print(\"Phase 3: Revalidation complete\")\n",
    "print(f\"Query: {validated_search.query}\")\n",
    "print(f\"Results: {validated_search.results} (type: {type(validated_search.results).__name__})\")\n",
    "print(f\"Has action calls: {has_action_calls(validated_search)}\")\n",
    "\n",
    "# Now safe for persistence\n",
    "final = ensure_no_action_calls(validated_search)\n",
    "print(f\"\\n✓ Safe for database: {final}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Direct Actions - Returning Entire Models\n",
    "\n",
    "Direct actions (no namespace) can return complete BaseModel instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct action parsed:\n",
      "Document type: ActionCall\n",
      "Action to execute: ActionCall(name='fetch_doc', function='fetch_document', arguments={'doc_id': 'report-123'}, raw_call='fetch_document(doc_id=\"report-123\")')\n",
      "\n",
      "After execution:\n",
      "Document: title='Q4 Report' content='Full text...' word_count=1500\n",
      "Title: Q4 Report\n"
     ]
    }
   ],
   "source": [
    "class Document(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "    word_count: int\n",
    "\n",
    "\n",
    "operable_doc = Operable(specs=[Spec(name=\"document\", base_type=Document)])\n",
    "\n",
    "# Direct action returns entire Document\n",
    "response_direct = \"\"\"\n",
    "<lact fetch_doc>fetch_document(doc_id=\"report-123\")</lact>\n",
    "\n",
    "OUT{\n",
    "    document: [fetch_doc]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output = parse_lndl(response_direct, operable_doc)\n",
    "\n",
    "print(\"Direct action parsed:\")\n",
    "print(f\"Document type: {type(output.document).__name__}\")\n",
    "print(f\"Action to execute: {output.actions['fetch_doc']}\")\n",
    "\n",
    "# Mock execution returning full model\n",
    "mock_document = Document(title=\"Q4 Report\", content=\"Full text...\", word_count=1500)\n",
    "action_results = {\"fetch_doc\": mock_document}\n",
    "\n",
    "# The direct action case is simpler - just replace the field value\n",
    "output.fields[\"document\"] = action_results[\"fetch_doc\"]\n",
    "\n",
    "print(\"\\nAfter execution:\")\n",
    "print(f\"Document: {output.document}\")\n",
    "print(f\"Title: {output.document.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Mixing Lvars and Lacts\n",
    "\n",
    "Powerful pattern: combine static values with dynamic actions in the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed lvar/lact construction:\n",
      "Dataset (static): customer_churn\n",
      "Method (static): random_forest\n",
      "Accuracy (action): ActionCall(name='acc', function='evaluate_model', arguments={'dataset': 'customer_churn'}, raw_call='evaluate_model(dataset=\"customer_churn\")')\n",
      "Confidence (action): ActionCall(name='conf', function='calculate_confidence', arguments={'model': 'rf'}, raw_call='calculate_confidence(model=\"rf\")')\n",
      "\n",
      "After revalidation:\n",
      "Accuracy: 0.87\n",
      "Confidence: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lion/projects/open-source/lionherd-core/.venv/lib/python3.11/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `float` - serialized value may not be as expected [field_name='accuracy', input_value=ActionCall(name='acc', fu...aset=\"customer_churn\")'), input_type=ActionCall])\n",
      "  PydanticSerializationUnexpectedValue(Expected `float` - serialized value may not be as expected [field_name='confidence', input_value=ActionCall(name='conf', f...confidence(model=\"rf\")'), input_type=ActionCall])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "class Analysis(BaseModel):\n",
    "    dataset: str  # Static\n",
    "    method: str  # Static\n",
    "    accuracy: float  # Dynamic (from action)\n",
    "    confidence: float  # Dynamic (from action)\n",
    "\n",
    "\n",
    "operable_mixed = Operable(specs=[Spec(name=\"analysis\", base_type=Analysis)])\n",
    "\n",
    "response_mixed = \"\"\"\n",
    "<lvar Analysis.dataset d>customer_churn</lvar>\n",
    "<lvar Analysis.method m>random_forest</lvar>\n",
    "<lact Analysis.accuracy acc>evaluate_model(dataset=\"customer_churn\")</lact>\n",
    "<lact Analysis.confidence conf>calculate_confidence(model=\"rf\")</lact>\n",
    "\n",
    "OUT{\n",
    "    analysis: [d, m, acc, conf]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output = parse_lndl(response_mixed, operable_mixed)\n",
    "\n",
    "print(\"Mixed lvar/lact construction:\")\n",
    "print(f\"Dataset (static): {output.analysis.dataset}\")\n",
    "print(f\"Method (static): {output.analysis.method}\")\n",
    "print(f\"Accuracy (action): {output.analysis.accuracy}\")\n",
    "print(f\"Confidence (action): {output.analysis.confidence}\")\n",
    "\n",
    "# Execute actions\n",
    "action_results = {\"acc\": 0.87, \"conf\": 0.92}\n",
    "validated_analysis = revalidate_with_action_results(output.analysis, action_results)\n",
    "\n",
    "print(\"\\nAfter revalidation:\")\n",
    "print(f\"Accuracy: {validated_analysis.accuracy}\")\n",
    "print(f\"Confidence: {validated_analysis.confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Handling - Type Mismatches\n",
    "\n",
    "The resolver validates that variable/action namespaces match the expected model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Type mismatch caught:\n",
      "  Variable 't' is for model 'Product', but field 'user' expects 'User'\n"
     ]
    }
   ],
   "source": [
    "class User(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "\n",
    "\n",
    "class Product(BaseModel):\n",
    "    title: str\n",
    "    price: float\n",
    "\n",
    "\n",
    "operable_mismatch = Operable(specs=[Spec(name=\"user\", base_type=User)])\n",
    "\n",
    "# Wrong model namespace\n",
    "response_wrong = \"\"\"\n",
    "<lvar Product.title t>Laptop</lvar>\n",
    "<lvar User.name n>Alice</lvar>\n",
    "\n",
    "OUT{\n",
    "    user: [t, n]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    parse_lndl(response_wrong, operable_mismatch)\n",
    "except* TypeMismatchError as eg:\n",
    "    print(\"✓ Type mismatch caught:\")\n",
    "    for exc in eg.exceptions:\n",
    "        print(f\"  {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Aggregation - ExceptionGroups\n",
    "\n",
    "Multiple validation errors are collected and reported together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Caught 2 errors:\n",
      "  1. ValueError: Variable or action 'missing_email' referenced in OUT{} but not declared\n",
      "  2. TypeMismatchError: Variable 'n' is for model 'User', but field 'product' expects 'Product'\n"
     ]
    }
   ],
   "source": [
    "operable_multi = Operable(\n",
    "    specs=[\n",
    "        Spec(name=\"user\", base_type=User),\n",
    "        Spec(name=\"product\", base_type=Product),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Multiple errors: missing variable + type mismatch\n",
    "response_multi_error = \"\"\"\n",
    "<lvar User.name n>Bob</lvar>\n",
    "<lvar Product.title t>Phone</lvar>\n",
    "\n",
    "OUT{\n",
    "    user: [n, missing_email],\n",
    "    product: [t, n]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    parse_lndl(response_multi_error, operable_multi)\n",
    "except ExceptionGroup as eg:\n",
    "    print(f\"✓ Caught {len(eg.exceptions)} errors:\")\n",
    "    for i, exc in enumerate(eg.exceptions, 1):\n",
    "        print(f\"  {i}. {type(exc).__name__}: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Name Collision Detection\n",
    "\n",
    "Lvar and lact names must be unique - no collisions allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Collision detected: Name collision detected: {'t'} used in both <lvar> and <lact> declarations\n"
     ]
    }
   ],
   "source": [
    "response_collision = \"\"\"\n",
    "<lvar Report.title t>Title from lvar</lvar>\n",
    "<lact Report.score t>calculate_score()</lact>\n",
    "\n",
    "OUT{\n",
    "    report: [t]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "operable_collision = Operable(specs=[Spec(name=\"report\", base_type=Report)])\n",
    "\n",
    "try:\n",
    "    parse_lndl(response_collision, operable_collision)\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Collision detected: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ensure No Action Calls - Safety Guard\n",
    "\n",
    "Critical guard before persisting models to prevent database corruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Guard blocked persistence: Report contains unexecuted actions in fields: score. Models with ActionCall placeholders must be re-validated after action execution. Call revalidate_with_action_results() before using this model.\n",
      "\n",
      "✓ Safe to persist: title='Unvalidated Report' score=0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lion/projects/open-source/lionherd-core/.venv/lib/python3.11/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `float` - serialized value may not be as expected [field_name='score', input_value=ActionCall(name='s', func...all='calculate_score()'), input_type=ActionCall])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# Create model with unexecuted actions\n",
    "response_guard = \"\"\"\n",
    "<lvar Report.title t>Unvalidated Report</lvar>\n",
    "<lact Report.score s>calculate_score()</lact>\n",
    "\n",
    "OUT{\n",
    "    report: [t, s]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output = parse_lndl(response_guard, operable)\n",
    "\n",
    "# Attempt to save without executing actions\n",
    "try:\n",
    "    ensure_no_action_calls(output.report)  # Guard prevents corruption\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Guard blocked persistence: {e}\")\n",
    "\n",
    "# Proper flow: execute then save\n",
    "action_results = {\"s\": 0.95}\n",
    "validated_report = revalidate_with_action_results(output.report, action_results)\n",
    "safe_report = ensure_no_action_calls(validated_report)\n",
    "print(f\"\\n✓ Safe to persist: {safe_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Scalar Actions\n",
    "\n",
    "Actions can return scalar values directly for non-BaseModel fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar actions parsed:\n",
      "Temperature: ActionCall(name='temp', function='get_temperature', arguments={'sensor': 'living_room'}, raw_call='get_temperature(sensor=\"living_room\")') (type: ActionCall)\n",
      "Status: ActionCall(name='stat', function='check_status', arguments={'system': 'hvac'}, raw_call='check_status(system=\"hvac\")') (type: ActionCall)\n",
      "\n",
      "Actions to execute: ['temp', 'stat']\n",
      "\n",
      "After execution:\n",
      "Temperature: 72.5\n",
      "Status: normal\n"
     ]
    }
   ],
   "source": [
    "operable_scalar_action = Operable(\n",
    "    specs=[\n",
    "        Spec(name=\"temperature\", base_type=float),\n",
    "        Spec(name=\"status\", base_type=str),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_scalar_action = \"\"\"\n",
    "<lact temp>get_temperature(sensor=\"living_room\")</lact>\n",
    "<lact stat>check_status(system=\"hvac\")</lact>\n",
    "\n",
    "OUT{\n",
    "    temperature: [temp],\n",
    "    status: [stat]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output = parse_lndl(response_scalar_action, operable_scalar_action)\n",
    "\n",
    "print(\"Scalar actions parsed:\")\n",
    "print(f\"Temperature: {output.temperature} (type: {type(output.temperature).__name__})\")\n",
    "print(f\"Status: {output.status} (type: {type(output.status).__name__})\")\n",
    "\n",
    "# These are ActionCall objects before execution\n",
    "print(f\"\\nActions to execute: {list(output.actions.keys())}\")\n",
    "\n",
    "# Execute and replace\n",
    "output.fields[\"temperature\"] = 72.5\n",
    "output.fields[\"status\"] = \"normal\"\n",
    "\n",
    "print(\"\\nAfter execution:\")\n",
    "print(f\"Temperature: {output.temperature}\")\n",
    "print(f\"Status: {output.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Low-Level API - resolve_references_prefixed\n",
    "\n",
    "For custom parsing workflows, use the low-level resolver directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted components:\n",
      "Lvars: ['t', 's']\n",
      "Lacts: []\n",
      "OUT fields: {'report': ['t', 's']}\n",
      "\n",
      "Resolved report: title='Custom Parsing' score=0.88\n"
     ]
    }
   ],
   "source": [
    "from lionherd_core.lndl.parser import (\n",
    "    extract_lacts_prefixed,\n",
    "    extract_lvars_prefixed,\n",
    "    extract_out_block,\n",
    "    parse_out_block_array,\n",
    ")\n",
    "\n",
    "response_lowlevel = \"\"\"\n",
    "<lvar Report.title t>Custom Parsing</lvar>\n",
    "<lvar Report.score s>0.88</lvar>\n",
    "\n",
    "OUT{\n",
    "    report: [t, s]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Extract components\n",
    "lvars = extract_lvars_prefixed(response_lowlevel)\n",
    "lacts = extract_lacts_prefixed(response_lowlevel)\n",
    "out_content = extract_out_block(response_lowlevel)\n",
    "out_fields = parse_out_block_array(out_content)\n",
    "\n",
    "print(\"Extracted components:\")\n",
    "print(f\"Lvars: {list(lvars.keys())}\")\n",
    "print(f\"Lacts: {list(lacts.keys())}\")\n",
    "print(f\"OUT fields: {out_fields}\")\n",
    "\n",
    "# Step 2: Resolve references\n",
    "output = resolve_references_prefixed(out_fields, lvars, lacts, operable)\n",
    "\n",
    "print(f\"\\nResolved report: {output.report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Complex Nested Models\n",
    "\n",
    "Resolution works with deeply nested Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: title='Understanding LNDL' author=Author(name='Alice Smith', email='alice@example.com') views=1500\n",
      "Author name: Alice Smith\n",
      "Author email: alice@example.com\n"
     ]
    }
   ],
   "source": [
    "class Author(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "\n",
    "\n",
    "class Article(BaseModel):\n",
    "    title: str\n",
    "    author: Author\n",
    "    views: int\n",
    "\n",
    "\n",
    "# Note: LNDL currently resolves one level - nested models need separate specs\n",
    "# or you use direct actions returning complete nested structures\n",
    "operable_nested = Operable(\n",
    "    specs=[\n",
    "        Spec(name=\"author\", base_type=Author),\n",
    "        Spec(name=\"article_title\", base_type=str),\n",
    "        Spec(name=\"article_views\", base_type=int),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_nested = \"\"\"\n",
    "<lvar Author.name n>Alice Smith</lvar>\n",
    "<lvar Author.email e>alice@example.com</lvar>\n",
    "\n",
    "OUT{\n",
    "    author: [n, e],\n",
    "    article_title: \"Understanding LNDL\",\n",
    "    article_views: 1500\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output = parse_lndl(response_nested, operable_nested)\n",
    "\n",
    "# Manually construct Article from resolved parts\n",
    "article = Article(title=output.article_title, author=output.author, views=output.article_views)\n",
    "\n",
    "print(f\"Article: {article}\")\n",
    "print(f\"Author name: {article.author.name}\")\n",
    "print(f\"Author email: {article.author.email}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "**LNDL Resolver Essentials:**\n",
    "- ✅ Resolves namespace-prefixed lvars/lacts against Operable specs\n",
    "- ✅ Validates type compatibility (strict matching)\n",
    "- ✅ Three-phase action lifecycle (parse → execute → revalidate)\n",
    "- ✅ Supports mixing static lvars with dynamic lacts\n",
    "- ✅ Aggregates validation errors into ExceptionGroups\n",
    "- ✅ Detects name collisions between lvars and lacts\n",
    "- ✅ Guards against persisting unexecuted actions\n",
    "- ✅ Handles both scalar and BaseModel field types\n",
    "- ✅ Direct actions can return complete models\n",
    "- ✅ Required/optional field validation\n",
    "\n",
    "**Key Safety Rules:**\n",
    "1. **Always revalidate** after executing actions\n",
    "2. **Use ensure_no_action_calls()** before persistence\n",
    "3. **Check has_action_calls()** to determine if execution needed\n",
    "4. **Handle ExceptionGroups** for comprehensive error reporting\n",
    "\n",
    "**Next Steps:**\n",
    "- See `lndl_fuzzy.ipynb` for fuzzy matching and error recovery\n",
    "- See `types_operable.ipynb` for Operable/Spec details\n",
    "- See `schema_function_call_parser.ipynb` for action parsing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
