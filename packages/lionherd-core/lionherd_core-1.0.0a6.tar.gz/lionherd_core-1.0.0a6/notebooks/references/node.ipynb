{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Reference Guide\n",
    "\n",
    "**Node** is the polymorphic container in lionherd - extends Element with structured content, embeddings, and automatic type registry.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. **Element Inheritance**: Inherits `id`, `metadata`, `created_at` from Element base class\n",
    "2. **Structured Content**: `content: dict | Serializable | BaseModel | None` enforces query-able, composable data (breaking change in Alpha3)\n",
    "3. **Embedding Support**: Optional `embedding: list[float]` with DB compatibility (JSON string coercion)\n",
    "4. **Auto-Registry**: Subclasses auto-register via `__pydantic_init_subclass__` for polymorphic deserialization\n",
    "5. **Serialization Modes**: `python`/`json`/`db` modes with automatic lion_class injection\n",
    "6. **Pydapter Integration**: TOML/YAML adapters with isolated per-subclass registries (Rust-like explicit pattern)\n",
    "\n",
    "## Design Philosophy\n",
    "\n",
    "- **Composition layer**: Node is structured composition vs Element (identity) vs Event (execution)\n",
    "- **JSONB one-stop-shop**: All content types guarantee PostgreSQL query-ability\n",
    "- **Pit of success**: Structured constraint forces graph-thinking, prevents primitive soup\n",
    "- **Zero-config subclasses**: Registry eliminates boilerplate - subclasses \"just work\"\n",
    "- **Database-first**: `mode=\"db\"` uses `node_metadata` to avoid column conflicts\n",
    "\n",
    "## ⚠️ Alpha3 Breaking Change\n",
    "\n",
    "**Content constraint** (PR #48): Primitives (str, int, float, etc.) **no longer accepted**.\n",
    "\n",
    "**Migration**:\n",
    "```python\n",
    "# ❌ Before (primitives accepted)\n",
    "Node(content=\"test\")\n",
    "Node(content=42)\n",
    "\n",
    "# ✅ After (structured types only)\n",
    "Node(content={\"value\": \"test\"})\n",
    "Node(content={\"count\": 42})\n",
    "\n",
    "# ✅ Or use Element.metadata for simple key-value\n",
    "Element(metadata={\"text\": \"test\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lionherd_core.base.node import NODE_REGISTRY, Node\n",
    "\n",
    "\n",
    "# Define sample Node subclasses (auto-register)\n",
    "class PersonNode(Node):\n",
    "    \"\"\"Node representing a person.\"\"\"\n",
    "\n",
    "    name: str = \"Unknown\"\n",
    "    age: int = 0\n",
    "\n",
    "\n",
    "class DocumentNode(Node):\n",
    "    \"\"\"Node representing a document.\"\"\"\n",
    "\n",
    "    title: str = \"Untitled\"\n",
    "    body: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Element Inheritance\n",
    "\n",
    "Node extends Element, inheriting automatic ID generation, metadata, and timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID (UUID): 20d339bf-e2b2-45f5-b4c4-7e5cc5b1e4f8\n",
      "Created at: 2025-11-11 15:28:58.315569+00:00\n",
      "Metadata: {}\n",
      "Content: {'text': 'Hello World'}\n",
      "\n",
      "Class name: lionherd_core.base.node.Node\n"
     ]
    }
   ],
   "source": [
    "# Create base Node - inherits Element features\n",
    "node = Node(content={\"text\": \"Hello World\"})\n",
    "\n",
    "print(f\"ID (UUID): {node.id}\")\n",
    "print(f\"Created at: {node.created_at}\")\n",
    "print(f\"Metadata: {node.metadata}\")\n",
    "print(f\"Content: {node.content}\")\n",
    "print(f\"\\nClass name: {node.class_name(full=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Content Constraint (Structured Types Only)\n",
    "\n",
    "The `content` field accepts **structured types only**: `dict`, `Serializable`, `BaseModel`, or `None`.\n",
    "\n",
    "**Why**: Enforces query-able, composable data for PostgreSQL JSONB and graph-of-graphs patterns.\n",
    "\n",
    "**Rejected**: Primitives (str, int, float, bool), collections (list, tuple, set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict content: {'key': 'value', 'nested': [1, 2, 3]}\n",
      "Wrapped list: {'items': ['a', 'b', 'c']}\n",
      "Nested Node: Alice, age 30\n",
      "\n",
      "❌ Primitive rejected: content must be Serializable, BaseModel, dict, or None. Got str. Use dict for un...\n"
     ]
    }
   ],
   "source": [
    "# Structured content examples\n",
    "node_dict = Node(content={\"key\": \"value\", \"nested\": [1, 2, 3]})\n",
    "node_wrapped = Node(content={\"items\": [\"a\", \"b\", \"c\"]})\n",
    "\n",
    "# Content can be nested Node (graph-of-graphs pattern)\n",
    "inner = PersonNode(name=\"Alice\", age=30)\n",
    "outer = Node(content=inner)\n",
    "\n",
    "print(f\"Dict content: {node_dict.content}\")\n",
    "print(f\"Wrapped list: {node_wrapped.content}\")\n",
    "print(f\"Nested Node: {outer.content.name}, age {outer.content.age}\")\n",
    "\n",
    "# ❌ Primitives rejected with helpful error\n",
    "try:\n",
    "    Node(content=\"plain string\")\n",
    "except TypeError as e:\n",
    "    print(f\"\\n❌ Primitive rejected: {str(e)[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nested Element Serialization\n",
    "\n",
    "When content contains Elements, they auto-serialize via `_serialize_content` field serializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized content type: <class 'dict'>\n",
      "Content includes lion_class: True\n",
      "\n",
      "Restored content type: <class '__main__.PersonNode'>\n",
      "Restored name: Bob\n",
      "Restored role: engineer\n"
     ]
    }
   ],
   "source": [
    "# Create Node with nested PersonNode\n",
    "person = PersonNode(name=\"Bob\", age=25, content={\"role\": \"engineer\"})\n",
    "wrapper = Node(content=person)\n",
    "\n",
    "# Serialize - content becomes dict automatically\n",
    "data = wrapper.to_dict()\n",
    "print(f\"Serialized content type: {type(data['content'])}\")\n",
    "print(f\"Content includes lion_class: {'lion_class' in data['content']['metadata']}\")\n",
    "\n",
    "# Deserialize - content becomes PersonNode automatically\n",
    "restored = Node.from_dict(data)\n",
    "print(f\"\\nRestored content type: {type(restored.content)}\")\n",
    "print(f\"Restored name: {restored.content.name}\")\n",
    "print(f\"Restored role: {restored.content.content['role']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding Field\n",
    "\n",
    "Optional `embedding: list[float]` with validation and JSON string coercion for DB compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: [0.1, 0.2, 0.3]\n",
      "From JSON string: [0.4, 0.5, 0.6]\n",
      "Int coerced to float: [1.0, 2.0, 3.0]\n",
      "All floats: True\n"
     ]
    }
   ],
   "source": [
    "# Embedding as list (standard)\n",
    "node1 = Node(content={\"text\": \"sample\"}, embedding=[0.1, 0.2, 0.3])\n",
    "print(f\"Embedding: {node1.embedding}\")\n",
    "\n",
    "# Embedding from JSON string (DB compatibility)\n",
    "import orjson\n",
    "\n",
    "json_str = orjson.dumps([0.4, 0.5, 0.6]).decode()\n",
    "node2 = Node(content={\"text\": \"sample\"}, embedding=json_str)\n",
    "print(f\"From JSON string: {node2.embedding}\")\n",
    "\n",
    "# Integer coercion to float\n",
    "node3 = Node(content={\"text\": \"sample\"}, embedding=[1, 2, 3])\n",
    "print(f\"Int coerced to float: {node3.embedding}\")\n",
    "print(f\"All floats: {all(isinstance(x, float) for x in node3.embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NODE_REGISTRY Auto-Registration\n",
    "\n",
    "Subclasses auto-register via `__pydantic_init_subclass__` - enables polymorphic deserialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry keys: ['Node', 'lionherd_core.base.node.Node', 'PersonNode', '__main__.PersonNode', 'DocumentNode', '__main__.DocumentNode']\n",
      "\n",
      "PersonNode registered: True\n",
      "DocumentNode registered: True\n",
      "\n",
      "CustomNode auto-registered: True\n",
      "Registry returns correct class: True\n"
     ]
    }
   ],
   "source": [
    "# Check registry\n",
    "print(\"Registry keys:\", list(NODE_REGISTRY.keys()))\n",
    "print(f\"\\nPersonNode registered: {'PersonNode' in NODE_REGISTRY}\")\n",
    "print(f\"DocumentNode registered: {'DocumentNode' in NODE_REGISTRY}\")\n",
    "\n",
    "\n",
    "# Dynamic subclass registration\n",
    "class CustomNode(Node):\n",
    "    custom_field: str = \"test\"\n",
    "\n",
    "\n",
    "print(f\"\\nCustomNode auto-registered: {'CustomNode' in NODE_REGISTRY}\")\n",
    "print(f\"Registry returns correct class: {NODE_REGISTRY['CustomNode'] is CustomNode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Polymorphic Deserialization\n",
    "\n",
    "`from_dict()` uses `lion_class` metadata to route to correct subclass from NODE_REGISTRY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person lion_class: __main__.PersonNode\n",
      "Doc lion_class: __main__.DocumentNode\n",
      "\n",
      "Restored person type: PersonNode\n",
      "Restored doc type: DocumentNode\n",
      "Person name: Charlie\n",
      "Doc title: Spec\n"
     ]
    }
   ],
   "source": [
    "# Serialize different node types\n",
    "person = PersonNode(name=\"Charlie\", age=35)\n",
    "doc = DocumentNode(title=\"Spec\", body=\"Requirements\")\n",
    "\n",
    "person_data = person.to_dict()\n",
    "doc_data = doc.to_dict()\n",
    "\n",
    "print(f\"Person lion_class: {person_data['metadata']['lion_class']}\")\n",
    "print(f\"Doc lion_class: {doc_data['metadata']['lion_class']}\")\n",
    "\n",
    "# Deserialize via base Node.from_dict() - polymorphic routing\n",
    "restored_person = Node.from_dict(person_data)\n",
    "restored_doc = Node.from_dict(doc_data)\n",
    "\n",
    "print(f\"\\nRestored person type: {type(restored_person).__name__}\")\n",
    "print(f\"Restored doc type: {type(restored_doc).__name__}\")\n",
    "print(f\"Person name: {restored_person.name}\")\n",
    "print(f\"Doc title: {restored_doc.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Heterogeneous Collections (Real-World DB Scenario)\n",
    "\n",
    "Single query returns mixed node types - polymorphic deserialization preserves types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deserialized types:\n",
      "  [0] PersonNode - Alice, age 30\n",
      "  [1] DocumentNode - Report\n",
      "  [2] PersonNode - Bob, age 25\n"
     ]
    }
   ],
   "source": [
    "# Simulate DB query returning mixed types with node_metadata\n",
    "db_records = [\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"node_metadata\": {\"lion_class\": \"PersonNode\"}},\n",
    "    {\"title\": \"Report\", \"body\": \"Data\", \"node_metadata\": {\"lion_class\": \"DocumentNode\"}},\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"node_metadata\": {\"lion_class\": \"PersonNode\"}},\n",
    "]\n",
    "\n",
    "# Deserialize - each gets correct type\n",
    "nodes = [Node.from_dict(record) for record in db_records]\n",
    "\n",
    "print(\"Deserialized types:\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"  [{i}] {type(node).__name__}\", end=\"\")\n",
    "    if isinstance(node, PersonNode):\n",
    "        print(f\" - {node.name}, age {node.age}\")\n",
    "    elif isinstance(node, DocumentNode):\n",
    "        print(f\" - {node.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Serialization Modes\n",
    "\n",
    "Three modes: `python` (in-memory), `json` (APIs), `db` (database with node_metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python mode has 'metadata': True\n",
      "Created_at type: datetime\n",
      "\n",
      "JSON mode has 'metadata': True\n",
      "Created_at type: str\n",
      "\n",
      "DB mode has 'node_metadata': True\n",
      "DB mode has 'metadata': False\n",
      "lion_class in node_metadata: True\n"
     ]
    }
   ],
   "source": [
    "node = PersonNode(name=\"David\", age=40)\n",
    "\n",
    "# Python mode - preserves datetime/UUID objects\n",
    "python_dict = node.to_dict(mode=\"python\")\n",
    "print(f\"Python mode has 'metadata': {'metadata' in python_dict}\")\n",
    "print(f\"Created_at type: {type(python_dict['created_at']).__name__}\")\n",
    "\n",
    "# JSON mode - serializes to strings\n",
    "json_dict = node.to_dict(mode=\"json\")\n",
    "print(f\"\\nJSON mode has 'metadata': {'metadata' in json_dict}\")\n",
    "print(f\"Created_at type: {type(json_dict['created_at']).__name__}\")\n",
    "\n",
    "# DB mode - uses node_metadata (avoids column conflicts)\n",
    "db_dict = node.to_dict(mode=\"db\")\n",
    "print(f\"\\nDB mode has 'node_metadata': {'node_metadata' in db_dict}\")\n",
    "print(f\"DB mode has 'metadata': {'metadata' in db_dict}\")\n",
    "print(f\"lion_class in node_metadata: {'lion_class' in db_dict['node_metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Serialization Roundtrip (All Modes)\n",
    "\n",
    "All modes support lossless roundtrip with polymorphic type preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python   -> Type: DocumentNode Title: Architecture    ID match: True\n",
      "json     -> Type: DocumentNode Title: Architecture    ID match: True\n",
      "db       -> Type: DocumentNode Title: Architecture    ID match: True\n"
     ]
    }
   ],
   "source": [
    "original = DocumentNode(title=\"Architecture\", body=\"System design\")\n",
    "\n",
    "for mode in [\"python\", \"json\", \"db\"]:\n",
    "    # Serialize\n",
    "    data = original.to_dict(mode=mode)\n",
    "\n",
    "    # Deserialize\n",
    "    restored = Node.from_dict(data)\n",
    "\n",
    "    # Verify\n",
    "    print(\n",
    "        f\"{mode:8} -> Type: {type(restored).__name__:12} Title: {restored.title:15} ID match: {restored.id == original.id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Pydapter Integration (Isolated Registry Pattern)\n",
    "\n",
    "Base Node has TOML/YAML built-in. Subclasses get **isolated registries** (Rust-like explicit) - must register adapters explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Node TOML (first 100 chars):\n",
      "id = \"f574241c-b702-4873-ab77-74cc5fdd48bd\"\n",
      "created_at = 2025-11-11T15:28:58.358997Z\n",
      "\n",
      "[content]\n",
      "valu\n",
      "\n",
      "PersonNode TOML (first 100 chars):\n",
      "id = \"2d45f8c7-57bb-4322-be15-3b5208fd9b92\"\n",
      "created_at = 2025-11-11T15:28:58.359326Z\n",
      "name = \"Eve\"\n",
      "ag\n",
      "\n",
      "Restored type: PersonNode\n",
      "Restored name: Eve\n"
     ]
    }
   ],
   "source": [
    "from pydapter.adapters import TomlAdapter\n",
    "\n",
    "# Base Node has toml/yaml built-in\n",
    "base_node = Node(content={\"value\": \"test\"})\n",
    "toml_str = base_node.adapt_to(\"toml\")\n",
    "print(\"Base Node TOML (first 100 chars):\")\n",
    "print(toml_str[:100])\n",
    "\n",
    "# Subclasses have ISOLATED registries - must register explicitly\n",
    "PersonNode.register_adapter(TomlAdapter)\n",
    "person = PersonNode(name=\"Eve\", age=28)\n",
    "person_toml = person.adapt_to(\"toml\")\n",
    "print(\"\\nPersonNode TOML (first 100 chars):\")\n",
    "print(person_toml[:100])\n",
    "\n",
    "# Roundtrip with polymorphism\n",
    "restored = Node.adapt_from(person_toml, \"toml\")\n",
    "print(f\"\\nRestored type: {type(restored).__name__}\")\n",
    "print(f\"Restored name: {restored.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced: created_at_format Options\n",
    "\n",
    "Control timestamp serialization: `datetime` (object), `isoformat` (string), `timestamp` (float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime format: datetime = 2025-11-11 15:28:58.364226+00:00\n",
      "isoformat: str = 2025-11-11T15:28:58.364226+00:00\n",
      "timestamp: float = 1762874938.364226\n"
     ]
    }
   ],
   "source": [
    "node = Node(content={\"value\": \"test\"})\n",
    "\n",
    "# Datetime format (default for python mode)\n",
    "data1 = node.to_dict(mode=\"python\", created_at_format=\"datetime\")\n",
    "print(f\"datetime format: {type(data1['created_at']).__name__} = {data1['created_at']}\")\n",
    "\n",
    "# ISO format (string)\n",
    "data2 = node.to_dict(mode=\"python\", created_at_format=\"isoformat\")\n",
    "print(f\"isoformat: {type(data2['created_at']).__name__} = {data2['created_at']}\")\n",
    "\n",
    "# Timestamp format (float)\n",
    "data3 = node.to_dict(mode=\"python\", created_at_format=\"timestamp\")\n",
    "print(f\"timestamp: {type(data3['created_at']).__name__} = {data3['created_at']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Advanced: Custom Content Serialization\n",
    "\n",
    "The `content_serializer` parameter enables custom transformation of content during serialization without modifying Node behavior.\n",
    "\n",
    "**Use Cases**: Compression, encryption, external storage references, format conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Round-Trip Serialization Patterns\n",
    "\n",
    "The `content_deserializer` parameter enables custom transformation during **deserialization**, complementing `content_serializer` for complete round-trip workflows.\n",
    "\n",
    "**Key Use Cases**:\n",
    "1. **Compression**: Store large content compressed, decompress on load\n",
    "2. **External Storage**: Store content by reference (S3/blob storage), fetch on demand\n",
    "3. **Encryption**: Secure sensitive data at rest, decrypt on access\n",
    "\n",
    "**Pattern**: Serializer transforms outbound, deserializer reverses inbound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 10,903 bytes\n",
      "Compressed: 876 chars\n",
      "Compression ratio: 12.45x\n",
      "\n",
      "Round-trip successful: True\n",
      "First record: {'id': 0, 'data': 'Record 0Record 0Record 0Record 0Record 0Record 0Record 0Record 0Record 0Record 0'}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Compression Round-Trip\n",
    "import base64\n",
    "import zlib\n",
    "\n",
    "\n",
    "def compress_content(content):\n",
    "    \"\"\"Compress content using zlib and encode as base64.\"\"\"\n",
    "    json_bytes = orjson.dumps(content)\n",
    "    compressed = zlib.compress(json_bytes, level=9)\n",
    "    return {\"compressed\": base64.b64encode(compressed).decode(), \"original_size\": len(json_bytes)}\n",
    "\n",
    "\n",
    "def decompress_content(serialized):\n",
    "    \"\"\"Decompress base64-encoded zlib content.\"\"\"\n",
    "    compressed = base64.b64decode(serialized[\"compressed\"])\n",
    "    json_bytes = zlib.decompress(compressed)\n",
    "    return orjson.loads(json_bytes)\n",
    "\n",
    "\n",
    "# Create large content\n",
    "large_data = {\"records\": [{\"id\": i, \"data\": f\"Record {i}\" * 10} for i in range(100)]}\n",
    "\n",
    "# Create Node with compression\n",
    "node = Node(content=large_data)\n",
    "compressed_dict = node.to_dict(content_serializer=compress_content)\n",
    "\n",
    "print(f\"Original size: {compressed_dict['content']['original_size']:,} bytes\")\n",
    "print(f\"Compressed: {len(compressed_dict['content']['compressed'])} chars\")\n",
    "print(\n",
    "    f\"Compression ratio: {compressed_dict['content']['original_size'] / len(compressed_dict['content']['compressed']):.2f}x\"\n",
    ")\n",
    "\n",
    "# Round-trip: Deserialize with decompressor\n",
    "restored = Node.from_dict(compressed_dict, content_deserializer=decompress_content)\n",
    "print(f\"\\nRound-trip successful: {restored.content == large_data}\")\n",
    "print(f\"First record: {restored.content['records'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content stored externally: simulated_s3\n",
      "Storage reference: ee085658-5853-45d7-a7da-ee1e889093a1\n",
      "Original size: 16,487,953 chars\n",
      "Serialized node (without content): -16,487,607 chars\n",
      "\n",
      "Round-trip successful: True\n",
      "First embedding dimension: 1536\n",
      "Metadata preserved: {'model': 'text-embedding-3-large'}\n"
     ]
    }
   ],
   "source": [
    "# Example 2: External Storage Pattern (simulated S3)\n",
    "from uuid import uuid4\n",
    "\n",
    "# Simulated external storage (in production: S3, GCS, blob storage)\n",
    "EXTERNAL_STORAGE = {}\n",
    "\n",
    "\n",
    "def store_externally(content):\n",
    "    \"\"\"Store content externally, return reference.\"\"\"\n",
    "    ref_id = str(uuid4())\n",
    "    EXTERNAL_STORAGE[ref_id] = content\n",
    "    return {\"storage_ref\": ref_id, \"storage_type\": \"simulated_s3\", \"size\": len(str(content))}\n",
    "\n",
    "\n",
    "def fetch_from_storage(serialized):\n",
    "    \"\"\"Fetch content from external storage using reference.\"\"\"\n",
    "    ref_id = serialized[\"storage_ref\"]\n",
    "    if ref_id not in EXTERNAL_STORAGE:\n",
    "        raise KeyError(f\"Content not found in external storage: {ref_id}\")\n",
    "    return EXTERNAL_STORAGE[ref_id]\n",
    "\n",
    "\n",
    "# Large dataset that should live externally\n",
    "dataset = {\n",
    "    \"embeddings\": [[0.1 * i] * 1536 for i in range(1000)],\n",
    "    \"metadata\": {\"model\": \"text-embedding-3-large\"},\n",
    "}\n",
    "\n",
    "# Serialize with external storage\n",
    "node = Node(content=dataset)\n",
    "external_dict = node.to_dict(content_serializer=store_externally)\n",
    "\n",
    "print(f\"Content stored externally: {external_dict['content']['storage_type']}\")\n",
    "print(f\"Storage reference: {external_dict['content']['storage_ref']}\")\n",
    "print(f\"Original size: {external_dict['content']['size']:,} chars\")\n",
    "print(\n",
    "    f\"Serialized node (without content): {len(str(external_dict)) - external_dict['content']['size']:,} chars\"\n",
    ")\n",
    "\n",
    "# Round-trip: Fetch from external storage on deserialization\n",
    "restored = Node.from_dict(external_dict, content_deserializer=fetch_from_storage)\n",
    "print(f\"\\nRound-trip successful: {restored.content == dataset}\")\n",
    "print(f\"First embedding dimension: {len(restored.content['embeddings'][0])}\")\n",
    "print(f\"Metadata preserved: {restored.content['metadata']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption algorithm: demo_xor\n",
      "Key hint: demo***\n",
      "Encrypted data: ddfrtXDcnXfYLl+NWgGmLmIbPHLG/EXzfXwoWlullO9916S9N8...\n",
      "Original keys hidden: True\n",
      "\n",
      "Round-trip successful: True\n",
      "Decrypted user_id: user_12345\n",
      "API keys accessible: ['openai', 'anthropic']\n",
      "\n",
      "⚠️  PRODUCTION NOTE: Use proper encryption libraries like cryptography.fernet or pycryptodome.AES\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Encryption Pattern (simple demo - use cryptography library in production)\n",
    "import hashlib\n",
    "\n",
    "# ⚠️ PRODUCTION WARNING: Use proper encryption libraries (cryptography, pycryptodome)\n",
    "# This is a simple XOR-based demo for educational purposes only\n",
    "\n",
    "\n",
    "def simple_encrypt(content, key: str):\n",
    "    \"\"\"Simple encryption (DEMO ONLY - use cryptography.fernet in production).\n",
    "\n",
    "    Args:\n",
    "        key: Encryption key. In production: use os.environ['ENCRYPTION_KEY']\"\"\"\n",
    "    json_bytes = orjson.dumps(content)\n",
    "    key_bytes = hashlib.sha256(key.encode()).digest()\n",
    "\n",
    "    # Simple XOR encryption (NOT SECURE - for demo only)\n",
    "    encrypted = bytes([b ^ key_bytes[i % len(key_bytes)] for i, b in enumerate(json_bytes)])\n",
    "    return {\n",
    "        \"encrypted\": base64.b64encode(encrypted).decode(),\n",
    "        \"algorithm\": \"demo_xor\",\n",
    "        \"key_hint\": key[:4] + \"***\",\n",
    "    }\n",
    "\n",
    "\n",
    "def simple_decrypt(serialized, key: str):\n",
    "    \"\"\"Simple decryption (DEMO ONLY - use cryptography.fernet in production).\n",
    "\n",
    "    Args:\n",
    "        key: Encryption key (must match encryption key).\"\"\"\n",
    "    encrypted = base64.b64decode(serialized[\"encrypted\"])\n",
    "    key_bytes = hashlib.sha256(key.encode()).digest()\n",
    "\n",
    "    # XOR decryption (reversible)\n",
    "    decrypted = bytes([b ^ key_bytes[i % len(key_bytes)] for i, b in enumerate(encrypted)])\n",
    "    return orjson.loads(decrypted)\n",
    "\n",
    "\n",
    "# Sensitive data requiring encryption\n",
    "sensitive_data = {\n",
    "    \"user_id\": \"user_12345\",\n",
    "    \"api_keys\": {\"openai\": \"sk-***secret***\", \"anthropic\": \"sk-ant-***secret***\"},\n",
    "    \"personal_info\": {\"ssn\": \"***-**-1234\", \"dob\": \"1990-01-01\"},\n",
    "}\n",
    "\n",
    "# Serialize with encryption\n",
    "node = Node(content=sensitive_data)\n",
    "encrypted_dict = node.to_dict(content_serializer=lambda c: simple_encrypt(c, key=\"demo_key_12345\"))\n",
    "\n",
    "print(f\"Encryption algorithm: {encrypted_dict['content']['algorithm']}\")\n",
    "print(f\"Key hint: {encrypted_dict['content']['key_hint']}\")\n",
    "print(f\"Encrypted data: {encrypted_dict['content']['encrypted'][:50]}...\")\n",
    "print(f\"Original keys hidden: {'api_keys' not in str(encrypted_dict['content'])}\")\n",
    "\n",
    "# Round-trip: Decrypt on deserialization\n",
    "restored = Node.from_dict(\n",
    "    encrypted_dict, content_deserializer=lambda s: simple_decrypt(s, key=\"demo_key_12345\")\n",
    ")\n",
    "print(f\"\\nRound-trip successful: {restored.content == sensitive_data}\")\n",
    "print(f\"Decrypted user_id: {restored.content['user_id']}\")\n",
    "print(f\"API keys accessible: {list(restored.content['api_keys'].keys())}\")\n",
    "\n",
    "print(\n",
    "    \"\\n⚠️  PRODUCTION NOTE: Use proper encryption libraries like cryptography.fernet or pycryptodome.AES\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "### Core Patterns Demonstrated\n",
    "\n",
    "- ✅ **Element Inheritance**: Node inherits `id`, `metadata`, `created_at` from Element\n",
    "- ✅ **Structured Content**: `content: dict | Serializable | BaseModel | None` enforces query-able data\n",
    "- ✅ **Nested Serialization**: Elements in content auto-serialize via `_serialize_content`\n",
    "- ✅ **Embedding Field**: `list[float]` with JSON string coercion + int→float coercion\n",
    "- ✅ **Auto-Registry**: `__pydantic_init_subclass__` registers subclasses in `NODE_REGISTRY`\n",
    "- ✅ **Polymorphic Deserialization**: `from_dict()` routes via `lion_class` metadata\n",
    "- ✅ **Heterogeneous Collections**: Single `Node.from_dict()` call handles mixed types\n",
    "- ✅ **Serialization Modes**: `python`/`json`/`db` with `node_metadata` for DB\n",
    "- ✅ **Pydapter Integration**: Isolated adapter registries (Rust-like explicit)\n",
    "- ✅ **Timestamp Control**: `created_at_format` options (datetime/isoformat/timestamp)\n",
    "- ✅ **Custom Content Serialization**: `content_serializer` parameter for compression, external refs, format conversion\n",
    "\n",
    "### Real-World Use Cases\n",
    "\n",
    "1. **Graph Databases**: Heterogeneous node types in single query → polymorphic deserialization\n",
    "2. **Nested Composition**: Node contains Graph contains Nodes (graph-of-graphs)\n",
    "3. **Vector Search**: Embedding field for semantic search with DB JSON compatibility\n",
    "4. **External Formats**: TOML/YAML serialization with type preservation\n",
    "5. **DB Storage**: `mode=\"db\"` with `node_metadata` avoids column conflicts\n",
    "6. **Content Transformation**: Custom serializers for compression, encryption, external storage\n",
    "\n",
    "### Key Design Decisions\n",
    "\n",
    "- **Structured content constraint (Alpha3)**: Enforces JSONB query-ability, prevents primitive soup\n",
    "- **Composition layer identity**: Node (structured) vs Element (identity) vs Event (execution)\n",
    "- **Zero-config subclasses**: Registry eliminates manual registration boilerplate\n",
    "- **Isolated adapter registries**: Prevents pollution, explicit > implicit\n",
    "- **Database-first design**: JSON string coercion, node_metadata field, serialization modes\n",
    "- **Custom serialization**: One-way content transformation without modifying Node behavior\n",
    "\n",
    "### Migration from Pre-Alpha3\n",
    "\n",
    "```python\n",
    "# ❌ Before: Primitives accepted\n",
    "Node(content=\"text\")\n",
    "Node(content=42)\n",
    "Node(content=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "# ✅ After: Structured types only\n",
    "Node(content={\"text\": \"value\"})\n",
    "Node(content={\"count\": 42})\n",
    "Node(content={\"items\": [\"a\", \"b\", \"c\"]})\n",
    "\n",
    "# ✅ Or use Element.metadata for simple key-value\n",
    "Element(metadata={\"text\": \"value\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Checklist\n",
    "\n",
    "### Core Patterns Demonstrated\n",
    "\n",
    "- ✅ **Element Inheritance**: Node inherits `id`, `metadata`, `created_at` from Element\n",
    "- ✅ **Structured Content**: `content: dict | Serializable | BaseModel | None` enforces query-able data\n",
    "- ✅ **Nested Serialization**: Elements in content auto-serialize via `_serialize_content`\n",
    "- ✅ **Embedding Field**: `list[float]` with JSON string coercion + int→float coercion\n",
    "- ✅ **Auto-Registry**: `__pydantic_init_subclass__` registers subclasses in `NODE_REGISTRY`\n",
    "- ✅ **Polymorphic Deserialization**: `from_dict()` routes via `lion_class` metadata\n",
    "- ✅ **Heterogeneous Collections**: Single `Node.from_dict()` call handles mixed types\n",
    "- ✅ **Serialization Modes**: `python`/`json`/`db` with `node_metadata` for DB\n",
    "- ✅ **Pydapter Integration**: Isolated adapter registries (Rust-like explicit)\n",
    "- ✅ **Timestamp Control**: `created_at_format` options (datetime/isoformat/timestamp)\n",
    "\n",
    "### Real-World Use Cases\n",
    "\n",
    "1. **Graph Databases**: Heterogeneous node types in single query → polymorphic deserialization\n",
    "2. **Nested Composition**: Node contains Graph contains Nodes (graph-of-graphs)\n",
    "3. **Vector Search**: Embedding field for semantic search with DB JSON compatibility\n",
    "4. **External Formats**: TOML/YAML serialization with type preservation\n",
    "5. **DB Storage**: `mode=\"db\"` with `node_metadata` avoids column conflicts\n",
    "\n",
    "### Key Design Decisions\n",
    "\n",
    "- **Structured content constraint (Alpha3)**: Enforces JSONB query-ability, prevents primitive soup\n",
    "- **Composition layer identity**: Node (structured) vs Element (identity) vs Event (execution)\n",
    "- **Zero-config subclasses**: Registry eliminates manual registration boilerplate\n",
    "- **Isolated adapter registries**: Prevents pollution, explicit > implicit\n",
    "- **Database-first design**: JSON string coercion, node_metadata field, serialization modes\n",
    "\n",
    "### Migration from Pre-Alpha3\n",
    "\n",
    "```python\n",
    "# ❌ Before: Primitives accepted\n",
    "Node(content=\"text\")\n",
    "Node(content=42)\n",
    "Node(content=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "# ✅ After: Structured types only\n",
    "Node(content={\"text\": \"value\"})\n",
    "Node(content={\"count\": 42})\n",
    "Node(content={\"items\": [\"a\", \"b\", \"c\"]})\n",
    "\n",
    "# ✅ Or use Element.metadata for simple key-value\n",
    "Element(metadata={\"text\": \"value\"})\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
