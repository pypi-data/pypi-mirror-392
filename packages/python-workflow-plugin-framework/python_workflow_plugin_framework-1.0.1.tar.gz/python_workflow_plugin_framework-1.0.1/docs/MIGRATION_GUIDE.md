# è¿ç§»æŒ‡å— - ä»åŸå§‹ä»£ç åˆ°æ¡†æ¶

æœ¬æŒ‡å—å±•ç¤ºå¦‚ä½•å°†ç°æœ‰çš„æ’ä»¶ä»£ç è¿ç§»åˆ° Python Plugin Frameworkã€‚

## å¯¹æ¯”ï¼šåŸå§‹ä»£ç  vs æ¡†æ¶ä»£ç 

### åŸå§‹ä»£ç ç»“æ„ï¼ˆ~450 è¡Œï¼‰

```python
#!/usr/bin/env python3
import grpc
import json
import logging
from concurrent import futures
from grpc_reflection.v1alpha import reflection
from langchain_ollama import OllamaLLM
import node_plugin_pb2
import node_plugin_pb2_grpc

# é…ç½®æ—¥å¿—
logging.basicConfig(...)
logger = logging.getLogger('LangChainOllama')

class LangChainOllamaService(node_plugin_pb2_grpc.NodePluginServiceServicer):
    def __init__(self):
        self.node_config = None
        self.server_endpoint = None
        self.request_count = 0
        logger.info("Service initialized")

    def GetMetadata(self, request, context):
        """è·å–æ’ä»¶å…ƒæ•°æ® - 50+ è¡Œ"""
        return node_plugin_pb2.GetMetadataResponse(
            kind="langchain_ollama_python",
            parameters=[
                node_plugin_pb2.ParameterDef(...),
                node_plugin_pb2.ParameterDef(...),
                # ... æ›´å¤šå‚æ•°
            ]
        )

    def Init(self, request, context):
        """åˆå§‹åŒ–èŠ‚ç‚¹ - 20+ è¡Œ"""
        try:
            self.node_config = json.loads(request.node_json)
            # ... æ›´å¤šåˆå§‹åŒ–ä»£ç 
            return node_plugin_pb2.InitResponse(success=True)
        except Exception as e:
            return node_plugin_pb2.InitResponse(success=False, error=str(e))

    def Run(self, request, context):
        """æ‰§è¡ŒèŠ‚ç‚¹ - 200+ è¡Œ"""
        # æå– metadata
        metadata = dict(context.invocation_metadata())
        trace_id = ...
        
        # è½¬æ¢å‚æ•°
        parameters = self._convert_proto_map_to_dict(request.parameters)
        
        # æ‰§è¡Œé€»è¾‘
        try:
            # ... å¤§é‡ä¸šåŠ¡é€»è¾‘
            yield node_plugin_pb2.RunResponse(...)
        except Exception as e:
            yield node_plugin_pb2.RunResponse(type=ERROR, error=str(e))

    def TestSecret(self, request, context):
        """æµ‹è¯•å¯†é’¥ - 10+ è¡Œ"""
        return node_plugin_pb2.TestSecretResponse(...)

    def HealthCheck(self, request, context):
        """å¥åº·æ£€æŸ¥ - 20+ è¡Œ"""
        return node_plugin_pb2.HealthCheckResponse(...)

    def _convert_proto_value_to_python(self, proto_value):
        """è½¬æ¢ protobuf å€¼ - 30+ è¡Œ"""
        # ... å¤æ‚çš„è½¬æ¢é€»è¾‘
        pass
    
    def _convert_proto_map_to_dict(self, proto_map):
        """è½¬æ¢ protobuf map - 10+ è¡Œ"""
        # ... è½¬æ¢é€»è¾‘
        pass

def serve(port: int = 50052):
    """å¯åŠ¨æœåŠ¡å™¨ - 40+ è¡Œ"""
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = LangChainOllamaService()
    node_plugin_pb2_grpc.add_NodePluginServiceServicer_to_server(service, server)
    # ... æ›´å¤šå¯åŠ¨ä»£ç 
    server.start()
    server.wait_for_termination()

if __name__ == "__main__":
    serve(50052)
```

### æ¡†æ¶ä»£ç ï¼ˆ~180 è¡Œï¼‰

```python
#!/usr/bin/env python3
import sys
from typing import Dict, Any, Iterator
from base_plugin import BasePluginService, serve_plugin
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

class LangChainOllamaPlugin(BasePluginService):
    def __init__(self):
        super().__init__(plugin_name="LangChainOllama")

    def get_plugin_metadata(self) -> Dict[str, Any]:
        """å®šä¹‰æ’ä»¶å…ƒæ•°æ® - åªéœ€è¿”å›å­—å…¸"""
        return {
            "kind": "langchain_ollama_python",
            "node_type": "Node",
            "description": "LangChain v1.0 + Ollama plugin",
            "version": "1.0.0",
            "parameters": [
                {
                    "name": "model",
                    "type": "string",
                    "description": "Ollama model name",
                    "required": True,
                    "default_value": "llama3.2"
                },
                # ... æ›´å¤šå‚æ•°ï¼ˆç®€å•çš„å­—å…¸ï¼‰
            ]
        }

    def execute(
        self,
        parameters: Dict[str, Any],
        parent_output: Dict[str, Any],
        global_vars: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Iterator[Dict[str, Any]]:
        """æ‰§è¡Œæ’ä»¶é€»è¾‘ - åªéœ€å…³æ³¨ä¸šåŠ¡é€»è¾‘"""
        
        # è·å–å‚æ•°ï¼ˆå·²ç»è½¬æ¢å¥½äº†ï¼‰
        model = parameters.get("model", "llama3.2")
        prompt_text = parameters.get("prompt", "")
        temperature = float(parameters.get("temperature", 0.7))
        
        # å‘é€æ—¥å¿—ï¼ˆç®€å•çš„å­—å…¸ï¼‰
        yield {"type": "log", "message": f"ğŸš€ Initializing model: {model}"}
        
        # ä¸šåŠ¡é€»è¾‘
        llm = OllamaLLM(model=model, temperature=temperature)
        chain = llm | StrOutputParser()
        response_text = chain.invoke(prompt_text)
        
        # è¿”å›ç»“æœï¼ˆç®€å•çš„å­—å…¸ï¼‰
        yield {
            "type": "result",
            "data": {
                "result": response_text,
                "model": model
            }
        }

    def health_check(self) -> tuple[bool, str]:
        """å¯é€‰ï¼šè‡ªå®šä¹‰å¥åº·æ£€æŸ¥"""
        try:
            import requests
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                return True, "âœ… Ollama is healthy"
            return False, "âš ï¸ Ollama not responding"
        except Exception as e:
            return False, f"âŒ Health check failed: {e}"

if __name__ == "__main__":
    port = int(sys.argv[1]) if len(sys.argv) > 1 else 50052
    serve_plugin(LangChainOllamaPlugin(), port)
```

## è¿ç§»æ­¥éª¤

### æ­¥éª¤ 1ï¼šåˆ›å»ºæ–°æ–‡ä»¶

```bash
cp my_plugin.py my_plugin_new.py
```

### æ­¥éª¤ 2ï¼šå¯¼å…¥æ¡†æ¶

```python
# åˆ é™¤è¿™äº›å¯¼å…¥
# import grpc
# from concurrent import futures
# from grpc_reflection.v1alpha import reflection
# import node_plugin_pb2
# import node_plugin_pb2_grpc

# æ·»åŠ æ¡†æ¶å¯¼å…¥
from base_plugin import BasePluginService, serve_plugin
```

### æ­¥éª¤ 3ï¼šä¿®æ”¹ç±»å®šä¹‰

```python
# åŸæ¥
class MyService(node_plugin_pb2_grpc.NodePluginServiceServicer):
    def __init__(self):
        self.node_config = None
        # ...

# ç°åœ¨
class MyPlugin(BasePluginService):
    def __init__(self):
        super().__init__(plugin_name="MyPlugin")
```

### æ­¥éª¤ 4ï¼šæå–å…ƒæ•°æ®

```python
# åŸæ¥çš„ GetMetadata æ–¹æ³•
def GetMetadata(self, request, context):
    return node_plugin_pb2.GetMetadataResponse(
        kind="my_plugin",
        parameters=[
            node_plugin_pb2.ParameterDef(
                name="param1",
                type="string",
                description="...",
                required=True,
                default_value="default"
            ),
        ]
    )

# è½¬æ¢ä¸º
def get_plugin_metadata(self) -> Dict[str, Any]:
    return {
        "kind": "my_plugin",
        "parameters": [
            {
                "name": "param1",
                "type": "string",
                "description": "...",
                "required": True,
                "default_value": "default"
            },
        ]
    }
```

### æ­¥éª¤ 5ï¼šæå–æ‰§è¡Œé€»è¾‘

```python
# åŸæ¥çš„ Run æ–¹æ³•ï¼ˆç®€åŒ–ç‰ˆï¼‰
def Run(self, request, context):
    # æå–å‚æ•°
    parameters = self._convert_proto_map_to_dict(request.parameters)
    value = parameters.get("param1")
    
    # å‘é€æ—¥å¿—
    yield node_plugin_pb2.RunResponse(
        type=node_plugin_pb2.RunResponse.LOG,
        log_message="Processing..."
    )
    
    # æ‰§è¡Œé€»è¾‘
    result = self._process(value)
    
    # è¿”å›ç»“æœ
    yield node_plugin_pb2.RunResponse(
        type=node_plugin_pb2.RunResponse.RESULT,
        result_json=json.dumps({"result": result})
    )

# è½¬æ¢ä¸º
def execute(self, parameters, parent_output, global_vars, context):
    # è·å–å‚æ•°ï¼ˆå·²ç»è½¬æ¢å¥½äº†ï¼‰
    value = parameters.get("param1")
    
    # å‘é€æ—¥å¿—
    yield {"type": "log", "message": "Processing..."}
    
    # æ‰§è¡Œé€»è¾‘
    result = self._process(value)
    
    # è¿”å›ç»“æœ
    yield {"type": "result", "data": {"result": result}}
```

### æ­¥éª¤ 6ï¼šå¯é€‰çš„å¥åº·æ£€æŸ¥

```python
# åŸæ¥çš„ HealthCheck æ–¹æ³•
def HealthCheck(self, request, context):
    try:
        # æ£€æŸ¥é€»è¾‘
        return node_plugin_pb2.HealthCheckResponse(
            healthy=True,
            message="Healthy"
        )
    except Exception as e:
        return node_plugin_pb2.HealthCheckResponse(
            healthy=False,
            message=str(e)
        )

# è½¬æ¢ä¸º
def health_check(self) -> tuple[bool, str]:
    try:
        # æ£€æŸ¥é€»è¾‘
        return True, "Healthy"
    except Exception as e:
        return False, str(e)
```

### æ­¥éª¤ 7ï¼šç®€åŒ–å¯åŠ¨ä»£ç 

```python
# åˆ é™¤æ•´ä¸ª serve() å‡½æ•°ï¼ˆ40+ è¡Œï¼‰

# æ›¿æ¢ä¸º
if __name__ == "__main__":
    import sys
    port = int(sys.argv[1]) if len(sys.argv) > 1 else 50052
    serve_plugin(MyPlugin(), port)
```

### æ­¥éª¤ 8ï¼šåˆ é™¤è¾…åŠ©æ–¹æ³•

```python
# åˆ é™¤è¿™äº›æ–¹æ³•ï¼ˆæ¡†æ¶å·²æä¾›ï¼‰
# def _convert_proto_value_to_python(self, proto_value): ...
# def _convert_proto_map_to_dict(self, proto_map): ...
# def Init(self, request, context): ...
# def TestSecret(self, request, context): ...
```

## è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] å¯¼å…¥æ¡†æ¶ï¼š`from base_plugin import BasePluginService, serve_plugin`
- [ ] ç»§æ‰¿åŸºç±»ï¼š`class MyPlugin(BasePluginService)`
- [ ] è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ï¼š`super().__init__(plugin_name="...")`
- [ ] å®ç° `get_plugin_metadata()` è¿”å›å­—å…¸
- [ ] å®ç° `execute()` ä½¿ç”¨ yield è¿”å›å­—å…¸
- [ ] å¯é€‰ï¼šå®ç° `health_check()` è¿”å›å…ƒç»„
- [ ] å¯é€‰ï¼šå®ç° `test_credentials()` è¿”å›å…ƒç»„
- [ ] å¯é€‰ï¼šå®ç° `on_init()` åˆå§‹åŒ–èµ„æº
- [ ] ç®€åŒ–å¯åŠ¨ä»£ç ï¼šä½¿ç”¨ `serve_plugin()`
- [ ] åˆ é™¤ä¸éœ€è¦çš„è¾…åŠ©æ–¹æ³•
- [ ] æµ‹è¯•æ’ä»¶

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•è®¿é—® trace_idï¼Ÿ

```python
# åŸæ¥
metadata = dict(context.invocation_metadata())
trace_id = metadata.get('x-trace-id', 'unknown')

# ç°åœ¨
def execute(self, parameters, parent_output, global_vars, context):
    trace_id = context.get("trace_id", "unknown")
```

### Q: å¦‚ä½•å¤„ç†åˆå§‹åŒ–ï¼Ÿ

```python
# åŸæ¥
def Init(self, request, context):
    self.node_config = json.loads(request.node_json)
    self.db = self._connect_db()
    return InitResponse(success=True)

# ç°åœ¨
def on_init(self, node_config, workflow_entity):
    # node_config å·²ç»æ˜¯å­—å…¸äº†
    self.db = self._connect_db()
```

### Q: å¦‚ä½•å¤„ç†é”™è¯¯ï¼Ÿ

```python
# åŸæ¥
try:
    result = process()
    yield RunResponse(type=RESULT, result_json=json.dumps(result))
except Exception as e:
    yield RunResponse(type=ERROR, error=str(e))

# ç°åœ¨
try:
    result = process()
    yield {"type": "result", "data": result}
except Exception as e:
    yield {"type": "error", "message": str(e)}
```

## è¿ç§»æ•ˆæœ

| æŒ‡æ ‡ | è¿ç§»å‰ | è¿ç§»å | æ”¹è¿› |
|------|--------|--------|------|
| æ€»è¡Œæ•° | ~450 | ~180 | -60% |
| æ ·æ¿ä»£ç  | ~200 | ~0 | -100% |
| æ ¸å¿ƒé€»è¾‘ | ~250 | ~180 | -28% |
| æ–¹æ³•æ•°é‡ | 8 | 2-5 | -38% to -75% |
| å¤æ‚åº¦ | é«˜ | ä½ | â¬‡ï¸â¬‡ï¸ |
| å¯è¯»æ€§ | ä¸­ | é«˜ | â¬†ï¸â¬†ï¸ |
| ç»´æŠ¤æ€§ | ä¸­ | é«˜ | â¬†ï¸â¬†ï¸ |

## å®Œæ•´ç¤ºä¾‹

æŸ¥çœ‹ `langchain_ollama_plugin.py` äº†è§£å®Œæ•´çš„è¿ç§»ç¤ºä¾‹ã€‚

## ä¸‹ä¸€æ­¥

1. è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸
2. æ›´æ–°æ–‡æ¡£
3. éƒ¨ç½²æ–°ç‰ˆæœ¬
4. åˆ é™¤æ—§ä»£ç 

## è·å–å¸®åŠ©

- æŸ¥çœ‹ [README.md](README.md) äº†è§£ API è¯¦æƒ…
- æŸ¥çœ‹ [QUICKSTART.md](QUICKSTART.md) å¿«é€Ÿä¸Šæ‰‹
- æŸ¥çœ‹ç¤ºä¾‹æ’ä»¶äº†è§£æœ€ä½³å®è·µ
