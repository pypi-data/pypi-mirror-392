name: cte_multi_adapter_example
description: Example pipeline demonstrating multiple WRP CTE adapters simultaneously

# Define interceptors at pipeline level
interceptors:
  # Configure multiple adapters
  - pkg_type: wrp_adapters
    pkg_name: cte_adapters
    posix: true                               # For general file I/O
    mpiio: true                               # For MPI-IO operations
    stdio: true                               # For buffered I/O
    vfd: false                                # HDF5 not needed
    nvidia_gds: false
    include: ["/data.*", "/scratch.*"]        # Regex patterns to include
    exclude: ["/data/private.*", "/scratch/tmp.*"]  # Exclude specific subdirs
    adapter_page_size: "1M"                   # 1MB page size

# Define packages
pkgs:
  # Configure CTE runtime first (Service, not Interceptor)
  - pkg_type: wrp_cte
    pkg_name: cte_runtime
    devices:
      - ["ram::cache", "4GB", 1.0]          # Fastest tier (RAM)
      - ["/mnt/nvme", "1TB", 0.9]           # Fast tier (NVMe)
      - ["/mnt/ssd", "2TB", 0.7]            # Medium tier (SATA SSD)
      - ["/mnt/hdd", "10TB", 0.4]           # Slow tier (HDD)
    dpe_type: "max_bw"

  # Initialization message
  - pkg_type: echo
    pkg_name: init
    msg: "Starting multi-adapter CTE test"

  # Example: Application using mixed I/O patterns
  # - pkg_type: my_mixed_io_app
  #   pkg_name: mixed_app
  #   interceptors: ["cte_adapters"]
  #   # This app might use both POSIX and MPI-IO
  #   # CTE will intercept both API calls

  # Example: Scientific workflow
  # - pkg_type: scientific_simulation
  #   pkg_name: simulation
  #   interceptors: ["cte_adapters"]
  #   nprocs: 16
  #   # Uses MPI-IO for parallel output
  #   # Uses POSIX for metadata files
  #   # Uses STDIO for logging

  # Cleanup message
  - pkg_type: echo
    pkg_name: complete
    interceptors: []
    msg: "Multi-adapter test complete"
