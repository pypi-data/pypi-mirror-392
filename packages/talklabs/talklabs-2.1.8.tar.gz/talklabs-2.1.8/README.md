# ğŸ TalkLabs Python SDK

<div align="center">

**SDK oficial da TalkLabs para sÃ­ntese de voz com streaming ultra-baixa latÃªncia**

[![PyPI version](https://badge.fury.io/py/talklabs.svg)](https://badge.fury.io/py/talklabs)
[![Python versions](https://img.shields.io/pypi/pyversions/talklabs.svg)](https://pypi.org/project/talklabs/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[ğŸš€ Quick Start](#uso-rÃ¡pido) â€¢
[ğŸ“š DocumentaÃ§Ã£o](#api-reference) â€¢
[ğŸ’¡ Exemplos](#exemplos-prÃ¡ticos) â€¢
[ğŸ†˜ Suporte](#suporte)

</div>

---

ğŸš€ **v2.1.8**: Streaming com latÃªncia de ~200-500ms + SessÃµes Persistentes!

## CaracterÃ­sticas

- âœ… **CompatÃ­vel com ElevenLabs**: Drop-in replacement para APIs existentes
- âš¡ **Ultra-Low Latency**: ~200-500ms atÃ© primeiro Ã¡udio (vs 5-10s tradicional)
- ğŸ§  **Processamento Inteligente**: SegmentaÃ§Ã£o natural avanÃ§ada
- ğŸ“¡ **Streaming Otimizado**: Sistema paralelo com 3 nÃ­veis de prioridade
- ğŸ§ **Real-time Playback**: Chunks de Ã¡udio prontos para reproduÃ§Ã£o imediata
- ğŸ”„ **Incremental Streaming**: Envio palavra-por-palavra para mÃ¡xima responsividade

## InstalaÃ§Ã£o

```bash
pip install talklabs
```

## Uso RÃ¡pido

### 1. GeraÃ§Ã£o Simples (SÃ­ncrona)

```python
from talklabs import TalkLabsClient

client = TalkLabsClient(api_key="tlk_live_xxxxx")

audio = client.generate(
    text="OlÃ¡! Bem-vindo ao TalkLabs.",
    voice="adam_rocha",
    language="pt",
    speed=1.0
)

with open("output.wav", "wb") as f:
    f.write(audio)
```

> **Exemplo completo:** Veja [examples/generate_simple.py](examples/generate_simple.py) que lÃª o texto de um arquivo `text.txt` e salva o Ã¡udio com o nome do script.

### 2. ğŸš€ Streaming WebSocket (Ultra-Low Latency)

```python
import asyncio
from talklabs import TalkLabsClient

async def stream_example():
    client = TalkLabsClient(api_key="tlk_live_xxxxx")

    # Coletar chunks durante o streaming
    chunks = []

    # Streaming via WebSocket (latÃªncia ~200-500ms)
    async for audio_chunk in client.stream_text(
        text="Este Ã© um teste de ultra baixa latÃªncia!",
        voice="adam_rocha",
        language="pt",
        speed=1.0
    ):
        chunks.append(audio_chunk)
        print(f"Chunk recebido: {len(audio_chunk)} bytes")

    # Juntar e salvar
    full_audio = b"".join(chunks)
    with open("output.wav", "wb") as f:
        f.write(full_audio)

asyncio.run(stream_example())
```

> **Exemplo completo:** Veja [examples/generate_stream_websocket.py](examples/generate_stream_websocket.py) com tratamento de arquivos e progresso detalhado.

### 3. SessÃ£o Persistente (RECOMENDADO para ProduÃ§Ã£o)

```python
import asyncio
from talklabs import TalkLabsClient

async def persistent_session_example():
    client = TalkLabsClient(api_key="tlk_live_xxxxx")

    # Criar sessÃ£o persistente (mantÃ©m conexÃ£o aberta)
    session = await client.create_session(
        voice="adam_rocha",
        language="pt",
        speed=1.0,
        ping_interval=20.0,
        ping_timeout=20.0
    )

    try:
        # MÃºltiplas sÃ­nteses na mesma sessÃ£o (sem reconectar)
        for text in ["Primeira frase.", "Segunda frase.", "Terceira frase."]:
            chunks = []
            async for audio_chunk in session.stream_text(text):
                chunks.append(audio_chunk)
                print(f"Chunk: {len(audio_chunk)} bytes")

            # Salvar cada Ã¡udio
            full_audio = b"".join(chunks)
            # ... processar ou salvar Ã¡udio
    finally:
        # IMPORTANTE: Sempre fechar a sessÃ£o
        await session.close()

asyncio.run(persistent_session_example())
```

> **Exemplo completo:** Veja [examples/persistent_session.py](examples/persistent_session.py) com dois exemplos: mÃºltiplas sÃ­nteses sequenciais e simulaÃ§Ã£o de chatbot interativo.

### 4. Streaming HTTP (MÃ©todo Alternativo)

âš ï¸ **ATENÃ‡ÃƒO**: O mÃ©todo `generate_stream()` via HTTP pode ter limitaÃ§Ãµes com textos muito longos. Para textos extensos (> 1000 caracteres), **use o mÃ©todo WebSocket `stream_text()`** (exemplo #2 acima).

```python
from talklabs import TalkLabsClient

client = TalkLabsClient(api_key="tlk_live_xxxxx")

chunks = []

# Streaming tradicional via HTTP (recomendado apenas para textos curtos)
for chunk in client.generate_stream(
    text="Streaming HTTP incremental",
    voice="adam_rocha",
    language="pt",
    speed=1.0
):
    chunks.append(chunk)
    print(f"Chunk recebido: {len(chunk)} bytes")

# Juntar e salvar
full_audio = b"".join(chunks)
with open("output.wav", "wb") as f:
    f.write(full_audio)
```

> **Exemplo completo:** Veja [examples/generate_stream.py](examples/generate_stream.py)

## API Reference

### `TalkLabsClient`

#### MÃ©todos Principais

**`generate(text, voice, **kwargs)` â†’ bytes**
- GeraÃ§Ã£o sÃ­ncrona completa via HTTP
- Retorna Ã¡udio WAV completo
- Ãštil para textos curtos e testes simples
- **ParÃ¢metros**:
  - `text`: Texto para sintetizar
  - `voice`: ID da voz (ex: "adam_rocha", "adam_rocha")
  - `language`: Idioma ("pt", "en", "es", etc) - padrÃ£o: "pt"
  - `speed`: Velocidade (0.5-2.0) - padrÃ£o: 1.0
  - `voice_settings`: ConfiguraÃ§Ãµes opcionais de voz

**`generate_stream(text, voice, **kwargs)` â†’ Iterator[bytes]**
- Streaming HTTP tradicional
- Retorna chunks progressivamente via HTTP
- âš ï¸ **LimitaÃ§Ã£o**: Pode processar apenas textos curtos (< 1000 caracteres). Para textos longos, use `stream_text()`
- Alternativa quando WebSocket nÃ£o estÃ¡ disponÃ­vel
- **ParÃ¢metros**: mesmos do `generate()`

**`stream_text(text, voice, **kwargs)` â†’ AsyncIterator[bytes]** âš¡ RECOMENDADO
- Streaming via WebSocket com ultra-baixa latÃªncia (~200-500ms)
- ConexÃ£o one-shot (abre e fecha para cada sÃ­ntese)
- Retorna chunks de Ã¡udio conforme sÃ£o gerados
- **ParÃ¢metros**: mesmos do `generate()`

**`create_session(voice, **kwargs)` â†’ StreamingSession** ğŸ¯ MELHOR PARA PRODUÃ‡ÃƒO
- Cria sessÃ£o persistente que mantÃ©m conexÃ£o WebSocket aberta
- Ideal para mÃºltiplas sÃ­nteses sem overhead de reconexÃ£o
- **ParÃ¢metros**:
  - `voice`: ID da voz para a sessÃ£o
  - `language`: Idioma padrÃ£o da sessÃ£o
  - `speed`: Velocidade padrÃ£o
  - `voice_settings`: ConfiguraÃ§Ãµes de voz
  - `ping_interval`: Intervalo de keep-alive (padrÃ£o: 20s)
  - `ping_timeout`: Timeout do keep-alive (padrÃ£o: 20s)

**`get_voices()` â†’ list**
- Lista todas as vozes disponÃ­veis
- Retorna array com metadados de cada voz

### Vozes DisponÃ­veis

```python
# Listar todas as vozes
voices = client.get_voices()
for voice in voices:
    print(f"{voice['voice_id']}: {voice['name']}")
```

**Vozes Populares**:
- `adam_rocha` - PortuguÃªs (BR) - Feminina
- `adam_rocha` - PortuguÃªs (BR) - Masculina
- `maria_silva` - PortuguÃªs (PT) - Feminina
- `joao_santos` - PortuguÃªs (PT) - Masculina

### `StreamingSession`

Classe para sessÃµes persistentes. MÃ©todos disponÃ­veis:

**`stream_text(text)` â†’ AsyncIterator[bytes]**
- Sintetiza texto usando a sessÃ£o existente
- NÃ£o reconecta, usa WebSocket jÃ¡ aberto
- Mesma assinatura do mÃ©todo principal

**`close()`**
- Fecha a conexÃ£o WebSocket
- Sempre chame ao terminar de usar a sessÃ£o

**Exemplo com context manager:**
```python
async with await client.create_session(voice="adam_rocha") as session:
    async for chunk in session.stream_text("OlÃ¡!"):
        process(chunk)
    # close() Ã© chamado automaticamente
```

## Arquitetura do Streaming Otimizado

### Como Funciona

1. **SegmentaÃ§Ã£o Inteligente**: Texto Ã© dividido em sentenÃ§as naturais
2. **Sistema de Filas**: Chunks sÃ£o processados com prioridades:
   - **P1 (Alta)**: Primeira sentenÃ§a - processada imediatamente
   - **P2 (MÃ©dia)**: SentenÃ§as intermediÃ¡rias
   - **P3 (Baixa)**: Ãšltima sentenÃ§a
3. **Processamento Paralelo**: TTS processa chunks simultaneamente
4. **Streaming Real-time**: Ãudio retorna conforme Ã© gerado

### BenefÃ­cios

- âš¡ **LatÃªncia 95% menor**: ~200-500ms vs 5-10s
- ğŸ¯ **Primeira Palavra RÃ¡pida**: UsuÃ¡rio ouve resposta quase instantÃ¢nea
- ğŸ“Š **EscalÃ¡vel**: Suporta mÃºltiplas sessÃµes simultÃ¢neas
- ğŸ§  **Inteligente**: Quebras naturais de sentenÃ§a garantidas

## ğŸ’¡ Exemplos PrÃ¡ticos

### Exemplos DisponÃ­veis

Confira nossos exemplos completos na pasta `examples/`:

- **`generate_simple.py`** - GeraÃ§Ã£o sÃ­ncrona simples
- **`generate_stream.py`** - Streaming HTTP (para textos curtos)
- **`generate_stream_websocket.py`** - Streaming WebSocket (ultra-baixa latÃªncia, recomendado para textos longos)
- **`persistent_session.py`** - SessÃµes persistentes (recomendado para produÃ§Ã£o)
- **`get_voices.py`** - Listar vozes disponÃ­veis

**Nota:** Todos os exemplos leem o texto de um arquivo `text.txt` compartilhado e geram arquivos `.wav` com o nome correspondente ao script.

### Exemplo: Salvar Chunks Progressivamente

```python
async def save_streaming():
    client = TalkLabsClient(api_key="tlk_live_xxxxx")

    with open("output_streaming.wav", "wb") as f:
        async for chunk in client.stream_text(
            text="Este Ã¡udio serÃ¡ salvo em tempo real.",
            voice="adam_rocha"
        ):
            f.write(chunk)

    print("Ãudio salvo!")

asyncio.run(save_streaming())
```

### ReproduÃ§Ã£o em Tempo Real com pyaudio

```python
import pyaudio
import asyncio
from talklabs import TalkLabsClient

async def play_realtime():
    client = TalkLabsClient(api_key="tlk_live_xxxxx")

    # Inicializar pyaudio
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=1, rate=24000, output=True)

    try:
        async for chunk in client.stream_text(
            text="OlÃ¡! Este Ã¡udio estÃ¡ sendo reproduzido em tempo real.",
            voice="adam_rocha"
        ):
            # Reproduzir imediatamente
            stream.write(chunk)
    finally:
        stream.stop_stream()
        stream.close()
        p.terminate()

asyncio.run(play_realtime())
```

### ConfiguraÃ§Ãµes AvanÃ§adas de Voz

```python
from talklabs import TalkLabsClient, VoiceSettings

client = TalkLabsClient(api_key="tlk_live_xxxxx")

settings = VoiceSettings(
    stability=0.85,           # Estabilidade da voz (0-1)
    similarity_boost=0.75,    # Similaridade com voz original
    style=0.0,                # Estilo expressivo (0-1)
    use_speaker_boost=True    # Boost de clareza
)

audio = client.generate(
    text="Teste com configuraÃ§Ãµes customizadas",
    voice="adam_rocha",
    voice_settings=settings,
    speed=1.2  # 20% mais rÃ¡pido
)
```

## Compatibilidade com ElevenLabs

Este SDK Ã© 100% compatÃ­vel com o SDK da ElevenLabs. Basta trocar:

```python
# ElevenLabs
from elevenlabs import ElevenLabs
client = ElevenLabs(api_key="...")

# TalkLabs (drop-in replacement)
from talklabs import TalkLabsClient
client = TalkLabsClient(api_key="tlk_live_...")
```

## Limites e ValidaÃ§Ãµes

### Limites de Tamanho de Texto

A API TalkLabs implementa limites para garantir performance e prevenir abusos:

| Endpoint | Limite MÃ¡ximo | Erro Retornado |
|----------|---------------|----------------|
| **HTTP** (`generate`, `generate_stream`) | 50.000 caracteres | HTTP 400/422 |
| **WebSocket** (`stream_text`, sessÃµes) | 10.000 caracteres/mensagem | WebSocket Error |
| **Buffer WebSocket** (acumulado) | 50.000 caracteres | WebSocket Error |
| **Modelo XTTS2** (limite interno por chunk) | ~200 caracteres (400 tokens) | AssertionError |

âš ï¸ **IMPORTANTE**: O modelo XTTS2 tem um limite interno de **400 tokens por sÃ­ntese** (~200-203 caracteres em portuguÃªs). A API divide automaticamente textos longos em chunks menores, mas chunks individuais que excedam esse limite causarÃ£o erro.

### ValidaÃ§Ãµes de ConteÃºdo

A API valida automaticamente:

- âœ… Texto nÃ£o pode estar vazio
- âœ… Texto nÃ£o pode conter apenas espaÃ§os
- âœ… Texto nÃ£o pode conter apenas pontuaÃ§Ã£o (ex: `"..."`, `"???"`)
- âœ… Texto deve conter ao menos um caractere alfanumÃ©rico

### Exemplos de Erros

```python
# âŒ Texto muito longo (> 50k)
try:
    client.generate(text="A" * 50001, voice="adam_rocha")
except Exception as e:
    print(e)  # "Text too long (50001 characters). Maximum allowed: 50,000 characters."

# âŒ Texto vazio
try:
    client.generate(text="", voice="adam_rocha")
except Exception as e:
    print(e)  # "Text cannot be empty"

# âŒ Apenas pontuaÃ§Ã£o
try:
    client.generate(text="...", voice="adam_rocha")
except Exception as e:
    print(e)  # "Text must contain at least one alphanumeric character"
```

### RecomendaÃ§Ãµes por Tamanho

| Tamanho do Texto | MÃ©todo Recomendado | ObservaÃ§Ãµes |
|------------------|-------------------|-------------|
| < 500 chars | `generate()` ou `generate_stream()` | SÃ­ntese simples via HTTP |
| 500 - 1k chars | `generate_stream()` ou `stream_text()` | HTTP streaming funciona bem |
| 1k - 10k chars | `stream_text()` ou sessÃ£o persistente | **WebSocket OBRIGATÃ“RIO para textos longos** |
| 10k - 50k chars | SessÃ£o persistente com mÃºltiplas mensagens | Dividir em parÃ¡grafos via WebSocket |
| > 50k chars | Dividir em mÃºltiplas requisiÃ§Ãµes | MÃºltiplas sÃ­nteses necessÃ¡rias |

âš ï¸ **IMPORTANTE**: O endpoint HTTP `generate_stream()` tem limitaÃ§Ãµes com textos longos e pode processar apenas a primeira sentenÃ§a. Para textos > 1000 caracteres, **sempre use WebSocket** (`stream_text()` ou sessÃµes persistentes).

**Dica**: Para textos grandes (> 10k), divida em parÃ¡grafos e envie mÃºltiplas mensagens via WebSocket para melhor experiÃªncia.

### Funcionalidades de NormalizaÃ§Ã£o

A API normaliza automaticamente:

- ğŸ’° **Moedas**: `R$ 99,90` â†’ "noventa e nove reais e noventa centavos"
- ğŸ’µ **DÃ³lares**: `$49.99` â†’ "quarenta e nove dÃ³lares e noventa e nove centavos"
- ğŸ“ **EspaÃ§os**: Remove espaÃ§os duplicados
- ğŸ“ **PontuaÃ§Ã£o**: Normaliza reticÃªncias e pontos

```python
# Exemplo com moedas
audio = client.generate(
    text="O produto custa R$ 150,00 e o frete Ã© US$ 25,50",
    voice="adam_rocha"
)
# TTS irÃ¡ falar: "O produto custa cento e cinquenta reais e o frete Ã© vinte e cinco dÃ³lares e cinquenta centavos"
```

## ConfiguraÃ§Ã£o

### Base URL

- **ProduÃ§Ã£o**: `https://api.talklabs.com.br`
- **Local**: `http://localhost:5000` (desenvolvimento)

### Endpoints

- **HTTP**: `/v1/text-to-speech/{voice_id}`
- **WebSocket**: `/v1/text-to-speech/{voice_id}/stream`

## Troubleshooting

### Erro: "Connection refused"

Verifique se a API estÃ¡ rodando:
```bash
curl https://api.talklabs.com.br/health
```

### LatÃªncia alta no streaming

1. Use `stream_text()` ou sessÃ£o persistente ao invÃ©s de `generate_stream()`
2. Verifique sua conexÃ£o com a API
3. Certifique-se que estÃ¡ usando a regiÃ£o mais prÃ³xima

### Chunks de Ã¡udio corrompidos

- Certifique-se de salvar/reproduzir como WAV 24kHz mono
- Use `io.BytesIO` para buffer temporÃ¡rio se necessÃ¡rio

---

## ğŸ†˜ Suporte

- ğŸ“§ **Email**: support@talklabs.com.br
- ğŸŒ **Website**: https://talklabs.com.br
- ğŸ’¡ **Exemplos**: Ver pasta `examples/` incluÃ­da no pacote
- ğŸ“š **DocumentaÃ§Ã£o**: Ver seÃ§Ã£o API Reference acima

---

## ğŸ“„ LicenÃ§a

MIT License - veja LICENSE para detalhes.

---

**Desenvolvido com â¤ï¸ pela equipe TalkLabs**
