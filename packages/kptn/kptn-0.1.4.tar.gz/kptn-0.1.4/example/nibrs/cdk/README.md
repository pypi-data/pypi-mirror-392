# NIBRS Estimation Pipeline CDK Project

This is the AWS CDK project for the NIBRS Estimation Pipeline. It is a TypeScript project that defines AWS resources to deploy for the pipeline. Basically, it deploys and initializes all of our required cloud infrastructure.

## Configuration

#### Node

You will need to have node configured on your local machine. I recommend using [Node Version Manager](https://github.com/nvm-sh/nvm) to help manage these node environments. Follow the install and usage instructions until you reach the point of activating the node environment with `nvm use node`

1. `nvm use node`
1. `npm install`

#### AWS

You will need to configure [awscli](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html). You can use homebrew if that is your preference. Once installed setup your environment so that you have a profile called "nibrs". This profile will be used to interact with AWS resources across all of the stacks.

1. [awscli](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
2. Create a folder $HOME/.aws/
3. aws configure --profile nibrs(it will prompt you to fill in each of the items in the config files below)
  * [ALTERNATIVE to aws configure]. Create “config” file (no file type ending) with the following contents:
  * [ALTERNATIVE to aws configure]. Create “credentials” file (no file type ending) with the following contents:

config

```
[nibrs]
output = json
```

credentials

```
[nibrs]
aws_access_key_id = access_key with permission to all stacks
aws_secret_access_key = secret_key with permission to all stacks
```

#### Github Personal Access Token (PAT)

If you don't have one, [create a GitHub Personal Access Token (PAT)](https://github.com/settings/tokens/new) (classic) with `read:packages` access in GitHub Enterprise. Use the command `npm config set //npm.pkg.github.com/:_authToken=MY_PAT` to set the token in your local npm configuration. Replace `MY_PAT` with the PAT you created.

Once the token is generated you will need to click `Configure SSO` and authorize `rti-international` using SSO.

If you previously set a token and the permissions expired on it, you can re-generate the token and follow the steps above agin. 

## CDK Deployment

Multiple CDK stacks are defined in this project. The order the stacks are deployed is important, and there are some manual steps that must be performed due to limitations in CDK's functionality. Follow the steps below to deploy the infrastructure.

**NOTE:** The names of the stacks are generated by CDK at run-time using `STACK_NAME` and `RSRC_SUFFIX`. This is equivalent to `{STACK_NAME}{stack_type}-{RSRC_SUFFIX}`.  For example: `STACK_NAME` is set to `nibrsep`, `RSRC_SUFFIX` is set to `alpha`. Then the "full stack name" of the `stack_type` "Foundation" would be `nibrsepFoundation-alpha`.

All of these commands are designed to be run from this directory (`<repo_root>/cdk/`). Replace ` <suffix>` with the env file suffix of the stack you wish to deploy.

1. Deploy the Foundation stack:

```bash
npm run cdk deploy Foundation -- -c stackSuffix=<suffix>
```

3. Deploy the Jumpbox stack:

```bash
npm run cdk deploy Jumpbox -- -c stackSuffix=<suffix>
```

Confirm SSH access to the EC2 instance:

```bash
ssh -i ~/.ssh/<KEY_PAIR_NAME>.pem ec2-user@<EC2_INSTANCE_IP>
```

Manual steps are possible to perform during this time. The two most common would be:

*  Mount an imported EFS
    * EFS -> Network -> Manage
    * VPC -> (cdk vpc)
    * subnet -> public subnet 1
    * security group -> nibrs EFS security Group
    * ssh -> `sudo mount -a -t efs,nfs4 defaults`
* Add the VPC eip to the database ingress security group
    * need to add the EIP of the VPC
    * Find the EIP: CloudFormation -> Foundation Stack -> Resources -> VPC -> publicSubnet1 -> EIP
    * Add the EIP to database security group
        * Find the sg: RDS -> prod-database reader instance -> Connectivty & Security -> VPC Security Groups
        * Add rule: Inbound Rules -> Edit inbound rules -> type: `PostgreSQL`, source: `custom` EIP found in previous step, description: name of stack

4. Build and Push Docker Images to ECR:

```bash
bash bin/build-and-push-to-ecr.sh <suffix> all
```

This will take some time. We are building and pushing three images to ECR.

5. Deploy the PrefectWebServer stack:

```bash
npm run cdk deploy PrefectWebServer -- -c stackSuffix=<suffix>
```

6. Deploy the PrefectEcsWorker stack:

```bash
npm run cdk deploy PrefectEcsWorker -- -c stackSuffix=<suffix>
```

7. Deploy the AuthProxy stack:

```bash
npm run cdk deploy AuthProxy -- -c stackSuffix=<suffix>
```

8. Initialize Prefect Flows/Deployments

```bash
bash bin/seed-prefect-deployments.sh <stack-suffix> <deployment-name> <flow-entrypoint>
```


## Addendum A: Getting stack outputs

This command will output environment variables needed for deploying flows to Prefect:

```bash
npm run cdk outputs
```

## Addendeum B: Destroying a stack

To destroy a stack:

```bash
npm run cdk destroy --force Jumpbox
```

You will need to destory the stacks "from top to bottom". So foundation can not be destoryed until all of the other stacks are already destroyed.

## Addendum C: Dask Dashboard

To view the dask-dashboard of an already running flow you can use the following hacky solution:

1. In WebBrowser:
  * Prefect UI: start flow
  * AWS Console-> ECS -> clusters -> nibrs -> tasks -> prefect scheduler -> private ip
  * Copy this private IP
1. In local machine terminal:
  * `ssh -L 8080:<dask-private-ip>:8787 <ssh-alias-of-region>`
  * `<dask-private-ip>` is the IP copied in step 1
  * `<ssh-alias-of-region>` is the ssh alias for the ec2 server in the region you are running the flow
  * if you want to use a port other than 8080, change that in the command.  **Do not change 8787.**
1. In WebBrowser:
  * go to `localhost:8080` to view the dashboard
  * If you changed the port in the previous step then go to that port instead of 8080
1. When the pipeline finishes the dask scheduler will close, so this dashboard will not be available.

**note:** the `dask-private-ip` changes everytime a new scheduler is created. If you start a new flow, you should close the previous ssh tunnel and create a new one with the new private ip.

## Prefect Deployments

**PRE-REQ:** See [AWS Configuration](#aws).

Deployments of flows is a two step processes **You should be inside the cdk directory when running these commands**:

1. Build and push the flow code to ECR
  * This can be accomplished with `bash bin/build-and-push-to-ecr.sh <region> <imageType>`
  * To get additional usage information on the script, run it without arguements.
2. Create a deployment in prefect-ui
  * This can be accomplished with `bash bin/seed-prefect-deployments.sh <region> <deployment-name> <flow-entrypoint>`
  * To get additional usage information on the script, run it without arguments.

### Examples of deployment/image "invalidations"

**NOTE:** Due to the current code setup, it is necessary that a prefect deployment and flowRunner image are done together. Every flow that we write will always attempt to pull `latest` image from the registry. So if you create a deployment and push an updated image, it will only be valid until you push another image.  If a second deployment needs a different version of the code, that deployment & its ECR push would "invalidate" the old deployment.

Examples:

* Starting a new phase of runs for the first time, aka new deployment:
  * Create the deployment & push the latest code to ECR
  * If you want to simply re-run the same code then you can do so through the UI.
  * If you need to update the code, but want to keep all the runs in the same deployment, simply build & push the updated code to ecr
  * As long as you want to perform runs inside this deployment, you only need to build & push when there are code changes.
* Starting a second phase, aka a new deployment, but an "old" deployment exists:
  * Create the deployment & push the latest code to ECR
  * This "new" deployment is now the active deployment, and works similar to the example above.
  * This would "invalidate" the old deployment.
    * Do not try to run an old deployment after creating a new one that is based on different code.
    * If you need to re-run something in the old deployment, you'll want to build & push an image based on that deployment's code. [which would then invalidate the "new" deployment]
