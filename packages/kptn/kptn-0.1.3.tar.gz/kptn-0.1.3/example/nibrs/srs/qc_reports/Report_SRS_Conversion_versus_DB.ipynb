{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f609f3",
   "metadata": {},
   "source": [
    "# SRS Conversion to Database Comparison\n",
    "\n",
    "This report compares the raw conversion code output to the converted counts stored in the database. It then highlights any differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce788d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import Engine\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "scratch_space = Path(os.getenv(\"OUTPUT_PIPELINE_DIR\"))\n",
    "state = os.getenv(\"INPUT_STATE\")\n",
    "converted_path = scratch_space / \"srs\"/\"extracts\"\n",
    "year=os.getenv(\"DATA_YEAR\")\n",
    "(scratch_space / \"srs\" / \"QC_output_files\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "nibrs = Path(\"nibrs-estimation-pipeline\")\n",
    "def connect_to_database() -> Engine:\n",
    "    \"\"\"This function opens a connection to the database.\"\"\"\n",
    "    user = os.getenv(\"PGUSER\")\n",
    "    password = os.getenv(\"PGPASSWORD\")\n",
    "    host = os.getenv(\"PGHOST\")\n",
    "    port = os.getenv(\"PGPORT\")\n",
    "    dbname = os.getenv(\"PGDATABASE\")\n",
    "    # --- Create connection\n",
    "    engine_database = create_engine(\n",
    "        f\"postgresql://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "    )\n",
    "    return engine_database\n",
    "engine_database = connect_to_database()\n",
    "\n",
    "srs_col_dict = [\n",
    "    'MURDER',\n",
    "    'MANSLAUGHTER',\n",
    "    'RAPE',\n",
    "    'FORCE RAPE',\n",
    "    'ATMPTD RAPE',\n",
    "    'ROBBERY',\n",
    "    'GUN ROBBERY',\n",
    "    'KNIFE ROBBERY',\n",
    "    'OTHER WEAPON ROBBERY',\n",
    "    'STRONG ARM ROBBERY',\n",
    "    'ASSAULT',\n",
    "    'GUN ASSAULT',\n",
    "    'KNIFE ASSAULT',\n",
    "    'OTHER WEAPON ASSAULT',\n",
    "    'HAND/FEET ASSAULT',\n",
    "    'SIMPLE ASSAULT',\n",
    "    'BURGLARY',\n",
    "    'BURGLARY FORCE ENTRY',\n",
    "    'BURGLARY ENTRY-NO FORCE',\n",
    "    'ATTEMPTED BURGLARY',\n",
    "    'LARCENY',\n",
    "    'VEHICLE THEFT',\n",
    "    'AUTO THEFT',\n",
    "    'TRUCK/BUS THEFT',\n",
    "    'OTHER VEHICLE THEFT',\n",
    "    'ALL FIELDS',\n",
    "]\n",
    "\n",
    "month_col_dict = {\n",
    "    70:\"JAN\",\n",
    "    188:\"FEB\",\n",
    "    306:\"MAR\",\n",
    "    424:\"APR\",\n",
    "    542:\"MAY\",\n",
    "    660:\"JUN\",\n",
    "    778:\"JUL\",\n",
    "    896:\"AUG\",\n",
    "    1014:\"SEP\",\n",
    "    1132:\"OCT\",\n",
    "    1250:\"NOV\",\n",
    "    1368:\"DEC\"\n",
    "}\n",
    "\n",
    "\n",
    "# derive the full list of v variables we need\n",
    "all_dict = {}\n",
    "for month in month_col_dict.keys():\n",
    "    for i in range(len(srs_col_dict)):\n",
    "        all_dict[f\"v{month + i}\"] = month_col_dict[month] + \" \" + srs_col_dict[i]\n",
    "\n",
    "# these are fields which are aggregates of other fields, so we drop them when comparing\n",
    "total_fields = [\"ALL FIELDS\",\"ROBBERY\",\"RAPE\",\"ASSAULT\",\"BURGLARY\",\"VEHICLE THEFT\"]\n",
    "invalid_fields = []\n",
    "for field in total_fields:\n",
    "    invalid_fields += [f\"{month} {field}\" for month in month_col_dict.values()]\n",
    "    \n",
    "    \n",
    "breakdown_dict = {\n",
    "    \"Assault - Firearm\":'GUN ASSAULT',\n",
    "    \"Assault - Hands, Fists, Feet\":'HAND/FEET ASSAULT',\n",
    "    \"Assault - Knife or Cutting Instrument\":'KNIFE ASSAULT',\n",
    "    \"Assault - Other Dangerous Weapon\":'OTHER WEAPON ASSAULT',\n",
    "    \"Burglary - Attempted Forcible Entry\":'ATTEMPTED BURGLARY',\n",
    "    \"Burglary - Forcible Entry\":'BURGLARY FORCE ENTRY',\n",
    "    \"Burglary - No Force\":'BURGLARY ENTRY-NO FORCE',\n",
    "    \"Auto Theft\":'AUTO THEFT',\n",
    "    \"Other Vehicle Theft\":'OTHER VEHICLE THEFT',\n",
    "    \"Truck and Bus Theft\":'TRUCK/BUS THEFT',\n",
    "    \"Murder and Nonnegligent Homicide\":'MURDER',\n",
    "    \"Attempted Rape\":'ATMPTD RAPE',\n",
    "    \"Rape\":'FORCE RAPE',\n",
    "    \"Robbery - Firearm\":'GUN ROBBERY',\n",
    "    \"Robbery - Hands, Fists, Feet\":'STRONG ARM ROBBERY',\n",
    "    \"Robbery - Knife or Cutting Instrument\":'KNIFE ROBBERY',\n",
    "    \"Robbery - Other Dangerous Weapon\":'OTHER WEAPON ROBBERY',\n",
    "    \"Simple Assault\":'SIMPLE ASSAULT',\n",
    "    \"Manslaughter by Negligence\":'MANSLAUGHTER',\n",
    "    'Larceny - Theft (Not Specified)':\"LARCENY\",\n",
    "}\n",
    "\n",
    "month_list = list(month_col_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0694af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output of step 2 of the SRS conversion\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    df_conversion_aggregated = pd.read_csv(converted_path / f\"SRS_{year}_{state}.csv\").drop(\n",
    "        columns=[\"ori\"]\n",
    "    ).rename(columns={\"legacy_ori\":\"ori\"}).sort_values(by=[\"ori\"]).reset_index(drop=True)\n",
    "\n",
    "    # get the SRS external file\n",
    "    df_srs_fromdb = pd.read_csv(\n",
    "            scratch_space /\n",
    "            \"initial_tasks_output\" /\n",
    "            f\"UCR_SRS_{year}_clean_reta_mm_selected_vars.csv\",\n",
    "            parse_dates=[\"NIBRS_START_DATE_UNIV\"]\n",
    "    ).rename(columns={\"ORI\":\"ori\"})\n",
    "\n",
    "# get the nibrs start dates for each ori\n",
    "unique_ori_unique = df_srs_fromdb[[\"ori\",\"NIBRS_START_DATE_UNIV\"]].drop_duplicates()\n",
    "\n",
    "# subset to just the one state we have the conversion file for\n",
    "df_srs_fromdb = df_srs_fromdb.loc[df_srs_fromdb[\"ori\"].isin(\n",
    "    df_conversion_aggregated[\"ori\"]\n",
    ")].sort_values(by=[\"ori\"]).reset_index(drop=True)[df_conversion_aggregated.columns]\n",
    "\n",
    "# rename columns from V form to text\n",
    "df_conversion_aggregated = df_conversion_aggregated.rename(\n",
    "    columns=all_dict\n",
    ").melt(id_vars=[\"ori\"])\n",
    "df_srs_fromdb = df_srs_fromdb.rename(\n",
    "    columns=all_dict\n",
    ").melt(id_vars=[\"ori\"])\n",
    "both_merged = df_conversion_aggregated.merge(df_srs_fromdb,on=[\"ori\",\"variable\"],suffixes=[\"_rti\",\"_cjis\"])\n",
    "\n",
    "\n",
    "# drop ori+variable combos for variables where the start date was both the year in question \n",
    "# and from a month after that variable's month\n",
    "def get_start_month(d):\n",
    "    if d == -1:\n",
    "        return d\n",
    "    if d.year > int(year):\n",
    "        # if the start year was after this year then no months are valid\n",
    "        return 13\n",
    "    elif d.year < int(year):\n",
    "        # if the start year was before this year then all months are valid\n",
    "        return -1\n",
    "    else:\n",
    "        return d.month\n",
    "\n",
    "unique_ori_unique[\"NIBRS_START_MONTH\"] = unique_ori_unique[\"NIBRS_START_DATE_UNIV\"].fillna(-1).apply(get_start_month)\n",
    "month_num_dict = {month_list[i]:i+1 for i in range(len(month_list))}\n",
    "both_merged[\"variable_month\"] = both_merged[\"variable\"].apply(lambda x: month_num_dict[x.split(\" \")[0]])\n",
    "both_merged = both_merged.merge(unique_ori_unique[[\"ori\",\"NIBRS_START_MONTH\",\"NIBRS_START_DATE_UNIV\"]],on=\"ori\",how=\"left\")\n",
    "both_merged = both_merged.loc[both_merged[\"variable_month\"] >= both_merged[\"NIBRS_START_MONTH\"]].drop(\n",
    "    columns=[\"variable_month\",\"NIBRS_START_MONTH\"]\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In this report we are looking at counts for the state of {state} for {year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039de621",
   "metadata": {},
   "source": [
    "## Part 1: Overall Differences\n",
    "\n",
    "Below are the overall differences in the Return A SRS offense counts for NIBRS agencies between the rti-converted counts and the cjis-converted table. \n",
    "\n",
    "First, let's see which agencies in the state had differences in their overall counts for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d553eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_level_diffs = both_merged.loc[both_merged[\"variable\"].str.endswith(\"ALL FIELDS\")].groupby([\"ori\"])[[\"value_rti\",\"value_cjis\"]].sum()\n",
    "ori_level_diffs = ori_level_diffs.loc[ori_level_diffs[\"value_rti\"] != ori_level_diffs[\"value_cjis\"]].copy()\n",
    "ori_level_diffs[\"diff\"] = ori_level_diffs[\"value_rti\"] - ori_level_diffs[\"value_cjis\"]\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(ori_level_diffs.sort_values(by=[\"diff\"],ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a950d",
   "metadata": {},
   "source": [
    "Next, let's break these differences down by variable and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee581565",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_index = both_merged.groupby([\"variable\"])[[\"value_rti\",\"value_cjis\"]].sum()\n",
    "\n",
    "all_indexes = []\n",
    "for month in month_num_dict.keys():\n",
    "    all_indexes += [f\"{month} {x}\" for x in srs_col_dict]\n",
    "\n",
    "rows_to_drop = [i for i in invalid_fields if i in merged_index.index]\n",
    "merged_index = merged_index.reindex(\n",
    "    [r for r in merged_index.index if r not in rows_to_drop]\n",
    ")\n",
    "# sort the index by month and varible and then add that sort order as an index we can use to re-sort later\n",
    "merged_index = merged_index.reindex(\n",
    "    [r for r in all_indexes if r in merged_index.index]\n",
    ").reset_index().reset_index().set_index(\"variable\")\n",
    "merged_index[\"diff\"] = merged_index[\"value_rti\"] - merged_index[\"value_cjis\"]\n",
    "merged_index = merged_index.loc[merged_index[\"diff\"] != 0]\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(merged_index.sort_values(by=[\"diff\",\"index\"],ascending=[False,True]).drop(columns=[\"index\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4d73b",
   "metadata": {},
   "source": [
    "## Part 2: Specific Agency Differences\n",
    "\n",
    "In this section we identify the specific sources of differences seen in the aggregate totals.\n",
    "\n",
    "First, below we see the agency-level differences for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fae7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = both_merged.loc[both_merged[\"value_rti\"] != both_merged[\"value_cjis\"]]\n",
    "# ignore total fields since we have the detailed categories\n",
    "diffs = diffs.loc[~diffs[\"variable\"].isin(invalid_fields)].rename(columns={\n",
    "    \"value_rti\":\"count_rti\",\n",
    "    \"value_cjis\":\"count_cjis\"\n",
    "})\n",
    "# display the places where we see different counts\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(diffs.reset_index(drop=True)[[\"ori\",\"NIBRS_START_DATE_UNIV\",\"variable\",\"count_rti\",\"count_cjis\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(diffs) > 0:\n",
    "\n",
    "    df_conversion_detailed = pd.read_csv(\n",
    "        converted_path / \n",
    "        f\"raw_SRS_incidents_{year}_{state}.csv\"\n",
    "    )\n",
    "    df_conversion_detailed[\"offense\"] = df_conversion_detailed[\"der_offense_month\"].apply(lambda x: all_dict[x])\n",
    "    df_conversion_detailed = df_conversion_detailed[[\"legacy_ori\",\"incident_id\",\"offense\",\"counts\"]].rename(\n",
    "        columns={\"offense\":\"variable\",\"counts\":\"count_rti\"}\n",
    "    )\n",
    "    df_conversion_detailed[\"match\"] = df_conversion_detailed[\"legacy_ori\"] + \"_\" + df_conversion_detailed[\"variable\"]\n",
    "\n",
    "    ori_list = \"('\"+\"','\".join(diffs['ori'].unique().tolist())+\"')\"\n",
    "    specific_incident_raw = f\"\"\"\n",
    "        select\n",
    "            ra.legacy_ori,\n",
    "            lso.offense_name,\n",
    "            lso.breakdown_name,\n",
    "            data_month,\n",
    "            smo.nibrs_incident_id,\n",
    "            smo.actual_count from ucr_prd.form_month fm\n",
    "        join ucr_prd.sum_month_offense smo using(form_month_id)\n",
    "        join ucr_prd.ref_agency ra using (agency_id)\n",
    "        join ucr_prd.lkup_srs_offense lso using (breakdown_id)\n",
    "        WHERE\n",
    "        data_year = {year} and ra.legacy_ori in {ori_list}\n",
    "    \"\"\"\n",
    "    specific_incident_df = pd.read_sql(specific_incident_raw, engine_database).drop_duplicates()\n",
    "    specific_incident_df[\"offense\"] = specific_incident_df[\"breakdown_name\"].apply(lambda x: breakdown_dict[x] if x in breakdown_dict else None)\n",
    "    specific_incident_df.dropna(subset=[\"offense\"],inplace=True)\n",
    "    specific_incident_df[\"offense\"] = specific_incident_df[\"data_month\"].apply(lambda m: month_list[m - 1]) + \" \" + specific_incident_df[\"offense\"]\n",
    "    specific_incident_df = specific_incident_df[[\"legacy_ori\",\"nibrs_incident_id\",\"offense\",\"actual_count\"]].rename(columns={\n",
    "        \"nibrs_incident_id\":\"incident_id\",\"actual_count\":\"count_cjis\",\"offense\":\"variable\"\n",
    "    })\n",
    "    specific_incident_df[\"match\"] = specific_incident_df[\"legacy_ori\"] + \"_\" + specific_incident_df[\"variable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(diffs) > 0:\n",
    "    print(\"Finally, let's split these differences out by specific NIBRS incident ID.\")\n",
    "    # for pairs of diffs, get the rows from both datasets which are around each\n",
    "    # then merge the two datasets on incident ID\n",
    "    diffs[\"match\"] = diffs[\"ori\"] + \"_\" + diffs[\"variable\"]\n",
    "    converted_incidents = df_conversion_detailed.loc[df_conversion_detailed[\"match\"].isin(diffs[\"match\"])].drop(columns=[\"match\"])\n",
    "    db_incidents = specific_incident_df.loc[specific_incident_df[\"match\"].isin(diffs[\"match\"])].drop(columns=[\"match\"])\n",
    "\n",
    "    converted_incidents[\"incident_id\"] = converted_incidents[\"incident_id\"].astype(float)\n",
    "    db_incidents[\"incident_id\"] = db_incidents[\"incident_id\"].astype(float)\n",
    "\n",
    "    both_groups = converted_incidents.merge(db_incidents,on=[\"legacy_ori\",\"incident_id\",\"variable\"],how=\"outer\")\n",
    "    both_groups[\"count_rti\"] = both_groups[\"count_rti\"].fillna(0)\n",
    "    both_groups[\"count_cjis\"] = both_groups[\"count_cjis\"].fillna(0)\n",
    "\n",
    "    both_groups = both_groups.loc[both_groups[\"count_rti\"] != both_groups[\"count_cjis\"]]\n",
    "    both_groups = both_groups.sort_values(by=[\"variable\",\"legacy_ori\"])[\n",
    "        ['legacy_ori', 'incident_id', 'variable','count_rti', 'count_cjis']\n",
    "    ].reset_index(drop=True)\n",
    "    both_groups.to_csv(scratch_space / \"srs\" / \"QC_output_files\" / f\"incident_level_differences_{state}_{year}.csv\",index=False)\n",
    "\n",
    "    with pd.option_context('display.max_rows', None):\n",
    "        display(both_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
