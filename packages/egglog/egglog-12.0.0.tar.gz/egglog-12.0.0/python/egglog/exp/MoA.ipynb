{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "922a695b",
   "metadata": {},
   "source": [
    "# Mathematics of Arrays in Egglog\n",
    "\n",
    "\n",
    "This notebook shows how if you define array operations as higher order functions, we can compose them and end up with a simpler algebra that just uses boolean and integers and functions.\n",
    "\n",
    "We take as our input this MoA program, defined in [the PSI compiler](https://saulshanabrook.github.io/psi-compiler/src/):\n",
    "\n",
    "\n",
    "```\n",
    "main ()\n",
    "\n",
    "{\n",
    "  array Amts^3 <2 3 4>;\n",
    "  array Ams^3 <2 3 4>;\n",
    "  const array RAMY^3 <2 3 4>=<1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 5 6 7 8 9 10 \n",
    "\t\t\t\t11 12>;\n",
    "  const array AMY^3 <2 3 4>=<9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9>;\n",
    "  Amts=<2> take (<2> drop (RAMY cat AMY));\n",
    "}\n",
    "```\n",
    "\n",
    "This result `Amts` is equivalent to `AMY`, since we are concatenating `RAMY` and `AMY` along the first axis, dropping the first 2 elements (which removes all of `RAMY`), and then taking the next 2 elements (which is all of `AMY`).\n",
    "\n",
    "Compiling it produces this C program which copies AMY into Amts:\n",
    "\n",
    "```c\n",
    "#include <stdlib.h>\n",
    "#include \"moalib.e\"\n",
    "\n",
    "main()\n",
    "\n",
    "{\n",
    "  double *offset0;\n",
    "  int i0;\n",
    "  int i1;\n",
    "  int i2;\n",
    "  double *shift;\n",
    "  double _RAMY[]={1.000000, 2.000000, 3.000000, 4.000000, 5.000000,\n",
    "    6.000000, 7.000000, 8.000000, 9.000000, 10.000000,\n",
    "    11.000000, 12.000000, 1.000000, 2.000000, 3.000000,\n",
    "    4.000000, 5.000000, 6.000000, 7.000000, 8.000000,\n",
    "    9.000000, 10.000000, 11.000000, 12.000000};\n",
    "  double _AMY[]={9.000000, 9.000000, 9.000000, 9.000000, 9.000000,\n",
    "    9.000000, 9.000000, 9.000000, 9.000000, 9.000000,\n",
    "    9.000000, 9.000000, 9.000000, 9.000000, 9.000000,\n",
    "    9.000000, 9.000000, 9.000000, 9.000000, 9.000000,\n",
    "    9.000000, 9.000000, 9.000000, 9.000000};\n",
    "  double _Y[]={8.000000, 8.000000, 8.000000, 8.000000, 8.000000,\n",
    "    8.000000, 8.000000, 8.000000, 8.000000, 8.000000,\n",
    "    8.000000, 8.000000, 8.000000, 8.000000, 8.000000,\n",
    "    8.000000, 8.000000, 8.000000, 8.000000, 8.000000,\n",
    "    8.000000, 8.000000, 8.000000, 8.000000};\n",
    "  double _V[]={1.000000, 1.000000};\n",
    "  double _Amts[2*3*4];\n",
    "\n",
    "/*******\n",
    "Amts=<2.000000> take (<2.000000> drop (RAMY cat AMY))\n",
    "********/\n",
    "\n",
    "  shift=_Amts+0*12+0*4+0;\n",
    "  offset0=_AMY+0*12+0*4+0;\n",
    "  for (i0=0; i0<2; i0++) {\n",
    "    for (i1=0; i1<3; i1++) {\n",
    "      for (i2=0; i2<4; i2++) {\n",
    "        *(shift)= *(offset0);\n",
    "        offset0+=1;\n",
    "        shift+=1;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "What we want to show here is not the full compilation into C and into loops, but just the fact that by defining each array operation as a higher order function, we can compose them and end up with a simpler algebra that just uses boolean and integers and functions. This could then be compiled into loops. The hypothesis here is that we don't *lose* any information by erasing the `take`, `drop`, and `cat` operations and replacing them with their definitions in terms of functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b715c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"n\">take</span><span class=\"p\">(</span><span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">cat</span><span class=\"p\">(</span><span class=\"n\">NDArray</span><span class=\"o\">.</span><span class=\"n\">from_memory</span><span class=\"p\">(</span><span class=\"n\">TupleInt</span><span class=\"o\">.</span><span class=\"n\">from_vec</span><span class=\"p\">(</span><span class=\"n\">Vec</span><span class=\"p\">(</span><span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))),</span> <span class=\"n\">RAMY</span><span class=\"p\">),</span> <span class=\"n\">NDArray</span><span class=\"o\">.</span><span class=\"n\">from_memory</span><span class=\"p\">(</span><span class=\"n\">TupleInt</span><span class=\"o\">.</span><span class=\"n\">from_vec</span><span class=\"p\">(</span><span class=\"n\">Vec</span><span class=\"p\">(</span><span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">Int</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))),</span> <span class=\"n\">AMY</span><span class=\"p\">))))</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{n}{take}\\PY{p}{(}\\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{,} \\PY{n}{drop}\\PY{p}{(}\\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{,} \\PY{n}{cat}\\PY{p}{(}\\PY{n}{NDArray}\\PY{o}{.}\\PY{n}{from\\PYZus{}memory}\\PY{p}{(}\\PY{n}{TupleInt}\\PY{o}{.}\\PY{n}{from\\PYZus{}vec}\\PY{p}{(}\\PY{n}{Vec}\\PY{p}{(}\\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{3}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,} \\PY{n}{RAMY}\\PY{p}{)}\\PY{p}{,} \\PY{n}{NDArray}\\PY{o}{.}\\PY{n}{from\\PYZus{}memory}\\PY{p}{(}\\PY{n}{TupleInt}\\PY{o}{.}\\PY{n}{from\\PYZus{}vec}\\PY{p}{(}\\PY{n}{Vec}\\PY{p}{(}\\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{3}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Int}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,} \\PY{n}{AMY}\\PY{p}{)}\\PY{p}{)}\\PY{p}{)}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "take(Int(2), drop(Int(2), cat(NDArray.from_memory(TupleInt.from_vec(Vec(Int(2), Int(3), Int(4))), RAMY), NDArray.from_memory(TupleInt.from_vec(Vec(Int(2), Int(3), Int(4))), AMY))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "from egglog import *\n",
    "\n",
    "array_ruleset = ruleset(name=\"array_ruleset\")\n",
    "\n",
    "\n",
    "class Boolean(Expr):\n",
    "    def __init__(self, val: BoolLike) -> None: ...\n",
    "    def if_bool(self, then: Int, else_: Int) -> Int: ...\n",
    "\n",
    "\n",
    "class Int(Expr):\n",
    "    def __init__(self, val: i64Like) -> None: ...\n",
    "    def __eq__(self, other: Int) -> Boolean: ...  # type: ignore[override]\n",
    "    def __lt__(self, other: Int) -> Boolean: ...\n",
    "    def __add__(self, other: Int) -> Int: ...\n",
    "    def __sub__(self, other: Int) -> Int: ...\n",
    "    def __mul__(self, other: Int) -> Int: ...\n",
    "\n",
    "\n",
    "@array_ruleset.register\n",
    "def _int(i: i64, j: i64, x: Int, y: Int):\n",
    "    yield rewrite(Int(i) + Int(j)).to(Int(i + j))\n",
    "    yield rewrite(Int(i) - Int(j)).to(Int(i - j))\n",
    "    yield rewrite(Int(i) * Int(j)).to(Int(i * j))\n",
    "    yield rewrite(Int(i) == Int(i)).to(Boolean(True))\n",
    "    yield rewrite(Int(i) == Int(j)).to(Boolean(False), i != j)\n",
    "    yield rewrite(Int(i) < Int(j)).to(Boolean(True), i < j)\n",
    "    yield rewrite(Int(i) < Int(j)).to(Boolean(False), i >= j)\n",
    "    yield rewrite(Boolean(True).if_bool(x, y)).to(x)\n",
    "    yield rewrite(Boolean(False).if_bool(x, y)).to(y)\n",
    "\n",
    "\n",
    "@function\n",
    "def vec_index(vec: Vec[Int], index: Int) -> Int: ...\n",
    "\n",
    "\n",
    "@array_ruleset.register\n",
    "def _vec_index(i: i64, xs: Vec[Int]):\n",
    "    yield rewrite(vec_index(xs, Int(i))).to(xs[i])\n",
    "\n",
    "\n",
    "class TupleInt(Expr, ruleset=array_ruleset):\n",
    "    def __init__(self, length: Int, getitem_fn: Callable[[Int], Int]) -> None: ...\n",
    "    def __getitem__(self, index: Int) -> Int: ...\n",
    "\n",
    "    @property\n",
    "    def length(self) -> Int: ...\n",
    "\n",
    "    @classmethod\n",
    "    def from_vec(cls, xs: Vec[Int]) -> TupleInt:\n",
    "        return TupleInt(\n",
    "            Int(xs.length()),\n",
    "            lambda i: vec_index(xs, i),\n",
    "        )\n",
    "\n",
    "\n",
    "@array_ruleset.register\n",
    "def _tuple_int(l: Int, fn: Callable[[Int], Int], i: Int):\n",
    "    ti = TupleInt(l, fn)\n",
    "    yield rewrite(ti.length).to(l)\n",
    "    yield rewrite(ti[i]).to(fn(i))\n",
    "\n",
    "\n",
    "class NDArray(Expr, ruleset=array_ruleset):\n",
    "    def __init__(self, shape: TupleInt, idx_fn: Callable[[TupleInt], Int]) -> None: ...\n",
    "\n",
    "    @classmethod\n",
    "    def from_memory(cls, shape: TupleInt, values: TupleInt) -> NDArray:\n",
    "        # Only work on ndim = 3 for now\n",
    "        return NDArray(\n",
    "            shape,\n",
    "            lambda idx: values[\n",
    "                idx[Int(0)] * (shape[Int(1)] * shape[Int(2)]) + idx[Int(1)] * shape[Int(2)] + idx[Int(2)]\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> TupleInt: ...\n",
    "\n",
    "    def __getitem__(self, index: TupleInt) -> Int: ...\n",
    "\n",
    "\n",
    "@array_ruleset.register\n",
    "def _ndarray(shape: TupleInt, fn: Callable[[TupleInt], Int], idx: TupleInt):\n",
    "    nda = NDArray(shape, fn)\n",
    "    yield rewrite(nda.shape).to(shape)\n",
    "    yield rewrite(nda[idx]).to(fn(idx))\n",
    "\n",
    "\n",
    "@function(subsume=True, ruleset=array_ruleset)\n",
    "def cat(l: NDArray, r: NDArray) -> NDArray:\n",
    "    \"\"\"\n",
    "    Returns the concatenation of two arrays, they should have the same shape and the first dimension is added.\n",
    "    \"\"\"\n",
    "    return NDArray(\n",
    "        TupleInt(\n",
    "            l.shape.length,\n",
    "            lambda i: (i == Int(0)).if_bool(l.shape[Int(0)] + r.shape[Int(0)], l.shape[i]),\n",
    "        ),\n",
    "        lambda idx: (idx[Int(0)] < l.shape[Int(0)]).if_bool(\n",
    "            l[idx], r[TupleInt(r.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - l.shape[Int(0)], idx[i]))]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "@function(subsume=True, ruleset=array_ruleset)\n",
    "def drop(x: Int, arr: NDArray) -> NDArray:\n",
    "    \"\"\"\n",
    "    Drops the first `x` elements off the front of the array `arr`.\n",
    "    \"\"\"\n",
    "    return NDArray(\n",
    "        TupleInt(\n",
    "            arr.shape.length,\n",
    "            lambda i: (i == Int(0)).if_bool(arr.shape[Int(0)] - x, arr.shape[i]),\n",
    "        ),\n",
    "        lambda idx: arr[\n",
    "            TupleInt(\n",
    "                arr.shape.length,\n",
    "                #  Add x to the first index, so it skips the first x elements\n",
    "                lambda i: (i == Int(0)).if_bool(idx[Int(0)] + x, idx[i]),\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "@function(subsume=True, ruleset=array_ruleset)\n",
    "def take(x: Int, arr: NDArray) -> NDArray:\n",
    "    \"\"\"\n",
    "    Takes the first `x` elements off the front of the array `arr`.\n",
    "    \"\"\"\n",
    "    return NDArray(\n",
    "        TupleInt(\n",
    "            arr.shape.length,\n",
    "            lambda i: (i == Int(0)).if_bool(x, arr.shape[i]),\n",
    "        ),\n",
    "        lambda idx: arr[idx],\n",
    "    )\n",
    "\n",
    "\n",
    "shape = TupleInt.from_vec(Vec(Int(2), Int(3), Int(4)))\n",
    "RAMY = NDArray.from_memory(shape, constant(\"RAMY\", TupleInt))\n",
    "AMY = NDArray.from_memory(shape, constant(\"AMY\", TupleInt))\n",
    "Amts = take(Int(2), drop(Int(2), cat(RAMY, AMY)))\n",
    "Amts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ada95b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amts.shape.length()=Int(3)\n",
      "Amts.shape[0]=Int(2)\n",
      "Amts.shape[1]=Int(3)\n",
      "Amts.shape[2]=Int(4)\n",
      "Amts[i, j, k]=((i + Int(2)) < Int(2)).if_bool(RAMY[(((i + Int(2)) * Int(12)) + (j * Int(4))) + k], AMY[((((i + Int(2)) - Int(2)) * Int(12)) + (j * Int(4))) + k])\n",
      "AMY[i, j, k]=AMY[((i * Int(12)) + (j * Int(4))) + k]\n"
     ]
    }
   ],
   "source": [
    "egraph = EGraph()\n",
    "ndim = egraph.let(\"ndim\", Amts.shape.length)\n",
    "shape_1 = egraph.let(\"shape_1\", Amts.shape[Int(0)])\n",
    "shape_2 = egraph.let(\"shape_2\", Amts.shape[Int(1)])\n",
    "shape_3 = egraph.let(\"shape_3\", Amts.shape[Int(2)])\n",
    "idxs = TupleInt.from_vec(Vec(constant(\"i\", Int), constant(\"j\", Int), constant(\"k\", Int)))\n",
    "idxed = egraph.let(\"idxed\", Amts[idxs])\n",
    "amy_idxed = egraph.let(\"amy_idxed\", AMY[idxs])\n",
    "\n",
    "egraph.run(array_ruleset.saturate())\n",
    "print(f\"Amts.shape.length()={egraph.extract(ndim)}\")\n",
    "print(f\"Amts.shape[0]={egraph.extract(shape_1)}\")\n",
    "print(f\"Amts.shape[1]={egraph.extract(shape_2)}\")\n",
    "print(f\"Amts.shape[2]={egraph.extract(shape_3)}\")\n",
    "print(f\"Amts[i, j, k]={egraph.extract(idxed)}\")\n",
    "print(f\"AMY[i, j, k]={egraph.extract(amy_idxed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfbd1f",
   "metadata": {},
   "source": [
    "We can see that Amts is equal to AMY, since they have the shape and indexing them produces the same result.\n",
    "\n",
    "With some basic range analysis we could make them simplify to the same expression in the e-graph as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a232786",
   "metadata": {},
   "source": [
    "If we want, we can also see all the intermediate steps to get to the indexed result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326942be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a56c640a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7b757ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take(\n",
      "    Int(2),\n",
      "    drop(\n",
      "        Int(2), cat(NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY), NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY))\n",
      "    ),\n",
      ")[TupleInt.from_vec(Vec[Int](i, j, k))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "_NDArray_3 = NDArray(\n",
      "    TupleInt(_NDArray_1.shape.length, lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")\n",
      "_NDArray_4 = NDArray(\n",
      "    TupleInt(_NDArray_3.shape.length, lambda i: (i == Int(0)).if_bool(_NDArray_3.shape[Int(0)] - Int(2), _NDArray_3.shape[i])),\n",
      "    lambda idx: _NDArray_3[TupleInt(_NDArray_3.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] + Int(2), idx[i]))],\n",
      ")\n",
      "NDArray(TupleInt(_NDArray_4.shape.length, lambda i: (i == Int(0)).if_bool(Int(2), _NDArray_4.shape[i])), lambda idx: _NDArray_4[idx])[TupleInt.from_vec(Vec[Int](i, j, k))] \n",
      "\n",
      "_TupleInt_1 = TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4)))\n",
      "_TupleInt_2 = TupleInt(\n",
      "    _TupleInt_1.length,\n",
      "    lambda i: (i == Int(0)).if_bool(\n",
      "        NDArray.from_memory(_TupleInt_1, RAMY).shape[Int(0)] + NDArray.from_memory(_TupleInt_1, AMY).shape[Int(0)], NDArray.from_memory(_TupleInt_1, RAMY).shape[i]\n",
      "    ),\n",
      ")\n",
      "_NDArray_1 = NDArray(\n",
      "    _TupleInt_2,\n",
      "    lambda idx: (idx[Int(0)] < NDArray.from_memory(_TupleInt_1, RAMY).shape[Int(0)]).if_bool(\n",
      "        NDArray.from_memory(_TupleInt_1, RAMY)[idx],\n",
      "        NDArray.from_memory(_TupleInt_1, AMY)[\n",
      "            TupleInt(\n",
      "                NDArray.from_memory(_TupleInt_1, AMY).shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - NDArray.from_memory(_TupleInt_1, RAMY).shape[Int(0)], idx[i])\n",
      "            )\n",
      "        ],\n",
      "    ),\n",
      ")\n",
      "(lambda arr, idx: arr[idx])(\n",
      "    NDArray(\n",
      "        TupleInt(_TupleInt_2.length, lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] - Int(2), _NDArray_1.shape[i])),\n",
      "        lambda idx: _NDArray_1[TupleInt(_NDArray_1.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] + Int(2), idx[i]))],\n",
      "    ),\n",
      "    TupleInt.from_vec(Vec[Int](i, j, k)),\n",
      ") \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "_NDArray_3 = NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_3.shape[Int(0)] - Int(2), _NDArray_3.shape[i])),\n",
      "    lambda idx: _NDArray_3[TupleInt(_NDArray_3.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] + Int(2), idx[i]))],\n",
      ")[TupleInt.from_vec(Vec[Int](i, j, k))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "(lambda arr, x, idx: arr[TupleInt(arr.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] + x, idx[i]))])(\n",
      "    NDArray(\n",
      "        TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "        lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "            _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "        ),\n",
      "    ),\n",
      "    Int(2),\n",
      "    TupleInt.from_vec(Vec[Int](i, j, k)),\n",
      ") \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "(lambda l, r, idx: (idx[Int(0)] < l.shape[Int(0)]).if_bool(l[idx], r[TupleInt(r.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - l.shape[Int(0)], idx[i]))]))(\n",
      "    NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY),\n",
      "    NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY),\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i])),\n",
      ") \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "_NDArray_1 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), RAMY)\n",
      "_NDArray_2 = NDArray.from_memory(TupleInt.from_vec(Vec[Int](Int(2), Int(3), Int(4))), AMY)\n",
      "NDArray(\n",
      "    TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(_NDArray_1.shape[Int(0)] + _NDArray_2.shape[Int(0)], _NDArray_1.shape[i])),\n",
      "    lambda idx: (idx[Int(0)] < _NDArray_1.shape[Int(0)]).if_bool(\n",
      "        _NDArray_1[idx], _NDArray_2[TupleInt(_NDArray_2.shape.length, lambda i: (i == Int(0)).if_bool(idx[Int(0)] - _NDArray_1.shape[Int(0)], idx[i]))]\n",
      "    ),\n",
      ")[TupleInt(Int(3), lambda i: (i == Int(0)).if_bool(TupleInt.from_vec(Vec[Int](i, j, k))[Int(0)] + Int(2), TupleInt.from_vec(Vec[Int](i, j, k))[i]))] \n",
      "\n",
      "((i + Int(2)) < Int(2)).if_bool(RAMY[(((i + Int(2)) * Int(12)) + (j * Int(4))) + k], AMY[((((i + Int(2)) - Int(2)) * Int(12)) + (j * Int(4))) + k]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da93b4d1d6241819757834a6da521dd",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "VisualizerWidget(egraphs=['{\"nodes\":{\"primitive-i64-2\":{\"op\":\"2\",\"children\":[],\"eclass\":\"i64-2\",\"cost\":1.0,\"suâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "egraph = EGraph()\n",
    "idxed = egraph.let(\"idxed\", Amts[idxs])\n",
    "egraph.saturate(array_ruleset, expr=idxed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642b054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egglog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
