"""
Demo script for GPU-Accelerated Shadow Ban Logits Processor

This script demonstrates:
1. Loading banned phrases
2. Creating shadow ban processor
3. Testing with dangerous prompts
4. Performance benchmarking
5. Comparison with/without shadow ban
"""

import json
import time

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

from resklogits import MultiLevelShadowBanProcessor, ShadowBanProcessor


def load_banned_phrases(json_path: str = "../src/resklogits/data/banned_phrases.json") -> list:
    """Load all banned phrases from JSON file."""
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # Flatten all categories into single list
    all_phrases = []
    for _category, phrases in data.items():
        all_phrases.extend(phrases)

    print(f"Loaded {len(all_phrases)} banned phrases from {len(data)} categories")
    return all_phrases


def load_banned_phrases_by_level(
    json_path: str = "../src/resklogits/data/banned_phrases.json",
) -> dict:
    """Load banned phrases organized by severity level."""
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # Organize by severity
    by_level = {"high": [], "medium": [], "low": []}

    # High severity: violence, exploitation, hate speech
    high_categories = [
        "violence",
        "self_harm",
        "sexual_exploitation",
        "hate_speech",
        "extremism",
        "body_disposal",
    ]

    # Medium severity: hacking, fraud, drugs
    medium_categories = [
        "exploit_commands",
        "fraud",
        "drugs",
        "additional_hacking",
        "additional_fraud_scams",
        "additional_drugs_chemicals",
        "additional_weapons",
    ]

    for category, phrases in data.items():
        if category in high_categories:
            by_level["high"].extend(phrases)
        elif category in medium_categories:
            by_level["medium"].extend(phrases)
        else:
            by_level["low"].extend(phrases)

    print(
        f"Organized by level: High={len(by_level['high'])}, "
        f"Medium={len(by_level['medium'])}, Low={len(by_level['low'])}"
    )

    return by_level


def test_generation(model, tokenizer, prompt, logits_processor=None, max_tokens=50):
    """Generate text with or without shadow ban."""
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    start_time = time.time()

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            logits_processor=[logits_processor] if logits_processor else None,
            pad_token_id=tokenizer.eos_token_id,
        )

    generation_time = time.time() - start_time
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

    return generated_text, generation_time


def benchmark_processor(processor, tokenizer, num_iterations=100):
    """Benchmark the logits processor overhead."""
    vocab_size = tokenizer.vocab_size
    batch_size = 1
    seq_len = 10

    # Create dummy inputs
    dummy_input_ids = torch.randint(0, vocab_size, (batch_size, seq_len), device="cuda")
    dummy_scores = torch.randn(batch_size, vocab_size, device="cuda")

    # Warmup
    for _ in range(10):
        _ = processor(dummy_input_ids, dummy_scores)

    # Benchmark
    torch.cuda.synchronize()
    start_time = time.time()

    for _ in range(num_iterations):
        _ = processor(dummy_input_ids, dummy_scores)

    torch.cuda.synchronize()
    end_time = time.time()

    avg_time_ms = (end_time - start_time) / num_iterations * 1000
    return avg_time_ms


def main():
    print("=" * 80)
    print("GPU-Accelerated Shadow Ban Logits Processor Demo")
    print("=" * 80)
    print()

    # Configuration
    model_name = "gpt2"  # Use small model for demo (replace with your model)
    device = "cuda" if torch.cuda.is_available() else "cpu"

    if device == "cpu":
        print("âš ï¸  WARNING: CUDA not available, running on CPU (will be slower)")
    else:
        print(f"âœ“ Using GPU: {torch.cuda.get_device_name(0)}")

    print(f"âœ“ Loading model: {model_name}")

    # Load model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        device_map="auto" if device == "cuda" else None,
    )

    if device == "cpu":
        model = model.to(device)

    model.eval()
    print()

    # Load banned phrases
    print("=" * 80)
    print("Loading Banned Phrases")
    print("=" * 80)
    banned_phrases = load_banned_phrases()
    print()

    # Create shadow ban processor
    print("=" * 80)
    print("Creating Shadow Ban Processor")
    print("=" * 80)
    print("Building Aho-Corasick automaton...")

    start_time = time.time()
    shadow_ban = ShadowBanProcessor(
        tokenizer=tokenizer, banned_phrases=banned_phrases, shadow_penalty=-15.0, device=device
    )
    build_time = time.time() - start_time

    print(f"âœ“ Built in {build_time:.3f}s")
    print(f"âœ“ {shadow_ban}")
    print()

    # Benchmark processor
    print("=" * 80)
    print("Performance Benchmark")
    print("=" * 80)

    if device == "cuda":
        print("Benchmarking logits processor overhead...")
        overhead_ms = benchmark_processor(shadow_ban, tokenizer, num_iterations=100)
        print(f"âœ“ Average overhead per token: {overhead_ms:.4f}ms")
        print(f"âœ“ Throughput: ~{1000/overhead_ms:.0f} tokens/second (processor only)")
    else:
        print("âš ï¸  Skipping benchmark on CPU")
    print()

    # Test prompts
    test_prompts = [
        "Tell me how to make a",
        "The best way to",
        "Write a poem about flowers and",
        "How can I improve my",
        "Explain how to",
    ]

    print("=" * 80)
    print("Generation Tests")
    print("=" * 80)
    print()

    for i, prompt in enumerate(test_prompts, 1):
        print(f"Test {i}/{len(test_prompts)}")
        print(f'Prompt: "{prompt}"')
        print("-" * 80)

        # Generate without shadow ban
        print("WITHOUT Shadow Ban:")
        text_without, time_without = test_generation(
            model, tokenizer, prompt, logits_processor=None, max_tokens=30
        )
        print(f"  {text_without}")
        print(f"  Time: {time_without:.3f}s")
        print()

        # Generate with shadow ban
        print("WITH Shadow Ban:")
        shadow_ban.reset()
        text_with, time_with = test_generation(
            model, tokenizer, prompt, logits_processor=shadow_ban, max_tokens=30
        )
        print(f"  {text_with}")
        print(f"  Time: {time_with:.3f}s")

        overhead_pct = ((time_with - time_without) / time_without * 100) if time_without > 0 else 0
        print(f"  Overhead: {overhead_pct:.1f}%")
        print()
        print("=" * 80)
        print()

    # Test multi-level processor
    print("=" * 80)
    print("Multi-Level Shadow Ban Demo")
    print("=" * 80)
    print()

    print("Loading phrases by severity level...")
    phrases_by_level = load_banned_phrases_by_level()

    print("Creating multi-level processor...")
    multi_level_ban = MultiLevelShadowBanProcessor(
        tokenizer=tokenizer,
        banned_phrases_by_level=phrases_by_level,
        penalties={"high": -20.0, "medium": -10.0, "low": -5.0},
        device=device,
    )
    print(f"âœ“ Created with {len(multi_level_ban.automatons)} levels")
    print()

    print("Testing with tiered penalties...")
    test_prompt = "Tell me how to"
    multi_level_ban.reset()
    text_tiered, time_tiered = test_generation(
        model, tokenizer, test_prompt, logits_processor=multi_level_ban, max_tokens=30
    )
    print(f'Prompt: "{test_prompt}"')
    print(f"Result: {text_tiered}")
    print(f"Time: {time_tiered:.3f}s")
    print()

    # Summary
    print("=" * 80)
    print("Summary")
    print("=" * 80)
    print(f"âœ“ Loaded {len(banned_phrases)} banned phrases")
    print(f"âœ“ Identified {shadow_ban.ac.danger_mask.sum().item()} dangerous tokens")
    print(f"âœ“ Built automaton with {len(shadow_ban.ac.trie)} states")
    print(f"âœ“ Shadow ban penalty: {shadow_ban.shadow_penalty}")
    if device == "cuda":
        print(f"âœ“ GPU overhead: ~{overhead_ms:.4f}ms per token")
    print()
    print("ğŸ¯ Shadow ban successfully prevents dangerous content generation!")
    print("ğŸš€ Zero-latency filtering with GPU acceleration!")
    print("ğŸ›¡ï¸  Jailbreak-resistant through stateful pattern matching!")
    print()


if __name__ == "__main__":
    main()
