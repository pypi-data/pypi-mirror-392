{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67eed2a3",
   "metadata": {},
   "source": [
    "# 为什么选择 CANNs？\n",
    "\n",
    "**预计阅读时间**: 8 分钟\n",
    "**目标读者**: 对类脑计算感兴趣的神经科学家、AI 研究人员、工程师和学生\n",
    "\n",
    "---\n",
    "\n",
    "## 挑战：建模连续神经表征\n",
    "\n",
    "你的大脑如何知道你在房间中的位置？海马体和内嗅皮层中的神经元如何在没有外部线索的情况下，维持稳定的位置、头部方向和导航路径的表征？这些问题触及神经科学最迷人的现象之一：**连续吸引子神经网络**（CANNs）。\n",
    "\n",
    "与处理离散输入输出的传统神经网络不同，大脑必须处理**连续状态空间**——位置、方向、速度和其他随时间平滑变化的变量。CANNs 提供了一个计算框架，用于理解神经群体如何通过称为\"吸引子\"的稳定活动模式来编码、维持和更新这些连续表征。\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../docs/_static/smooth_tracking_1d.gif\" width=\"400\">\n",
    "<p><em>1D CANN 追踪平滑移动刺激，展示稳定的 bump 动力学</em></p>\n",
    "</div>\n",
    "\n",
    "尽管在理论上取得了数十年的进展，CANNs 仍然具有挑战性：\n",
    "- **缺乏标准化实现** – 研究人员为每项研究从头构建模型\n",
    "- **工具碎片化** – 任务生成、模型仿真和分析需要不同的代码库\n",
    "- **可重复性障碍** – 在没有共享基础设施的情况下，比较不同研究的结果很困难\n",
    "- **学习曲线陡峭** – 学生必须在探索想法之前实现复杂的动力学\n",
    "\n",
    "**这就是 CANNs 库的用武之地。**\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../docs/_static/CANN2D_encoding.gif\" width=\"400\">\n",
    "<p><em>CANN 网络中的 2D 空间编码模式</em></p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## CANNs 的独特之处是什么？\n",
    "\n",
    "### 生物真实性与理论优雅的结合\n",
    "\n",
    "**连续吸引子神经网络**具有连接神经科学和 AI 的独特属性：\n",
    "\n",
    "1. **稳定的连续表征**\n",
    "   CANNs 自然地在连续状态空间中维持稳定的活动模式（吸引子）。与需要仔细调整的循环神经网络（RNNs）不同，CANNs 有强大的理论基础确保稳定性——活动 bump 在没有外部输入的情况下持续存在，实现短期记忆和鲁棒编码。\n",
    "\n",
    "2. **类脑动力学**\n",
    "   与基于注意力的模型（如 Transformers）相比，CANNs 通过更接近生物神经回路的机制运作。它们擅长建模：\n",
    "   - 海马体中的**位置细胞**（空间位置编码）\n",
    "   - 内嗅皮层中的**网格细胞**（周期性空间地图）\n",
    "   - **头部方向细胞**（角度方向）\n",
    "   - **工作记忆**网络（持续活动）\n",
    "\n",
    "3. **连续状态空间处理**\n",
    "   传统的深度学习模型将世界离散化。CANNs 原生处理连续变量——与大脑处理位置、方向和感觉刺激的平滑变化的方式相匹配。\n",
    "\n",
    "4. **路径积分和导航**\n",
    "   CANNs 自然地执行路径积分：随时间整合速度信号以跟踪位置，无需外部地标——这是啮齿动物导航和人类空间认知中的核心计算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8bdb1",
   "metadata": {},
   "source": [
    "### 最新突破：A-CANN 和 Theta 扫描现象\n",
    "\n",
    "最近的一项重大进展将 **CANNs 与神经适应**（A-CANN）结合，以解释休息和睡眠期间海马体序列重放的多样模式。通过引入适应——一种普遍的神经特性——作为单一控制变量，研究人员统一了看似不同的现象：静态重放、扩散序列和超扩散扫描。\n",
    "\n",
    "这项工作展示了 CANN 的力量：**简单的、生物学上合理的机制可以解释复杂的神经动力学，对记忆编码和检索具有深远影响。**\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../docs/_static/theta_sweep_animation.gif\" width=\"600\">\n",
    "<p><em>网格细胞和头部方向网络中的 theta 扫描动力学</em></p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 谁应该使用这个库？\n",
    "\n",
    "CANNs 库服务于三个主要社区：\n",
    "\n",
    "### 🔬 计算神经科学家\n",
    "连续吸引子网络在系统神经科学中越来越受欢迎。研究人员希望：\n",
    "- **分析实验数据**以寻找吸引子特征\n",
    "- **构建 CANN 模型**以验证针对神经记录的假设\n",
    "- 高效地**重现和扩展**已发表的 CANN 研究\n",
    "\n",
    "### 🛠️ 工程师和开发者\n",
    "随着 CANNs 的成熟，它们需要**标准化的开发实践**——类似于 Transformers 如何通过一致的 API 和共享基础设施革新了 NLP。工程师需要统一的工具来：\n",
    "- 实现类脑导航和记忆系统\n",
    "- 系统地对 CANN 架构进行基准测试\n",
    "- 在机器人和 AI 中部署基于 CANN 的应用\n",
    "\n",
    "### 🎓 学生和教育者\n",
    "学习 CANNs 不应该需要从头实现复杂的动力学。学生受益于：\n",
    "- **即用型模型**用于实践探索\n",
    "- **清晰的示例**展示关键概念\n",
    "- **可修改的代码**用于实验参数和架构\n",
    "\n",
    "**如果没有标准化工具，每个群体都在重新发明轮子。CANNs 库改变了这一点。**\n",
    "\n",
    "---\n",
    "\n",
    "## 关键应用场景\n",
    "\n",
    "### 1. Theta 扫描建模和分析\n",
    "\n",
    "**挑战**：海马神经元在休息和睡眠期间表现出丰富的顺序发放模式——静态、扩散、超扩散——具有重要的认知功能。理解这些\"theta 扫描\"是记忆研究的核心。\n",
    "\n",
    "**解决方案**：A-CANN 框架（CANN + 神经适应）通过单一变量解释了这些多样模式。本库提供：\n",
    "- **预构建模型**：`HeadDirectionNetwork`、`GridCellNetwork`、`PlaceCellNetwork`\n",
    "- **专业可视化**：Theta 扫描动画和分析工具\n",
    "- **可重现管道**：`ThetaSweepPipeline` 协调仿真、分析和绘图\n",
    "\n",
    "**影响**：研究人员可以立即在这项工作的基础上进行构建，而无需重新实现模型和分析工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583cdd1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 2. 教育和研究培训\n",
    "\n",
    "**挑战**：传统的 CANN 教学需要学生每学期从头实现模型。这消耗了本可以用于科学探索的数周时间。\n",
    "\n",
    "**解决方案**：使用此库，学生可以：\n",
    "- 用 **3 行代码**实例化 CANN 模型\n",
    "- 以**最小的设置**生成任务数据（平滑跟踪、群体编码）\n",
    "- 使用**内置分析工具**可视化动力学\n",
    "\n",
    "**影响**：教育者报告说，学生现在专注于**理解机制**而不是调试实现。\n",
    "\n",
    "### 3. 高性能仿真\n",
    "\n",
    "**挑战**：长时间仿真和大规模实验（例如参数扫描、拓扑数据分析）计算成本高昂。\n",
    "\n",
    "**解决方案**：配套的 **`canns-lib`** Rust 库提供：\n",
    "- 空间导航任务相对于纯 Python **700× 加速**（RatInABox 兼容 API）\n",
    "- 拓扑分析**平均 1.13×，峰值 1.82× 加速**（Ripser 算法）\n",
    "- **完美准确性** – 与参考实现 100% 结果匹配\n",
    "- **GPU/TPU 支持** – 通过 JAX/BrainState 后端\n",
    "\n",
    "**影响**：曾经需要数小时的工作现在几分钟内完成。研究人员可以大规模探索参数空间和分析数据集。\n",
    "\n",
    "| 仿真步数 | 纯 Python | canns-lib (Rust) | 加速比 |\n",
    "|----------|-----------|------------------|--------|\n",
    "| 10²      | 0.020 s   | <0.001 s         | 477×   |\n",
    "| 10⁴      | 1.928 s   | 0.003 s          | 732×   |\n",
    "| 10⁶      | 192.775 s | 0.266 s          | 726×   |\n",
    "\n",
    "---\n",
    "\n",
    "## 为什么选择这个库？统一生态系统的优势\n",
    "\n",
    "### 问题：碎片化的格局\n",
    "\n",
    "目前，CANN 研究类似于 **Transformers 之前的 NLP**——每个实验室使用自定义代码、不同的实现和不兼容的格式。这种碎片化导致：\n",
    "- **重新发明的开销**：研究人员反复重新实现基础知识\n",
    "- **可重复性问题**：比较研究需要逆向工程代码\n",
    "- **进展缓慢**：没有共享模型、基准或最佳实践\n",
    "\n",
    "### 愿景：CANNs 作为吸引子网络的\"Hugging Face Transformers\"\n",
    "\n",
    "就像 Hugging Face 标准化了 Transformer 的使用一样，**CANNs 库旨在统一 CANN 研究**：\n",
    "\n",
    "1. **标准化模型库**\n",
    "   - 预构建的 1D/2D CANNs、SFA 变体、分层网络\n",
    "   - 类脑模型：Hopfield 网络、基于脉冲（LIF）的模型\n",
    "   - 结合 CANNs 和 ANNs 的混合架构\n",
    "\n",
    "2. **统一任务 API**\n",
    "   - 平滑跟踪、群体编码、闭环/开环导航\n",
    "   - 直接导入实验轨迹\n",
    "   - 跨任务的一致数据格式\n",
    "\n",
    "3. **完整分析管道**\n",
    "   - 能量景观、调谐曲线、发放场、脉冲嵌入\n",
    "   - 拓扑数据分析（UMAP、TDA、持久同调）\n",
    "   - Theta 扫描和 RNN 动力学分析\n",
    "\n",
    "4. **可扩展架构**\n",
    "   - 用于自定义组件的基类（`BasicModel`、`Task`、`Trainer`、`Pipeline`）\n",
    "   - 基于 BrainState 构建，用于 JAX 驱动的 JIT 编译和自动微分\n",
    "   - 开箱即用的 GPU/TPU 加速\n",
    "\n",
    "5. **社区和共享**\n",
    "   - 模型和基准共享的开源基础\n",
    "   - 统一的评估协议\n",
    "   - 不断增长的示例和教程生态系统\n",
    "\n",
    "---\n",
    "\n",
    "## 技术基础\n",
    "\n",
    "是什么让这个库强大？\n",
    "\n",
    "### 🚀 通过 BrainState + Rust 实现性能\n",
    "- **BrainState 集成**：具有 JAX 的 JIT 编译、自动微分和 GPU/TPU 支持的高级动力学 API\n",
    "- **canns-lib 加速**：用于任务生成和拓扑分析的 Rust 驱动的热路径\n",
    "- **高效编译**：用简单的 Python 编写模型，以 C++ 速度运行\n",
    "\n",
    "### 🧩 综合工具链\n",
    "- **模型**：1D/2D CANNs、分层网络、SFA 变体、类脑模型\n",
    "- **任务**：跟踪、导航、群体编码、轨迹导入\n",
    "- **分析器**：可视化、TDA、bump 拟合、动力学分析\n",
    "- **训练器**：Hebbian 学习、预测工作流\n",
    "- **管道**：单次调用中的端到端工作流（例如 theta 扫描）\n",
    "\n",
    "### 🔬 研究级质量\n",
    "- **经过验证的实现**：模型重现已发表的结果\n",
    "- **全面测试**：Pytest 套件覆盖关键行为\n",
    "- **积极开发**：定期更新、错误修复、社区贡献\n",
    "\n",
    "---\n",
    "\n",
    "## 当前状态和未来方向\n",
    "\n",
    "**开发阶段**：该库已经积极开发了 4 个月，目前处于 **beta**（v0.x）阶段。我们的研究小组正在内部使用它，并根据用户反馈积极扩展功能。\n",
    "\n",
    "**验证**：\n",
    "- ✅ 模型重现了已建立的 CANN 行为\n",
    "- ✅ 性能基准显示显著加速（canns-lib）\n",
    "- ✅ 跨模型和任务的工作示例不断增加\n",
    "\n",
    "**路线图**：\n",
    "- 扩展类脑模型集合（循环网络、基于脉冲的模型）\n",
    "- 添加混合 CANN-ANN 架构\n",
    "- 开发全面的基准测试套件\n",
    "- 构建社区贡献的模型库\n",
    "- 发表记录库设计的配套论文\n",
    "\n",
    "**局限性**（我们相信透明度）：\n",
    "- Beta 软件 – API 可能会根据反馈而演变\n",
    "- 文档正在积极扩展（欢迎您的贡献！）\n",
    "- 目前预训练模型有限（我们正在构建）\n",
    "- 与成熟的深度学习框架相比，社区较小（但正在增长！）\n",
    "\n",
    "---\n",
    "\n",
    "## 下一步：深入了解！\n",
    "\n",
    "### 快速开始\n",
    "准备好构建您的第一个 CANN？跳转到我们的**[快速入门指南](link-to-quick-start)**，在 <10 分钟内进行实践演练。\n",
    "\n",
    "### 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU 版本\n",
    "pip install canns\n",
    "# GPU 支持（Linux）\n",
    "pip install canns[cuda12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eede77",
   "metadata": {},
   "source": [
    "### 了解更多\n",
    "- **[核心概念](link-to-core-concepts)**：理解库的设计理念\n",
    "- **[基础教程](link-to-basic-tutorials)**：常见任务的分步指南\n",
    "- **[完整 API 文档](link-to-api-docs)**：所有模型和方法的完整参考\n",
    "- **[示例库](link-to-examples)**：展示关键功能的即用脚本\n",
    "\n",
    "### 参与其中\n",
    "- 🐛 **报告问题**：[GitHub Issues](https://github.com/routhleck/canns/issues)\n",
    "- 💬 **提问**：[GitHub Discussions](https://github.com/routhleck/canns/discussions)\n",
    "- 🤝 **贡献**：查看我们的[贡献指南](link-to-contributing)\n",
    "- ⭐ **给仓库加星**：[github.com/routhleck/canns](https://github.com/routhleck/canns)\n",
    "\n",
    "---\n",
    "\n",
    "## 总结：为什么选择 CANNs？\n",
    "\n",
    "| **问题** | **答案** |\n",
    "|---------|---------|\n",
    "| **它解决什么问题？** | 通过标准化模型、任务和分析工具统一碎片化的 CANN 研究 |\n",
    "| **它适合谁？** | 分析数据的神经科学家、构建系统的工程师、学习动力学的学生 |\n",
    "| **它有什么独特之处？** | 第一个全面的 CANN 库——从模型到可视化的完整生态系统 |\n",
    "| **它有多快？** | 导航任务 700× 加速，GPU/TPU 支持，JIT 编译 |\n",
    "| **我可以信任它吗？** | 针对已发表结果进行验证，积极开发，开源 |\n",
    "| **我从哪里开始？** | `pip install canns` → 快速入门指南 → 10 分钟内构建您的第一个 CANN |\n",
    "\n",
    "**碎片化 CANN 实现的时代正在结束。统一、可重现、可访问的吸引子网络研究的时代正在开始。**\n",
    "\n",
    "**让我们一起构建它。**\n",
    "\n",
    "---\n",
    "\n",
    "*对这份文档有疑问或建议？在 [GitHub](https://github.com/routhleck/canns) 上提出问题或讨论！*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "bash",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
