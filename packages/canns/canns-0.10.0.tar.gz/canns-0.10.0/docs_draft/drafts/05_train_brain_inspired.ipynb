{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# How to Train Brain-Inspired Model?\n",
    "\n",
    "**Goal**: By the end of this guide, you'll be able to train a Hopfield network to store and recall patterns using Hebbian learning.\n",
    "\n",
    "**Estimated Reading Time**: 12 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Unlike deep learning models trained with backpropagation, **brain-inspired models** use biologically plausible learning rules like **Hebbian learning**:\n",
    "\n",
    "> *\"Neurons that fire together, wire together.\"* — Donald Hebb (1949)\n",
    "\n",
    "This guide introduces:\n",
    "1. The Hebbian learning principle\n",
    "2. Training a Hopfield network for pattern memory\n",
    "3. Using the Trainer framework\n",
    "4. Key differences from deep learning\n",
    "\n",
    "We'll train a model to memorize and recall images—demonstrating associative memory in action.\n",
    "\n",
    "## What is Hebbian Learning?\n",
    "\n",
    "**Hebbian learning** is an unsupervised learning rule where synaptic weights strengthen when pre- and post-synaptic neurons are co-active:\n",
    "\n",
    "```\n",
    "Δw_ij = η × x_i × x_j\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `w_ij`: Connection weight from neuron `i` to neuron `j`\n",
    "- `x_i, x_j`: Activities of neurons `i` and `j`\n",
    "- `η`: Learning rate (often set to 1 for simple rules)\n",
    "\n",
    "**Key properties**:\n",
    "- **Local**: Weight updates depend only on activities of connected neurons (no global error signal)\n",
    "- **Unsupervised**: No labels or target outputs required\n",
    "- **Biologically plausible**: Matches synaptic plasticity observed in real neurons\n",
    "\n",
    "**Contrast with backpropagation**:\n",
    "- Backprop: Global error signal, supervised, requires differentiable loss\n",
    "- Hebbian: Local activity, unsupervised, no gradient computation\n",
    "\n",
    "## The Hopfield Network\n",
    "\n",
    "An **Amari-Hopfield Network** is a recurrent network that stores patterns as stable attractor states. When presented with a partial or noisy pattern, the network converges to the nearest stored memory.\n",
    "\n",
    "**Use case**: Associative memory, pattern completion, error correction"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-1",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from canns.models.brain_inspired import AmariHopfieldNetwork\n",
    "\n",
    "# Create a Hopfield network with 16,384 neurons (128x128 flattened image)\n",
    "model = AmariHopfieldNetwork(\n",
    "    num_neurons=128 * 128,  # Image size when flattened\n",
    "    asyn=False,             # Synchronous updates (all neurons update together)\n",
    "    activation=\"sign\"       # Binary activation: +1 or -1\n",
    ")\n",
    "model.init_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "**Parameters**:\n",
    "- `num_neurons`: Network size (must match input dimensionality)\n",
    "- `asyn`: Asynchronous (one neuron at a time) vs synchronous updates\n",
    "- `activation`: \"sign\" for binary Hopfield, \"tanh\" for continuous variant\n",
    "\n",
    "## The Trainer Framework\n",
    "\n",
    "The library provides a **unified Trainer API** that abstracts training logic:\n",
    "\n",
    "```\n",
    "Model + Trainer + Data → Trained Model\n",
    "```\n",
    "\n",
    "**Philosophy** (from the Design Philosophy docs):\n",
    "- **Separation of concerns**: Model defines dynamics, Trainer defines learning\n",
    "- **Reusability**: Same trainer works for different models with compatible learning rules\n",
    "- **Composability**: Stack trainers for multi-stage training\n",
    "\n",
    "For Hebbian learning, we use `HebbianTrainer`:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-3",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from canns.trainer import HebbianTrainer\n",
    "\n",
    "trainer = HebbianTrainer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "**Key methods**:\n",
    "- `trainer.train(data)`: Train on a list of patterns\n",
    "- `trainer.predict(pattern)`: Recall a single pattern\n",
    "- `trainer.predict_batch(patterns)`: Batch recall (compiled for speed)\n",
    "\n",
    "## Complete Example: Image Memory\n",
    "\n",
    "Let's train a Hopfield network to memorize 4 images and recall them from corrupted versions.\n",
    "\n",
    "### Step 1: Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-5",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_mean\n",
    "\n",
    "def preprocess_image(img, size=128):\n",
    "    \"\"\"Convert image to binary {-1, +1} pattern.\"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if img.ndim == 3:\n",
    "        img = rgb2gray(img)\n",
    "\n",
    "    # Resize to fixed size\n",
    "    img = resize(img, (size, size), anti_aliasing=True)\n",
    "\n",
    "    # Threshold to binary\n",
    "    thresh = threshold_mean(img)\n",
    "    binary = img > thresh\n",
    "\n",
    "    # Map to {-1, +1}\n",
    "    pattern = np.where(binary, 1.0, -1.0).astype(np.float32)\n",
    "\n",
    "    # Flatten to 1D\n",
    "    return pattern.reshape(size * size)\n",
    "\n",
    "# Load example images from scikit-image\n",
    "camera = preprocess_image(skimage.data.camera())\n",
    "astronaut = preprocess_image(skimage.data.astronaut())\n",
    "horse = preprocess_image(skimage.data.horse().astype(np.float32))\n",
    "coffee = preprocess_image(skimage.data.coffee())\n",
    "\n",
    "training_data = [camera, astronaut, horse, coffee]\n",
    "\n",
    "print(f\"Number of patterns: {len(training_data)}\")\n",
    "print(f\"Pattern shape: {training_data[0].shape}\")  # (16384,) = 128*128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "**Why binary {-1, +1}?**\n",
    "- Classic Hopfield networks use binary neurons\n",
    "- Simplifies the energy function and update rules\n",
    "- Real-valued extensions exist (use `activation=\"tanh\"`)\n",
    "\n",
    "### Step 2: Create Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-7",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from canns.models.brain_inspired import AmariHopfieldNetwork\n",
    "from canns.trainer import HebbianTrainer\n",
    "\n",
    "# Create Hopfield network\n",
    "model = AmariHopfieldNetwork(\n",
    "    num_neurons=training_data[0].shape[0],\n",
    "    asyn=False,\n",
    "    activation=\"sign\"\n",
    ")\n",
    "model.init_state()\n",
    "\n",
    "# Create Hebbian trainer\n",
    "trainer = HebbianTrainer(model)\n",
    "\n",
    "print(\"Model and trainer initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Step 3: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-9",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all patterns (this computes Hebbian weight matrix)\n",
    "trainer.train(training_data)\n",
    "\n",
    "print(\"Training complete! Patterns stored in weights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "**What happened internally**:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-11",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified version of Hebbian weight update\n",
    "for pattern in training_data:\n",
    "    W += np.outer(pattern, pattern)  # Hebbian: w_ij += x_i * x_j\n",
    "W /= len(training_data)  # Normalize\n",
    "np.fill_diagonal(W, 0)   # No self-connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "The weight matrix `W` now encodes all training patterns as attractor states.\n",
    "\n",
    "### Step 4: Test Pattern Recall\n",
    "\n",
    "Create corrupted versions of the training images:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-13",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_pattern(pattern, noise_level=0.3):\n",
    "    \"\"\"Randomly flip 30% of pixels.\"\"\"\n",
    "    corrupted = np.copy(pattern)\n",
    "    num_flips = int(len(pattern) * noise_level)\n",
    "    flip_indices = np.random.choice(len(pattern), num_flips, replace=False)\n",
    "    corrupted[flip_indices] *= -1  # Flip sign\n",
    "    return corrupted\n",
    "\n",
    "# Create test patterns (30% corrupted)\n",
    "test_patterns = [corrupt_pattern(p, 0.3) for p in training_data]\n",
    "\n",
    "print(f\"Created {len(test_patterns)} corrupted test patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### Step 5: Recall Patterns"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-15",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch prediction (compiled for efficiency)\n",
    "recalled = trainer.predict_batch(test_patterns, show_sample_progress=True)\n",
    "\n",
    "print(\"Pattern recall complete!\")\n",
    "print(f\"Recalled patterns shape: {np.array(recalled).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "**What's happening**:\n",
    "- For each corrupted pattern, the network iterates its dynamics\n",
    "- The activity converges to the nearest stored attractor (original image)\n",
    "- The result is the \"cleaned up\" pattern\n",
    "\n",
    "### Step 6: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-17",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reshape_for_display(pattern, size=128):\n",
    "    \"\"\"Reshape 1D pattern back to 2D image.\"\"\"\n",
    "    return pattern.reshape(size, size)\n",
    "\n",
    "# Plot original, corrupted, and recalled patterns\n",
    "fig, axes = plt.subplots(len(training_data), 3, figsize=(8, 10))\n",
    "\n",
    "for i in range(len(training_data)):\n",
    "    # Column 1: Original training image\n",
    "    axes[i, 0].imshow(reshape_for_display(training_data[i]), cmap='gray')\n",
    "    axes[i, 0].axis('off')\n",
    "    if i == 0:\n",
    "        axes[i, 0].set_title('Original')\n",
    "\n",
    "    # Column 2: Corrupted test input\n",
    "    axes[i, 1].imshow(reshape_for_display(test_patterns[i]), cmap='gray')\n",
    "    axes[i, 1].axis('off')\n",
    "    if i == 0:\n",
    "        axes[i, 1].set_title('Corrupted (30%)')\n",
    "\n",
    "    # Column 3: Recalled output\n",
    "    axes[i, 2].imshow(reshape_for_display(recalled[i]), cmap='gray')\n",
    "    axes[i, 2].axis('off')\n",
    "    if i == 0:\n",
    "        axes[i, 2].set_title('Recalled')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hopfield_memory_recall.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "**Expected result**:\n",
    "- Original images are clean\n",
    "- Corrupted inputs have ~30% noise\n",
    "- Recalled outputs match originals (noise corrected!)\n",
    "\n",
    "## Complete Runnable Code\n",
    "\n",
    "Here's the full example in one block:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-19",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_mean\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from canns.models.brain_inspired import AmariHopfieldNetwork\n",
    "from canns.trainer import HebbianTrainer\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Preprocess images\n",
    "def preprocess_image(img, size=128):\n",
    "    if img.ndim == 3:\n",
    "        img = rgb2gray(img)\n",
    "    img = resize(img, (size, size), anti_aliasing=True)\n",
    "    thresh = threshold_mean(img)\n",
    "    binary = img > thresh\n",
    "    pattern = np.where(binary, 1.0, -1.0).astype(np.float32)\n",
    "    return pattern.reshape(size * size)\n",
    "\n",
    "camera = preprocess_image(skimage.data.camera())\n",
    "astronaut = preprocess_image(skimage.data.astronaut())\n",
    "horse = preprocess_image(skimage.data.horse().astype(np.float32))\n",
    "coffee = preprocess_image(skimage.data.coffee())\n",
    "\n",
    "training_data = [camera, astronaut, horse, coffee]\n",
    "\n",
    "# 2. Create model and trainer\n",
    "model = AmariHopfieldNetwork(num_neurons=training_data[0].shape[0], asyn=False, activation=\"sign\")\n",
    "model.init_state()\n",
    "trainer = HebbianTrainer(model)\n",
    "\n",
    "# 3. Train\n",
    "trainer.train(training_data)\n",
    "\n",
    "# 4. Create corrupted test patterns\n",
    "def corrupt_pattern(pattern, noise_level=0.3):\n",
    "    corrupted = np.copy(pattern)\n",
    "    num_flips = int(len(pattern) * noise_level)\n",
    "    flip_indices = np.random.choice(len(pattern), num_flips, replace=False)\n",
    "    corrupted[flip_indices] *= -1\n",
    "    return corrupted\n",
    "\n",
    "test_patterns = [corrupt_pattern(p, 0.3) for p in training_data]\n",
    "\n",
    "# 5. Recall patterns\n",
    "recalled = trainer.predict_batch(test_patterns, show_sample_progress=True)\n",
    "\n",
    "# 6. Visualize\n",
    "def reshape(pattern, size=128):\n",
    "    return pattern.reshape(size, size)\n",
    "\n",
    "fig, axes = plt.subplots(len(training_data), 3, figsize=(8, 10))\n",
    "for i in range(len(training_data)):\n",
    "    axes[i, 0].imshow(reshape(training_data[i]), cmap='gray')\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(reshape(test_patterns[i]), cmap='gray')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(reshape(recalled[i]), cmap='gray')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 1].set_title('Corrupted')\n",
    "axes[0, 2].set_title('Recalled')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hopfield_memory.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## CANN vs. Deep Learning Training\n",
    "\n",
    "| Aspect | CANNs / Hebbian Learning | Deep Learning (ANNs) |\n",
    "|--------|-------------------------|----------------------|\n",
    "| **Learning rule** | Local (Hebbian, STDP) | Global (Backpropagation) |\n",
    "| **Supervision** | Unsupervised | Supervised (usually) |\n",
    "| **Gradient** | No gradient computation | Requires autodiff |\n",
    "| **Training data** | Patterns to memorize | Labeled input-output pairs |\n",
    "| **Objective** | Form attractors | Minimize loss function |\n",
    "| **Biological plausibility** | High | Low |\n",
    "| **Speed** | Fast (one-shot learning possible) | Slow (many epochs) |\n",
    "| **Capacity** | Limited (~0.15N patterns for N neurons) | Very large (overparameterization) |\n",
    "\n",
    "**When to use each**:\n",
    "- **Hebbian/CANNs**: Associative memory, pattern completion, neuroscience modeling\n",
    "- **Backprop/ANNs**: Classification, regression, large-scale pattern recognition\n",
    "\n",
    "## The Trainer Abstraction\n",
    "\n",
    "The `Trainer` framework provides a consistent interface across different learning paradigms:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-21",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All trainers follow this pattern\n",
    "trainer = SomeTrainer(model)\n",
    "trainer.train(data)\n",
    "output = trainer.predict(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "**Available trainers**:\n",
    "- `HebbianTrainer`: Hebbian learning (as shown here)\n",
    "- Future trainers: STDP, BCM, reinforcement learning, etc.\n",
    "\n",
    "**Why this design?**\n",
    "- **Modularity**: Swap learning rules without changing model code\n",
    "- **Consistency**: Same API for different learning algorithms\n",
    "- **Extensibility**: Easy to add custom trainers\n",
    "\n",
    "See the Design Philosophy docs for more details on this architecture.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Congratulations! You've trained a brain-inspired model using Hebbian learning. Now explore:\n",
    "\n",
    "1. **[Core Concepts](link-to-core-concepts)** - Deepen your understanding of all library components\n",
    "2. **[Brain-Inspired Training](link-to-core-concepts-training)** - Learn about other learning rules (STDP, BCM, etc.)\n",
    "3. **[Full Trainer API](link-to-full-details-training)** - Complete reference for all trainers and training methods\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Reference**:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-23",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebbian training template\n",
    "from canns.models.brain_inspired import AmariHopfieldNetwork\n",
    "from canns.trainer import HebbianTrainer\n",
    "\n",
    "# Create model\n",
    "model = AmariHopfieldNetwork(num_neurons=N, activation=\"sign\")\n",
    "model.init_state()\n",
    "\n",
    "# Create trainer\n",
    "trainer = HebbianTrainer(model)\n",
    "\n",
    "# Train on patterns\n",
    "trainer.train([pattern1, pattern2, ...])\n",
    "\n",
    "# Recall\n",
    "output = trainer.predict(noisy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Questions? Check the [Trainer Framework Guide](link-to-core-concepts-trainer) or [GitHub Discussions](https://github.com/routhleck/canns/discussions).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}