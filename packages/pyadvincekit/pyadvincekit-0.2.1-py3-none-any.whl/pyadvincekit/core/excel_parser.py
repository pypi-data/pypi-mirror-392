#!/usr/bin/env python3
"""
Excelæ•°æ®åº“è®¾è®¡è§£æå™¨

ä¸“é—¨ç”¨äºè§£æç‰¹å®šæ ¼å¼çš„Excelæ•°æ®åº“è®¾è®¡æ–‡ä»¶
"""

import os
import re
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import pandas as pd

from pyadvincekit.logging import get_logger
from pyadvincekit.core.excel_generator import (
    ColumnType, ConstraintType, ColumnConstraint, TableColumn, 
    TableDefinition, DatabaseDesign, TableIndex
)

logger = get_logger(__name__)


class DatabaseDesignParser:
    """æ•°æ®åº“è®¾è®¡è§£æå™¨"""
    
    def __init__(self, add_standard_fields: bool = True):
        self.add_standard_fields = add_standard_fields
        self.supported_types = {
            # æ•´æ•°ç±»å‹
            "int": ColumnType.INTEGER,
            "integer": ColumnType.INTEGER,
            "bigint": ColumnType.BIGINT,
            "smallint": ColumnType.SMALLINT,
            "tinyint": ColumnType.TINYINT,
            "long": ColumnType.BIGINT,  # Longç±»å‹æ˜ å°„åˆ°BIGINT
            
            # æµ®ç‚¹ç±»å‹
            "float": ColumnType.FLOAT,
            "double": ColumnType.DOUBLE,
            "decimal": ColumnType.DECIMAL,
            "numeric": ColumnType.DECIMAL,
            
            # å­—ç¬¦ä¸²ç±»å‹
            "varchar": ColumnType.VARCHAR,
            "char": ColumnType.CHAR,
            "text": ColumnType.TEXT,
            "longtext": ColumnType.LONGTEXT,
            "string": ColumnType.VARCHAR,
            "str": ColumnType.VARCHAR,
            
            # æ—¥æœŸæ—¶é—´ç±»å‹
            "date": ColumnType.DATE,
            "datetime": ColumnType.DATETIME,
            "timestamp": ColumnType.TIMESTAMP,
            "time": ColumnType.TIME,
            
            # å¸ƒå°”ç±»å‹
            "boolean": ColumnType.BOOLEAN,
            "bool": ColumnType.BOOLEAN,
            
            # JSONç±»å‹
            "json": ColumnType.JSON,
            
            # äºŒè¿›åˆ¶ç±»å‹
            "blob": ColumnType.BLOB,
            "longblob": ColumnType.LONGBLOB,
        }
    
    def parse_excel_file(self, file_path: str) -> DatabaseDesign:
        """è§£æExcelæ–‡ä»¶"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Excel file not found: {file_path}")
        
        logger.info(f"Parsing Excel file: {file_path}")
        
        # è¯»å–Excelæ–‡ä»¶
        if file_path.lower().endswith('.xls'):
            excel_data = pd.read_excel(file_path, sheet_name=None, engine='xlrd')
        else:
            excel_data = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')
        
        # è§£ææ•°æ®åº“è®¾è®¡
        design = DatabaseDesign(name="Generated Database")
        
        # è§£ææ¯ä¸ªå·¥ä½œè¡¨
        for sheet_name, sheet_data in excel_data.items():
            logger.info(f"Processing sheet: {sheet_name}")
            table = self._parse_table(sheet_name, sheet_data)
            if table:
                design.tables.append(table)
        
        logger.info(f"Parsed {len(design.tables)} tables from Excel file")
        return design
    
    def _create_standard_columns(self) -> List[TableColumn]:
        """åˆ›å»ºæ ‡å‡†å­—æ®µï¼šid, created_at, updated_at"""
        standard_columns = []
        
        # 1. ä¸»é”® ID å­—æ®µ
        id_column = TableColumn(
            name="id",
            type=ColumnType.VARCHAR,
            length=36,  # UUID é•¿åº¦
            nullable=False,
            comment="ä¸»é”®ID",
            default_value="(UUID())",  # MySQL å‡½æ•°æ ¼å¼
            constraints=[
                ColumnConstraint(
                    type=ConstraintType.PRIMARY_KEY
                )
            ]
        )
        standard_columns.append(id_column)
        
        # 2. åˆ›å»ºæ—¶é—´å­—æ®µ
        created_at_column = TableColumn(
            name="created_at",
            type=ColumnType.DATETIME,
            nullable=False,
            comment="åˆ›å»ºæ—¶é—´",
            default_value="CURRENT_TIMESTAMP"
        )
        standard_columns.append(created_at_column)
        
        # 3. æ›´æ–°æ—¶é—´å­—æ®µ  
        # æ³¨æ„ï¼šON UPDATE é€»è¾‘å°†åœ¨ SQL ç”Ÿæˆå™¨ä¸­å¤„ç†
        updated_at_column = TableColumn(
            name="updated_at",
            type=ColumnType.DATETIME,
            nullable=False,
            comment="æ›´æ–°æ—¶é—´", 
            default_value="CURRENT_TIMESTAMP"
        )
        # ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ¥è¡¨ç¤ºéœ€è¦ ON UPDATE
        updated_at_column.comment += " [AUTO_UPDATE]"
        standard_columns.append(updated_at_column)
        
        logger.info("Added standard columns: id, created_at, updated_at")
        return standard_columns
    
    def _parse_table(self, sheet_name: str, data: pd.DataFrame) -> Optional[TableDefinition]:
        """è§£æè¡¨å®šä¹‰"""
        if data.empty or len(data) < 5:
            logger.warning(f"Sheet {sheet_name} has insufficient data, skipping")
            return None
        
        # ğŸ”¥ æ–°å¢æ ¡éªŒï¼šæ£€æŸ¥A0å’ŒA1å•å…ƒæ ¼å†…å®¹æ˜¯å¦ç¬¦åˆè¡¨æ ¼å¼
        try:
            # æ£€æŸ¥A0å•å…ƒæ ¼æ˜¯å¦ä¸º"è¡¨å"
            a0_value = str(data.iloc[0, 0]).strip() if not pd.isna(data.iloc[0, 0]) else ""
            # æ£€æŸ¥A1å•å…ƒæ ¼æ˜¯å¦ä¸º"è¡¨æè¿°"  
            a1_value = str(data.iloc[1, 0]).strip() if not pd.isna(data.iloc[1, 0]) else ""
            
            if a0_value != "è¡¨æè¿°" or a1_value != "è¡¨ç©ºé—´":
                logger.info(f"Sheet {sheet_name} is not a table definition (A0='{a0_value}', A1='{a1_value}'), skipping")
                return None
                
            logger.info(f"Sheet {sheet_name} passed table validation (A0='{a0_value}', A1='{a1_value}')")
            
        except Exception as e:
            logger.warning(f"Error validating sheet {sheet_name}: {e}, skipping")
            return None
        
        # è·å–è¡¨ä¿¡æ¯ï¼ˆå‰4è¡Œï¼‰
        table_info = self._extract_table_info(data)
        table_name = table_info.get('name', sheet_name)
        
        # è·å–åˆ—ä¿¡æ¯ï¼ˆä»ç¬¬5è¡Œå¼€å§‹ï¼‰
        columns = self._extract_columns(data)
        
        if not columns:
            logger.warning(f"Sheet {sheet_name} has no valid columns, skipping")
            return None
        
        table = TableDefinition(
            name=table_name,
            comment=table_info.get('description', ''),
            engine="InnoDB",
            charset="utf8mb4",
            collate="utf8mb4_unicode_ci"
        )
        
        # ğŸ”¥ æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è‡ªåŠ¨æ·»åŠ æ ‡å‡†å­—æ®µ
        if self.add_standard_fields:
            # å…ˆæ·»åŠ ç”¨æˆ·å®šä¹‰çš„åˆ—
            for column in columns:
                table.columns.append(column)
            
            # æ£€æŸ¥å“ªäº›æ ‡å‡†å­—æ®µä¸å­˜åœ¨ï¼Œåªæ·»åŠ ç¼ºå¤±çš„æ ‡å‡†å­—æ®µ
            existing_field_names = {col.name.lower() for col in table.columns}
            standard_columns = self._create_standard_columns()
            
            for std_column in standard_columns:
                # åªæœ‰å½“å­—æ®µä¸å­˜åœ¨æ—¶æ‰æ·»åŠ 
                if std_column.name.lower() not in existing_field_names:
                    table.columns.append(std_column)
                    logger.info(f"Added missing standard field: {std_column.name}")
                else:
                    logger.info(f"Standard field {std_column.name} already exists in Excel, skipping auto-generation")
        else:
            # å¦‚æœä¸æ·»åŠ æ ‡å‡†å­—æ®µï¼Œç›´æ¥æ·»åŠ ç”¨æˆ·å®šä¹‰çš„åˆ—
            for column in columns:
                table.columns.append(column)
        
        # æ·»åŠ ç´¢å¼•
        indexes = self._extract_indexes(data, table_name)
        for index in indexes:
            table_index = TableIndex(
                name=index["name"],
                columns=index["columns"],
                unique=index["unique"],
                type=index["type"]
            )
            table.indexes.append(table_index)
        
        logger.info(f"Table {table.name}: {len(table.columns)} columns, {len(table.indexes)} indexes")
        return table
    
    def _extract_table_info(self, data: pd.DataFrame) -> dict:
        """æå–è¡¨ä¿¡æ¯"""
        info = {}
        
        # æ ¹æ®ç”¨æˆ·è¯´æ˜ï¼š
        # B0æ˜¯è¡¨åï¼ŒB1æ˜¯è¡¨æè¿°ï¼ŒB2æ˜¯è¡¨ç©ºé—´ï¼ŒB3æ˜¯ç´¢å¼•ç©ºé—´
        # åœ¨pandasä¸­ï¼ŒBåˆ—æ˜¯ç´¢å¼•1ï¼ˆ0-basedï¼‰
        
        if len(data) >= 1 and len(data.columns) > 1:
            # B0 - è¡¨å
            info['name'] = str(data.columns[1]).strip()
        
        if len(data) >= 2 and len(data.columns) > 1:
            # B1 - è¡¨æè¿°
            if pd.notna(data.iloc[0, 1]):
                info['description'] = str(data.iloc[0, 1]).strip()
        
        if len(data) >= 3 and len(data.columns) > 1:
            # B2 - è¡¨ç©ºé—´
            if pd.notna(data.iloc[1, 1]):
                info['tablespace'] = str(data.iloc[1, 1]).strip()
        
        if len(data) >= 4 and len(data.columns) > 1:
            # B3 - ç´¢å¼•ç©ºé—´
            if pd.notna(data.iloc[2, 1]):
                info['indexspace'] = str(data.iloc[2, 1]).strip()
        
        logger.info(f"Table info: {info}")
        return info
    
    def _extract_columns(self, data: pd.DataFrame) -> List[TableColumn]:
        """æå–åˆ—å®šä¹‰"""
        columns = []
        
        # ä»ç¬¬5è¡Œå¼€å§‹æ˜¯åˆ—å®šä¹‰ï¼ˆç´¢å¼•4ï¼‰
        start_row = 3
        if len(data) <= start_row:
            return columns
        
        # è·å–åˆ—æ ‡é¢˜è¡Œ
        header_row = data.iloc[start_row]
        column_headers = [str(header).strip() for header in header_row if pd.notna(header)]
        
        logger.info(f"Column headers: {column_headers}")
        
        # è§£ææ¯ä¸€åˆ—
        for i in range(start_row + 1, len(data)):
            row = data.iloc[i]
            if len(row) < 3:  # è‡³å°‘éœ€è¦åˆ—åã€ç±»å‹ã€é•¿åº¦
                continue
            
            column = self._parse_column(row, column_headers)
            if column:
                columns.append(column)
        
        return columns
    
    def _parse_column(self, row: pd.Series, headers: List[str]) -> Optional[TableColumn]:
        """è§£æåˆ—å®šä¹‰"""
        if len(row) < 3:
            return None
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        name = str(row.iloc[0]).strip() if pd.notna(row.iloc[0]) else ""
        type_str = str(row.iloc[1]).strip() if pd.notna(row.iloc[1]) else ""
        length_str = str(row.iloc[2]).strip() if len(row) > 2 and pd.notna(row.iloc[2]) else ""
        
        if not name or not type_str:
            return None
        
        # è§£æé•¿åº¦
        length = None
        if length_str and length_str.isdigit():
            length = int(length_str)
        
        # ç¡®å®šåˆ—ç±»å‹
        column_type = self._get_column_type(type_str)
        if not column_type:
            logger.warning(f"Unknown column type: {type_str}")
            return None
        
        # åˆ›å»ºåˆ—å¯¹è±¡
        column = TableColumn(
            name=name,
            type=column_type,
            length=length,
            nullable=True,  # é»˜è®¤å¯ä¸ºç©º
            comment=""
        )
        
        # è§£æå…¶ä»–å±æ€§
        if len(row) > 3:
            # ç©ºå€¼åˆ—
            null_str = str(row.iloc[3]).strip() if pd.notna(row.iloc[3]) else ""
            if null_str and "å¦" in null_str:
                column.nullable = False
        
        if len(row) > 4:
            # ç¼ºçœå€¼
            default_str = str(row.iloc[4]).strip() if pd.notna(row.iloc[4]) else ""
            if default_str and default_str != "":
                column.default_value = default_str
        
        if len(row) > 5:
            # ä¸­æ–‡åç§°ä½œä¸ºæ³¨é‡Š
            chinese_name = str(row.iloc[5]).strip() if pd.notna(row.iloc[5]) else ""
            if chinese_name:
                column.comment = chinese_name
        
        # è§£æçº¦æŸï¼ˆä»ç´¢å¼•åˆ—ï¼‰
        self._parse_column_constraints(column, row, headers)
        
        return column
    
    def _parse_column_constraints(self, column: TableColumn, row: pd.Series, headers: List[str]):
        """è§£æåˆ—çº¦æŸ"""
        # æŸ¥æ‰¾å”¯ä¸€ç´¢å¼•åˆ—
        for i, header in enumerate(headers):
            if "UIDX" in header or "å”¯ä¸€ç´¢å¼•" in header:
                if i < len(row) and pd.notna(row.iloc[i]):
                    value = str(row.iloc[i]).strip()
                    if value and "Y" in value.upper():
                        column.constraints.append(ColumnConstraint(ConstraintType.UNIQUE))
                        break
        
        # æŸ¥æ‰¾ä¸»é”®ï¼ˆé€šå¸¸ç¬¬ä¸€ä¸ªå”¯ä¸€ç´¢å¼•æ˜¯ä¸»é”®ï¼‰
        if column.constraints and column.constraints[0].type == ConstraintType.UNIQUE:
            # å°†ç¬¬ä¸€ä¸ªå”¯ä¸€çº¦æŸè®¾ä¸ºä¸»é”®
            column.constraints[0].type = ConstraintType.PRIMARY_KEY
    
    def _extract_indexes(self, data: pd.DataFrame, table_name: str) -> List[Dict[str, Any]]:
        """æå–ç´¢å¼•å®šä¹‰"""
        indexes = []
        
        if len(data) < 5:
            return indexes
        
        # ç¬¬5è¡Œï¼ˆç´¢å¼•4ï¼‰æ˜¯åˆ—æ ‡é¢˜è¡Œï¼Œä»Håˆ—å¼€å§‹æ˜¯ç´¢å¼•ä¿¡æ¯
        # Håˆ—æ˜¯ç´¢å¼•7ï¼ˆ0-basedï¼‰
        header_row = data.iloc[3]
        
        # æŸ¥æ‰¾ç´¢å¼•åˆ—
        index_columns = []
        for i, header in enumerate(header_row):
            if pd.notna(header):
                header_str = str(header).strip()
                if "UIDX" in header_str or "IDX" in header_str:
                    index_columns.append((i, header_str))
        
        logger.info(f"Found index columns: {index_columns}")
        
        # æŒ‰ç´¢å¼•åç§°æ”¶é›†åˆ—
        index_columns_map = {}
        
        # è§£ææ¯ä¸€è¡Œçš„ç´¢å¼•ä¿¡æ¯
        for row_idx in range(3, len(data)):
            row = data.iloc[row_idx]
            if len(row) < 3:  # è‡³å°‘éœ€è¦åˆ—å
                continue
            
            column_name = str(row.iloc[0]).strip() if pd.notna(row.iloc[0]) else ""
            if not column_name:
                continue
            
            # æ£€æŸ¥æ¯ä¸ªç´¢å¼•åˆ—
            for col_idx, index_name in index_columns:
                if col_idx < len(row) and pd.notna(row.iloc[col_idx]):
                    value = str(row.iloc[col_idx]).strip()
                    if value and "Y" in value.upper():
                        # æ”¶é›†åˆ°ç´¢å¼•æ˜ å°„ä¸­
                        if index_name not in index_columns_map:
                            index_columns_map[index_name] = []
                        index_columns_map[index_name].append(column_name)
        
        # åˆ›å»ºç´¢å¼•
        for index_name, columns in index_columns_map.items():
            if columns:
                if "UIDX" in index_name:
                    # å”¯ä¸€ç´¢å¼•
                    index = self._create_index(index_name, columns, True, table_name)
                else:
                    # éå”¯ä¸€ç´¢å¼•
                    index = self._create_index(index_name, columns, False, table_name)
                
                if index:
                    indexes.append(index)
        
        logger.info(f"Created {len(indexes)} indexes")
        return indexes
    
    def _create_index(self, index_name: str, columns: List[str], unique: bool, table_name: str) -> Optional[Dict[str, Any]]:
        """åˆ›å»ºç´¢å¼•å¯¹è±¡"""
        if not columns:
            return None
        
        # ç”Ÿæˆç´¢å¼•åç§°
        full_index_name = f"{index_name}_{table_name}"
        
        return {
            "name": full_index_name,
            "columns": columns,
            "unique": unique,
            "type": "BTREE"
        }
    
    def _get_column_type(self, type_str: str) -> Optional[ColumnType]:
        """è·å–åˆ—ç±»å‹"""
        # æ¸…ç†ç±»å‹å­—ç¬¦ä¸²
        type_str = re.sub(r'[^a-zA-Z0-9]', '', type_str.lower())
        
        return self.supported_types.get(type_str)


# ä¾¿æ·å‡½æ•°
def parse_database_design_excel(file_path: str) -> DatabaseDesign:
    """è§£ææ•°æ®åº“è®¾è®¡Excelæ–‡ä»¶çš„ä¾¿æ·å‡½æ•°"""
    parser = DatabaseDesignParser()
    return parser.parse_excel_file(file_path)

