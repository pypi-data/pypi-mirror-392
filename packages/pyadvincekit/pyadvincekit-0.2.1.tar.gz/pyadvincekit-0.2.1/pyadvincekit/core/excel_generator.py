#!/usr/bin/env python3
"""
Excelæ•°æ®åº“è®¾è®¡è‡ªåŠ¨ç”Ÿæˆå™¨

ä»Excelæ–‡ä»¶è‡ªåŠ¨ç”ŸæˆSQLã€ORMå’ŒPydanticå¯¹è±¡
"""

import os
import re
from typing import Dict, List, Optional, Any, Tuple, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum
import uuid
from datetime import datetime

from pyadvincekit.logging import get_logger

if TYPE_CHECKING:
    import pandas as pd

logger = get_logger(__name__)


class ColumnType(Enum):
    """æ•°æ®åº“åˆ—ç±»å‹"""
    # æ•´æ•°ç±»å‹
    INTEGER = "INTEGER"
    BIGINT = "BIGINT"
    SMALLINT = "SMALLINT"
    TINYINT = "TINYINT"
    
    # æµ®ç‚¹ç±»å‹
    FLOAT = "FLOAT"
    DOUBLE = "DOUBLE"
    DECIMAL = "DECIMAL"
    
    # å­—ç¬¦ä¸²ç±»å‹
    VARCHAR = "VARCHAR"
    CHAR = "CHAR"
    TEXT = "TEXT"
    LONGTEXT = "LONGTEXT"
    
    # æ—¥æœŸæ—¶é—´ç±»å‹
    DATE = "DATE"
    DATETIME = "DATETIME"
    TIMESTAMP = "TIMESTAMP"
    TIME = "TIME"
    
    # å¸ƒå°”ç±»å‹
    BOOLEAN = "BOOLEAN"
    
    # JSONç±»å‹
    JSON = "JSON"
    
    # äºŒè¿›åˆ¶ç±»å‹
    BLOB = "BLOB"
    LONGBLOB = "LONGBLOB"


class ConstraintType(Enum):
    """çº¦æŸç±»å‹"""
    PRIMARY_KEY = "PRIMARY KEY"
    FOREIGN_KEY = "FOREIGN KEY"
    UNIQUE = "UNIQUE"
    NOT_NULL = "NOT NULL"
    DEFAULT = "DEFAULT"
    CHECK = "CHECK"
    INDEX = "INDEX"


@dataclass
class ColumnConstraint:
    """åˆ—çº¦æŸ"""
    type: ConstraintType
    value: Optional[str] = None
    reference_table: Optional[str] = None
    reference_column: Optional[str] = None


@dataclass
class TableColumn:
    """è¡¨åˆ—å®šä¹‰"""
    name: str
    type: ColumnType
    length: Optional[int] = None
    precision: Optional[int] = None
    scale: Optional[int] = None
    nullable: bool = True
    default_value: Optional[str] = None
    comment: str = ""
    constraints: List[ColumnConstraint] = field(default_factory=list)
    
    def get_sql_type(self) -> str:
        """è·å–SQLç±»å‹å­—ç¬¦ä¸²"""
        type_str = self.type.value
        
        if self.type in [ColumnType.VARCHAR, ColumnType.CHAR] and self.length:
            type_str += f"({self.length})"
        elif self.type == ColumnType.DECIMAL and self.precision and self.scale:
            type_str += f"({self.precision},{self.scale})"
        elif self.type == ColumnType.DECIMAL and self.precision:
            type_str += f"({self.precision})"
        
        return type_str


@dataclass
class TableIndex:
    """è¡¨ç´¢å¼•"""
    name: str
    columns: List[str]
    unique: bool = False
    type: str = "BTREE"


@dataclass
class TableDefinition:
    """è¡¨å®šä¹‰"""
    name: str
    comment: str = ""
    columns: List[TableColumn] = field(default_factory=list)
    indexes: List[TableIndex] = field(default_factory=list)
    engine: str = "InnoDB"
    charset: str = "utf8mb4"
    collate: str = "utf8mb4_unicode_ci"


@dataclass
class DatabaseDesign:
    """æ•°æ®åº“è®¾è®¡"""
    name: str
    version: str = "1.0.0"
    description: str = ""
    tables: List[TableDefinition] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)


class ExcelParser:
    """Excelè§£æå™¨"""
    
    def __init__(self):
        self.supported_types = {
            # æ•´æ•°ç±»å‹
            "int": ColumnType.INTEGER,
            "integer": ColumnType.INTEGER,
            "bigint": ColumnType.BIGINT,
            "smallint": ColumnType.SMALLINT,
            "tinyint": ColumnType.TINYINT,
            "long": ColumnType.BIGINT,  # Longç±»å‹æ˜ å°„åˆ°BIGINT
            
            # æµ®ç‚¹ç±»å‹
            "float": ColumnType.FLOAT,
            "double": ColumnType.DOUBLE,
            "decimal": ColumnType.DECIMAL,
            "numeric": ColumnType.DECIMAL,
            
            # å­—ç¬¦ä¸²ç±»å‹
            "varchar": ColumnType.VARCHAR,
            "char": ColumnType.CHAR,
            "text": ColumnType.TEXT,
            "longtext": ColumnType.LONGTEXT,
            "string": ColumnType.VARCHAR,
            "str": ColumnType.VARCHAR,
            
            # æ—¥æœŸæ—¶é—´ç±»å‹
            "date": ColumnType.DATE,
            "datetime": ColumnType.DATETIME,
            "timestamp": ColumnType.TIMESTAMP,
            "time": ColumnType.TIME,
            
            # å¸ƒå°”ç±»å‹
            "boolean": ColumnType.BOOLEAN,
            "bool": ColumnType.BOOLEAN,
            
            # JSONç±»å‹
            "json": ColumnType.JSON,
            
            # äºŒè¿›åˆ¶ç±»å‹
            "blob": ColumnType.BLOB,
            "longblob": ColumnType.LONGBLOB,
        }
    
    def parse_excel_file(self, file_path: str) -> DatabaseDesign:
        """è§£æExcelæ–‡ä»¶"""
        try:
            import pandas as pd
        except ImportError:
            raise ImportError("pandas is required for Excel parsing. Install with: pip install pandas openpyxl")
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Excel file not found: {file_path}")
        
        logger.info(f"Parsing Excel file: {file_path}")
        
        # è¯»å–Excelæ–‡ä»¶
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©å¼•æ“
        if file_path.lower().endswith('.xls'):
            # .xlsæ–‡ä»¶ä½¿ç”¨xlrdå¼•æ“
            try:
                excel_data = pd.read_excel(file_path, sheet_name=None, engine='xlrd')
            except ImportError:
                raise ImportError("xlrd is required for .xls files. Install with: pip install xlrd")
        else:
            # .xlsxæ–‡ä»¶ä½¿ç”¨openpyxlå¼•æ“
            try:
                excel_data = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')
            except ImportError:
                raise ImportError("openpyxl is required for .xlsx files. Install with: pip install openpyxl")
        
        # è§£ææ•°æ®åº“è®¾è®¡
        design = DatabaseDesign(name="Generated Database")
        
        # è§£ææ¯ä¸ªå·¥ä½œè¡¨ä½œä¸ºè¡¨å®šä¹‰
        for sheet_name, sheet_data in excel_data.items():
            if sheet_name.lower() in ['_metadata', 'metadata', 'info']:
                # è§£æå…ƒæ•°æ®
                self._parse_metadata(sheet_data, design)
            else:
                # è§£æè¡¨å®šä¹‰
                table = self._parse_table(sheet_name, sheet_data)
                if table:
                    design.tables.append(table)
        
        logger.info(f"Parsed {len(design.tables)} tables from Excel file")
        return design
    
    def _parse_metadata(self, data: "pd.DataFrame", design: DatabaseDesign):
        """è§£æå…ƒæ•°æ®"""
        for _, row in data.iterrows():
            key = str(row.iloc[0]).lower() if len(row) > 0 else ""
            value = str(row.iloc[1]) if len(row) > 1 else ""
            
            if key == "name":
                design.name = value
            elif key == "version":
                design.version = value
            elif key == "description":
                design.description = value
    
    def _parse_table(self, table_name: str, data: "pd.DataFrame") -> Optional[TableDefinition]:
        """è§£æè¡¨å®šä¹‰"""
        if data.empty:
            return None
        
        # é¢„æœŸçš„åˆ—ç»“æ„ï¼šåˆ—å, ç±»å‹, é•¿åº¦, æ˜¯å¦ä¸ºç©º, é»˜è®¤å€¼, æ³¨é‡Š, çº¦æŸ
        expected_columns = ["åˆ—å", "ç±»å‹", "é•¿åº¦", "æ˜¯å¦ä¸ºç©º", "é»˜è®¤å€¼", "æ³¨é‡Š", "çº¦æŸ"]
        
        # æ£€æŸ¥åˆ—å
        if len(data.columns) < 2:
            logger.warning(f"Table {table_name} has insufficient columns")
            return None
        
        table = TableDefinition(name=table_name)
        
        for _, row in data.iterrows():
            try:
                column = self._parse_column(row)
                if column:
                    table.columns.append(column)
            except Exception as e:
                logger.warning(f"Failed to parse column in table {table_name}: {e}")
                continue
        
        return table if table.columns else None
    
    def _parse_column(self, row: "pd.Series") -> Optional[TableColumn]:
        """è§£æåˆ—å®šä¹‰"""
        if len(row) < 2:
            return None
        
        # è·å–åˆ—ä¿¡æ¯
        name = str(row.iloc[0]).strip()
        type_str = str(row.iloc[1]).strip().lower()
        length = None
        nullable = True
        default_value = None
        comment = ""
        constraints = []
        
        # è§£æé•¿åº¦
        if len(row) > 2 and pd.notna(row.iloc[2]):
            try:
                length = int(row.iloc[2])
            except (ValueError, TypeError):
                pass
        
        # è§£ææ˜¯å¦ä¸ºç©º
        if len(row) > 3 and pd.notna(row.iloc[3]):
            nullable_str = str(row.iloc[3]).strip().lower()
            nullable = nullable_str not in ["no", "false", "0", "å¦", "ä¸å¯ä¸ºç©º"]
        
        # è§£æé»˜è®¤å€¼
        if len(row) > 4 and pd.notna(row.iloc[4]):
            default_value = str(row.iloc[4]).strip()
            if default_value.lower() in ["null", "none", ""]:
                default_value = None
        
        # è§£ææ³¨é‡Š
        if len(row) > 5 and pd.notna(row.iloc[5]):
            comment = str(row.iloc[5]).strip()
        
        # è§£æçº¦æŸ
        if len(row) > 6 and pd.notna(row.iloc[6]):
            constraint_str = str(row.iloc[6]).strip()
            constraints = self._parse_constraints(constraint_str)
        
        # ç¡®å®šåˆ—ç±»å‹
        column_type = self._get_column_type(type_str)
        if not column_type:
            logger.warning(f"Unknown column type: {type_str}")
            return None
        
        return TableColumn(
            name=name,
            type=column_type,
            length=length,
            nullable=nullable,
            default_value=default_value,
            comment=comment,
            constraints=constraints
        )
    
    def _get_column_type(self, type_str: str) -> Optional[ColumnType]:
        """è·å–åˆ—ç±»å‹"""
        # æ¸…ç†ç±»å‹å­—ç¬¦ä¸²
        type_str = re.sub(r'[^a-zA-Z0-9]', '', type_str.lower())
        
        return self.supported_types.get(type_str)
    
    def _parse_constraints(self, constraint_str: str) -> List[ColumnConstraint]:
        """è§£æçº¦æŸ"""
        constraints = []
        
        if not constraint_str:
            return constraints
        
        # åˆ†å‰²çº¦æŸ
        constraint_parts = [part.strip() for part in constraint_str.split(',')]
        
        for part in constraint_parts:
            part = part.upper()
            
            if "PRIMARY KEY" in part or "ä¸»é”®" in part:
                constraints.append(ColumnConstraint(ConstraintType.PRIMARY_KEY))
            elif "UNIQUE" in part or "å”¯ä¸€" in part:
                constraints.append(ColumnConstraint(ConstraintType.UNIQUE))
            elif "NOT NULL" in part or "éç©º" in part:
                constraints.append(ColumnConstraint(ConstraintType.NOT_NULL))
            elif "FOREIGN KEY" in part or "å¤–é”®" in part:
                # è§£æå¤–é”®å¼•ç”¨
                ref_match = re.search(r'REFERENCES\s+(\w+)\.(\w+)', part)
                if ref_match:
                    constraints.append(ColumnConstraint(
                        ConstraintType.FOREIGN_KEY,
                        reference_table=ref_match.group(1),
                        reference_column=ref_match.group(2)
                    ))
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„å¼•ç”¨ï¼Œä»ç„¶æ·»åŠ å¤–é”®çº¦æŸ
                    constraints.append(ColumnConstraint(ConstraintType.FOREIGN_KEY))
            elif "INDEX" in part or "ç´¢å¼•" in part:
                constraints.append(ColumnConstraint(ConstraintType.INDEX))
        
        return constraints


class SQLGenerator:
    """SQLç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.dialect = "mysql"  # é»˜è®¤MySQL
    
    def generate_create_database_sql(self, design: DatabaseDesign) -> str:
        """ç”Ÿæˆåˆ›å»ºæ•°æ®åº“çš„SQL"""
        sql = f"""-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE IF NOT EXISTS `{design.name}` 
DEFAULT CHARACTER SET utf8mb4 
DEFAULT COLLATE utf8mb4_unicode_ci;

USE `{design.name}`;

"""
        return sql
    
    def generate_create_table_sql(self, table: TableDefinition) -> str:
        """ç”Ÿæˆåˆ›å»ºè¡¨çš„SQL"""
        sql_lines = [f"-- åˆ›å»ºè¡¨: {table.name}"]
        if table.comment:
            sql_lines.append(f"-- {table.comment}")
        
        sql_lines.append(f"CREATE TABLE `{table.name}` (")
        
        # ç”Ÿæˆåˆ—å®šä¹‰
        column_definitions = []
        primary_keys = []
        
        for column in table.columns:
            col_def = self._generate_column_definition(column)
            column_definitions.append(f"  {col_def}")
            
            # æ”¶é›†ä¸»é”®ï¼ˆé¿å…é‡å¤ï¼‰
            for constraint in column.constraints:
                if constraint.type == ConstraintType.PRIMARY_KEY:
                    if column.name not in primary_keys:  # é¿å…é‡å¤æ·»åŠ 
                        primary_keys.append(column.name)
        
        # æ·»åŠ ä¸»é”®çº¦æŸ
        if primary_keys:
            column_definitions.append(f"  PRIMARY KEY (`{'`, `'.join(primary_keys)}`)")
        
        # æ·»åŠ å¤–é”®çº¦æŸ
        for column in table.columns:
            for constraint in column.constraints:
                if constraint.type == ConstraintType.FOREIGN_KEY:
                    fk_name = f"fk_{table.name}_{column.name}"
                    fk_def = f"  CONSTRAINT `{fk_name}` FOREIGN KEY (`{column.name}`) REFERENCES `{constraint.reference_table}` (`{constraint.reference_column}`)"
                    column_definitions.append(fk_def)
        
        sql_lines.append(",\n".join(column_definitions))
        sql_lines.append(f") ENGINE={table.engine} DEFAULT CHARSET={table.charset} COLLATE={table.collate};")
        
        # æ·»åŠ ç´¢å¼•
        for index in table.indexes:
            unique_keyword = "UNIQUE " if index.unique else ""
            sql_lines.append(f"CREATE {unique_keyword}INDEX `{index.name}` ON `{table.name}` (`{'`, `'.join(index.columns)}`);")
        
        return "\n".join(sql_lines) + "\n"
    
    def _generate_column_definition(self, column: TableColumn) -> str:
        """ç”Ÿæˆåˆ—å®šä¹‰"""
        parts = [f"`{column.name}`", column.get_sql_type()]
        
        # æ·»åŠ NOT NULLçº¦æŸ
        if not column.nullable:
            parts.append("NOT NULL")
        
        # æ·»åŠ é»˜è®¤å€¼
        if column.default_value is not None:
            if column.default_value.upper() in ["CURRENT_TIMESTAMP", "NOW()"]:
                parts.append(f"DEFAULT {column.default_value}")
            else:
                # æ™ºèƒ½å¤„ç†é»˜è®¤å€¼ï¼Œé¿å…é‡å¤å¼•å·
                default_val = column.default_value.strip()
                
                # å¦‚æœå·²ç»è¢«å¼•å·åŒ…å›´ï¼Œç›´æ¥ä½¿ç”¨
                if (default_val.startswith("'") and default_val.endswith("'")) or \
                   (default_val.startswith('"') and default_val.endswith('"')):
                    # ç§»é™¤å¤–å±‚å¼•å·ï¼Œç„¶åæ·»åŠ æ ‡å‡†çš„å•å¼•å·
                    inner_value = default_val[1:-1]
                    parts.append(f"DEFAULT '{inner_value}'")
                elif self._is_numeric_value(default_val):
                    # æ•°å­—ä¸éœ€è¦å¼•å·
                    parts.append(f"DEFAULT {default_val}")
                else:
                    # å­—ç¬¦ä¸²éœ€è¦å•å¼•å·
                    parts.append(f"DEFAULT '{default_val}'")
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦éœ€è¦ ON UPDATEï¼ˆé€šè¿‡æ³¨é‡Šä¸­çš„ç‰¹æ®Šæ ‡è®°ï¼‰
        if column.comment and "[AUTO_UPDATE]" in column.comment:
            parts.append("ON UPDATE CURRENT_TIMESTAMP")
        
        # æ·»åŠ æ³¨é‡Šï¼ˆç§»é™¤ç‰¹æ®Šæ ‡è®°ï¼‰
        if column.comment:
            clean_comment = column.comment.replace(" [AUTO_UPDATE]", "")
            parts.append(f"COMMENT '{clean_comment}'")
        
        return " ".join(parts)
    
    def _is_numeric_value(self, value: str) -> bool:
        """æ£€æŸ¥å€¼æ˜¯å¦ä¸ºæ•°å­—ï¼ˆæ•´æ•°æˆ–å°æ•°ï¼‰"""
        try:
            float(value)
            return True
        except ValueError:
            return False
    
    def _clean_default_value(self, value: str) -> str:
        """æ¸…ç†é»˜è®¤å€¼ï¼Œç§»é™¤å¤šä½™çš„å¼•å·"""
        if not value:
            return value
            
        value = value.strip()
        
        # å¦‚æœè¢«åŒå¼•å·åŒ…å›´ï¼Œç§»é™¤å¤–å±‚å¼•å·
        if value.startswith('"') and value.endswith('"'):
            return value[1:-1]
        
        # å¦‚æœè¢«å•å¼•å·åŒ…å›´ï¼Œç§»é™¤å¤–å±‚å¼•å·
        if value.startswith("'") and value.endswith("'"):
            return value[1:-1]
        
        return value
    
    def generate_all_sql(self, design: DatabaseDesign) -> str:
        """ç”Ÿæˆæ‰€æœ‰SQL"""
        sql_parts = [
            self.generate_create_database_sql(design),
            ""
        ]
        
        for table in design.tables:
            sql_parts.append(self.generate_create_table_sql(table))
            sql_parts.append("")
        
        return "\n".join(sql_parts)


class ORMGenerator:
    """ORMç”Ÿæˆå™¨"""
    
    def generate_model(self, table: TableDefinition) -> str:
        """ç”ŸæˆSQLAlchemyæ¨¡å‹ï¼ˆä½¿ç”¨PyAdvanceKitå°è£…çš„å­—æ®µå‡½æ•°ï¼‰"""
        imports = [
            "from typing import Optional",
            "from datetime import datetime, date, time",
            "from decimal import Decimal",
            "from sqlalchemy.orm import Mapped"
        ]
        
        # å¦‚æœæœ‰ç´¢å¼•ï¼Œéœ€è¦å¯¼å…¥Index
        if table.indexes:
            imports.append("from sqlalchemy import Index")
        
        # æ™ºèƒ½é€‰æ‹©åŸºç±»å’Œæ··å…¥ç±»
        base_classes = self._determine_base_classes(table)
        
        imports.extend([
            "from pyadvincekit import (",
            f"    {', '.join(base_classes)},",
            "    # å­—æ®µåˆ›å»ºå‡½æ•°",
            "    create_required_string_column, create_optional_string_column, create_text_column,",
            "    create_integer_column, create_bigint_column, create_float_column,",
            "    create_boolean_column, create_datetime_column, create_date_column,",
            "    create_time_column, create_decimal_column, create_json_column,",
            "    create_status_column, create_version_column, create_foreign_key_column",
            ")"
        ])
        
        # æ„å»ºç»§æ‰¿åˆ—è¡¨
        inheritance = ", ".join(base_classes)
        
        model_lines = [
            f"class {self._to_pascal_case(table.name)}({inheritance}):",
            f'    """{table.comment or f"{table.name} model"}"""',
            f'    __tablename__ = "{table.name}"',
            ""
        ]
        
        # ç”Ÿæˆåˆ—å®šä¹‰
        # ç¡®å®šå“ªäº›å­—æ®µä¼šè¢«æ··å…¥ç±»æä¾›
        provided_fields = set()
        if "IdMixin" in base_classes:
            provided_fields.add("id")
        if "UpperIdMixin" in base_classes:
            provided_fields.add("ID")  # UpperIdMixin æä¾› ID å­—æ®µ
        if "TimestampMixin" in base_classes:
            provided_fields.update(["created_at", "updated_at"])
        if "SoftDeleteMixin" in base_classes:
            provided_fields.update(["is_deleted", "deleted_at"])
        
        provided_fields_lower = {field.lower() for field in provided_fields}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸»é”®å­—æ®µ
        has_primary_key = self._table_has_primary_key(table, base_classes)
        
        # ç”Ÿæˆå­—æ®µå®šä¹‰
        first_field_processed = False
        for i, column in enumerate(table.columns):
            if column.name.lower() not in provided_fields_lower:
                # å¦‚æœæ²¡æœ‰ä¸»é”®ä¸”è¿™æ˜¯ç¬¬ä¸€ä¸ªéè·³è¿‡å­—æ®µï¼Œè‡ªåŠ¨è®¾ä¸ºä¸»é”®
                if not has_primary_key and not first_field_processed:
                    model_lines.append(f"    # è‡ªåŠ¨è®¾ç½®ç¬¬ä¸€ä¸ªå­—æ®µä¸ºä¸»é”®")
                    model_lines.append(self._generate_pyadvincekit_column_with_primary_key(column))
                    first_field_processed = True
                else:
                    # æ£€æŸ¥è¿™ä¸ªå­—æ®µæ˜¯å¦åœ¨æ•°æ®åº“ä¸­æ˜¯ä¸»é”®ï¼Œå¦‚æœæ˜¯ä½†å·²ç»æœ‰IdMixinæˆ–UpperIdMixinï¼Œåˆ™è½¬ä¸ºå”¯ä¸€çº¦æŸ
                    is_db_primary = any(c.type == ConstraintType.PRIMARY_KEY for c in column.constraints)
                    if is_db_primary and ("IdMixin" in base_classes or "UpperIdMixin" in base_classes):
                        model_lines.append(f"    # å­—æ®µ '{column.name}' åœ¨æ•°æ®åº“ä¸­æ˜¯ä¸»é”®ï¼Œä½†å·²æœ‰IdMixinï¼Œè½¬ä¸ºå”¯ä¸€çº¦æŸ")
                        model_lines.append(self._generate_pyadvincekit_column_with_unique(column))
                    else:
                        model_lines.append(self._generate_pyadvincekit_column(column))
            else:
                model_lines.append(f"    # è·³è¿‡å­—æ®µ '{column.name}'ï¼Œç”±æ··å…¥ç±»æä¾›")
        
        # ğŸ”¥ ç”Ÿæˆç´¢å¼•å®šä¹‰
        if table.indexes:
            model_lines.append("")
            model_lines.append("    # ç´¢å¼•å®šä¹‰")
            index_definitions = []
            for index in table.indexes:
                index_def = self._generate_single_index_definition(index, base_classes, table)
                if index_def:  # åªæ·»åŠ æœ‰æ•ˆçš„ç´¢å¼•å®šä¹‰
                    index_definitions.append(index_def)
            
            # å°†æ‰€æœ‰ç´¢å¼•æ”¾åœ¨ä¸€ä¸ª __table_args__ ä¸­
            if len(index_definitions) == 1:
                model_lines.append(f"    __table_args__ = ({index_definitions[0]},)")
            else:
                model_lines.append("    __table_args__ = (")
                for i, index_def in enumerate(index_definitions):
                    if i == len(index_definitions) - 1:
                        model_lines.append(f"        {index_def}")
                    else:
                        model_lines.append(f"        {index_def},")
                model_lines.append("    )")
        
        return "\n".join(imports + [""] + model_lines)
    
    def _generate_single_index_definition(self, index: TableIndex, base_classes: list, table: TableDefinition) -> str:
        """ç”Ÿæˆå•ä¸ªSQLAlchemyç´¢å¼•å®šä¹‰"""
        # æ„å»ºåˆ—å¼•ç”¨åˆ—è¡¨
        column_refs = []
        for col_name in index.columns:
            # æ˜ å°„å­—æ®µåï¼šæ£€æŸ¥å­—æ®µæ˜¯å¦ç”±æ··å…¥ç±»æä¾›
            mapped_name = col_name
            
            if self._is_field_provided_by_mixin(col_name, base_classes):
                # ä½¿ç”¨æ··å…¥ç±»æä¾›çš„å­—æ®µåï¼ˆå°å†™ï¼‰
                if col_name.upper() == 'ID':
                    mapped_name = 'id'
                elif col_name.upper() == 'CREATED_AT':
                    mapped_name = 'created_at'
                elif col_name.upper() == 'UPDATED_AT':
                    mapped_name = 'updated_at'
                elif col_name.upper() == 'IS_DELETED':
                    mapped_name = 'is_deleted'
                elif col_name.upper() == 'DELETED_AT':
                    mapped_name = 'deleted_at'
            
            column_refs.append(f"'{mapped_name}'")
        
        # æ„å»ºç´¢å¼•å®šä¹‰
        unique_param = ", unique=True" if index.unique else ""
        columns_str = ", ".join(column_refs)
        
        return f"Index('{index.name}', {columns_str}{unique_param})"
    
    def _create_field_mapping(self, base_classes: list, table: TableDefinition) -> dict:
        """åˆ›å»ºå­—æ®µåæ˜ å°„è¡¨"""
        mapping = {}
        
        # ä¸ºæ··å…¥ç±»æä¾›çš„å­—æ®µåˆ›å»ºæ˜ å°„
        if "IdMixin" in base_classes:
            mapping["ID"] = "id"
        if "TimestampMixin" in base_classes:
            mapping["CREATED_AT"] = "created_at"
            mapping["UPDATED_AT"] = "updated_at"
        if "SoftDeleteMixin" in base_classes:
            mapping["IS_DELETED"] = "is_deleted"
            mapping["DELETED_AT"] = "deleted_at"
        
        return mapping
    
    def _determine_base_classes(self, table: TableDefinition) -> list:
        """æ™ºèƒ½é€‰æ‹©åŸºç±»å’Œæ··å…¥ç±»"""
        base_classes = ["BaseModel"]
        
        # æ£€æŸ¥è¡¨ä¸­çš„å­—æ®µï¼Œå†³å®šä½¿ç”¨å“ªäº› Mixin
        original_field_names = [col.name for col in table.columns]
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ IdMixin æˆ– UpperIdMixinï¼ˆåªæœ‰Excelä¸­å­˜åœ¨ç›¸åº”å­—æ®µæ—¶æ‰æ·»åŠ ï¼‰
        if "ID" in original_field_names:
            base_classes.append("UpperIdMixin")
        elif "id" in original_field_names:
            base_classes.append("IdMixin")
        # å¦‚æœExcelä¸­æ²¡æœ‰idå­—æ®µï¼Œå°±ä¸æ·»åŠ ä»»ä½•IdMixin
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´æˆ³å­—æ®µ
        timestamp_fields = {"created_at", "updated_at", "CREATED_AT", "UPDATED_AT"}
        if any(field.upper() in {f.upper() for f in timestamp_fields} for field in original_field_names):
            base_classes.append("TimestampMixin")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è½¯åˆ é™¤å­—æ®µ
        soft_delete_fields = {"is_deleted", "deleted_at", "IS_DELETED", "DELETED_AT"}
        if any(field.upper() in {f.upper() for f in soft_delete_fields} for field in original_field_names):
            base_classes.append("SoftDeleteMixin")
        
        # ç¡®ä¿è¿”å›çš„åŸºç±»åˆ—è¡¨ä¸­ä¸åŒ…å« UpperIdMixin
        if "UpperIdMixin" in base_classes:
            base_classes.remove("UpperIdMixin")
        
        return base_classes
    
    def _is_field_provided_by_mixin(self, field_name: str, base_classes: list) -> bool:
        """æ£€æŸ¥å­—æ®µæ˜¯å¦ç”±æ··å…¥ç±»æä¾›"""
        field_upper = field_name.upper()
        
        if "IdMixin" in base_classes and field_upper == "ID":
            return True
        if "TimestampMixin" in base_classes and field_upper in ["CREATED_AT", "UPDATED_AT"]:
            return True
        if "SoftDeleteMixin" in base_classes and field_upper in ["IS_DELETED", "DELETED_AT"]:
            return True
        
        return False
    
    def _table_has_primary_key(self, table: TableDefinition, base_classes: list) -> bool:
        """æ£€æŸ¥è¡¨æ˜¯å¦æœ‰ä¸»é”®å­—æ®µ"""
        # å¦‚æœä½¿ç”¨äº† IdMixin æˆ– UpperIdMixinï¼Œåˆ™æœ‰ä¸»é”®
        if "IdMixin" in base_classes or "UpperIdMixin" in base_classes:
            return True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼çš„ä¸»é”®çº¦æŸ
        for column in table.columns:
            for constraint in column.constraints:
                if constraint.type == ConstraintType.PRIMARY_KEY:
                    return True
        
        return False
    
    def _generate_pyadvincekit_column_with_primary_key(self, column: TableColumn) -> str:
        """ç”Ÿæˆå¸¦ä¸»é”®çš„PyAdvanceKitå­—æ®µå®šä¹‰"""
        # ç¡®å®šPythonç±»å‹æ³¨è§£
        python_type = self._get_python_type_annotation(column)
        
        # ç¡®å®šå­—æ®µåˆ›å»ºå‡½æ•°ï¼Œå¹¶å¼ºåˆ¶æ·»åŠ ä¸»é”®å‚æ•°
        function_name, params = self._determine_field_function_and_params(column)
        params["primary_key"] = True  # å¼ºåˆ¶è®¾ä¸ºä¸»é”®
        
        # æ„å»ºå‚æ•°åˆ—è¡¨
        param_strs = []
        for key, value in params.items():
            if isinstance(value, str):
                param_strs.append(f'{key}="{value}"')
            elif isinstance(value, bool):
                param_strs.append(f'{key}={value}')
            elif value is not None:
                param_strs.append(f'{key}={value}')
        
        if param_strs:
            field_function = f"{function_name}({', '.join(param_strs)})"
        else:
            field_function = f"{function_name}(primary_key=True)"
        
        # æ„å»ºå­—æ®µå®šä¹‰
        return f"    {column.name}: {python_type} = {field_function}"
    
    def _generate_pyadvincekit_column_with_unique(self, column: TableColumn) -> str:
        """ç”Ÿæˆå¸¦å”¯ä¸€çº¦æŸçš„PyAdvanceKitå­—æ®µå®šä¹‰"""
        # ç¡®å®šPythonç±»å‹æ³¨è§£
        python_type = self._get_python_type_annotation(column)
        
        # ç¡®å®šå­—æ®µåˆ›å»ºå‡½æ•°ï¼Œå¹¶å¼ºåˆ¶æ·»åŠ å”¯ä¸€çº¦æŸ
        function_name, params = self._determine_field_function_and_params(column)
        params["unique"] = True  # å¼ºåˆ¶è®¾ä¸ºå”¯ä¸€
        # ç¡®ä¿ä¸è®¾ç½®ä¸»é”®
        params.pop("primary_key", None)
        
        # æ„å»ºå‚æ•°åˆ—è¡¨
        param_strs = []
        for key, value in params.items():
            if isinstance(value, str):
                param_strs.append(f'{key}="{value}"')
            elif isinstance(value, bool):
                param_strs.append(f'{key}={value}')
            elif value is not None:
                param_strs.append(f'{key}={value}')
        
        if param_strs:
            field_function = f"{function_name}({', '.join(param_strs)})"
        else:
            field_function = f"{function_name}(unique=True)"
        
        # æ„å»ºå­—æ®µå®šä¹‰
        return f"    {column.name}: {python_type} = {field_function}"
    
    def _generate_pyadvincekit_column(self, column: TableColumn) -> str:
        """ç”Ÿæˆä½¿ç”¨PyAdvanceKitå°è£…å‡½æ•°çš„åˆ—å®šä¹‰"""
        # ç¡®å®šPythonç±»å‹æ³¨è§£
        python_type = self._get_python_type_annotation(column)
        
        # ç¡®å®šå­—æ®µåˆ›å»ºå‡½æ•°
        field_function = self._get_field_creation_function(column)
        
        # æ„å»ºå­—æ®µå®šä¹‰
        return f"    {column.name}: {python_type} = {field_function}"
    
    def _get_python_type_annotation(self, column: TableColumn) -> str:
        """è·å–Pythonç±»å‹æ³¨è§£ï¼ˆåŒ…å«MappedåŒ…è£…ï¼‰"""
        base_type = self._get_base_python_type(column.type)
        
        # æ£€æŸ¥æ˜¯å¦å¯ä¸ºç©º
        if column.nullable and not self._has_not_null_constraint(column):
            return f"Mapped[Optional[{base_type}]]"
        else:
            return f"Mapped[{base_type}]"
    
    def _get_base_python_type(self, column_type: ColumnType) -> str:
        """è·å–åŸºç¡€Pythonç±»å‹"""
        type_mapping = {
            ColumnType.INTEGER: "int",
            ColumnType.BIGINT: "int", 
            ColumnType.SMALLINT: "int",
            ColumnType.TINYINT: "int",
            ColumnType.FLOAT: "float",
            ColumnType.DOUBLE: "float",
            ColumnType.DECIMAL: "Decimal",
            ColumnType.VARCHAR: "str",
            ColumnType.CHAR: "str", 
            ColumnType.TEXT: "str",
            ColumnType.LONGTEXT: "str",
            ColumnType.DATE: "date",
            ColumnType.DATETIME: "datetime",
            ColumnType.TIMESTAMP: "datetime",
            ColumnType.TIME: "time",
            ColumnType.BOOLEAN: "bool",
            ColumnType.JSON: "dict",
            ColumnType.BLOB: "bytes",
            ColumnType.LONGBLOB: "bytes",
        }
        return type_mapping.get(column_type, "str")
    
    def _has_not_null_constraint(self, column: TableColumn) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰éç©ºçº¦æŸ"""
        return any(c.type == ConstraintType.NOT_NULL for c in column.constraints)
    
    def _get_field_creation_function(self, column: TableColumn) -> str:
        """è·å–å­—æ®µåˆ›å»ºå‡½æ•°è°ƒç”¨"""
        function_name, params = self._determine_field_function_and_params(column)
        
        # æ„å»ºå‚æ•°åˆ—è¡¨
        param_strs = []
        for key, value in params.items():
            if isinstance(value, str):
                param_strs.append(f'{key}="{value}"')
            elif isinstance(value, bool):
                param_strs.append(f'{key}={value}')
            elif value is not None:
                param_strs.append(f'{key}={value}')
        
        if param_strs:
            return f"{function_name}({', '.join(param_strs)})"
        else:
            return f"{function_name}()"
    
    def _determine_field_function_and_params(self, column: TableColumn) -> tuple:
        """ç¡®å®šå­—æ®µå‡½æ•°å’Œå‚æ•°"""
        params = {}
        
        # æ·»åŠ æ³¨é‡Š
        if column.comment:
            params["comment"] = self._clean_comment(column.comment)
        
        # æ·»åŠ é»˜è®¤å€¼
        if column.default_value:
            if column.default_value.upper() in ["CURRENT_TIMESTAMP", "NOW()"]:
                if column.type == ColumnType.DATETIME:
                    params["auto_now_add"] = True
                elif column.type == ColumnType.DATE:
                    params["auto_now_add"] = True
            else:
                # æ™ºèƒ½å¤„ç†é»˜è®¤å€¼ï¼Œé¿å…é‡å¤å¼•å·
                params["default"] = self._clean_default_value(column.default_value)
        
        # æ£€æŸ¥çº¦æŸ
        is_unique = any(c.type == ConstraintType.UNIQUE for c in column.constraints)
        is_primary = any(c.type == ConstraintType.PRIMARY_KEY for c in column.constraints)
        is_foreign_key = any(c.type == ConstraintType.FOREIGN_KEY for c in column.constraints)
        
        # å¤„ç†çº¦æŸï¼šä¸»é”®å’Œå”¯ä¸€çº¦æŸ
        if is_primary:
            # å¦‚æœå­—æ®µåœ¨æ•°æ®åº“ä¸­æ˜¯ä¸»é”®ï¼Œé»˜è®¤è®¾ä¸ºä¸»é”®
            # ä¸Šå±‚é€»è¾‘ä¼šæ ¹æ®æ˜¯å¦ä½¿ç”¨ IdMixin æ¥å†³å®šæ˜¯å¦è¦†ç›–
            params["primary_key"] = True
        elif is_unique:
            params["unique"] = True
        
        # æ ¹æ®å­—æ®µç±»å‹å’Œç‰¹å¾é€‰æ‹©å‡½æ•°
        if is_foreign_key:
            # å¤–é”®å­—æ®µ
            foreign_key_constraint = next((c for c in column.constraints if c.type == ConstraintType.FOREIGN_KEY), None)
            if foreign_key_constraint and foreign_key_constraint.reference_table:
                ref_table = foreign_key_constraint.reference_table
                ref_column = foreign_key_constraint.reference_column or "id"
                params = {"foreign_key": f"{ref_table}.{ref_column}", **params}
                return "create_foreign_key_column", params
        
        # æ ¹æ®å­—æ®µåç§°æ™ºèƒ½åˆ¤æ–­
        column_name_lower = column.name.lower()
        
        if "email" in column_name_lower or "mail" in column_name_lower:
            return "create_email_column", params
        elif "phone" in column_name_lower or "mobile" in column_name_lower or "tel" in column_name_lower:
            return "create_phone_column", params
        elif "url" in column_name_lower or "link" in column_name_lower or "website" in column_name_lower:
            return "create_url_column", params
        elif "status" in column_name_lower or "stat" in column_name_lower:
            return "create_status_column", params
        elif "sort" in column_name_lower or "order" in column_name_lower:
            return "create_sort_order_column", params
        elif "version" in column_name_lower or "ver" in column_name_lower:
            # create_version_column ä¸æ”¯æŒ unique å‚æ•°ï¼Œéœ€è¦ç§»é™¤
            version_params = {k: v for k, v in params.items() if k != "unique"}
            return "create_version_column", version_params
        
        # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©å‡½æ•°
        if column.type in [ColumnType.VARCHAR, ColumnType.CHAR]:
            # å­—ç¬¦ä¸²ç±»å‹
            if column.length:
                params["max_length"] = column.length
            
            if column.nullable and not self._has_not_null_constraint(column):
                return "create_optional_string_column", params
            else:
                return "create_required_string_column", params
                
        elif column.type == ColumnType.TEXT or column.type == ColumnType.LONGTEXT:
            return "create_text_column", params
            
        elif column.type == ColumnType.INTEGER:
            return "create_integer_column", params
            
        elif column.type == ColumnType.BIGINT:
            return "create_bigint_column", params
            
        elif column.type in [ColumnType.FLOAT, ColumnType.DOUBLE]:
            return "create_float_column", params
            
        elif column.type == ColumnType.DECIMAL:
            if column.precision:
                params["precision"] = column.precision
            if column.scale:
                params["scale"] = column.scale
            return "create_decimal_column", params
            
        elif column.type == ColumnType.BOOLEAN:
            return "create_boolean_column", params
            
        elif column.type == ColumnType.DATETIME or column.type == ColumnType.TIMESTAMP:
            return "create_datetime_column", params
            
        elif column.type == ColumnType.DATE:
            return "create_date_column", params
            
        elif column.type == ColumnType.TIME:
            return "create_time_column", params
            
        elif column.type == ColumnType.JSON:
            return "create_json_column", params
            
        elif column.type in [ColumnType.BLOB, ColumnType.LONGBLOB]:
            if column.length:
                params["max_length"] = column.length
            return "create_binary_column", params
        
        # é»˜è®¤è¿”å›å¯é€‰å­—ç¬¦ä¸²å­—æ®µ
        return "create_optional_string_column", params
    
    def _generate_orm_column(self, column: TableColumn) -> str:
        """ç”ŸæˆORMåˆ—å®šä¹‰"""
        # ç¡®å®šSQLAlchemyç±»å‹
        sa_type = self._get_sqlalchemy_type(column.type)
        
        # æ„å»ºåˆ—å‚æ•°
        args = [sa_type]
        kwargs = []
        
        # æ·»åŠ é•¿åº¦å‚æ•°
        if column.length and column.type in [ColumnType.VARCHAR, ColumnType.CHAR]:
            args.append(column.length)
        
        # æ·»åŠ ç²¾åº¦å‚æ•°
        if column.type == ColumnType.DECIMAL and column.precision:
            if column.scale:
                args.append(f"{column.precision}, {column.scale}")
            else:
                args.append(str(column.precision))
        
        # æ·»åŠ çº¦æŸ
        for constraint in column.constraints:
            if constraint.type == ConstraintType.PRIMARY_KEY:
                kwargs.append("primary_key=True")
            elif constraint.type == ConstraintType.UNIQUE:
                kwargs.append("unique=True")
            elif constraint.type == ConstraintType.NOT_NULL:
                kwargs.append("nullable=False")
        
        # æ·»åŠ é»˜è®¤å€¼
        if column.default_value:
            if column.default_value.upper() in ["CURRENT_TIMESTAMP", "NOW()"]:
                kwargs.append("default=datetime.now")
            else:
                clean_value = self._clean_default_value(column.default_value)
                if self._is_numeric_value(str(clean_value)):
                    kwargs.append(f"default={clean_value}")
                else:
                    kwargs.append(f"default='{clean_value}'")
        
        # æ·»åŠ æ³¨é‡Š
        if column.comment:
            kwargs.append(f"comment='{column.comment}'")
        
        # æ„å»ºåˆ—å®šä¹‰
        args_str = ", ".join([str(arg) for arg in args])
        kwargs_str = ", ".join(kwargs)
        
        if kwargs_str:
            column_def = f"    {column.name} = Column({args_str}, {kwargs_str})"
        else:
            column_def = f"    {column.name} = Column({args_str})"
        
        return column_def
    
    def _get_sqlalchemy_type(self, column_type: ColumnType) -> str:
        """è·å–SQLAlchemyç±»å‹"""
        type_mapping = {
            ColumnType.INTEGER: "Integer",
            ColumnType.BIGINT: "BigInteger",
            ColumnType.SMALLINT: "SmallInteger",
            ColumnType.TINYINT: "SmallInteger",
            ColumnType.FLOAT: "Float",
            ColumnType.DOUBLE: "Float",
            ColumnType.DECIMAL: "Numeric",
            ColumnType.VARCHAR: "String",
            ColumnType.CHAR: "String",
            ColumnType.TEXT: "Text",
            ColumnType.LONGTEXT: "Text",
            ColumnType.DATE: "Date",
            ColumnType.DATETIME: "DateTime",
            ColumnType.TIMESTAMP: "DateTime",
            ColumnType.TIME: "Time",
            ColumnType.BOOLEAN: "Boolean",
            ColumnType.JSON: "JSON",
            ColumnType.BLOB: "LargeBinary",
            ColumnType.LONGBLOB: "LargeBinary",
        }
        
        return type_mapping.get(column_type, "String")
    
    def _to_pascal_case(self, name: str) -> str:
        """è½¬æ¢ä¸ºPascalCase"""
        return ''.join(word.capitalize() for word in name.split('_'))
    
    def _clean_default_value(self, value: str) -> str:
        """æ¸…ç†é»˜è®¤å€¼ï¼Œç§»é™¤å¤šä½™çš„å¼•å·"""
        if not value:
            return value
            
        value = value.strip()
        
        # å¦‚æœè¢«åŒå¼•å·åŒ…å›´ï¼Œç§»é™¤å¤–å±‚å¼•å·
        if value.startswith('"') and value.endswith('"'):
            return value[1:-1]
        
        # å¦‚æœè¢«å•å¼•å·åŒ…å›´ï¼Œç§»é™¤å¤–å±‚å¼•å·
        if value.startswith("'") and value.endswith("'"):
            return value[1:-1]
        
        return value
    
    def _is_numeric_value(self, value: str) -> bool:
        """æ£€æŸ¥å€¼æ˜¯å¦ä¸ºæ•°å­—ï¼ˆæ•´æ•°æˆ–å°æ•°ï¼‰"""
        try:
            float(value)
            return True
        except ValueError:
            return False
    
    def _clean_comment(self, comment: str) -> str:
        """æ¸…ç†æ³¨é‡Šï¼Œå¤„ç†æ¢è¡Œç¬¦å’Œç‰¹æ®Šå­—ç¬¦"""
        if not comment:
            return comment
        
        # ç§»é™¤æ¢è¡Œç¬¦å’Œå¤šä½™çš„ç©ºç™½å­—ç¬¦
        cleaned = comment.replace('\n', ' ').replace('\r', ' ')
        
        # å‹ç¼©å¤šä¸ªç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼
        import re
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        # è½¬ä¹‰å¼•å·
        cleaned = cleaned.replace('"', '\\"').replace("'", "\\'")
        
        return cleaned
    
    
    def _has_standard_fields(self, table: TableDefinition) -> bool:
        """æ£€æŸ¥è¡¨æ˜¯å¦åŒ…å«æ ‡å‡†å­—æ®µï¼ˆid, created_at, updated_atï¼‰"""
        field_names = {col.name.lower() for col in table.columns}
        standard_fields = {"id", "created_at", "updated_at"}
        
        # å¦‚æœè¡¨åŒ…å«ä»»ä½•æ ‡å‡†å­—æ®µï¼Œåˆ™ä½¿ç”¨æ··å…¥ç±»
        return bool(standard_fields.intersection(field_names))


class PydanticGenerator:
    """Pydanticç”Ÿæˆå™¨"""
    
    def generate_schema(self, table: TableDefinition) -> str:
        """ç”ŸæˆPydanticæ¨¡å¼"""
        imports = [
            "from pydantic import BaseModel, Field",
            "from datetime import datetime, date, time",
            "from typing import Optional, Any",
            "from decimal import Decimal"
        ]
        
        schema_lines = [
            f"class {self._to_pascal_case(table.name)}Base(BaseModel):",
            f'    """{table.comment or f"{table.name} base schema"}"""',
            ""
        ]
        
        # ç”Ÿæˆå­—æ®µå®šä¹‰ï¼ˆè·³è¿‡æ ‡å‡†å­—æ®µï¼Œé¿å…ä¸BaseModelå†²çªï¼‰
        standard_fields = {"id", "created_at", "updated_at"}
        # åŒæ—¶æ£€æŸ¥å¤§å°å†™å˜ä½“ï¼Œé¿å…å­—æ®µå†²çª
        standard_fields_lower = {field.lower() for field in standard_fields}
        
        for column in table.columns:
            # æ£€æŸ¥å­—æ®µåæ˜¯å¦ä¸BaseModelçš„æ ‡å‡†å­—æ®µå†²çªï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
            if column.name.lower() not in standard_fields_lower:
                schema_lines.append(self._generate_pydantic_field(column))
        
        # æ·»åŠ  Config ç±»åˆ° Base æ¨¡å‹
        schema_lines.extend([
            "",
            "    class Config:",
            "        populate_by_name = True  # å…è®¸ä½¿ç”¨å­—æ®µåæˆ–åˆ«å",
            "        allow_population_by_field_name = True  # æ”¯æŒå­—æ®µåå¡«å……",
        ])
        
        # ç”Ÿæˆå®Œæ•´çš„CRUDæ¨¡å¼
        schema_lines.extend([
            "",
            f"class {self._to_pascal_case(table.name)}Create({self._to_pascal_case(table.name)}Base):",
            '    """åˆ›å»ºæ—¶ä½¿ç”¨çš„æ¨¡å¼"""',
            "    pass",
            "",
            f"class {self._to_pascal_case(table.name)}Update({self._to_pascal_case(table.name)}Base):",
            '    """æ›´æ–°æ—¶ä½¿ç”¨çš„æ¨¡å¼ï¼ˆæ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯é€‰çš„ï¼‰"""',
            "    pass",
            "",
            f"class {self._to_pascal_case(table.name)}Response({self._to_pascal_case(table.name)}Base):",
            '    """APIå“åº”æ—¶ä½¿ç”¨çš„æ¨¡å¼"""',
            "    id: str  # PyAdvanceKitä½¿ç”¨UUIDä½œä¸ºä¸»é”®",
            "    created_at: datetime",
            "    updated_at: datetime",
            "",
            "    class Config:",
            "        from_attributes = True",
            "        populate_by_name = True  # å…è®¸ä½¿ç”¨å­—æ®µåæˆ–åˆ«å",
            "        allow_population_by_field_name = True  # æ”¯æŒå­—æ®µåå¡«å……",
        ])
        
        schema_lines.extend([
            "",
            f"class {self._to_pascal_case(table.name)}InDB({self._to_pascal_case(table.name)}Response):",
            '    """æ•°æ®åº“å­˜å‚¨æ¨¡å¼ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰"""',
            "    pass",
            "",
            f"class {self._to_pascal_case(table.name)}Query(BaseModel):",
            '    """æŸ¥è¯¢å‚æ•°æ¨¡å¼"""',
            "    page: Optional[int] = Field(default=1, ge=1, description='é¡µç ')",
            "    size: Optional[int] = Field(default=10, ge=1, le=100, description='æ¯é¡µæ•°é‡')",
            "    search: Optional[str] = Field(default=None, description='æœç´¢å…³é”®è¯')",
            "    order_by: Optional[str] = Field(default=None, description='æ’åºå­—æ®µ')",
            "    order_desc: Optional[bool] = Field(default=False, description='æ˜¯å¦é™åº')",
            "",
            f"class {self._to_pascal_case(table.name)}Filter(BaseModel):",
            '    """è¿‡æ»¤æ¡ä»¶æ¨¡å¼"""',
            "    search: Optional[str] = Field(default=None, description='æœç´¢å…³é”®è¯')",
            "    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ å…·ä½“çš„è¿‡æ»¤å­—æ®µ",
        ])
        
        # ä¸ºå¸¸è§çš„è¿‡æ»¤å­—æ®µæ·»åŠ è¿‡æ»¤æ¡ä»¶
        filter_fields = []
        for column in table.columns:
            if self._is_filterable_field(column):
                filter_fields.append(self._generate_filter_field(column))
        
        if filter_fields:
            schema_lines.extend(filter_fields)
        else:
            schema_lines.append("    pass")
        
        return "\n".join(imports + [""] + schema_lines)
    
    def _is_filterable_field(self, column: TableColumn) -> bool:
        """åˆ¤æ–­å­—æ®µæ˜¯å¦é€‚åˆä½œä¸ºè¿‡æ»¤æ¡ä»¶"""
        # æ’é™¤ä¸€äº›ä¸é€‚åˆè¿‡æ»¤çš„å­—æ®µç±»å‹
        exclude_types = [ColumnType.TEXT, ColumnType.LONGTEXT, ColumnType.BLOB, ColumnType.LONGBLOB]
        if column.type in exclude_types:
            return False
        
        # æ’é™¤ä¸€äº›ä¸é€‚åˆè¿‡æ»¤çš„å­—æ®µå
        exclude_names = ['created_at', 'updated_at', 'deleted_at', 'password', 'token']
        if column.name.lower() in exclude_names:
            return False
        
        # å¸¸è§çš„è¿‡æ»¤å­—æ®µ
        filter_keywords = ['status', 'type', 'category', 'level', 'priority', 'state']
        column_name_lower = column.name.lower()
        
        return any(keyword in column_name_lower for keyword in filter_keywords)
    
    def _generate_filter_field(self, column: TableColumn) -> str:
        """ç”Ÿæˆè¿‡æ»¤å­—æ®µ"""
        python_type = self._get_python_type(column.type)
        field_name = f"{column.name.lower()}_filter"
        
        if column.type in [ColumnType.INTEGER, ColumnType.BIGINT]:
            # æ•°å€¼ç±»å‹æ”¯æŒèŒƒå›´è¿‡æ»¤
            return f"    {field_name}_min: Optional[{python_type}] = Field(default=None, description='{column.comment or column.name}æœ€å°å€¼')"
        elif column.type in [ColumnType.VARCHAR, ColumnType.CHAR]:
            # å­—ç¬¦ä¸²ç±»å‹æ”¯æŒæ¨¡ç³ŠåŒ¹é…
            return f"    {field_name}: Optional[{python_type}] = Field(default=None, description='{column.comment or column.name}è¿‡æ»¤')"
        elif column.type == ColumnType.BOOLEAN:
            # å¸ƒå°”ç±»å‹ç›´æ¥è¿‡æ»¤
            return f"    {field_name}: Optional[{python_type}] = Field(default=None, description='{column.comment or column.name}è¿‡æ»¤')"
        else:
            # å…¶ä»–ç±»å‹
            return f"    {field_name}: Optional[{python_type}] = Field(default=None, description='{column.comment or column.name}è¿‡æ»¤')"
    
    def _generate_pydantic_field(self, column: TableColumn) -> str:
        """ç”ŸæˆPydanticå­—æ®µ"""
        # ç¡®å®šPythonç±»å‹
        python_type = self._get_python_type(column.type)
        
        # å¤„ç†å¯é€‰å­—æ®µ
        if column.nullable:
            python_type = f"Optional[{python_type}]"
        
        # ç”Ÿæˆé©¼å³°å‘½åçš„å­—æ®µå
        camel_case_name = self._to_camel_case(column.name)
        
        # æ„å»ºå­—æ®µå®šä¹‰
        field_parts = [f"    {camel_case_name}: {python_type}"]
        
        # æ·»åŠ Fieldå‚æ•°
        field_kwargs = []
        
        # æ·»åŠ åˆ«åæ˜ å°„ï¼ˆå°†é©¼å³°åæ˜ å°„åˆ°æ•°æ®åº“å­—æ®µåï¼‰
        if camel_case_name != column.name:
            field_kwargs.append(f"alias='{column.name}'")
        
        # æ·»åŠ é»˜è®¤å€¼å‚æ•°
        if not column.nullable:
            # å¯¹äºå¿…éœ€å­—æ®µï¼Œä¸æ·»åŠ é»˜è®¤å€¼å‚æ•°ï¼Œè®© Pydantic è‡ªåŠ¨å¤„ç†
            pass
        else:
            field_kwargs.append("default=None")  # å¯é€‰å­—æ®µ
        
        # ç„¶åæ·»åŠ å…¶ä»–å‚æ•°
        if column.comment:
            cleaned_comment = self._clean_comment(column.comment)
            field_kwargs.append(f"description='{cleaned_comment}'")
        
        if field_kwargs:
            field_parts.append(f" = Field({', '.join(field_kwargs)})")
        
        return "".join(field_parts)
    
    def _get_python_type(self, column_type: ColumnType) -> str:
        """è·å–Pythonç±»å‹"""
        type_mapping = {
            ColumnType.INTEGER: "int",
            ColumnType.BIGINT: "int",
            ColumnType.SMALLINT: "int",
            ColumnType.TINYINT: "int",
            ColumnType.FLOAT: "float",
            ColumnType.DOUBLE: "float",
            ColumnType.DECIMAL: "Decimal",
            ColumnType.VARCHAR: "str",
            ColumnType.CHAR: "str",
            ColumnType.TEXT: "str",
            ColumnType.LONGTEXT: "str",
            ColumnType.DATE: "date",
            ColumnType.DATETIME: "datetime",
            ColumnType.TIMESTAMP: "datetime",
            ColumnType.TIME: "time",
            ColumnType.BOOLEAN: "bool",
            ColumnType.JSON: "Any",
            ColumnType.BLOB: "bytes",
            ColumnType.LONGBLOB: "bytes",
        }
        
        return type_mapping.get(column_type, "str")
    
    def _clean_comment(self, comment: str) -> str:
        """æ¸…ç†æ³¨é‡Šï¼Œç§»é™¤æ¢è¡Œç¬¦å’Œç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢è¯­æ³•é”™è¯¯"""
        if not comment:
            return ""
        
        # ç§»é™¤æ¢è¡Œç¬¦å’Œå¤šä½™çš„ç©ºç™½å­—ç¬¦
        cleaned = ' '.join(comment.strip().split())
        
        # è½¬ä¹‰å•å¼•å·
        cleaned = cleaned.replace("'", "\\'")
        
        # é™åˆ¶é•¿åº¦ï¼Œé¿å…è¿‡é•¿çš„æè¿°
        if len(cleaned) > 100:
            cleaned = cleaned[:97] + "..."
        
        return cleaned
    
    def _to_pascal_case(self, name: str) -> str:
        """è½¬æ¢ä¸ºPascalCase"""
        return ''.join(word.capitalize() for word in name.split('_'))
    
    def _to_camel_case(self, name: str) -> str:
        """è½¬æ¢ä¸ºcamelCaseï¼ˆé¦–å­—æ¯å°å†™çš„é©¼å³°å‘½åï¼‰"""
        if '_' not in name:
            # å¦‚æœæ²¡æœ‰ä¸‹åˆ’çº¿ï¼Œç›´æ¥è¿”å›å°å†™
            camel_name = name.lower()
        else:
            words = name.split('_')
            # ç¬¬ä¸€ä¸ªå•è¯å°å†™ï¼Œå…¶ä½™å•è¯é¦–å­—æ¯å¤§å†™
            camel_name = words[0].lower() + ''.join(word.capitalize() for word in words[1:])
        
        # æ£€æŸ¥æ˜¯å¦ä¸ Python å†…ç½®ç±»å‹å†²çªï¼Œå¦‚æœå†²çªåˆ™æ·»åŠ åç¼€
        python_builtins = {
            'bytes', 'str', 'int', 'float', 'bool', 'list', 'dict', 'set', 'tuple',
            'type', 'object', 'property', 'classmethod', 'staticmethod', 'super',
            'len', 'range', 'enumerate', 'zip', 'map', 'filter', 'sorted', 'reversed',
            'min', 'max', 'sum', 'any', 'all', 'abs', 'round', 'pow', 'divmod',
            'id', 'hash', 'repr', 'format', 'input', 'print', 'open', 'file'
        }
        
        if camel_name in python_builtins:
            # å¦‚æœä¸å†…ç½®ç±»å‹å†²çªï¼Œæ·»åŠ  Data åç¼€
            camel_name = camel_name + 'Data'
        
        return camel_name


class ExcelCodeGenerator:
    """Excelä»£ç ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.parser = ExcelParser()
        self.sql_generator = SQLGenerator()
        self.orm_generator = ORMGenerator()
        self.pydantic_generator = PydanticGenerator()
    
    def generate_from_excel(
        self,
        excel_file: str,
        output_dir: str,
        generate_sql: bool = True,
        generate_orm: bool = True,
        generate_pydantic: bool = True
    ) -> Dict[str, str]:
        """ä»Excelæ–‡ä»¶ç”Ÿæˆä»£ç """
        # è§£æExcelæ–‡ä»¶
        design = self.parser.parse_excel_file(excel_file)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        generated_files = {}
        
        # ç”ŸæˆSQL
        if generate_sql:
            sql_content = self.sql_generator.generate_all_sql(design)
            sql_file = os.path.join(output_dir, f"{design.name}.sql")
            with open(sql_file, 'w', encoding='utf-8') as f:
                f.write(sql_content)
            generated_files['sql'] = sql_file
            logger.info(f"Generated SQL file: {sql_file}")
        
        # ç”ŸæˆORMæ¨¡å‹
        if generate_orm:
            orm_content = self._generate_all_orm_models(design)
            orm_file = os.path.join(output_dir, "models.py")
            with open(orm_file, 'w', encoding='utf-8') as f:
                f.write(orm_content)
            generated_files['orm'] = orm_file
            logger.info(f"Generated ORM file: {orm_file}")
        
        # ç”ŸæˆPydanticæ¨¡å¼
        if generate_pydantic:
            pydantic_content = self._generate_all_pydantic_schemas(design)
            pydantic_file = os.path.join(output_dir, "schemas.py")
            with open(pydantic_file, 'w', encoding='utf-8') as f:
                f.write(pydantic_content)
            generated_files['pydantic'] = pydantic_file
            logger.info(f"Generated Pydantic file: {pydantic_file}")
        
        return generated_files
    
    def _generate_all_orm_models(self, design: DatabaseDesign) -> str:
        """ç”Ÿæˆæ‰€æœ‰ORMæ¨¡å‹"""
        content_parts = [
            "#!/usr/bin/env python3",
            '"""',
            f"Generated ORM models for {design.name}",
            f"Generated at: {datetime.now().isoformat()}",
            '"""',
            "",
            "from sqlalchemy import Column, Integer, String, DateTime, Boolean, Text, Float, JSON, Date, Time, Numeric, BigInteger, SmallInteger, LargeBinary",
            "from sqlalchemy.ext.declarative import declarative_base",
            "from pyadvincekit.models.base import BaseModel",
            "from datetime import datetime, date, time",
            "from typing import Optional",
            "",
            "Base = declarative_base()",
            ""
        ]
        
        for table in design.tables:
            content_parts.append(self.orm_generator.generate_model(table))
            content_parts.append("")
        
        return "\n".join(content_parts)
    
    def _generate_all_pydantic_schemas(self, design: DatabaseDesign) -> str:
        """ç”Ÿæˆæ‰€æœ‰Pydanticæ¨¡å¼"""
        content_parts = [
            "#!/usr/bin/env python3",
            '"""',
            f"Generated Pydantic schemas for {design.name}",
            f"Generated at: {datetime.now().isoformat()}",
            '"""',
            "",
            "from pydantic import BaseModel, Field",
            "from datetime import datetime, date, time",
            "from typing import Optional, Any",
            "from decimal import Decimal",
            ""
        ]
        
        for table in design.tables:
            content_parts.append(self.pydantic_generator.generate_schema(table))
            content_parts.append("")
        
        return "\n".join(content_parts)


# ä¾¿æ·å‡½æ•°
def generate_from_excel(
    excel_file: str,
    output_dir: str,
    generate_sql: bool = True,
    generate_orm: bool = True,
    generate_pydantic: bool = True
) -> Dict[str, str]:
    """ä»Excelæ–‡ä»¶ç”Ÿæˆä»£ç çš„ä¾¿æ·å‡½æ•°"""
    generator = ExcelCodeGenerator()
    return generator.generate_from_excel(
        excel_file=excel_file,
        output_dir=output_dir,
        generate_sql=generate_sql,
        generate_orm=generate_orm,
        generate_pydantic=generate_pydantic
    )
