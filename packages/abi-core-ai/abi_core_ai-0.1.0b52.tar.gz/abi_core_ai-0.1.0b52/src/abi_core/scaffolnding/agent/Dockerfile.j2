# {{ agent_name }} Agent Dockerfile
# Generated by ABI-Core scaffolding

FROM smarbuy/abi-image:latest

# Set working directory
WORKDIR /app

# Copy agent-specific requirements and install
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy agent files
COPY . .

# Environment variables for abi-entrypoint.sh
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV ABI_ROLE="{{ agent_name }} Agent"
ENV ABI_NODE="ABI AGENT"
ENV AGENT_HOST=0.0.0.0
ENV AGENT_PORT={{ agent_port | default('8000') }}

# ABI Entrypoint configuration
ENV START_OLLAMA=true
ENV LOAD_MODELS=true
ENV SERVICE_MODULE=main
ENV SERVICE_PORT={{ agent_port | default('8000') }}

# Create non-root user but keep root for model access
RUN useradd -m -u 1000 {{ agent_name.replace('-', '_') }} && \
    chown -R {{ agent_name.replace('-', '_') }}:{{ agent_name.replace('-', '_') }} /app && \
    chmod -R 755 /root/.ollama || true

# Health check - verify both Ollama and agent are ready
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags >/dev/null 2>&1 && \
        curl -f http://localhost:{{ agent_port | default('8000') }}/health >/dev/null 2>&1 || exit 1

# Expose ports (agent + Ollama)
EXPOSE {{ agent_port | default('8000') }}
EXPOSE 11434

# Volume for model data (always enabled for agents)
VOLUME ["/root/.ollama"]

# Use abi-entrypoint.sh (inherited from abi-image)
# The entrypoint will handle Ollama startup, model loading, and agent startup
# No need to override CMD - entrypoint will use SERVICE_MODULE