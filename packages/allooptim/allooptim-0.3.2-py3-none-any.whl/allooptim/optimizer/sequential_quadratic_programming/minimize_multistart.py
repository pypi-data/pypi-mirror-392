"""Multi-start sequential quadratic programming utilities.

This module provides utilities for performing global optimization using sequential quadratic
programming (SQP) with multiple random starting points. The multi-start approach helps avoid
getting stuck in local optima by exploring the solution space from various initial conditions.

Key features:
- Multi-start SQP optimization
- Random initial weight generation
- Local optima avoidance
- Portfolio weight constraints handling
- Solver failure detection and recovery
"""

import logging
from typing import Callable, Optional

import numpy as np
from scipy.optimize import minimize

logger = logging.getLogger(__name__)

# Constants for solver validation
SOLVER_FAILURE_WEIGHT_SUM_THRESHOLD = 1.05


def minimize_given_initial(
    objective_function: Callable,
    allow_cash: bool,
    x0: np.ndarray,
    jacobian: Optional[Callable] = None,
    hessian: Optional[Callable] = None,
    maxiter: int = 100,
    ftol: float = 1e-6,
    optimizer_name: str = "SLSQP",
) -> np.ndarray:
    """Perform optimization with multiple starting points to avoid local minima.

    Tries:
    1. Equal weights (1/n for each asset)
    2. Previous best weights (if available)

    Returns the best result.
    """
    # Constraint: 0 <= sum(weights) <= 1.0 (allow cash holding)
    if allow_cash:
        constraints = ({"type": "ineq", "fun": lambda x: 1.0 - np.sum(x)},)  # sum <= 1
    else:
        constraints = ({"type": "eq", "fun": lambda x: 1.0 - np.sum(x)},)  # sum == 1

    n_assets = len(x0)
    bounds = [(0, 1) for _ in range(n_assets)]

    if hessian is not None and optimizer_name not in ["trust-constr", "Newton-CG"]:
        logger.debug(
            f"Hessian provided but optimizer '{optimizer_name}' may not support it. "
            "Consider using 'trust-constr' or 'Newton-CG' for Hessian support."
        )
        hessian = None

    res_equal = minimize(
        objective_function,
        x0=x0,
        method=optimizer_name,
        constraints=constraints,
        bounds=bounds,
        jac=jacobian,
        hess=hessian,
        options={
            "disp": False,
            "maxiter": maxiter,
            "ftol": ftol,
        },
    )

    if not res_equal.success:
        logger.warning(f"Optimization {optimizer_name} failed: {res_equal.message}")

    return res_equal


def minimize_with_multistart(
    objective_function: Callable,
    n_assets: int,
    allow_cash: bool,
    previous_best_weights: Optional[np.ndarray],
    jacobian: Optional[Callable] = None,
    hessian: Optional[Callable] = None,
    maxiter: int = 100,
    ftol: float = 1e-6,
    optimizer_name: str = "SLSQP",
) -> np.ndarray:
    """Perform optimization with multiple starting points to avoid local minima.

    Tries:
    1. Equal weights (1/n for each asset)
    2. Previous best weights (if available)

    Returns the best result.
    """
    best_weights = None
    best_cost = np.inf

    # Starting point 1: Equal weights
    x0_equal = np.ones(n_assets) / n_assets

    res_equal = minimize_given_initial(
        objective_function,
        allow_cash=allow_cash,
        x0=x0_equal,
        jacobian=jacobian,
        hessian=hessian,
        maxiter=maxiter,
        ftol=ftol,
        optimizer_name=optimizer_name,
    )

    if res_equal.success and res_equal.fun < best_cost:
        best_weights = res_equal.x
        best_cost = res_equal.fun

    # Starting point 2: Previous best weights (if available)
    if previous_best_weights is not None and len(previous_best_weights) == n_assets:
        res_prev = minimize_given_initial(
            objective_function,
            allow_cash=allow_cash,
            x0=previous_best_weights,
            jacobian=jacobian,
            hessian=hessian,
            maxiter=maxiter,
            ftol=ftol,
            optimizer_name=optimizer_name,
        )

        if res_prev.success and res_prev.fun < best_cost:
            best_weights = res_prev.x
            best_cost = res_prev.fun

    elif previous_best_weights is not None:
        logger.warning("Previous best weights length does not match number of assets, skipping that start point.")

    # Return best result, or equal weights start if all failed
    if best_weights is None:
        logger.error("All optimization attempts failed, using equal weights fallback")
        best_weights = x0_equal

    weight_sum = np.sum(best_weights)
    if weight_sum > 1.0:
        if weight_sum > SOLVER_FAILURE_WEIGHT_SUM_THRESHOLD:
            logger.error(
                f"Weight sum {weight_sum:.4f} > {SOLVER_FAILURE_WEIGHT_SUM_THRESHOLD}, "
                "likely the solver failed, normalizing weights"
            )
        else:
            logger.debug(f"Weight sum {weight_sum:.4f} > 1.0, normalizing for safety")
        best_weights = best_weights / weight_sum

    return best_weights
