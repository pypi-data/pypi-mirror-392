# Follows https://arxiv.org/pdf/2209.12782#page=13.82
dataset:
  name: 'amp'
  params:
    split: 'D'
    nfold: 5

network:
  # Input size and output size are computed based on the environment
  encoder_params:
    vocab_size: 29
    max_length: 60
    num_heads: 8
    num_layers: 4

    embedding_size: 64
    hidden_size: 64
    intermediate_size: 64

    dropout_rate: 0.0
    attention_dropout_rate: 0.0
  output_dim: 1

training:
  batch_size: 256
  learning_rate: 1e-4
  weight_decay: 1e-6
  num_epochs: 1000    # Very large number, but we will use early stopping
  val_each_epoch: 2   
  early_stop_tol: 5
  task: 'classification'

seed: 1
save_path: proxy/weights/amp/