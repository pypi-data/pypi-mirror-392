seed: 111
env_init_seed: 1
eval_init_seed: 2

num_train_steps: 50000
num_envs: 16

agent:
  learning_rate: 1e-3
  logZ_learning_rate: 5e-2
  weight_decay: 1e-5
  start_eps: 1e-3
  end_eps: 1e-3
  exploration_steps: 50_000 # Should be <= of num_train_steps
  train_backward: false

network:
  # Input size and output size are computed based on the environment
  num_heads: 8
  num_layers: 3

  embedding_size: 64
  hidden_size: 64
  intermediate_size: 64

  dropout_rate: 0.0
  attention_dropout_rate: 0.0

environment:
  k: 8
  n: 120
  num_modes: 60
  reward_exponent: 3.0

metrics:
  n_rounds : 10
  batch_size : 7200
  mode_threshold : 30

logging:
  track_each: 1 # in terms of total training steps, not divided by num_envs
  eval_each: 1000 # in terms of total training steps, not divided by num_envs
  tqdm_print_rate: 20
  use_writer: true
  log_dir: null # If null, dir will be automatically created
  checkpoint_dir: null # If null, dir will be automatically created

# Technical information for writer
writer:
  writer_type: wandb # wandb, trackio or null (no logging online)
  save_locally: false # Save metrics locally or not
  entity: null
  project: EPS

# Technical information for hydra
hydra:
  run:
    dir: ./tmp/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ./tmp/${now:%Y-%m-%d}/${now:%H-%M-%S} 