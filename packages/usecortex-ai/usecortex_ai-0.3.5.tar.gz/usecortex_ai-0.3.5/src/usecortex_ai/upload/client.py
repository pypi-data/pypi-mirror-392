# This file was auto-generated by Fern from our API Definition.

import typing

from .. import core
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.app_sources_upload_data import AppSourcesUploadData
from ..types.batch_upload_data import BatchUploadData
from ..types.markdown_upload_request import MarkdownUploadRequest
from ..types.processing_status import ProcessingStatus
from ..types.single_upload_data import SingleUploadData
from ..types.source_model import SourceModel
from ..types.webpage_scrape_request import WebpageScrapeRequest
from .raw_client import AsyncRawUploadClient, RawUploadClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class UploadClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawUploadClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawUploadClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawUploadClient
        """
        return self._raw_client

    def batch_upload(
        self,
        *,
        tenant_id: str,
        files: typing.List[core.File],
        sub_tenant_id: typing.Optional[str] = None,
        file_ids: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Upload multiple documents simultaneously for efficient bulk processing.

        This endpoint allows you to upload several files at once, which is ideal for large document collections or periodic data imports. Each file gets processed asynchronously, and you can track the progress of individual files using their returned file IDs.

        The system automatically handles file parsing, content extraction, and indexing across all uploaded documents. You'll receive confirmation once all files are queued for processing.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        files : typing.List[core.File]
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_ids : typing.Optional[str]
            Optional JSON string array of file IDs for the uploaded content. If not provided or empty, will be generated automatically.

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.batch_upload(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.batch_upload(
            tenant_id=tenant_id,
            files=files,
            sub_tenant_id=sub_tenant_id,
            file_ids=file_ids,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def batch_update(
        self,
        *,
        tenant_id: str,
        files: typing.List[core.File],
        sub_tenant_id: typing.Optional[str] = None,
        source_ids: typing.Optional[typing.List[str]] = OMIT,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Update multiple existing documents with new content and metadata.

        Use this endpoint when you need to replace or modify several documents that are already in your knowledge base. Each file must correspond to an existing source ID, ensuring that updates are applied to the correct documents.

        The system processes updates asynchronously, allowing you to continue working while your documents are re-indexed. Track the progress using the returned file IDs to know when updates are complete.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        files : typing.List[core.File]
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        source_ids : typing.Optional[typing.List[str]]
            List of source IDs corresponding to the files being updated

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.batch_update(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.batch_update(
            tenant_id=tenant_id,
            files=files,
            sub_tenant_id=sub_tenant_id,
            source_ids=source_ids,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def upload_document(
        self,
        *,
        tenant_id: str,
        file: core.File,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload a single document for processing and indexing into your knowledge base.

        This endpoint accepts documents in various formats and processes them for search and retrieval. You can include custom metadata to help organize and categorize your content.

        The system extracts text content, processes it asynchronously, and makes it available for search queries. You can track the processing status using the returned file ID.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        file : core.File
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.upload_document(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.upload_document(
            tenant_id=tenant_id,
            file=file,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def update_document(
        self,
        *,
        source_id: str,
        tenant_id: str,
        file: core.File,
        sub_tenant_id: typing.Optional[str] = None,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Replace an existing document with updated content.

        This endpoint allows you to update a specific document that's already in your knowledge base. Provide the source ID of the document you want to modify, along with the new file content.

        The system will process your update asynchronously and re-index the document with the new content. You can monitor the progress using the returned file ID.

        Parameters
        ----------
        source_id : str
            The source ID of the document to update

        tenant_id : str
            Unique identifier for the tenant/organization

        file : core.File
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.update_document(source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.update_document(
            source_id=source_id,
            tenant_id=tenant_id,
            file=file,
            sub_tenant_id=sub_tenant_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def upload_app_sources(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[SourceModel],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AppSourcesUploadData:
        """
        Upload structured data from applications or APIs for indexing.

        This endpoint is designed for importing data from applications. If you are specifically using Cortex to provide search to an application, you should prefer this endpoint. It accepts structured source objects and allows you to clearly define contents of attachments

        The system processes each source asynchronously and makes the content available for search and retrieval. Use this when you need to integrate search and indexing from data in your applications into your knowledge base.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[SourceModel]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AppSourcesUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI, SourceModel

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.upload_app_sources(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[SourceModel()], )
        """
        _response = self._raw_client.upload_app_sources(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def upload_markdown(
        self,
        *,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload text or markdown content directly for processing.

        This endpoint accepts plain text or markdown-formatted content that you want to add to your knowledge base. It's perfect for notes, documentation, articles, or any text-based content you want to make searchable.

        You can include custom metadata to help organize and categorize your content. You can track the processing status using the returned file ID.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.upload_markdown(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        """
        _response = self._raw_client.upload_markdown(
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def upload_text(
        self,
        *,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload text or markdown content directly for processing.

        This endpoint accepts plain text or markdown-formatted content that you want to add to your knowledge base. It's perfect for notes, documentation, articles, or any text-based content you want to make searchable.

        You can include custom metadata to help organize and categorize your content. You can track the processing status using the returned file ID.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.upload_text(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        """
        _response = self._raw_client.upload_text(
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def update_markdown(
        self,
        *,
        source_id: str,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update existing text or markdown content with new information.

        This endpoint allows you to modify text or markdown content that's already in your knowledge base. Provide the source ID of the content you want to update, along with the new text.

        The system will reprocess and re-index the updated content asynchronously. Use this when you need to correct information, add details, or refresh existing documentation.

        Parameters
        ----------
        source_id : str
            The source ID of the document to update

        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.update_markdown(source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        """
        _response = self._raw_client.update_markdown(
            source_id=source_id,
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def update_text(
        self,
        *,
        source_id: str,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update existing text or markdown content with new information.

        This endpoint allows you to modify text or markdown content that's already in your knowledge base. Provide the source ID of the content you want to update, along with the new text.

        The system will reprocess and re-index the updated content asynchronously. Use this when you need to correct information, add details, or refresh existing documentation.

        Parameters
        ----------
        source_id : str
            The source ID of the document to update

        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.update_text(source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        """
        _response = self._raw_client.update_text(
            source_id=source_id,
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    def batch_upload_markdown(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[MarkdownUploadRequest],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Upload multiple markdown/text documents simultaneously for efficient bulk processing.

        This endpoint allows you to upload several markdown or text contents at once. Each content item gets processed asynchronously, and you can track the progress using their returned file IDs.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[MarkdownUploadRequest]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI, MarkdownUploadRequest

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.batch_upload_markdown(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[MarkdownUploadRequest(content='<content>', )], )
        """
        _response = self._raw_client.batch_upload_markdown(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def batch_upload_text(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[MarkdownUploadRequest],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Upload multiple markdown/text documents simultaneously for efficient bulk processing.

        This endpoint allows you to upload several markdown or text contents at once. Each content item gets processed asynchronously, and you can track the progress using their returned file IDs.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[MarkdownUploadRequest]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI, MarkdownUploadRequest

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.batch_upload_text(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[MarkdownUploadRequest(content='<content>', )], )
        """
        _response = self._raw_client.batch_upload_text(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def upload_embeddings(
        self,
        *,
        tenant_id: str,
        embeddings: typing.Sequence[typing.Sequence[float]],
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload pre-computed embeddings for advanced similarity search.

        This endpoint accepts vector embeddings that you've generated externally, allowing you to integrate with custom embedding models or existing vector databases. The embeddings represent chunks of your content as numerical vectors.

        The system stores these embeddings and makes them available for semantic search and similarity matching. Use this when you want to leverage specialized embedding models or have existing vector representations.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        embeddings : typing.Sequence[typing.Sequence[float]]
            The embeddings of source you want to index

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            The Source ID of the target source you want to index

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.upload_embeddings(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', embeddings=[[0.123413, 0.655367, 0.987654, 0.123456, 0.789012], [0.123413, 0.655367, 0.987654, 0.123456, 0.789012]], )
        """
        _response = self._raw_client.upload_embeddings(
            tenant_id=tenant_id,
            embeddings=embeddings,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            request_options=request_options,
        )
        return _response.data

    def update_embeddings(
        self,
        *,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        embeddings: typing.Optional[typing.Dict[str, typing.Sequence[float]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update existing embeddings with new vector representations.

        This endpoint allows you to modify embeddings that are already stored in your knowledge base. Provide updated vector representations for specific chunks of content, identified by their chunk IDs.

        The system will replace the existing embeddings with your new ones, ensuring that similarity searches reflect the most current vector representations. Use this when you need to update embeddings due to model improvements or content changes.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        embeddings : typing.Optional[typing.Dict[str, typing.Sequence[float]]]
            The embeddings of source you want to index

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.update_embeddings(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.update_embeddings(
            tenant_id=tenant_id, sub_tenant_id=sub_tenant_id, embeddings=embeddings, request_options=request_options
        )
        return _response.data

    def scrape_webpage(
        self,
        *,
        web_url: str,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Extract and index content from web pages automatically.

        This endpoint initiates web scraping for the specified URL, extracting the main content, text, and structure from the webpage. It's perfect for capturing articles, documentation, or any web content you want to include in your knowledge base.

        The system processes the webpage content asynchronously, cleaning and structuring the information for optimal search and retrieval. Use this when you need to add web content without manual copying and pasting.

        Parameters
        ----------
        web_url : str
            The URL of the webpage to scrape and index

        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional custom file ID for the scraped content. If not provided, a unique ID will be generated

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.scrape_webpage(web_url='https://www.usecortex.ai/', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', file_id='CortexDoc1234', )
        """
        _response = self._raw_client.scrape_webpage(
            web_url=web_url,
            tenant_id=tenant_id,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            request_options=request_options,
        )
        return _response.data

    def update_webpage(
        self,
        *,
        web_url: str,
        source_id: str,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update web scraping content with fresh data from the source URL.

        This endpoint refreshes the content for an existing web scraping job. Provide the source ID of the webpage content you want to update, and the system will re-scrape the URL to capture any changes.

        The updated content gets processed asynchronously and re-indexed in your knowledge base. Use this to keep web content current when the source pages are frequently updated.

        Parameters
        ----------
        web_url : str
            The URL of the webpage to re-scrape

        source_id : str
            The file ID of the existing web scraping job to update

        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.update_webpage(web_url='https://www.usecortex.ai/', source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.update_webpage(
            web_url=web_url,
            source_id=source_id,
            tenant_id=tenant_id,
            sub_tenant_id=sub_tenant_id,
            request_options=request_options,
        )
        return _response.data

    def batch_scrape_webpage(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[WebpageScrapeRequest],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Extract and index content from multiple web pages simultaneously.

        This endpoint initiates web scraping for multiple URLs at once, extracting the main content, text, and structure from each webpage. It's perfect for capturing multiple articles, documentation pages, or any web content you want to include in your knowledge base.

        The system processes all webpage content asynchronously, cleaning and structuring the information for optimal search and retrieval.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[WebpageScrapeRequest]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI, WebpageScrapeRequest

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.batch_scrape_webpage(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[WebpageScrapeRequest(web_url='https://www.usecortex.ai/', )], )
        """
        _response = self._raw_client.batch_scrape_webpage(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def delete_source(
        self,
        *,
        tenant_id: str,
        source_ids: typing.Sequence[str],
        sub_tenant_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Remove documents and content from your knowledge base.

        This endpoint permanently deletes the specified sources from your knowledge base. Once deleted, the content will no longer be available for search or retrieval.

        Use this carefully as the action cannot be undone. The system will confirm successful deletion of each source ID you specify.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        source_ids : typing.Sequence[str]
            List of source IDs to delete

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.delete_source(tenant_id='tenant_1234', source_ids=['CortexDoc1234', 'CortexDoc4567'], )
        """
        _response = self._raw_client.delete_source(
            tenant_id=tenant_id, source_ids=source_ids, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def delete_memory(
        self,
        *,
        tenant_id: str,
        source_ids: typing.Sequence[str],
        sub_tenant_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Remove documents and content from your knowledge base.

        This endpoint permanently deletes the specified sources from your knowledge base. Once deleted, the content will no longer be available for search or retrieval.

        Use this carefully as the action cannot be undone. The system will confirm successful deletion of each source ID you specify.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        source_ids : typing.Sequence[str]
            List of source IDs to delete

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.delete_memory(tenant_id='tenant_1234', source_ids=['CortexDoc1234', 'CortexDoc4567'], )
        """
        _response = self._raw_client.delete_memory(
            tenant_id=tenant_id, source_ids=source_ids, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def verify_processing(
        self,
        *,
        file_id: str,
        tenant_id: typing.Optional[str] = None,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ProcessingStatus:
        """
        Check the current processing status of your uploaded content.

        This endpoint allows you to monitor the progress of documents, text, or other content you've uploaded. Simply provide the file ID to see whether processing is complete, still in progress, or if any errors occurred.

        Use this to determine when your content is ready for search and retrieval, or to troubleshoot any processing issues.

        Parameters
        ----------
        file_id : str
            The file ID to check processing status for

        tenant_id : typing.Optional[str]
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ProcessingStatus
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.upload.verify_processing(file_id='CortexDoc1234', tenant_id='tenant_1234', )
        """
        _response = self._raw_client.verify_processing(
            file_id=file_id, tenant_id=tenant_id, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data


class AsyncUploadClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawUploadClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawUploadClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawUploadClient
        """
        return self._raw_client

    async def batch_upload(
        self,
        *,
        tenant_id: str,
        files: typing.List[core.File],
        sub_tenant_id: typing.Optional[str] = None,
        file_ids: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Upload multiple documents simultaneously for efficient bulk processing.

        This endpoint allows you to upload several files at once, which is ideal for large document collections or periodic data imports. Each file gets processed asynchronously, and you can track the progress of individual files using their returned file IDs.

        The system automatically handles file parsing, content extraction, and indexing across all uploaded documents. You'll receive confirmation once all files are queued for processing.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        files : typing.List[core.File]
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_ids : typing.Optional[str]
            Optional JSON string array of file IDs for the uploaded content. If not provided or empty, will be generated automatically.

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.batch_upload(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.batch_upload(
            tenant_id=tenant_id,
            files=files,
            sub_tenant_id=sub_tenant_id,
            file_ids=file_ids,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def batch_update(
        self,
        *,
        tenant_id: str,
        files: typing.List[core.File],
        sub_tenant_id: typing.Optional[str] = None,
        source_ids: typing.Optional[typing.List[str]] = OMIT,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Update multiple existing documents with new content and metadata.

        Use this endpoint when you need to replace or modify several documents that are already in your knowledge base. Each file must correspond to an existing source ID, ensuring that updates are applied to the correct documents.

        The system processes updates asynchronously, allowing you to continue working while your documents are re-indexed. Track the progress using the returned file IDs to know when updates are complete.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        files : typing.List[core.File]
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        source_ids : typing.Optional[typing.List[str]]
            List of source IDs corresponding to the files being updated

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.batch_update(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.batch_update(
            tenant_id=tenant_id,
            files=files,
            sub_tenant_id=sub_tenant_id,
            source_ids=source_ids,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def upload_document(
        self,
        *,
        tenant_id: str,
        file: core.File,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload a single document for processing and indexing into your knowledge base.

        This endpoint accepts documents in various formats and processes them for search and retrieval. You can include custom metadata to help organize and categorize your content.

        The system extracts text content, processes it asynchronously, and makes it available for search queries. You can track the processing status using the returned file ID.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        file : core.File
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.upload_document(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.upload_document(
            tenant_id=tenant_id,
            file=file,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def update_document(
        self,
        *,
        source_id: str,
        tenant_id: str,
        file: core.File,
        sub_tenant_id: typing.Optional[str] = None,
        tenant_metadata: typing.Optional[str] = OMIT,
        document_metadata: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Replace an existing document with updated content.

        This endpoint allows you to update a specific document that's already in your knowledge base. Provide the source ID of the document you want to modify, along with the new file content.

        The system will process your update asynchronously and re-index the document with the new content. You can monitor the progress using the returned file ID.

        Parameters
        ----------
        source_id : str
            The source ID of the document to update

        tenant_id : str
            Unique identifier for the tenant/organization

        file : core.File
            See core.File for more documentation

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        tenant_metadata : typing.Optional[str]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"


        document_metadata : typing.Optional[str]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"



        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.update_document(source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.update_document(
            source_id=source_id,
            tenant_id=tenant_id,
            file=file,
            sub_tenant_id=sub_tenant_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def upload_app_sources(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[SourceModel],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AppSourcesUploadData:
        """
        Upload structured data from applications or APIs for indexing.

        This endpoint is designed for importing data from applications. If you are specifically using Cortex to provide search to an application, you should prefer this endpoint. It accepts structured source objects and allows you to clearly define contents of attachments

        The system processes each source asynchronously and makes the content available for search and retrieval. Use this when you need to integrate search and indexing from data in your applications into your knowledge base.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[SourceModel]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AppSourcesUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI, SourceModel

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.upload_app_sources(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[SourceModel()], )
        asyncio.run(main())
        """
        _response = await self._raw_client.upload_app_sources(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def upload_markdown(
        self,
        *,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload text or markdown content directly for processing.

        This endpoint accepts plain text or markdown-formatted content that you want to add to your knowledge base. It's perfect for notes, documentation, articles, or any text-based content you want to make searchable.

        You can include custom metadata to help organize and categorize your content. You can track the processing status using the returned file ID.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.upload_markdown(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        asyncio.run(main())
        """
        _response = await self._raw_client.upload_markdown(
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def upload_text(
        self,
        *,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload text or markdown content directly for processing.

        This endpoint accepts plain text or markdown-formatted content that you want to add to your knowledge base. It's perfect for notes, documentation, articles, or any text-based content you want to make searchable.

        You can include custom metadata to help organize and categorize your content. You can track the processing status using the returned file ID.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.upload_text(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        asyncio.run(main())
        """
        _response = await self._raw_client.upload_text(
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def update_markdown(
        self,
        *,
        source_id: str,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update existing text or markdown content with new information.

        This endpoint allows you to modify text or markdown content that's already in your knowledge base. Provide the source ID of the content you want to update, along with the new text.

        The system will reprocess and re-index the updated content asynchronously. Use this when you need to correct information, add details, or refresh existing documentation.

        Parameters
        ----------
        source_id : str
            The source ID of the document to update

        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.update_markdown(source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        asyncio.run(main())
        """
        _response = await self._raw_client.update_markdown(
            source_id=source_id,
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def update_text(
        self,
        *,
        source_id: str,
        tenant_id: str,
        content: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        tenant_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        document_metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update existing text or markdown content with new information.

        This endpoint allows you to modify text or markdown content that's already in your knowledge base. Provide the source ID of the content you want to update, along with the new text.

        The system will reprocess and re-index the updated content asynchronously. Use this when you need to correct information, add details, or refresh existing documentation.

        Parameters
        ----------
        source_id : str
            The source ID of the document to update

        tenant_id : str
            Unique identifier for the tenant/organization

        content : str
            The text or markdown content to upload

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional file ID for the uploaded content. If not provided, will be generated automatically.

        tenant_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing tenant-level document metadata (e.g., department, compliance_tag)

            Example: > "{"department":"Finance","compliance_tag":"GDPR"}"

        document_metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            JSON string containing document-specific metadata (e.g., title, author, file_id). If file_id is not provided, the system will generate an ID automatically.

            Example: > "{"title":"Q1 Report.pdf","author":"Alice Smith","file_id":"custom_file_123"}"


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.update_text(source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', content='<content>', )
        asyncio.run(main())
        """
        _response = await self._raw_client.update_text(
            source_id=source_id,
            tenant_id=tenant_id,
            content=content,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            tenant_metadata=tenant_metadata,
            document_metadata=document_metadata,
            request_options=request_options,
        )
        return _response.data

    async def batch_upload_markdown(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[MarkdownUploadRequest],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Upload multiple markdown/text documents simultaneously for efficient bulk processing.

        This endpoint allows you to upload several markdown or text contents at once. Each content item gets processed asynchronously, and you can track the progress using their returned file IDs.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[MarkdownUploadRequest]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI, MarkdownUploadRequest

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.batch_upload_markdown(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[MarkdownUploadRequest(content='<content>', )], )
        asyncio.run(main())
        """
        _response = await self._raw_client.batch_upload_markdown(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def batch_upload_text(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[MarkdownUploadRequest],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Upload multiple markdown/text documents simultaneously for efficient bulk processing.

        This endpoint allows you to upload several markdown or text contents at once. Each content item gets processed asynchronously, and you can track the progress using their returned file IDs.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[MarkdownUploadRequest]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI, MarkdownUploadRequest

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.batch_upload_text(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[MarkdownUploadRequest(content='<content>', )], )
        asyncio.run(main())
        """
        _response = await self._raw_client.batch_upload_text(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def upload_embeddings(
        self,
        *,
        tenant_id: str,
        embeddings: typing.Sequence[typing.Sequence[float]],
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Upload pre-computed embeddings for advanced similarity search.

        This endpoint accepts vector embeddings that you've generated externally, allowing you to integrate with custom embedding models or existing vector databases. The embeddings represent chunks of your content as numerical vectors.

        The system stores these embeddings and makes them available for semantic search and similarity matching. Use this when you want to leverage specialized embedding models or have existing vector representations.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        embeddings : typing.Sequence[typing.Sequence[float]]
            The embeddings of source you want to index

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            The Source ID of the target source you want to index

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.upload_embeddings(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', embeddings=[[0.123413, 0.655367, 0.987654, 0.123456, 0.789012], [0.123413, 0.655367, 0.987654, 0.123456, 0.789012]], )
        asyncio.run(main())
        """
        _response = await self._raw_client.upload_embeddings(
            tenant_id=tenant_id,
            embeddings=embeddings,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            request_options=request_options,
        )
        return _response.data

    async def update_embeddings(
        self,
        *,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        embeddings: typing.Optional[typing.Dict[str, typing.Sequence[float]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update existing embeddings with new vector representations.

        This endpoint allows you to modify embeddings that are already stored in your knowledge base. Provide updated vector representations for specific chunks of content, identified by their chunk IDs.

        The system will replace the existing embeddings with your new ones, ensuring that similarity searches reflect the most current vector representations. Use this when you need to update embeddings due to model improvements or content changes.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        embeddings : typing.Optional[typing.Dict[str, typing.Sequence[float]]]
            The embeddings of source you want to index

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.update_embeddings(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.update_embeddings(
            tenant_id=tenant_id, sub_tenant_id=sub_tenant_id, embeddings=embeddings, request_options=request_options
        )
        return _response.data

    async def scrape_webpage(
        self,
        *,
        web_url: str,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Extract and index content from web pages automatically.

        This endpoint initiates web scraping for the specified URL, extracting the main content, text, and structure from the webpage. It's perfect for capturing articles, documentation, or any web content you want to include in your knowledge base.

        The system processes the webpage content asynchronously, cleaning and structuring the information for optimal search and retrieval. Use this when you need to add web content without manual copying and pasting.

        Parameters
        ----------
        web_url : str
            The URL of the webpage to scrape and index

        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        file_id : typing.Optional[str]
            Optional custom file ID for the scraped content. If not provided, a unique ID will be generated

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.scrape_webpage(web_url='https://www.usecortex.ai/', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', file_id='CortexDoc1234', )
        asyncio.run(main())
        """
        _response = await self._raw_client.scrape_webpage(
            web_url=web_url,
            tenant_id=tenant_id,
            sub_tenant_id=sub_tenant_id,
            file_id=file_id,
            request_options=request_options,
        )
        return _response.data

    async def update_webpage(
        self,
        *,
        web_url: str,
        source_id: str,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SingleUploadData:
        """
        Update web scraping content with fresh data from the source URL.

        This endpoint refreshes the content for an existing web scraping job. Provide the source ID of the webpage content you want to update, and the system will re-scrape the URL to capture any changes.

        The updated content gets processed asynchronously and re-indexed in your knowledge base. Use this to keep web content current when the source pages are frequently updated.

        Parameters
        ----------
        web_url : str
            The URL of the webpage to re-scrape

        source_id : str
            The file ID of the existing web scraping job to update

        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SingleUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.update_webpage(web_url='https://www.usecortex.ai/', source_id='CortexDoc1234', tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.update_webpage(
            web_url=web_url,
            source_id=source_id,
            tenant_id=tenant_id,
            sub_tenant_id=sub_tenant_id,
            request_options=request_options,
        )
        return _response.data

    async def batch_scrape_webpage(
        self,
        *,
        tenant_id: str,
        request: typing.Sequence[WebpageScrapeRequest],
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchUploadData:
        """
        Extract and index content from multiple web pages simultaneously.

        This endpoint initiates web scraping for multiple URLs at once, extracting the main content, text, and structure from each webpage. It's perfect for capturing multiple articles, documentation pages, or any web content you want to include in your knowledge base.

        The system processes all webpage content asynchronously, cleaning and structuring the information for optimal search and retrieval.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        request : typing.Sequence[WebpageScrapeRequest]

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchUploadData
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI, WebpageScrapeRequest

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.batch_scrape_webpage(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', request=[WebpageScrapeRequest(web_url='https://www.usecortex.ai/', )], )
        asyncio.run(main())
        """
        _response = await self._raw_client.batch_scrape_webpage(
            tenant_id=tenant_id, request=request, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def delete_source(
        self,
        *,
        tenant_id: str,
        source_ids: typing.Sequence[str],
        sub_tenant_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Remove documents and content from your knowledge base.

        This endpoint permanently deletes the specified sources from your knowledge base. Once deleted, the content will no longer be available for search or retrieval.

        Use this carefully as the action cannot be undone. The system will confirm successful deletion of each source ID you specify.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        source_ids : typing.Sequence[str]
            List of source IDs to delete

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.delete_source(tenant_id='tenant_1234', source_ids=['CortexDoc1234', 'CortexDoc4567'], )
        asyncio.run(main())
        """
        _response = await self._raw_client.delete_source(
            tenant_id=tenant_id, source_ids=source_ids, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def delete_memory(
        self,
        *,
        tenant_id: str,
        source_ids: typing.Sequence[str],
        sub_tenant_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[typing.Any]:
        """
        Remove documents and content from your knowledge base.

        This endpoint permanently deletes the specified sources from your knowledge base. Once deleted, the content will no longer be available for search or retrieval.

        Use this carefully as the action cannot be undone. The system will confirm successful deletion of each source ID you specify.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        source_ids : typing.Sequence[str]
            List of source IDs to delete

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.delete_memory(tenant_id='tenant_1234', source_ids=['CortexDoc1234', 'CortexDoc4567'], )
        asyncio.run(main())
        """
        _response = await self._raw_client.delete_memory(
            tenant_id=tenant_id, source_ids=source_ids, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def verify_processing(
        self,
        *,
        file_id: str,
        tenant_id: typing.Optional[str] = None,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ProcessingStatus:
        """
        Check the current processing status of your uploaded content.

        This endpoint allows you to monitor the progress of documents, text, or other content you've uploaded. Simply provide the file ID to see whether processing is complete, still in progress, or if any errors occurred.

        Use this to determine when your content is ready for search and retrieval, or to troubleshoot any processing issues.

        Parameters
        ----------
        file_id : str
            The file ID to check processing status for

        tenant_id : typing.Optional[str]
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ProcessingStatus
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.upload.verify_processing(file_id='CortexDoc1234', tenant_id='tenant_1234', )
        asyncio.run(main())
        """
        _response = await self._raw_client.verify_processing(
            file_id=file_id, tenant_id=tenant_id, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data
