# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.add_user_memory_response import AddUserMemoryResponse
from ..types.delete_user_memory_response import DeleteUserMemoryResponse
from ..types.list_user_memories_response import ListUserMemoriesResponse
from ..types.retrieve_user_memory_response import RetrieveUserMemoryResponse
from ..types.user_assistant_pair import UserAssistantPair
from .raw_client import AsyncRawUserMemoryClient, RawUserMemoryClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class UserMemoryClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawUserMemoryClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawUserMemoryClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawUserMemoryClient
        """
        return self._raw_client

    def list_user_memories(
        self,
        *,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListUserMemoriesResponse:
        """
        Retrieve all stored user memories for your tenant.

        This endpoint returns a comprehensive list of all user memories that have been stored,
        whether they were added manually or generated through AI. User memories help personalize
        your experience by storing context, preferences, and important information.

        You can optionally specify a sub-tenant to filter memories within that specific scope.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListUserMemoriesResponse
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.user_memory.list_user_memories(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.list_user_memories(
            tenant_id=tenant_id, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def delete_user_memory(
        self,
        *,
        tenant_id: str,
        memory_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DeleteUserMemoryResponse:
        """
        Permanently remove a specific user memory from storage.

        This endpoint allows you to delete a user memory by its unique identifier.
        Once deleted, the memory cannot be recovered, so use this operation carefully.

        The memory will be removed from your tenant's storage and will no longer
        appear in search results or memory listings.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        memory_id : str
            Unique identifier of the memory to delete

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DeleteUserMemoryResponse
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.user_memory.delete_user_memory(tenant_id='tenant_1234', memory_id='memory_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.delete_user_memory(
            tenant_id=tenant_id, memory_id=memory_id, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    def retrieve_user_memory(
        self,
        *,
        tenant_id: str,
        query: str,
        sub_tenant_id: typing.Optional[str] = None,
        max_count: typing.Optional[int] = None,
        user_name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RetrieveUserMemoryResponse:
        """
        Find relevant user memories using semantic search and knowledge graph.

        This endpoint performs parallel searches:
        1. Semantic search in Weaviate across all stored user memories
        2. Entity-based search in the knowledge graph for memory entities

        Results from both sources are combined and ranked by relevance to provide
        comprehensive memory retrieval.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        query : str
            Search query to find relevant user memories

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        max_count : typing.Optional[int]
            Maximum number of memories to return (default: 5)

        user_name : typing.Optional[str]
            User's name to enhance personalisation

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RetrieveUserMemoryResponse
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.user_memory.retrieve_user_memory(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', max_count=5, query='Which mode does user prefer', )
        """
        _response = self._raw_client.retrieve_user_memory(
            tenant_id=tenant_id,
            query=query,
            sub_tenant_id=sub_tenant_id,
            max_count=max_count,
            user_name=user_name,
            request_options=request_options,
        )
        return _response.data

    def add_user_memory(
        self,
        *,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        raw_text: typing.Optional[str] = OMIT,
        user_assistant_pairs: typing.Optional[typing.Sequence[UserAssistantPair]] = OMIT,
        expiry_time: typing.Optional[int] = OMIT,
        infer: typing.Optional[bool] = OMIT,
        custom_instructions: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AddUserMemoryResponse:
        """
        Store new user memories for future reference.

        This endpoint allows you to add memories in two formats:
        1. Raw text string - A single text-based memory
        2. User/Assistant pairs array - Conversation pairs that will be chunked as a single memory

        The stored memories will be chunked, indexed in both Weaviate and the knowledge graph,
        and made available for semantic search and graph-based retrieval.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        raw_text : typing.Optional[str]
            Single raw text memory to store

        user_assistant_pairs : typing.Optional[typing.Sequence[UserAssistantPair]]
            Array of user/assistant conversation pairs to store as a single memory

        expiry_time : typing.Optional[int]
            Expiry time in seconds for the memory (optional)

        infer : typing.Optional[bool]
            If true, process and compress chunks into inferred representations before indexing (default: False)

        custom_instructions : typing.Optional[str]
            Custom instructions to guide cortex

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AddUserMemoryResponse
            Successful Response

        Examples
        --------
        from usecortex-ai import CortexAI

        client = CortexAI(token="YOUR_TOKEN", )
        client.user_memory.add_user_memory(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        """
        _response = self._raw_client.add_user_memory(
            tenant_id=tenant_id,
            sub_tenant_id=sub_tenant_id,
            raw_text=raw_text,
            user_assistant_pairs=user_assistant_pairs,
            expiry_time=expiry_time,
            infer=infer,
            custom_instructions=custom_instructions,
            request_options=request_options,
        )
        return _response.data


class AsyncUserMemoryClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawUserMemoryClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawUserMemoryClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawUserMemoryClient
        """
        return self._raw_client

    async def list_user_memories(
        self,
        *,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListUserMemoriesResponse:
        """
        Retrieve all stored user memories for your tenant.

        This endpoint returns a comprehensive list of all user memories that have been stored,
        whether they were added manually or generated through AI. User memories help personalize
        your experience by storing context, preferences, and important information.

        You can optionally specify a sub-tenant to filter memories within that specific scope.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListUserMemoriesResponse
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.user_memory.list_user_memories(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.list_user_memories(
            tenant_id=tenant_id, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def delete_user_memory(
        self,
        *,
        tenant_id: str,
        memory_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DeleteUserMemoryResponse:
        """
        Permanently remove a specific user memory from storage.

        This endpoint allows you to delete a user memory by its unique identifier.
        Once deleted, the memory cannot be recovered, so use this operation carefully.

        The memory will be removed from your tenant's storage and will no longer
        appear in search results or memory listings.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        memory_id : str
            Unique identifier of the memory to delete

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DeleteUserMemoryResponse
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.user_memory.delete_user_memory(tenant_id='tenant_1234', memory_id='memory_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.delete_user_memory(
            tenant_id=tenant_id, memory_id=memory_id, sub_tenant_id=sub_tenant_id, request_options=request_options
        )
        return _response.data

    async def retrieve_user_memory(
        self,
        *,
        tenant_id: str,
        query: str,
        sub_tenant_id: typing.Optional[str] = None,
        max_count: typing.Optional[int] = None,
        user_name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> RetrieveUserMemoryResponse:
        """
        Find relevant user memories using semantic search and knowledge graph.

        This endpoint performs parallel searches:
        1. Semantic search in Weaviate across all stored user memories
        2. Entity-based search in the knowledge graph for memory entities

        Results from both sources are combined and ranked by relevance to provide
        comprehensive memory retrieval.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        query : str
            Search query to find relevant user memories

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        max_count : typing.Optional[int]
            Maximum number of memories to return (default: 5)

        user_name : typing.Optional[str]
            User's name to enhance personalisation

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        RetrieveUserMemoryResponse
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.user_memory.retrieve_user_memory(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', max_count=5, query='Which mode does user prefer', )
        asyncio.run(main())
        """
        _response = await self._raw_client.retrieve_user_memory(
            tenant_id=tenant_id,
            query=query,
            sub_tenant_id=sub_tenant_id,
            max_count=max_count,
            user_name=user_name,
            request_options=request_options,
        )
        return _response.data

    async def add_user_memory(
        self,
        *,
        tenant_id: str,
        sub_tenant_id: typing.Optional[str] = None,
        raw_text: typing.Optional[str] = OMIT,
        user_assistant_pairs: typing.Optional[typing.Sequence[UserAssistantPair]] = OMIT,
        expiry_time: typing.Optional[int] = OMIT,
        infer: typing.Optional[bool] = OMIT,
        custom_instructions: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AddUserMemoryResponse:
        """
        Store new user memories for future reference.

        This endpoint allows you to add memories in two formats:
        1. Raw text string - A single text-based memory
        2. User/Assistant pairs array - Conversation pairs that will be chunked as a single memory

        The stored memories will be chunked, indexed in both Weaviate and the knowledge graph,
        and made available for semantic search and graph-based retrieval.

        Parameters
        ----------
        tenant_id : str
            Unique identifier for the tenant/organization

        sub_tenant_id : typing.Optional[str]
            Optional sub-tenant identifier used to organize data within a tenant. If omitted, the default sub-tenant created during tenant setup will be used.

        raw_text : typing.Optional[str]
            Single raw text memory to store

        user_assistant_pairs : typing.Optional[typing.Sequence[UserAssistantPair]]
            Array of user/assistant conversation pairs to store as a single memory

        expiry_time : typing.Optional[int]
            Expiry time in seconds for the memory (optional)

        infer : typing.Optional[bool]
            If true, process and compress chunks into inferred representations before indexing (default: False)

        custom_instructions : typing.Optional[str]
            Custom instructions to guide cortex

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AddUserMemoryResponse
            Successful Response

        Examples
        --------
        import asyncio

        from usecortex-ai import AsyncCortexAI

        client = AsyncCortexAI(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.user_memory.add_user_memory(tenant_id='tenant_1234', sub_tenant_id='sub_tenant_4567', )
        asyncio.run(main())
        """
        _response = await self._raw_client.add_user_memory(
            tenant_id=tenant_id,
            sub_tenant_id=sub_tenant_id,
            raw_text=raw_text,
            user_assistant_pairs=user_assistant_pairs,
            expiry_time=expiry_time,
            infer=infer,
            custom_instructions=custom_instructions,
            request_options=request_options,
        )
        return _response.data
