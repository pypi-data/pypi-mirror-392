# Web Scraping Configuration
# Settings for scraping web pages

# User agent string
user_agent: "STIndex-Research/1.0 (https://github.com/yourusername/stindex)"

# Rate limiting
rate_limit: 2.0                # Seconds between requests
max_retries: 3                 # Maximum retry attempts
retry_delay: 1.0               # Delay between retries (seconds)

# Request settings
timeout: 30                    # Request timeout in seconds
max_redirects: 5               # Maximum number of redirects to follow
verify_ssl: true               # Verify SSL certificates

# Headers
headers:
  Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
  Accept-Language: "en-US,en;q=0.9"
  Accept-Encoding: "gzip, deflate, br"
  DNT: "1"                     # Do Not Track

# Content filtering
content:
  max_page_size_mb: 10         # Maximum page size to download
  allowed_content_types:       # Allowed content types
    - "text/html"
    - "text/plain"
    - "application/pdf"
    - "application/xml"

# JavaScript rendering (requires selenium/playwright - future feature)
javascript:
  enabled: false               # Enable JavaScript rendering
  wait_time: 2                 # Wait time after page load (seconds)
  headless: true               # Run browser in headless mode

# Caching
cache:
  enabled: true                # Enable response caching
  cache_dir: ".stindex/cache/scraping"
  ttl_hours: 24                # Cache time-to-live in hours

# Robots.txt compliance
robots:
  respect_robots_txt: true     # Respect robots.txt rules
  user_agent_for_robots: "STIndex-Research"

# Error handling
error_handling:
  skip_on_error: true          # Skip failed pages instead of crashing
  log_errors: true             # Log scraping errors
  save_error_pages: false      # Save HTML of error pages for debugging
