# OntologySyncService - Guia de ImplementaÃ§Ã£o
  
  **Data**: 2025-10-02  
  **Status**: âœ… **IMPLEMENTADO**
  
  ---
  
  > AtualizaÃ§Ã£o (2025-10-04)
  >
  > - Runner oficial: `scripts/main_sync.py` (o `sync.py` da raiz estÃ¡ depreciado e apenas encaminha para o runner novo).
  > - Carga de relaÃ§Ãµes: âœ… Implementada com suporte a `backing_dataset_rid` e mapeamentos (`fromPropertyMapping`, `toPropertyMapping`, `propertyMappings`). HÃ¡ caminho otimizado via `COPY` quando `SYNC_ENABLE_COPY_RELS=1`.
  > - VariÃ¡veis de ambiente Ãºteis: `KUZU_DB_PATH`, `DUCKDB_PATH`, `SYNC_ENABLE_COPY_RELS`, `SYNC_SETUP`.

  ## ğŸ¯ **O Que Ã‰ o OntologySyncService?**

  O **OntologySyncService** Ã© o motor ETL que materializa nosso grafo de conhecimento. Ele conecta trÃªs "planos":

  ```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   PLANO DE CONTROLE                 â”‚
  â”‚   (Metadados - SQLModel)            â”‚
  â”‚   - ObjectType                      â”‚
  â”‚   - LinkType                        â”‚
  â”‚   - Dataset                         â”‚
  â”‚   - ObjectTypeDataSource            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“ (lÃª metadados)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   ONTOLOGY SYNC SERVICE             â”‚
  â”‚   (Motor ETL)                       â”‚
  â”‚   - Extrai                          â”‚
  â”‚   - Transforma                      â”‚
  â”‚   - Carrega                         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“ (extrai dados)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   PLANO DE DADOS BRUTOS             â”‚
  â”‚   (DuckDB / Parquet)                â”‚
  â”‚   - Tabelas                          â”‚
  â”‚   - Arquivos                         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“ (carrega grafo)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   PLANO SEMÃ‚NTICO                   â”‚
  â”‚   (KÃ¹zuDB - Grafo)                  â”‚
  â”‚   - NÃ³s (ObjectType instances)      â”‚
  â”‚   - Arestas (LinkType instances)    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ```

---

## ğŸ—ï¸ **Arquitetura**

### **Analogia: Chef de Cozinha**

- **Plano de Controle** = Livro de Receitas  
  - `ObjectType` = Receita do "Bolo de Chocolate"
  
- **Plano de Dados Brutos** = Ingredientes na Despensa  
  - Farinha, ovos, aÃ§Ãºcar (dados brutos)
  
- **OntologySyncService** = Chef  
  - LÃª a receita
  - Pega os ingredientes
  - Mistura e assa
  
- **Plano SemÃ¢ntico** = Bolo Pronto  
  - Pronto para servir (consultar)

---

## ğŸ“Š **Fluxo de SincronizaÃ§Ã£o**

### **MÃ©todo Principal: `sync_ontology()`**

```python
service = OntologySyncService(
    metadata_session=session,
    kuzu_conn=kuzu_conn,
    duckdb_conn=duckdb_conn
)

metrics = service.sync_ontology(duckdb_path='analytics.duckdb')
```

### **Passos Executados**

#### **1. ConstruÃ§Ã£o do Esquema (_build_graph_schema)**
```
Para cada ObjectType:
  â”œâ”€ LÃª propriedades (PropertyType)
  â”œâ”€ Mapeia tipos de dados â†’ KÃ¹zuDB
  â””â”€ Executa: CREATE NODE TABLE customer (id STRING, name STRING, PRIMARY KEY (id))

Para cada LinkType:
  â”œâ”€ Identifica from_object_type e to_object_type
  â””â”€ Executa: CREATE REL TABLE placesOrder (FROM customer TO order)
```

#### **2. AnexaÃ§Ã£o do DuckDB (_attach_duckdb)**
```
Executa: ATTACH 'analytics.duckdb' AS duckdb (dbtype 'duckdb')
Permite: COPY direto do DuckDB â†’ KÃ¹zuDB
```

#### **3. Carga dos NÃ³s (_load_nodes_into_graph)**
```
Para cada ObjectType:
  â”œâ”€ Encontra ObjectTypeDataSource links
  â”œâ”€ Para cada Dataset:
  â”‚   â”œâ”€ LÃª dados (Polars)
  â”‚   â”‚   â”œâ”€ source_type = 'duckdb_table' â†’ pl.read_database()
  â”‚   â”‚   â””â”€ source_type = 'parquet_file' â†’ pl.read_parquet()
  â”‚   â”œâ”€ Aplica property_mappings (renomeia colunas)
  â”‚   â””â”€ Adiciona ao pool de uniÃ£o
  â”œâ”€ Une (UNION) todos os DataFrames
  â”œâ”€ Remove duplicatas (pela primary_key)
  â””â”€ Carrega em lote: kuzu_conn.load_from_polars(df, 'customer')
```

#### **4. Carga das RelaÃ§Ãµes (_load_rels_into_graph)**
```
Para cada LinkType:
  â”œâ”€ Encontra backing_dataset (dataset de junÃ§Ã£o)
  â”œâ”€ Usa from_property_mapping e to_property_mapping
  â””â”€ Executa: COPY placesOrder FROM duckdb.customer_orders (FROM customer_id TO order_id)
```

---

## ğŸ’¡ **Recursos Implementados**

### **1. SyncMetrics - Monitoramento**
```python
metrics = service.sync_ontology()

print(metrics.summary())
# ============================================================
# SYNC METRICS SUMMARY
# ============================================================
# Duration: 2.45s
# Nodes Created: 150
#   - customer: 100
#   - order: 50
# Relations Created: 75
#   - placesOrder: 75
# Warnings: 0
# Errors: 0
# ============================================================
```

### **2. Mapeamento de Tipos**
```python
type_mapping = {
    'string': 'STRING',
    'integer': 'INT64',
    'double': 'DOUBLE',
    'boolean': 'BOOL',
    'date': 'DATE',
    'timestamp': 'TIMESTAMP',
}
```

### **3. MÃºltiplas Fontes (Federation)**
```python
# ObjectType pode ter mÃºltiplos Datasets
customer.data_sources â†’ [
    Dataset('customer_main.parquet'),
    Dataset('customer_updates.parquet'),
    Dataset('customer_legacy_table')
]

# ServiÃ§o une todos automaticamente
# e remove duplicatas pela primary_key
```

### **4. Tratamento de Erros**
- Erros individuais nÃ£o param o processo completo
- Cada erro Ã© registrado em `metrics.errors`
- Warnings para fontes nÃ£o processÃ¡veis

---

## ğŸš€ **Como Usar**

### **InstalaÃ§Ã£o de DependÃªncias**
```bash
# DependÃªncias principais (jÃ¡ instaladas)
pip install sqlmodel pydantic registro

# DependÃªncias do sync service (opcionais)
pip install kuzu duckdb polars
```

### **Exemplo Completo (scripts/main_sync.py)**
```python
from ontologia.application import OntologySyncService
import kuzu
import duckdb
from sqlmodel import Session

# 1. Setup dos bancos
metadata_engine = create_engine("sqlite:///metadata.db")
duckdb_conn = duckdb.connect('analytics.duckdb')
kuzu_conn = kuzu.Connection(kuzu.Database('graph_db'))

# 2. Popular Plano de Controle
with Session(metadata_engine) as session:
    setup_control_plane(session)  # Criar ObjectTypes, Datasets, etc.

# 3. Criar dados brutos no DuckDB
create_sample_data(duckdb_conn)

# 4. Sincronizar!
with Session(metadata_engine) as session:
    service = OntologySyncService(session, kuzu_conn, duckdb_conn)
    metrics = service.sync_ontology(duckdb_path='analytics.duckdb')

# 5. Consultar o grafo
result = kuzu_conn.execute("MATCH (c:customer) RETURN c.name, c.age;")
print(result.get_as_df())
```

### **Executar o Exemplo**
```bash
# Executar o runner oficial
python scripts/main_sync.py

# SaÃ­da esperada:
# ============================================================
# ONTOLOGY SYNC SERVICE - EXEMPLO COMPLETO
# ============================================================
# ğŸ“¦ Inicializando banco de metadados...
# âœ… Banco de metadados criado
# ğŸ“‹ Populando Plano de Controle...
# ...
# âœ… EXEMPLO COMPLETO EXECUTADO COM SUCESSO!
```

---

## ğŸ“ **Arquivos Criados**

### **CÃ³digo Principal**
- âœ… `ontologia/application/sync_service.py` - OntologySyncService
- âœ… `ontologia/application/__init__.py` - Exports

  ### **Exemplos**
  - âœ… `sync.py` - Exemplo end-to-end completo

  ### **Testes**
  - âœ… `test_sync_service.py` - Testes unitÃ¡rios

### **DocumentaÃ§Ã£o**
- âœ… `SYNC_SERVICE_GUIDE.md` - Este guia

---
{{ ... }}

## ğŸ§ª **Testes**

### **Rodar Testes UnitÃ¡rios**
```bash
pytest test_sync_service.py -v
```

### **Testes IncluÃ­dos**
- âœ… `test_sync_metrics` - Tracking de mÃ©tricas
- âœ… `test_sync_service_imports` - Imports funcionando
- âœ… `test_sync_service_initialization` - InicializaÃ§Ã£o
- âœ… `test_control_plane_setup` - Setup do plano de controle
- âœ… `test_type_mapping` - Mapeamento de tipos

---

## ğŸ¯ **Recursos AvanÃ§ados (Futuro)**

### **1. Incremental Sync**
```python
# Usar TransactionType para determinar estratÃ©gia
if transaction.transaction_type == TransactionType.SNAPSHOT:
    # Substituir todos os dados
    truncate_and_load()
elif transaction.transaction_type == TransactionType.APPEND:
    # Apenas adicionar novos
    append_only()
```

### **2. Propriedades em Relacionamentos**
```python
# LinkType com propriedades
CREATE REL TABLE placesOrder (
    FROM customer TO order,
    order_date TIMESTAMP,
    status STRING
)
```

### **3. Scheduling & AutomaÃ§Ã£o**
```python
# Agendar sync periÃ³dico
import schedule

def sync_job():
    with Session(engine) as session:
        service = OntologySyncService(session, kuzu_conn, duckdb_conn)
        service.sync_ontology()

schedule.every().hour.do(sync_job)
```

### **4. Delta Detection**
```python
# Detectar apenas mudanÃ§as desde Ãºltima sync
def sync_delta(since: datetime):
    # Ler apenas registros modificados apÃ³s 'since'
    # Aplicar apenas essas mudanÃ§as no grafo
    pass
```

---

## ğŸ“Š **Exemplos de Queries no Grafo**

### **Query 1: Todos os Clientes**
```cypher
MATCH (c:customer)
RETURN c.customer_id, c.name, c.email
ORDER BY c.name;
```

### **Query 2: Pedidos por Cliente**
```cypher
MATCH (c:customer)-[:placesOrder]->(o:order)
RETURN c.name, COUNT(o) as order_count, SUM(o.total) as total_spent
ORDER BY total_spent DESC;
```

### **Query 3: Clientes sem Pedidos**
```cypher
MATCH (c:customer)
WHERE NOT EXISTS {
    MATCH (c)-[:placesOrder]->()
}
RETURN c.name, c.email;
```

### **Query 4: Pedidos Recentes**
```cypher
MATCH (c:customer)-[:placesOrder]->(o:order)
WHERE o.order_date > timestamp('2024-01-25')
RETURN c.name, o.order_id, o.total, o.order_date
ORDER BY o.order_date DESC;
```

---

## ğŸ”§ **ConfiguraÃ§Ã£o Recomendada**

### **Estrutura de Projeto**
```
 /ontologia/
 â”œâ”€â”€ metadata.db           # Plano de Controle (SQLite)
 â”œâ”€â”€ analytics.duckdb      # Plano de Dados Brutos (DuckDB)
 â”œâ”€â”€ graph_db/             # Plano SemÃ¢ntico (KÃ¹zuDB)
 â”‚
 â”œâ”€â”€ scripts/
 â”‚   â””â”€â”€ main_sync.py      # Runner oficial de sincronizaÃ§Ã£o
 â”‚
 â”œâ”€â”€ ontologia/
 â”‚   â”œâ”€â”€ application/
 â”‚   â”‚   â”œâ”€â”€ __init__.py
 â”‚   â”‚   â””â”€â”€ sync_service.py  # â† ServiÃ§o
 â”‚   â”‚
 â”‚   â””â”€â”€ domain/
 â”‚       â””â”€â”€ metamodels/
 â”‚           â””â”€â”€ instances/
 â”‚               â””â”€â”€ dtos.py  # DTOs de instÃ¢ncia (Pydantic)
 â”‚
 â””â”€â”€ datacatalog/
     â””â”€â”€ models.py
```

### **Workflow Recomendado**
```
1. Design â†’ Criar ObjectTypes, LinkTypes (main_with_datacatalog.py)
2. Data â†’ Criar/popular Datasets no DuckDB
3. Link â†’ Criar ObjectTypeDataSource (conectar ObjectType â†’ Dataset)
4. Sync â†’ Executar OntologySyncService
5. Query â†’ Consultar grafo no KÃ¹zuDB
6. Iterate â†’ Refinar modelo e repetir
```

---

## âš ï¸ **LimitaÃ§Ãµes Atuais**

### **1. LinkType Relations**
- Carga de relaÃ§Ãµes requer `backing_dataset_rid` em LinkType
- Ainda nÃ£o implementado (TODO)
- Workaround: criar relaÃ§Ãµes manualmente via Cypher

### **2. Source Types**
- Suportados: `duckdb_table`, `parquet_file`
- NÃ£o suportados ainda: `postgres`, `mysql`, `csv`

### **3. Schema Evolution**
- MudanÃ§as no schema do ObjectType nÃ£o sÃ£o detectadas automaticamente
- Requer drop/recreate do grafo

### **4. TransaÃ§Ãµes**
- NÃ£o hÃ¡ suporte transacional (all-or-nothing)
- Erros em parte dos dados nÃ£o revertem o resto

---

## ğŸ“ˆ **MÃ©tricas de Performance**

### **Benchmarks (estimados)**

| OperaÃ§Ã£o | Tamanho | Tempo | Throughput |
|----------|---------|-------|------------|
| CREATE NODE TABLE | 1 tabela | ~10ms | - |
| LOAD NODES | 10K rows | ~500ms | 20K rows/s |
| LOAD NODES | 100K rows | ~3s | 33K rows/s |
| LOAD NODES | 1M rows | ~25s | 40K rows/s |

---

## âœ… **Status de ImplementaÃ§Ã£o**

| Funcionalidade | Status | Detalhes |
|----------------|--------|----------|
| **Schema Building** | âœ… COMPLETO | NODE TABLE, REL TABLE |
| **DuckDB Attach** | âœ… COMPLETO | AnexaÃ§Ã£o automÃ¡tica |
| **Node Loading** | âœ… COMPLETO | Union, dedup, bulk load |
| **Relation Loading** | âœ… COMPLETO | COPY via DuckDB opcional; fallback suportado |
| **Metrics** | âœ… COMPLETO | Tracking completo |
| **Error Handling** | âœ… COMPLETO | Graceful degradation |
| **Type Mapping** | âœ… COMPLETO | Todos tipos bÃ¡sicos |
| **Multiple Sources** | âœ… COMPLETO | Federation funcional |
| **Parquet Support** | âœ… COMPLETO | Via Polars |
| **DuckDB Support** | âœ… COMPLETO | Via Polars |

---

## ğŸ§­ **Modo de Grafo Unificado (padrÃ£o obrigatÃ³rio)**

O projeto usa um modelo de grafo unificado obrigatÃ³rio, onde todas as instÃ¢ncias sÃ£o armazenadas em uma Ãºnica `NODE TABLE Object`. Esse modo elimina `UNION` em consultas de Interface e utiliza mÃºltiplos rÃ³tulos (labels) por nÃ³.

### O que muda

- **Schema (KÃ¹zuDB) â€“ criado pelo SyncService:**
  - `Object(rid STRING PRIMARY KEY, objectTypeApiName STRING, pkValue STRING, labels STRING[], properties STRING)`
  - RelaÃ§Ãµes: `CREATE REL TABLE <LinkTypeApiName> (FROM Object TO Object)`
- **Identificador estÃ¡vel (`rid`):** `"{service}:{instance}:{objectTypeApiName}:{pk}"`
- **Propriedades:** armazenadas como JSON em `properties`.
- **Labels:** incluem o ObjectType concreto e as Interfaces implementadas.

### Leitura (API / RepositÃ³rios)

- `GraphInstancesRepository` usa `MATCH (o:Object)` e filtra por `objectTypeApiName`, `pkValue` e `labels`.
- `list_by_interface()` filtra via `'<interface>' IN o.labels` (sem `UNION`).
- `get_linked_objects()` faz traversal `Object â†’ Object` pelas `REL TABLEs` dos `LinkTypes`.
- `AnalyticsService` (quando disponÃ­vel grafo): lista do `Object` e agrega em memÃ³ria a partir de `properties` (JSON). MantÃ©m path legado quando flag desativada.

### Como garantir

1. Verifique `ontologia.toml` (valor padrÃ£o jÃ¡ Ã© `true`):

   ```toml
   [features]
   use_unified_graph = true
   ```

2. (Opcional) exporte `KUZU_DB_PATH` para apontar para o diretÃ³rio desejado.

> ObservaÃ§Ã£o: tentativas de desabilitar com `USE_UNIFIED_GRAPH=0` sÃ£o ignoradas; o `OntologySyncService._build_graph_schema()` Ã© sempre a fonte da verdade.

### MigraÃ§Ã£o / Reset

1. Pare a API e garanta que nenhum processo esteja usando o KÃ¹zu.
2. Limpe (ou aponte para outro diretÃ³rio) o DB do KÃ¹zu. VocÃª pode usar o comando

```bash
ontologia graph reset --yes
```

   ou remover manualmente o diretÃ³rio: `rm -rf ${KUZU_DB_PATH:-instance_graph.kuzu}`.

3. Certifique-se de que `use_unified_graph` permaneÃ§a `true` no manifest (o padrÃ£o) e, se necessÃ¡rio, defina `KUZU_DB_PATH`.
4. Execute o `OntologySyncService` novamente para reconstruir o schema unificado e recarregar nÃ³s e relaÃ§Ãµes.
5. Valide consultas de Interface (sem `UNION`) e traversal `Objectâ†’Object` pelas rotas v2.

### Compatibilidade

- O grafo unificado Ã© o Ãºnico modo suportado. Caso o KÃ¹zu nÃ£o esteja disponÃ­vel, os repositÃ³rios retornam ao SQLModel.

---

## ğŸš€ **PrÃ³ximos Passos**

### **Para a Equipe de Desenvolvimento**

1. **Implementar Backing Dataset em LinkType**
   - Adicionar `backing_dataset_rid` campo
   - Adicionar `from_property_mapping`, `to_property_mapping`
   - Completar `_load_rels_into_graph()`

2. **Adicionar Mais Source Types**
   - PostgreSQL
   - MySQL
   - CSV files
   - REST APIs

3. **Implementar Incremental Sync**
   - Usar `TransactionType` (SNAPSHOT vs APPEND)
   - Delta detection
   - Upsert logic

4. **Schema Evolution**
   - Detectar mudanÃ§as no ObjectType
   - Migrar dados automaticamente
   - ALTER TABLE support

5. **TransaÃ§Ãµes & Rollback**
   - Atomic operations
   - Checkpoints
   - Recovery on failure

---

## ğŸ“š **ReferÃªncias**

- **KÃ¹zuDB Docs**: https://kuzudb.com/docs
- **DuckDB Docs**: https://duckdb.org/docs
- **Polars Docs**: https://pola-rs.github.io/polars/
- **Palantir Foundry**: InspiraÃ§Ã£o para o padrÃ£o Dataset/Transaction/Branch

---

## ğŸ‰ **ConclusÃ£o**

O **OntologySyncService** estÃ¡ **implementado e funcional**!

**O que funciona:**
- âœ… Leitura de metadados do Plano de Controle
- âœ… ConstruÃ§Ã£o automÃ¡tica do esquema do grafo
- âœ… ExtraÃ§Ã£o de dados do DuckDB/Parquet
- âœ… UniÃ£o de mÃºltiplas fontes (federation)
- âœ… RemoÃ§Ã£o de duplicatas
- âœ… Bulk load otimizado no KÃ¹zuDB
- âœ… Tracking completo de mÃ©tricas
- âœ… Error handling robusto

**Para usar:**
```bash
# 1. Instalar dependÃªncias
pip install kuzu duckdb polars

# 2. Executar exemplo
python sync.py

# 3. Consultar o grafo!
```

**A plataforma agora tem um motor ETL completo que materializa
o conhecimento do Plano de Controle em um grafo consultÃ¡vel!** ğŸš€

---

**Implementado por**: Sistema de IA  
**Data**: 2025-10-02  
**VersÃ£o**: 1.0.0
