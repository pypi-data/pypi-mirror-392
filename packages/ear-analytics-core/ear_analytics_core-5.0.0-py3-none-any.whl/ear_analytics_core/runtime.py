######################################################################
# Copyright (c) 2024 Energy Aware Solutions, S.L
#
# This program and the accompanying materials are made
# available under the terms of the Eclipse Public License 2.0
# which is available at https://www.eclipse.org/legal/epl-2.0/
#
# SPDX-License-Identifier: EPL-2.0
#######################################################################


"""Methods for generating static images"""
import re
import sys
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

from mpl_toolkits.axes_grid1 import ImageGrid

from . import io_api


def _start_end_index_1s(start, end, orig_index):
    """Returns an Index based on `orig_index`, starting at `start` and ending
        at `end`. Each entry is 1s from to its previous/next entry.
    """
    return (pd.date_range(start=pd.to_datetime(start, unit='s'),
                          end=pd.to_datetime(end, unit='s'), freq='1s')
            .union(orig_index))


def _build_gradient_norm(data_values, step, v_min=None, v_max=None):
    """Return a discretized normalization for `data_values`, maintaining a
        `step` between each interval.
    """
    bounds = np.arange(v_min if v_min is not None else np.nanmin(data_values),
                       v_max + step if v_max is not None
                       else np.nanmax(data_values) + step,
                       step)
    if bounds.size == 1:
        print(f'Warning: Requested data range is constant: {bounds}')
        bounds = np.array([bounds[0] - step, bounds[0], bounds[0] + step])
    elif bounds.size > 16 or bounds.size < 5:
        print(f'Warning! {bounds.size} discrete intervals generated.')

        if bounds.size > 16:
            print(f'Consider increasing the step (currently {step})')
        else:
            print(f'Consider decreasing the step (currently {step})')
    cmap = mpl.colormaps['viridis_r']
    return mpl.colors.BoundaryNorm(bounds, cmap.N, extend='both')


def _get_elapsed(index, tick_idx):
    """Returns the elapsed time since `index`'s' begining time
    based on `tick_idx`.
    """
    # Compute time deltas to be showed to
    # the end user instead of an absolute timestamp.
    time_deltas = [i - index[0] for i in index]
    return time_deltas[tick_idx].seconds


def _metric_timeseries_by_node(df, metric):
    """
    """
    columns = ['JOBID', 'STEPID', 'APPID', 'NODENAME']
    return (df
            .pivot_table(columns=columns, values=metric, index='TIMESTAMP')
            )


def runtime_metric_timeline_fig(df, df_app, metric, step, runtime_config,
                                **kwargs):
    """
    Generates the timeline gradient figure.
    - df: DataFrame with EAR loop signatures.
    - df_app: DataFrame with EAR application signatures.
    - metric: The EAR metric for which to generate the gradient.
    - step: The gradient is built on discretized values to help for
            interpreting results. The step specifies the gap between discrete
            values.
    kwargs:
        - v_min: Heatmap gradient lower bound. Default: None.
        - v_max: Heatmap gradient upper bound. Default: None.
        - fig_title: Resulting figure title. Default: ''.
        - metric_display_name: Specify how the metric name must be displayed.
            Default: ''.
        - gpu_metrics_re: A regex to find GPU columns.
        - start_time_colname: The name of column which has the start time.
        - end_time_colname: The name of the column which has the end time.

    Returns: A figure.
    """
    def reindex_application(df, start_time, end_time):
        """
        This function calls DataFrame.reindex on the passed df by passing the
        Index generated by calling _start_end_index_1s.
        """
        return df.reindex(_start_end_index_1s(start_time, end_time, df.index))

    def flat_df_columns(df):
        """
        This function converts df's columns MultiIndex to an Index of Tuples
        """
        df.columns = df.columns.to_flat_index()
        return df

    # Metric data is a pivot table indexed by TIMESTAMP, with a MultiIndex
    # columns with (metric, JOBID, STEPID, APPID, NODENAME).
    m_data = _metric_timeseries_by_node(df, df.filter(regex=metric).columns)

    # Convert index to datetime
    m_data.index = pd.to_datetime(m_data.index, unit='s')

    # Job start time column name
    st_colname = kwargs.get('start_time_colname', 'JOB_EARL_START_TIME')

    # Job end time column name
    et_colname = kwargs.get('end_time_colname', 'JOB_EARL_END_TIME')

    # Job DataFrame indexed by (JOBID, STEPID, APPID, NODENAME)
    job_data = (df_app
                .set_index(['JOBID', 'STEPID', 'APPID', 'NODENAME'])
                .loc[:, [st_colname, et_colname]]  # Start/end time
                .apply(pd.to_datetime, unit='s'))

    # Fill data between the start/end time of each job,step,app,node
    jobs = []
    for job_id, step_id, app_id, node in job_data.index:
        start_time = job_data.loc[(job_id, step_id, app_id, node),
                                  st_colname]
        end_time = job_data.loc[(job_id, step_id, app_id, node), et_colname]

        app_node_df = (m_data
                       .loc[:,
                            (slice(None), job_id, step_id, app_id, node)]
                       .pipe(reindex_application, start_time, end_time)
                       .bfill())
        jobs.append(app_node_df)

    m_data = pd.concat(jobs, axis=1).pipe(flat_df_columns)

    m_data_array = m_data.values.transpose()

    # Create the resulting figure for current metric
    print("Creating the figure...")

    fig = plt.figure()
    axs = ImageGrid(fig, 111, nrows_ncols=(len(m_data_array), 1), axes_pad=0,
                    label_mode='L', cbar_mode='single', cbar_location='bottom',
                    cbar_pad=0.5, cbar_size='20%')

    print(f'Setting title: {kwargs.get("fig_title", "")}')
    axs[0].set_title(kwargs.get('fig_title', ''))

    # Normalize values
    norm = _build_gradient_norm(m_data_array, step,
                                kwargs.get('v_min', None),
                                kwargs.get('v_max', None))
    gpu_metric_regex = re.compile(kwargs.get('gpu_metrics_re', ''))

    for i, _ in enumerate(m_data_array):
        gpu_metric_match = gpu_metric_regex.search(m_data.columns[i][0])

        if gpu_metric_match:
            ylabel_text = (f'{m_data.columns[i][1]}'
                           f'.{m_data.columns[i][2]}'
                           f'.{m_data.columns[i][3]}@{m_data.columns[i][4]}.GPU{gpu_metric_match.group(1)}')
        else:
            ylabel_text = (f'{m_data.columns[i][1]}'
                           f'.{m_data.columns[i][2]}'
                           f'.{m_data.columns[i][3]}@{m_data.columns[i][4]}')

        axs[i].grid(axis='x', alpha=0.5)
        axs[i].set_yticks([0], labels=[ylabel_text])
        axs[i].set_xmargin(0)
        axs[i].set_ymargin(0)

        # Generate the timeline gradient
        viridis = mpl.colormaps['viridis_r']
        axs[i].bar(range(len(m_data_array[i])), len(m_data_array[i])/10,
                   width=1, color=[viridis(norm(x)) if not np.isnan(x) else
                                   'white' for x in m_data_array[i]])

    axs[-1].minorticks_on()

    # Create the figure colorbar

    axs.cbar_axes[0].colorbar(mpl.cm.ScalarMappable(norm=norm,
                                                    cmap='viridis_r'),
                              label=kwargs.get('metric_display_name', metric),
                              format=None)

    return fig


def runtime_config_section(runtime_config_func):
    def try_getting_section(*args, **kwargs):
        try:
            return runtime_config_func(*args, **kwargs)
        except KeyError as e:
            sys.exit(f'Your configuration hasn\'t the following field: {e}')
    return try_getting_section


@runtime_config_section
def runtime_get_configuration(config_fn):
    """
    Reads the configuration file name passed and returns runtime configuration.
    The returned configuration may be used when calling other methods for
    retrieving specific configuration.
    """
    return io_api.read_configuration(config_fn)['runtime']


@runtime_config_section
def runtime_node_metrics_configuration(runtime_config):
    """
    Returns the node metrics configuration from runtime configuration
    """
    return runtime_config['metrics']


@runtime_config_section
def runtime_gpu_metrics_configuration(runtime_config):
    """
    Returns the gpu metrics configuration from runtime configuration
    """
    return runtime_config['gpu_metrics']


@runtime_config_section
def runtime_socket_metrics_configuration(runtime_config):
    """
    Returns the socket metrics configuration from runtime configuration
    """
    return runtime_config['socket_metrics']


@runtime_config_section
def runtime_app_start_time_col(runtime_config):
    """
    Returns the column refering to the START_TIME of an application
    """
    return runtime_config['app_info']['start_time']


@runtime_config_section
def runtime_app_end_time_col(runtime_config):
    """
    Returns the column refering to the START_TIME of an application
    """
    return runtime_config['app_info']['end_time']


@runtime_config_section
def runtime_get_gpu_metrics_regex(runtime_config):
    """
    Returns the regex to match GPU columns
    """
    try:
        return runtime_config['gpu_data']['gpu_columns_re']
    except KeyError as e:
        sys.exit(f'{e} field not found in configuration:{runtime_config}')


@runtime_config_section
def runtime_section(configuration):
    """
    Returns the 'runtime' section of the configuration dict.
    """
    return configuration['runtime']
