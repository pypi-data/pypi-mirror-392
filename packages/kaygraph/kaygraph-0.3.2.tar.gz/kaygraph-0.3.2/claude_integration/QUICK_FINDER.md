# KayGraph Workbook Quick Finder

## ğŸ¯ Find the Right Example Fast

### "I need to build..."

#### **An AI Agent** 
- Simple agent with decisions â†’ `kaygraph-agent/`
- Agent with memory â†’ `kaygraph-agent-memory/`
- Agent with tools/functions â†’ `kaygraph-agent-tools/`
- Multiple agents working together â†’ `kaygraph-multi-agent/`
- Agent that learns from feedback â†’ `kaygraph-agent-feedback/`

#### **A Chatbot**
- Basic chat â†’ `kaygraph-chat/`
- Chat with conversation memory â†’ `kaygraph-chat-memory/`
- Chat with safety guardrails â†’ `kaygraph-chat-guardrail/`
- Voice chat interface â†’ `kaygraph-voice-chat/`

#### **A RAG System**
- Complete RAG pipeline â†’ `kaygraph-rag/`
- Text to SQL queries â†’ `kaygraph-text2sql/`
- PDF processing with vision â†’ `kaygraph-tool-pdf-vision/`
- Web crawler + search â†’ `kaygraph-tool-crawler/`

#### **Batch Processing**
- Process multiple items â†’ `kaygraph-batch/`
- Parallel batch processing â†’ `kaygraph-parallel-batch/`
- Nested batch operations â†’ `kaygraph-nested-batch/`
- MapReduce pattern â†’ `kaygraph-distributed-mapreduce/`

#### **A Workflow**
- Simple pipeline â†’ `kaygraph-workflow/`
- With human approval â†’ `kaygraph-human-in-the-loop/`
- Parallel tasks â†’ `kaygraph-workflow-parallelization/`
- With error handling â†’ `kaygraph-fault-tolerant-workflow/`
- Task routing/branching â†’ `kaygraph-workflow-routing/`

#### **Production Features**
- API server â†’ `kaygraph-production-ready-api/`
- Real-time monitoring â†’ `kaygraph-realtime-monitoring/`
- Metrics dashboard â†’ `kaygraph-metrics-dashboard/`
- Background jobs â†’ `kaygraph-fastapi-background/`
- WebSocket support â†’ `kaygraph-fastapi-websocket/`

## ğŸŸ¢ Start Here (Simplest)

1. **kaygraph-hello-world/** - Absolute basics
2. **kaygraph-workflow/** - Simple pipeline
3. **kaygraph-chat/** - Basic LLM interaction
4. **kaygraph-batch/** - Process multiple items

## ğŸŸ¡ Common Combinations

| You Want | Combine These Examples |
|----------|----------------------|
| ChatGPT Clone | `chat-memory` + `streaming-llm` |
| Research Assistant | `agent` + `rag` + `tool-search` |
| Data Pipeline | `workflow` + `batch` + `validated-pipeline` |
| Multi-Agent System | `multi-agent` + `supervisor` + `agent-memory` |
| Production API | `production-ready-api` + `metrics-dashboard` + `fault-tolerant` |

## ğŸ”´ Advanced Patterns

- **kaygraph-supervisor/** - Supervisor-worker pattern
- **kaygraph-distributed-tracing/** - OpenTelemetry integration
- **kaygraph-think-act-reflect/** - Cognitive architecture
- **kaygraph-streaming-llm/** - Stream LLM responses
- **kaygraph-code-generator/** - Generate code with LLMs

## ğŸš€ Quick Start Path

```bash
# 1. Start with hello world
cd workbooks/kaygraph-hello-world
python main.py

# 2. Try a simple workflow
cd ../kaygraph-workflow
python main.py

# 3. Add LLM capabilities
cd ../kaygraph-chat
# Set up Ollama (see below)
python main.py

# 4. Build your custom solution
# Pick and combine patterns from above
```

## ğŸ› ï¸ Setting Up Ollama (Free Local LLM)

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull a model (3.8GB)
ollama pull llama3.2

# Start Ollama server
ollama serve

# Test it works
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt": "Hello"
}'
```

Now all examples work with your local LLM!

## ğŸ“Š Complexity Levels

- ğŸŸ¢ **Beginner**: hello-world, workflow, batch, chat
- ğŸŸ¡ **Intermediate**: agent, rag, chat-memory, human-in-the-loop
- ğŸ”´ **Advanced**: multi-agent, supervisor, distributed-*, streaming-*
- âš« **Production**: production-ready-api, realtime-monitoring, metrics-dashboard

## ğŸ’¡ Tips

1. **Start simple** - Get a basic version working first
2. **Combine gradually** - Add one pattern at a time
3. **Use the same utils** - Copy `utils/call_llm.py` from any example
4. **Test locally** - Use Ollama to avoid API costs
5. **Check design.md** - Some workbooks have detailed design docs