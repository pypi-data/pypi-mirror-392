from __future__ import annotations
import argparse, sys
from pathlib import Path
from textwrap import dedent
from . import __version__

BANNER = f"nulla {__version__} — bootstrap/placeholder CLI"

# ---------- helpers ----------
def _default_root() -> Path:
    # Prefer DEFAULT_ROOT from bootstrap.py if present
    try:
        from .bootstrap import DEFAULT_ROOT  # type: ignore
        return Path(DEFAULT_ROOT)
    except Exception:
        return Path.home() / "nulla_source"

def _require_setup_assets() -> object:
    try:
        from . import setup_assets  # type: ignore
        return setup_assets
    except Exception:
        print(
            "ERROR: setup_assets.py not found in the installed package.\n"
            "Add nulla/setup_assets.py (the orchestrator) to the project, rebuild, and reinstall.\n"
            "For now, you can run:  python -m nulla setup-ffmpeg  --root <path>\n"
        )
        raise SystemExit(2)

# ---------- init scaffold (unchanged) ----------
def cmd_init(dest: str) -> None:
    base = Path(dest).expanduser().resolve()
    subdirs = [
        "scripts",
        "Whisper",        # placeholder only
        "llama.cpp",      # placeholder only
        "XTTS-v2",        # placeholder only
        "models",         # for GGUF etc. (not included)
        "assets/audio",
        "assets/images",
    ]
    base.mkdir(parents=True, exist_ok=True)
    for d in subdirs:
        (base / d).mkdir(parents=True, exist_ok=True)

    readme = dedent(f"""\
    # Nulla Project Scaffold

    Generated by `nulla {__version__}`.

    This scaffold includes **no** third-party code, models, or binaries.
    Future setup scripts should fetch required components from their **official sources** and you must
    accept each upstream license yourself.

    ## Not included (by design)
    - OpenAI Whisper (MIT) — install from its official source
    - llama.cpp (MIT) — build/fetch from official repo
    - XTTS-v2 (Coqui, non-commercial license) — review license and fetch officially
    - GGUF models (e.g., OpenHermes-2.5-Mistral-7B) — follow original/model licenses
    - Any audio/images (e.g., salutations.wav by shadoWisp — CC BY 3.0)

    ## Next ideas
    - Add a setup script that downloads from official URLs.
    - Keep NOTICE/README up to date with licenses and links.
    """)
    (base / "README_NULLA_SETUP.md").write_text(readme, encoding="utf-8")

    gitignore = dedent("""\
    __pycache__/
    .venv/
    dist/
    *.pyc
    *.pyo
    .DS_Store
    """)
    (base / ".gitignore").write_text(gitignore, encoding="utf-8")

    print(f"Created scaffold at: {base}")
    for d in subdirs:
        print("  -", base / d)

# ---------- setup-ffmpeg (works now via bootstrap.py) ----------
def cmd_setup_ffmpeg(root_arg: str | None) -> None:
    root = Path(root_arg).expanduser().resolve() if root_arg else _default_root()
    try:
        from .bootstrap import setup_ffmpeg  # type: ignore
    except Exception:
        print(
            "ERROR: FFmpeg bootstrap not found.\n"
            "Add 'nulla/bootstrap.py' (the FFmpeg downloader) to your package, "
            "then rebuild/reinstall. After that, run this again."
        )
        raise SystemExit(2)
    print(f">> Setting up FFmpeg under: {root}")
    setup_ffmpeg(root)
    print("FFmpeg ready. Check: bin/ffmpeg/ffmpeg.exe and ffprobe.exe")

# ---------- umbrella setup (calls setup_assets.do_setup) ----------
def cmd_setup(root_arg: str | None, assume_yes: bool) -> None:
    root = Path(root_arg).expanduser().resolve() if root_arg else _default_root()
    sa = _require_setup_assets()
    print(f">> Running full setup under: {root}")
    sa.do_setup(root=root, assume_yes=assume_yes)  # you will implement this in setup_assets.py

# ---------- fine-grained sub-steps (defer to setup_assets if present) ----------
def cmd_setup_whisper(root_arg: str | None, model_size: str, assume_yes: bool) -> None:
    root = Path(root_arg).expanduser().resolve() if root_arg else _default_root()
    sa = _require_setup_assets()
    sa.setup_whisper(root=root, model_size=model_size, assume_yes=assume_yes)

def cmd_setup_xtts(root_arg: str | None, torch_spec: str | None, assume_yes: bool) -> None:
    root = Path(root_arg).expanduser().resolve() if root_arg else _default_root()
    sa = _require_setup_assets()
    sa.setup_xtts(root=root, torch_spec=torch_spec, assume_yes=assume_yes)

def cmd_setup_llamacpp(root_arg: str | None, method: str, assume_yes: bool) -> None:
    root = Path(root_arg).expanduser().resolve() if root_arg else _default_root()
    sa = _require_setup_assets()
    sa.setup_llamacpp(root=root, method=method, assume_yes=assume_yes)

def cmd_setup_model(root_arg: str | None, gguf_file: str, repo_id: str, assume_yes: bool) -> None:
    root = Path(root_arg).expanduser().resolve() if root_arg else _default_root()
    sa = _require_setup_assets()
    sa.setup_model(root=root, repo_id=repo_id, gguf_filename=gguf_file, assume_yes=assume_yes)

# ---------- optional run placeholder ----------
def cmd_run(root_arg: str | None) -> None:
    root = Path(root_arg).expanduser().resolve() if root_arg else _default_root()
    print("Nulla 'run' is a placeholder. After setup, start your launcher here.")
    print(f"Root: {root}")

# ---------- CLI ----------
def main(argv=None):
    parser = argparse.ArgumentParser(prog="nulla", description=BANNER)
    parser.add_argument("--version", action="version", version=f"nulla {__version__}")
    sub = parser.add_subparsers(dest="cmd")

    # init
    p_init = sub.add_parser("init", help="Create a local project scaffold (no third-party assets).")
    p_init.add_argument("--dest", default="Nulla", help="Target directory (default: ./Nulla)")

    # umbrella setup
    p_setup = sub.add_parser("setup", help="Run the full orchestrated setup (FFmpeg, Whisper, llama.cpp, GGUF, XTTS).")
    p_setup.add_argument("--root", help="Install root (default: ~/nulla_source or bootstrap.DEFAULT_ROOT)")
    p_setup.add_argument("-y", "--yes", action="store_true", help="Assume 'yes' to prompts.")

    # individual steps
    p_ff = sub.add_parser("setup-ffmpeg", help="Download and place FFmpeg under <root>\\bin\\ffmpeg\\")
    p_ff.add_argument("--root", help="Install root (default: ~/nulla_source or bootstrap.DEFAULT_ROOT)")

    p_w = sub.add_parser("setup-whisper", help="Create Whisper venv and fetch a model.")
    p_w.add_argument("--root", help="Install root (default: ~/nulla_source)")
    p_w.add_argument("--model", default="small", help="Whisper model size (tiny, base, small, medium, large)")
    p_w.add_argument("-y", "--yes", action="store_true", help="Assume 'yes' to prompts.")

    p_x = sub.add_parser("setup-xtts", help="Create XTTS-v2 venv and install Torch + TTS.")
    p_x.add_argument("--root", help="Install root (default: ~/nulla_source)")
    p_x.add_argument("--torch-spec", help="Override torch install spec (e.g. 'torch==2.7.0+cu128 torchaudio==2.7.0+cu128 -f https://download.pytorch.org/whl/cu128/torch_stable.html')")
    p_x.add_argument("-y", "--yes", action="store_true", help="Assume 'yes' to prompts.")

    p_l = sub.add_parser("setup-llamacpp", help="Fetch llama.cpp binaries (or prompt user).")
    p_l.add_argument("--root", help="Install root (default: ~/nulla_source)")
    p_l.add_argument("--method", choices=["prompt", "download"], default="prompt",
                     help="How to provide binaries: 'prompt' (user drops exes) or 'download' (try to fetch a release).")
    p_l.add_argument("-y", "--yes", action="store_true", help="Assume 'yes' to prompts.")

    p_m = sub.add_parser("setup-model", help="Download a GGUF to <root>\\models\\")
    p_m.add_argument("--root", help="Install root (default: ~/nulla_source)")
    p_m.add_argument("--repo", default="TheBloke/OpenHermes-2.5-Mistral-7B-GGUF", help="Hugging Face repo_id")
    p_m.add_argument("--file", default="openhermes-2.5-mistral-7b.Q4_K_M.gguf", help="GGUF filename in the repo")
    p_m.add_argument("-y", "--yes", action="store_true", help="Assume 'yes' to prompts.")

    # run (optional)
    p_run = sub.add_parser("run", help="(Placeholder) start Nulla after setup.")
    p_run.add_argument("--root", help="Install root (default: ~/nulla_source)")

    args = parser.parse_args(argv)

    if args.cmd == "init":
        return cmd_init(args.dest)
    if args.cmd == "setup":
        return cmd_setup(args.root, args.yes)
    if args.cmd == "setup-ffmpeg":
        return cmd_setup_ffmpeg(args.root)
    if args.cmd == "setup-whisper":
        return cmd_setup_whisper(args.root, args.model, args.yes)
    if args.cmd == "setup-xtts":
        return cmd_setup_xtts(args.root, args.torch_spec, args.yes)
    if args.cmd == "setup-llamacpp":
        return cmd_setup_llamacpp(args.root, args.method, args.yes)
    if args.cmd == "setup-model":
        return cmd_setup_model(args.root, args.file, args.repo, args.yes)
    if args.cmd == "run":
        return cmd_run(args.root)

    parser.print_help()

if __name__ == "__main__":
    main()
