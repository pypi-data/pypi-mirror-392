/**
 * @file turboloader_bindings.cpp
 * @brief Python bindings for TurboLoader v1.5.1 with full transform API
 *
 * Provides PyTorch-compatible DataLoader interface using pybind11.
 * Includes all 19 SIMD-accelerated transforms with comprehensive docstrings.
 */

#include <pybind11/pybind11.h>
#include <pybind11/stl.h>
#include <pybind11/numpy.h>
#include "../pipeline/pipeline.hpp"
#include "../transforms/transforms.hpp"
#include "../readers/tbl_v2_reader.hpp"
#include "../writers/tbl_v2_writer.hpp"
#include "../formats/tbl_v2_format.hpp"
#include <thread>
#include <chrono>

namespace py = pybind11;
using namespace turboloader;
using namespace turboloader::transforms;

/**
 * @brief Convert UnifiedSample to Python dict with NumPy array
 */
py::dict sample_to_dict(const UnifiedSample& sample) {
    py::dict result;

    result["index"] = sample.index;
    result["filename"] = sample.filename;
    result["width"] = sample.width;
    result["height"] = sample.height;
    result["channels"] = sample.channels;

    // Convert image data to NumPy array (zero-copy when possible)
    if (!sample.image_data.empty() && sample.width > 0 && sample.height > 0) {
        // Create NumPy array with shape (H, W, C)
        py::array_t<uint8_t> img_array({
            static_cast<py::ssize_t>(sample.height),
            static_cast<py::ssize_t>(sample.width),
            static_cast<py::ssize_t>(sample.channels)
        });

        // Copy data (necessary because C++ sample will be destroyed)
        auto buf = img_array.request();
        uint8_t* ptr = static_cast<uint8_t*>(buf.ptr);
        std::memcpy(ptr, sample.image_data.data(), sample.image_data.size());

        result["image"] = img_array;
    } else {
        result["image"] = py::none();
    }

    return result;
}

/**
 * @brief Python-friendly DataLoader wrapper for UnifiedPipeline
 *
 * Drop-in replacement for PyTorch DataLoader with TurboLoader performance.
 */
class DataLoader {
public:
    /**
     * @brief Constructor - PyTorch-compatible interface
     *
     * @param data_path Path to data (TAR, video, CSV, etc.)
     * @param batch_size Batch size (default: 32)
     * @param num_workers Number of worker threads (default: 4)
     * @param shuffle Enable shuffling (future feature, default: false)
     */
    DataLoader(
        const std::string& data_path,
        size_t batch_size = 32,
        size_t num_workers = 4,
        bool shuffle = false
    ) {
        config_.data_path = data_path;
        config_.batch_size = batch_size;
        config_.num_workers = num_workers;
        config_.shuffle = shuffle;
        config_.queue_size = 256;  // Good default for high throughput

        // Create pipeline (will auto-detect format)
        pipeline_ = std::make_unique<UnifiedPipeline>(config_);
        pipeline_->start();
        started_ = true;
    }

    ~DataLoader() {
        if (pipeline_) {
            pipeline_->stop();
        }
    }

    /**
     * @brief Get next batch
     *
     * @return List of sample dictionaries
     */
    py::list next_batch() {
        if (!pipeline_) {
            throw std::runtime_error("DataLoader not initialized");
        }

        auto batch = pipeline_->next_batch();
        py::list result;

        for (const auto& sample : batch.samples) {
            result.append(sample_to_dict(sample));
        }

        return result;
    }

    /**
     * @brief Check if finished
     */
    bool is_finished() const {
        if (!pipeline_) {
            return true;
        }
        return pipeline_->is_finished();
    }

    /**
     * @brief Stop the pipeline
     */
    void stop() {
        if (pipeline_) {
            pipeline_->stop();
        }
    }

    /**
     * @brief Context manager: __enter__
     */
    DataLoader& enter() {
        return *this;
    }

    /**
     * @brief Context manager: __exit__
     */
    void exit(py::object exc_type, py::object exc_value, py::object traceback) {
        stop();
    }

    /**
     * @brief Iterator: __iter__
     */
    DataLoader& iter() {
        return *this;
    }

    /**
     * @brief Iterator: __next__
     */
    py::list next() {
        if (is_finished()) {
            throw py::stop_iteration();
        }

        // Keep trying to get a batch, with small sleep between attempts
        // This handles the case where workers need time to process
        py::list batch;
        int attempts = 0;
        const int max_attempts = 100;  // Up to 10 seconds (100ms * 100)

        while (attempts < max_attempts) {
            batch = next_batch();

            // If we got samples, return them
            if (py::len(batch) > 0) {
                return batch;
            }

            // If pipeline is finished and no samples, stop iteration
            if (is_finished()) {
                throw py::stop_iteration();
            }

            // Give workers time to process (release GIL while sleeping)
            py::gil_scoped_release release;
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
            attempts++;
        }

        // Timeout - if we got here, something might be wrong
        // Return empty batch rather than hanging forever
        return batch;
    }

private:
    UnifiedPipelineConfig config_;
    std::unique_ptr<UnifiedPipeline> pipeline_;
    bool started_ = false;
};

/**
 * @brief Helper to convert ImageData to NumPy array
 */
py::array_t<uint8_t> imagedata_to_numpy(const ImageData& img) {
    py::array_t<uint8_t> array({
        static_cast<py::ssize_t>(img.height),
        static_cast<py::ssize_t>(img.width),
        static_cast<py::ssize_t>(img.channels)
    });

    auto buf = array.request();
    uint8_t* ptr = static_cast<uint8_t*>(buf.ptr);
    std::memcpy(ptr, img.data, img.width * img.height * img.channels);

    return array;
}

/**
 * @brief Helper to convert NumPy array to ImageData
 */
std::unique_ptr<ImageData> numpy_to_imagedata(py::array_t<uint8_t> array) {
    auto buf = array.request();
    if (buf.ndim != 3) {
        throw std::runtime_error("Array must be 3D (H, W, C)");
    }

    int height = buf.shape[0];
    int width = buf.shape[1];
    int channels = buf.shape[2];

    size_t size = height * width * channels;
    auto data = new uint8_t[size];
    std::memcpy(data, buf.ptr, size);

    return std::make_unique<ImageData>(data, width, height, channels,
                                       width * channels, true);
}

/**
 * @brief pybind11 module definition
 *
 * Module is named _turboloader (with underscore) to avoid conflicts
 * with the turboloader package. The Python __init__.py re-exports the API.
 */
PYBIND11_MODULE(_turboloader, m) {
    m.doc() = "TurboLoader v1.6.0 - High-performance data loading with 19 SIMD transforms\n\n"
              "Drop-in replacement for PyTorch DataLoader with 12x speedup.\n\n"
              "Features:\n"
              "- TBL v2 format with LZ4 compression (40-60% space savings)\n"
              "- 19 SIMD-accelerated transforms (AVX2/NEON)\n"
              "- TAR archives (52+ Gbps local, HTTP/S3/GCS remote)\n"
              "- Multi-threaded with lock-free queues\n"
              "- AutoAugment policies (ImageNet, CIFAR10, SVHN)\n"
              "- PyTorch & TensorFlow tensor conversion\n"
              "- Data integrity validation (CRC32/CRC16)\n"
              "- Zero-copy where possible\n"
              "- Professional documentation and API\n\n"
              "Usage:\n"
              "    import turboloader\n"
              "    loader = turboloader.DataLoader('data.tar', batch_size=32, num_workers=8)\n"
              "    for batch in loader:\n"
              "        # batch is list of dicts with 'image' (numpy array) and metadata\n"
              "        pass\n\n"
              "Transforms:\n"
              "    transform = turboloader.Resize(224, 224, turboloader.InterpolationMode.BILINEAR)\n"
              "    output = transform.apply(image)\n\n"
              "Documentation:\n"
              "    https://github.com/ALJainProjects/TurboLoader/tree/main/docs";

    // DataLoader class (PyTorch-compatible)
    py::class_<DataLoader>(m, "DataLoader")
        .def(py::init<const std::string&, size_t, size_t, bool>(),
             py::arg("data_path"),
             py::arg("batch_size") = 32,
             py::arg("num_workers") = 4,
             py::arg("shuffle") = false,
             "Create TurboLoader DataLoader (PyTorch-compatible)\n\n"
             "Args:\n"
             "    data_path (str): Path to data (TAR, video, CSV, Parquet)\n"
             "                    Supports: local files, http://, https://, s3://, gs://\n"
             "    batch_size (int): Samples per batch (default: 32)\n"
             "    num_workers (int): Worker threads (default: 4)\n"
             "    shuffle (bool): Shuffle samples (future feature, default: False)\n\n"
             "Returns:\n"
             "    DataLoader: Iterable that yields batches\n\n"
             "Example:\n"
             "    >>> loader = turboloader.DataLoader('imagenet.tar', batch_size=128, num_workers=8)\n"
             "    >>> for batch in loader:\n"
             "    >>>     images = [sample['image'] for sample in batch]  # NumPy arrays\n"
             "    >>>     # Train your model..."
        )
        .def("next_batch", &DataLoader::next_batch,
             "Get next batch\n\n"
             "Returns:\n"
             "    list: Batch of samples, each a dict with:\n"
             "        - 'index' (int): Sample index\n"
             "        - 'filename' (str): Original filename\n"
             "        - 'width' (int): Image width\n"
             "        - 'height' (int): Image height\n"
             "        - 'channels' (int): Number of channels (3 for RGB)\n"
             "        - 'image' (np.ndarray): Image data (H, W, C) uint8"
        )
        .def("is_finished", &DataLoader::is_finished,
             "Check if all data has been processed\n\n"
             "Returns:\n"
             "    bool: True if pipeline finished")
        .def("stop", &DataLoader::stop,
             "Stop the pipeline and clean up resources")
        .def("__enter__", &DataLoader::enter,
             "Context manager entry")
        .def("__exit__", &DataLoader::exit,
             "Context manager exit")
        .def("__iter__", &DataLoader::iter,
             "Make DataLoader iterable")
        .def("__next__", &DataLoader::next,
             "Get next batch (iterator protocol)");

    // Module-level functions
    m.def("version", []() { return "1.6.0"; },
          "Get TurboLoader version\n\n"
          "Returns:\n"
          "    str: Version string (e.g., '1.6.0')");

    m.def("features", []() {
        py::dict features;
        features["version"] = "1.6.0";
        features["tar_support"] = true;
        features["remote_tar"] = true;
        features["http_support"] = true;
        features["s3_support"] = true;
        features["gcs_support"] = true;
        features["jpeg_decode"] = true;
        features["png_decode"] = true;
        features["webp_decode"] = true;
        features["simd_acceleration"] = true;
        features["lock_free_queues"] = true;
        features["num_transforms"] = 19;
        features["autoaugment"] = true;
        features["pytorch_tensors"] = true;
        features["tensorflow_tensors"] = true;
        features["lanczos_interpolation"] = true;
        return features;
    }, "Get TurboLoader feature support\n\n"
       "Returns:\n"
       "    dict: Feature flags and capabilities\n\n"
       "Example:\n"
       "    >>> import turboloader\n"
       "    >>> features = turboloader.features()\n"
       "    >>> print(f\"Version: {features['version']}\")\n"
       "    >>> print(f\"Transforms: {features['num_transforms']}\")");

    m.def("list_transforms", []() {
        py::list transforms;
        transforms.append("Resize");
        transforms.append("Normalize");
        transforms.append("ImageNetNormalize");
        transforms.append("RandomHorizontalFlip");
        transforms.append("RandomVerticalFlip");
        transforms.append("CenterCrop");
        transforms.append("RandomCrop");
        transforms.append("ColorJitter");
        transforms.append("Grayscale");
        transforms.append("Pad");
        transforms.append("RandomRotation");
        transforms.append("RandomAffine");
        transforms.append("GaussianBlur");
        transforms.append("RandomErasing");
        transforms.append("RandomPosterize");
        transforms.append("RandomSolarize");
        transforms.append("RandomPerspective");
        transforms.append("AutoAugment");
        transforms.append("ToTensor");
        return transforms;
    }, "List all available transforms\n\n"
       "Returns:\n"
       "    list[str]: Names of all 19 transforms\n\n"
       "Example:\n"
       "    >>> import turboloader\n"
       "    >>> print(turboloader.list_transforms())");

    // ========================================================================
    // TRANSFORM BINDINGS
    // ========================================================================

    // Enums
    py::enum_<InterpolationMode>(m, "InterpolationMode",
                 "Interpolation modes for image resizing\n\n"
                 "Available modes:\n"
                 "  NEAREST: Nearest-neighbor (fastest, lowest quality)\n"
                 "  BILINEAR: Bilinear interpolation (good balance)\n"
                 "  BICUBIC: Bicubic interpolation (higher quality)\n"
                 "  LANCZOS: Lanczos resampling (highest quality, best for downsampling)")
        .value("NEAREST", InterpolationMode::NEAREST)
        .value("BILINEAR", InterpolationMode::BILINEAR)
        .value("BICUBIC", InterpolationMode::BICUBIC)
        .value("LANCZOS", InterpolationMode::LANCZOS);

    py::enum_<PaddingMode>(m, "PaddingMode",
                 "Padding modes for image operations\n\n"
                 "Available modes:\n"
                 "  CONSTANT: Pad with constant value\n"
                 "  EDGE: Pad with edge pixel values\n"
                 "  REFLECT: Reflect pixels at border")
        .value("CONSTANT", PaddingMode::CONSTANT)
        .value("EDGE", PaddingMode::EDGE)
        .value("REFLECT", PaddingMode::REFLECT);

    py::enum_<TensorFormat>(m, "TensorFormat",
                 "Tensor format for framework compatibility\n\n"
                 "Available formats:\n"
                 "  NONE: Keep as HWC uint8\n"
                 "  PYTORCH_CHW: Convert to CHW float32 (PyTorch)\n"
                 "  TENSORFLOW_HWC: Convert to HWC float32 (TensorFlow)")
        .value("NONE", TensorFormat::NONE)
        .value("PYTORCH_CHW", TensorFormat::PYTORCH_CHW)
        .value("TENSORFLOW_HWC", TensorFormat::TENSORFLOW_HWC);

    // Base Transform class
    py::class_<Transform>(m, "Transform",
             "Base class for all image transforms\n\n"
             "All transforms inherit from this class and provide SIMD-accelerated operations.\n"
             "Transforms can be composed into pipelines for efficient batch processing.")
        .def("apply", [](Transform& self, py::array_t<uint8_t> img) {
            auto input = numpy_to_imagedata(img);
            auto output = self.apply(*input);
            return imagedata_to_numpy(*output);
        }, "Apply transform to image\n\n"
           "Args:\n"
           "    img (np.ndarray): Input image (H, W, C) uint8\n\n"
           "Returns:\n"
           "    np.ndarray: Transformed image (H, W, C) uint8")
        .def("name", &Transform::name,
             "Get transform name\n\n"
             "Returns:\n"
             "    str: Name of the transform")
        .def("is_deterministic", &Transform::is_deterministic,
             "Check if transform is deterministic\n\n"
             "Returns:\n"
             "    bool: True if transform produces same output for same input");

    // Resize
    py::class_<ResizeTransform, Transform>(m, "Resize",
             "SIMD-accelerated image resizing transform\n\n"
             "Resizes images to target dimensions using optimized interpolation.\n"
             "Performance: 3.2x faster than torchvision\n\n"
             "Example:\n"
             "    >>> transform = turboloader.Resize(224, 224, turboloader.InterpolationMode.BILINEAR)\n"
             "    >>> output = transform.apply(image)")
        .def(py::init<int, int, InterpolationMode>(),
             py::arg("width"), py::arg("height"),
             py::arg("interpolation") = InterpolationMode::BILINEAR,
             "Create Resize transform\n\n"
             "Args:\n"
             "    width (int): Target width in pixels\n"
             "    height (int): Target height in pixels\n"
             "    interpolation (InterpolationMode): Interpolation method (default: BILINEAR)");

    // Normalize
    py::class_<NormalizeTransform, Transform>(m, "Normalize",
             "SIMD-accelerated normalization transform\n\n"
             "Normalizes images using mean and standard deviation.\n"
             "Formula: output = (input - mean) / std\n\n"
             "Example:\n"
             "    >>> transform = turboloader.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])")
        .def(py::init<const std::vector<float>&, const std::vector<float>&, bool>(),
             py::arg("mean"), py::arg("std"), py::arg("to_float") = false,
             "Create Normalize transform\n\n"
             "Args:\n"
             "    mean (list[float]): Mean values for each channel\n"
             "    std (list[float]): Standard deviation for each channel\n"
             "    to_float (bool): Convert to float32 (default: False)");

    py::class_<ImageNetNormalize, NormalizeTransform>(m, "ImageNetNormalize",
             "ImageNet normalization preset\n\n"
             "Uses ImageNet mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\n"
             "Convenient shorthand for ImageNet training/validation.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.ImageNetNormalize(to_float=True)")
        .def(py::init<bool>(), py::arg("to_float") = false,
             "Create ImageNet normalization transform\n\n"
             "Args:\n"
             "    to_float (bool): Convert to float32 (default: False)");

    // Flips
    py::class_<RandomHorizontalFlipTransform, Transform>(m, "RandomHorizontalFlip",
             "SIMD-accelerated random horizontal flip\n\n"
             "Randomly flips images horizontally with probability p.\n"
             "Performance: 10,000+ img/s\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomHorizontalFlip(p=0.5)")
        .def(py::init<float, unsigned>(),
             py::arg("p") = 0.5f, py::arg("seed") = std::random_device{}(),
             "Create RandomHorizontalFlip transform\n\n"
             "Args:\n"
             "    p (float): Probability of flipping (default: 0.5)\n"
             "    seed (int): Random seed for reproducibility");

    py::class_<RandomVerticalFlipTransform, Transform>(m, "RandomVerticalFlip",
             "SIMD-accelerated random vertical flip\n\n"
             "Randomly flips images vertically with probability p.\n"
             "Performance: 10,000+ img/s\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomVerticalFlip(p=0.5)")
        .def(py::init<float, unsigned>(),
             py::arg("p") = 0.5f, py::arg("seed") = std::random_device{}(),
             "Create RandomVerticalFlip transform\n\n"
             "Args:\n"
             "    p (float): Probability of flipping (default: 0.5)\n"
             "    seed (int): Random seed for reproducibility");

    // Crops
    py::class_<CenterCropTransform, Transform>(m, "CenterCrop",
             "Center crop transform\n\n"
             "Crops the center region of the image to target size.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.CenterCrop(224, 224)")
        .def(py::init<int, int>(), py::arg("width"), py::arg("height"),
             "Create CenterCrop transform\n\n"
             "Args:\n"
             "    width (int): Target width\n"
             "    height (int): Target height");

    py::class_<RandomCropTransform, Transform>(m, "RandomCrop",
             "Random crop with optional padding\n\n"
             "Randomly crops a region from the image with optional padding.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomCrop(224, 224, padding=32)")
        .def(py::init<int, int, int, PaddingMode, uint8_t, unsigned>(),
             py::arg("width"), py::arg("height"),
             py::arg("padding") = 0,
             py::arg("pad_mode") = PaddingMode::CONSTANT,
             py::arg("pad_value") = 0,
             py::arg("seed") = std::random_device{}(),
             "Create RandomCrop transform\n\n"
             "Args:\n"
             "    width (int): Target crop width\n"
             "    height (int): Target crop height\n"
             "    padding (int): Padding size (default: 0)\n"
             "    pad_mode (PaddingMode): Padding mode (default: CONSTANT)\n"
             "    pad_value (int): Padding value for CONSTANT mode (default: 0)\n"
             "    seed (int): Random seed");

    // ColorJitter
    py::class_<ColorJitterTransform, Transform>(m, "ColorJitter",
             "SIMD-accelerated color jitter transform\n\n"
             "Randomly adjusts brightness, contrast, saturation, and hue.\n"
             "Performance: 5,000+ img/s\n\n"
             "Example:\n"
             "    >>> transform = turboloader.ColorJitter(brightness=0.2, contrast=0.2)")
        .def(py::init<float, float, float, float, unsigned>(),
             py::arg("brightness") = 0.0f,
             py::arg("contrast") = 0.0f,
             py::arg("saturation") = 0.0f,
             py::arg("hue") = 0.0f,
             py::arg("seed") = std::random_device{}(),
             "Create ColorJitter transform\n\n"
             "Args:\n"
             "    brightness (float): Brightness adjustment factor (0.0 = no change)\n"
             "    contrast (float): Contrast adjustment factor (0.0 = no change)\n"
             "    saturation (float): Saturation adjustment factor (0.0 = no change)\n"
             "    hue (float): Hue adjustment factor (0.0 = no change)\n"
             "    seed (int): Random seed");

    // Grayscale
    py::class_<GrayscaleTransform, Transform>(m, "Grayscale",
             "Convert image to grayscale\n\n"
             "Converts RGB images to grayscale using weighted average.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.Grayscale(num_output_channels=1)")
        .def(py::init<int>(), py::arg("num_output_channels") = 1,
             "Create Grayscale transform\n\n"
             "Args:\n"
             "    num_output_channels (int): Output channels (1 or 3, default: 1)");

    // Pad
    py::class_<PadTransform, Transform>(m, "Pad",
             "Pad image with specified mode\n\n"
             "Adds padding around the image border.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.Pad(32, mode=turboloader.PaddingMode.REFLECT)")
        .def(py::init<int, PaddingMode, uint8_t>(),
             py::arg("padding"),
             py::arg("mode") = PaddingMode::CONSTANT,
             py::arg("value") = 0,
             "Create Pad transform\n\n"
             "Args:\n"
             "    padding (int): Padding size on all sides\n"
             "    mode (PaddingMode): Padding mode (default: CONSTANT)\n"
             "    value (int): Padding value for CONSTANT mode (default: 0)");

    // Rotation
    py::class_<RandomRotationTransform, Transform>(m, "RandomRotation",
             "Random rotation transform\n\n"
             "Randomly rotates images by angle in [-degrees, +degrees].\n"
             "Uses SIMD-accelerated bilinear interpolation.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomRotation(15.0)")
        .def(py::init<float, bool, uint8_t, unsigned>(),
             py::arg("degrees"),
             py::arg("expand") = false,
             py::arg("fill") = 0,
             py::arg("seed") = std::random_device{}(),
             "Create RandomRotation transform\n\n"
             "Args:\n"
             "    degrees (float): Rotation range [-degrees, +degrees]\n"
             "    expand (bool): Expand output to fit rotated image (default: False)\n"
             "    fill (int): Fill value for empty areas (default: 0)\n"
             "    seed (int): Random seed");

    // Affine
    py::class_<RandomAffineTransform, Transform>(m, "RandomAffine",
             "Random affine transformation\n\n"
             "Applies random affine transformations (rotation, translation, scale, shear).\n"
             "Uses SIMD-accelerated interpolation.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomAffine(degrees=15, scale_min=0.8, scale_max=1.2)")
        .def(py::init<float, float, float, float, float, float, uint8_t, unsigned>(),
             py::arg("degrees") = 0.0f,
             py::arg("translate_x") = 0.0f,
             py::arg("translate_y") = 0.0f,
             py::arg("scale_min") = 1.0f,
             py::arg("scale_max") = 1.0f,
             py::arg("shear") = 0.0f,
             py::arg("fill") = 0,
             py::arg("seed") = std::random_device{}(),
             "Create RandomAffine transform\n\n"
             "Args:\n"
             "    degrees (float): Rotation range (default: 0.0)\n"
             "    translate_x (float): Horizontal translation fraction (default: 0.0)\n"
             "    translate_y (float): Vertical translation fraction (default: 0.0)\n"
             "    scale_min (float): Minimum scale factor (default: 1.0)\n"
             "    scale_max (float): Maximum scale factor (default: 1.0)\n"
             "    shear (float): Shear angle in degrees (default: 0.0)\n"
             "    fill (int): Fill value for empty areas (default: 0)\n"
             "    seed (int): Random seed");

    // Blur
    py::class_<GaussianBlurTransform, Transform>(m, "GaussianBlur",
             "SIMD-accelerated Gaussian blur\n\n"
             "Applies Gaussian blur using separable convolution.\n"
             "Performance: 2,000+ img/s (kernel_size=5)\n\n"
             "Example:\n"
             "    >>> transform = turboloader.GaussianBlur(kernel_size=5, sigma=1.5)")
        .def(py::init<int, float>(),
             py::arg("kernel_size"), py::arg("sigma") = 0.0f,
             "Create GaussianBlur transform\n\n"
             "Args:\n"
             "    kernel_size (int): Blur kernel size (must be odd)\n"
             "    sigma (float): Gaussian sigma (default: auto-calculate from kernel_size)");

    // Erasing
    py::class_<RandomErasingTransform, Transform>(m, "RandomErasing",
             "Random erasing augmentation (Cutout)\n\n"
             "Randomly erases rectangular regions for data augmentation.\n"
             "Performance: 8,000+ img/s\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomErasing(p=0.5, scale_min=0.02, scale_max=0.33)")
        .def(py::init<float, float, float, float, float, uint8_t, unsigned>(),
             py::arg("p") = 0.5f,
             py::arg("scale_min") = 0.02f,
             py::arg("scale_max") = 0.33f,
             py::arg("ratio_min") = 0.3f,
             py::arg("ratio_max") = 3.33f,
             py::arg("value") = 0,
             py::arg("seed") = std::random_device{}(),
             "Create RandomErasing transform\n\n"
             "Args:\n"
             "    p (float): Probability of applying erasing (default: 0.5)\n"
             "    scale_min (float): Minimum erased area relative to image (default: 0.02)\n"
             "    scale_max (float): Maximum erased area relative to image (default: 0.33)\n"
             "    ratio_min (float): Minimum aspect ratio (default: 0.3)\n"
             "    ratio_max (float): Maximum aspect ratio (default: 3.33)\n"
             "    value (int): Fill value for erased region (default: 0)\n"
             "    seed (int): Random seed");

    // Advanced Transforms (v0.7.0)

    // Posterize
    py::class_<RandomPosterizeTransform, Transform>(m, "RandomPosterize",
             "Random posterize transform (NEW in v0.7.0)\n\n"
             "Reduces bit depth for a posterization effect.\n"
             "Ultra-fast bitwise operations.\n"
             "Performance: 336,000+ img/s\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomPosterize(bits=4, p=0.5)")
        .def(py::init<int, float, unsigned>(),
             py::arg("bits"), py::arg("p") = 1.0f, py::arg("seed") = std::random_device{}(),
             "Create RandomPosterize transform\n\n"
             "Args:\n"
             "    bits (int): Number of bits to keep (1-8)\n"
             "    p (float): Probability of applying (default: 1.0)\n"
             "    seed (int): Random seed");

    // Solarize
    py::class_<RandomSolarizeTransform, Transform>(m, "RandomSolarize",
             "Random solarize transform (NEW in v0.7.0)\n\n"
             "Inverts pixels above threshold for a solarization effect.\n"
             "Performance: 21,000+ img/s\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomSolarize(threshold=128, p=0.5)")
        .def(py::init<uint8_t, float, unsigned>(),
             py::arg("threshold"), py::arg("p") = 1.0f, py::arg("seed") = std::random_device{}(),
             "Create RandomSolarize transform\n\n"
             "Args:\n"
             "    threshold (int): Inversion threshold (0-255)\n"
             "    p (float): Probability of applying (default: 1.0)\n"
             "    seed (int): Random seed");

    // Perspective
    py::class_<RandomPerspectiveTransform, Transform>(m, "RandomPerspective",
             "Random perspective warp (NEW in v0.7.0)\n\n"
             "Applies random perspective transformation with SIMD interpolation.\n"
             "Performance: 9,900+ img/s\n\n"
             "Example:\n"
             "    >>> transform = turboloader.RandomPerspective(distortion_scale=0.5, p=0.5)")
        .def(py::init<float, float, uint8_t, unsigned>(),
             py::arg("distortion_scale"), py::arg("p") = 0.5f,
             py::arg("fill") = 0, py::arg("seed") = std::random_device{}(),
             "Create RandomPerspective transform\n\n"
             "Args:\n"
             "    distortion_scale (float): Perspective distortion amount (0.0-1.0)\n"
             "    p (float): Probability of applying (default: 0.5)\n"
             "    fill (int): Fill value for empty areas (default: 0)\n"
             "    seed (int): Random seed");

    // AutoAugment
    py::enum_<AutoAugmentPolicy>(m, "AutoAugmentPolicy",
                 "AutoAugment policy presets (NEW in v0.7.0)\n\n"
                 "Learned augmentation policies for different datasets:\n"
                 "  IMAGENET: Optimized for ImageNet classification\n"
                 "  CIFAR10: Optimized for CIFAR-10\n"
                 "  SVHN: Optimized for Street View House Numbers")
        .value("IMAGENET", AutoAugmentPolicy::IMAGENET)
        .value("CIFAR10", AutoAugmentPolicy::CIFAR10)
        .value("SVHN", AutoAugmentPolicy::SVHN);

    py::class_<AutoAugmentTransform, Transform>(m, "AutoAugment",
             "AutoAugment learned policies (NEW in v0.7.0)\n\n"
             "State-of-the-art learned augmentation policies.\n"
             "Performance: 19,800+ img/s (ImageNet policy)\n\n"
             "Example:\n"
             "    >>> transform = turboloader.AutoAugment(policy=turboloader.AutoAugmentPolicy.IMAGENET)")
        .def(py::init<AutoAugmentPolicy, unsigned>(),
             py::arg("policy") = AutoAugmentPolicy::IMAGENET,
             py::arg("seed") = std::random_device{}(),
             "Create AutoAugment transform\n\n"
             "Args:\n"
             "    policy (AutoAugmentPolicy): Augmentation policy (default: IMAGENET)\n"
             "    seed (int): Random seed");

    // ToTensor
    py::class_<ToTensorTransform, Transform>(m, "ToTensor",
             "Convert to tensor format\n\n"
             "Converts uint8 images to float32 tensors in PyTorch (CHW) or TensorFlow (HWC) format.\n"
             "Includes normalization to [0,1] range.\n\n"
             "Example:\n"
             "    >>> transform = turboloader.ToTensor(format=turboloader.TensorFormat.PYTORCH_CHW)")
        .def(py::init<TensorFormat, bool>(),
             py::arg("format") = TensorFormat::PYTORCH_CHW,
             py::arg("normalize") = true,
             "Create ToTensor transform\n\n"
             "Args:\n"
             "    format (TensorFormat): Output tensor format (default: PYTORCH_CHW)\n"
             "    normalize (bool): Normalize to [0,1] range (default: True)");

    // Python-side Compose helper (stores Python object references)
    // Since C++ Transform objects can't be easily cloned across the Python/C++ boundary,
    // we create a Python-side wrapper class that holds references to Python transform objects
    class PyTransformPipeline {
    private:
        std::vector<py::object> transforms_;

    public:
        explicit PyTransformPipeline(py::list transforms) {
            for (auto transform_obj : transforms) {
                transforms_.push_back(py::reinterpret_borrow<py::object>(transform_obj));
            }
        }

        py::array_t<uint8_t> apply(py::array_t<uint8_t> img) {
            py::array_t<uint8_t> current = img;

            // Apply each transform sequentially
            for (const auto& transform_obj : transforms_) {
                // Call the transform's apply method
                current = transform_obj.attr("apply")(current).cast<py::array_t<uint8_t>>();
            }

            return current;
        }

        size_t size() const { return transforms_.size(); }
    };

    // Bind PyTransformPipeline
    py::class_<PyTransformPipeline>(m, "ComposedTransforms",
                  "Transform pipeline that applies multiple transforms sequentially\n\n"
                  "This class composes multiple transforms into a single operation.\n"
                  "Transforms are applied in the order they were added.")
        .def("apply", &PyTransformPipeline::apply,
             py::arg("img"),
             "Apply all transforms in sequence\n\n"
             "Args:\n"
             "    img (np.ndarray): Input image (H, W, C) uint8\n\n"
             "Returns:\n"
             "    np.ndarray: Transformed image")
        .def("__len__", &PyTransformPipeline::size,
             "Get number of transforms in pipeline")
        .def("__call__", &PyTransformPipeline::apply,
             py::arg("img"),
             "Apply pipeline (callable interface)");

    // Compose helper function
    m.def("Compose", [](py::list transforms) -> PyTransformPipeline {
        if (transforms.size() == 0) {
            throw std::runtime_error("Compose() requires at least one transform");
        }

        // Validate that all items have an 'apply' method
        for (auto transform_obj : transforms) {
            if (!py::hasattr(transform_obj, "apply")) {
                throw std::runtime_error(
                    "Compose() requires all items to have an 'apply' method. "
                    "Make sure you're passing Transform objects."
                );
            }
        }

        return PyTransformPipeline(transforms);
    }, py::arg("transforms"),
       "Create a transform pipeline (Compose multiple transforms)\n\n"
       "Combines multiple transforms into a single pipeline that applies them sequentially.\n"
       "This is equivalent to calling each transform individually, but more convenient.\n\n"
       "Args:\n"
       "    transforms (list[Transform]): List of transforms to apply in order\n\n"
       "Returns:\n"
       "    ComposedTransforms: Pipeline that applies all transforms sequentially\n\n"
       "Example:\n"
       "    >>> import turboloader\n"
       "    >>> import numpy as np\n"
       "    >>> \n"
       "    >>> # Create individual transforms\n"
       "    >>> resize = turboloader.Resize(224, 224)\n"
       "    >>> flip = turboloader.RandomHorizontalFlip(0.5)\n"
       "    >>> normalize = turboloader.ImageNetNormalize()\n"
       "    >>> \n"
       "    >>> # Compose them into a pipeline\n"
       "    >>> pipeline = turboloader.Compose([resize, flip, normalize])\n"
       "    >>> \n"
       "    >>> # Apply pipeline to an image\n"
       "    >>> img = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n"
       "    >>> transformed = pipeline.apply(img)\n"
       "    >>> # Or use callable interface\n"
       "    >>> transformed = pipeline(img)");

    // ========================================================================
    // TBL V2 FORMAT BINDINGS (NEW in v1.5.0)
    // ========================================================================

    // SampleFormat enum
    py::enum_<formats::SampleFormat>(m, "SampleFormat",
                 "Sample format types for TBL v2\n\n"
                 "Available formats:\n"
                 "  UNKNOWN: Unknown/unsupported format\n"
                 "  JPEG: JPEG image\n"
                 "  PNG: PNG image\n"
                 "  WEBP: WebP image\n"
                 "  BMP: BMP image\n"
                 "  TIFF: TIFF image\n"
                 "  VIDEO_MP4: MP4 video\n"
                 "  VIDEO_AVI: AVI video")
        .value("UNKNOWN", formats::SampleFormat::UNKNOWN)
        .value("JPEG", formats::SampleFormat::JPEG)
        .value("PNG", formats::SampleFormat::PNG)
        .value("WEBP", formats::SampleFormat::WEBP)
        .value("BMP", formats::SampleFormat::BMP)
        .value("TIFF", formats::SampleFormat::TIFF)
        .value("VIDEO_MP4", formats::SampleFormat::VIDEO_MP4)
        .value("VIDEO_AVI", formats::SampleFormat::VIDEO_AVI);

    // MetadataType enum
    py::enum_<formats::MetadataType>(m, "MetadataType",
                 "Metadata types for TBL v2\n\n"
                 "Available types:\n"
                 "  NONE: No metadata\n"
                 "  JSON: JSON-formatted metadata\n"
                 "  PROTOBUF: Protocol Buffers\n"
                 "  MSGPACK: MessagePack format\n"
                 "  CUSTOM: Custom binary format")
        .value("NONE", formats::MetadataType::NONE)
        .value("JSON", formats::MetadataType::JSON)
        .value("PROTOBUF", formats::MetadataType::PROTOBUF)
        .value("MSGPACK", formats::MetadataType::MSGPACK)
        .value("CUSTOM", formats::MetadataType::CUSTOM);

    // TblReaderV2 class
    py::class_<readers::TblReaderV2>(m, "TblReaderV2",
             "TBL v2 format reader with LZ4 decompression (NEW in v1.5.0)\n\n"
             "Features:\n"
             "- Memory-mapped I/O for zero-copy reads\n"
             "- Automatic LZ4 decompression\n"
             "- Checksum verification\n"
             "- Metadata access\n"
             "- Dimension-based filtering\n\n"
             "Example:\n"
             "    >>> reader = turboloader.TblReaderV2('dataset.tbl', verify_checksums=True)\n"
             "    >>> print(f'Samples: {reader.num_samples()}')\n"
             "    >>> data, size = reader.read_sample(0)\n"
             "    >>> metadata, meta_type = reader.read_metadata(0)")
        .def(py::init<const std::string&, bool>(),
             py::arg("path"),
             py::arg("verify_checksums") = true,
             "Create TBL v2 reader\n\n"
             "Args:\n"
             "    path (str): Path to TBL v2 file\n"
             "    verify_checksums (bool): Enable checksum verification (default: True)")
        .def("read_sample", [](readers::TblReaderV2& self, size_t index) {
            auto [data, size] = self.read_sample(index);
            // Return as Python bytes
            return py::bytes(reinterpret_cast<const char*>(data), size);
        }, py::arg("index"),
           "Read sample data by index\n\n"
           "Returns decompressed data if sample is compressed.\n"
           "Verifies checksum if verification is enabled.\n\n"
           "Args:\n"
           "    index (int): Sample index\n\n"
           "Returns:\n"
           "    bytes: Sample data (decompressed if needed)")
        .def("read_metadata", [](readers::TblReaderV2& self, size_t index) {
            auto [metadata, type] = self.read_metadata(index);
            return py::make_tuple(metadata, type);
        }, py::arg("index"),
           "Read metadata for a sample\n\n"
           "Args:\n"
           "    index (int): Sample index\n\n"
           "Returns:\n"
           "    tuple: (metadata_string, MetadataType)")
        .def("num_samples", &readers::TblReaderV2::num_samples,
             "Get number of samples in the file\n\n"
             "Returns:\n"
             "    int: Number of samples")
        .def("is_compressed", &readers::TblReaderV2::is_compressed,
             "Check if file uses compression\n\n"
             "Returns:\n"
             "    bool: True if compressed with LZ4")
        .def("has_metadata", &readers::TblReaderV2::has_metadata,
             "Check if file has metadata section\n\n"
             "Returns:\n"
             "    bool: True if file has metadata")
        .def("filter_by_dimensions", &readers::TblReaderV2::filter_by_dimensions,
             py::arg("min_width") = 0, py::arg("min_height") = 0,
             py::arg("max_width") = 0, py::arg("max_height") = 0,
             "Get indices of samples matching dimension filter\n\n"
             "Args:\n"
             "    min_width (int): Minimum width (0 = no filter)\n"
             "    min_height (int): Minimum height (0 = no filter)\n"
             "    max_width (int): Maximum width (0 = no filter)\n"
             "    max_height (int): Maximum height (0 = no filter)\n\n"
             "Returns:\n"
             "    list[int]: Matching sample indices")
        .def("filter_by_format", &readers::TblReaderV2::filter_by_format,
             py::arg("format"),
             "Get indices of samples matching format filter\n\n"
             "Args:\n"
             "    format (SampleFormat): Sample format to filter by\n\n"
             "Returns:\n"
             "    list[int]: Matching sample indices")
        .def("get_sample_info", [](readers::TblReaderV2& self, size_t index) {
            const auto& info = self.get_sample_info(index);
            py::dict result;
            result["offset"] = info.offset;
            result["size"] = info.size;
            result["uncompressed_size"] = info.uncompressed_size;
            result["width"] = info.width;
            result["height"] = info.height;
            result["format"] = info.format;
            result["is_compressed"] = info.is_compressed();
            result["has_metadata"] = info.has_metadata();
            return result;
        }, py::arg("index"),
           "Get sample information without reading data\n\n"
           "Args:\n"
           "    index (int): Sample index\n\n"
           "Returns:\n"
           "    dict: Sample info (offset, size, dimensions, format, flags)");

    // TblWriterV2 class
    py::class_<writers::TblWriterV2>(m, "TblWriterV2",
             "Streaming TBL v2 format writer with LZ4 compression (NEW in v1.5.0)\n\n"
             "Key improvements over v1:\n"
             "- Constant memory usage (streams samples directly to disk)\n"
             "- LZ4 compression support (40-60% additional space savings)\n"
             "- Metadata support (labels, dimensions, EXIF)\n"
             "- Data integrity checksums (CRC32/CRC16)\n"
             "- Dimension caching for fast filtered loading\n\n"
             "Example:\n"
             "    >>> writer = turboloader.TblWriterV2('output.tbl', enable_compression=True)\n"
             "    >>> with open('image.jpg', 'rb') as f:\n"
             "    >>>     data = f.read()\n"
             "    >>> idx = writer.add_sample(data, turboloader.SampleFormat.JPEG, width=256, height=256)\n"
             "    >>> writer.add_metadata(idx, '{\"label\": \"cat\"}', turboloader.MetadataType.JSON)\n"
             "    >>> writer.finalize()")
        .def(py::init<const std::string&, bool>(),
             py::arg("path"),
             py::arg("enable_compression") = true,
             "Create TBL v2 writer\n\n"
             "Args:\n"
             "    path (str): Output file path\n"
             "    enable_compression (bool): Enable LZ4 compression (default: True)")
        .def("add_sample", [](writers::TblWriterV2& self, py::bytes data,
                              formats::SampleFormat format, uint16_t width, uint16_t height) {
            // Convert Python bytes to C++ buffer
            char* buffer;
            Py_ssize_t length;
            if (PYBIND11_BYTES_AS_STRING_AND_SIZE(data.ptr(), &buffer, &length)) {
                throw std::runtime_error("Failed to extract bytes data");
            }
            return self.add_sample(reinterpret_cast<const uint8_t*>(buffer),
                                  length, format, width, height);
        }, py::arg("data"), py::arg("format"),
           py::arg("width") = 0, py::arg("height") = 0,
           "Add a sample to the TBL file\n\n"
           "Args:\n"
           "    data (bytes): Sample data\n"
           "    format (SampleFormat): Sample format (JPEG, PNG, etc.)\n"
           "    width (int): Image width (0 if unknown/not image)\n"
           "    height (int): Image height (0 if unknown/not image)\n\n"
           "Returns:\n"
           "    int: Index of the added sample")
        .def("add_metadata", &writers::TblWriterV2::add_metadata,
             py::arg("sample_index"), py::arg("metadata"),
             py::arg("type") = formats::MetadataType::JSON,
             "Add metadata for a sample\n\n"
             "Args:\n"
             "    sample_index (int): Index of the sample\n"
             "    metadata (str): Metadata content\n"
             "    type (MetadataType): Metadata type (default: JSON)")
        .def("finalize", &writers::TblWriterV2::finalize,
             "Finalize the TBL file\n\n"
             "Writes the header, index, data, and metadata sections.\n"
             "Must be called before closing the file.")
        .def("num_samples", &writers::TblWriterV2::num_samples,
             "Get the number of samples written\n\n"
             "Returns:\n"
             "    int: Number of samples")
        .def("is_compression_enabled", &writers::TblWriterV2::is_compression_enabled,
             "Check if compression is enabled\n\n"
             "Returns:\n"
             "    bool: True if LZ4 compression is enabled")
        .def("__enter__", [](writers::TblWriterV2& self) -> writers::TblWriterV2& {
            return self;
        }, "Context manager entry")
        .def("__exit__", [](writers::TblWriterV2& self, py::object, py::object, py::object) {
            self.finalize();
        }, "Context manager exit (auto-finalizes)");
}
