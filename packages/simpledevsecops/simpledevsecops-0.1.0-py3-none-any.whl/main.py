#!/usr/bin/env python3
"""
Enhanced Universal DevSecOps Pipeline Generator
Interactive tool to create secure, optimized CI/CD pipelines with professional formatting
"""

import os
import yaml
import textwrap
from datetime import datetime

class PipelineGenerator:
    def __init__(self):
        self.pipeline_config = {}
        self.templates_dir = "templates"
        
    def clear_screen(self):
        os.system('cls' if os.name == 'nt' else 'clear')
    
    def print_banner(self):
        banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                ğŸš€ Enhanced DevSecOps Pipeline Generator               â•‘
â•‘           Secure & Optimized CI/CD Pipeline Creator                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        print(banner)
    
    def ask_question(self, question, options=None, default=None, required=True):
        """Ask interactive questions with validation"""
        while True:
            if options:
                print(f"\n{question}")
                for i, option in enumerate(options, 1):
                    print(f"  {i}. {option}")
                choice = input(f"\nChoose (1-{len(options)}): ").strip()
                if choice.isdigit() and 1 <= int(choice) <= len(options):
                    return options[int(choice) - 1]
                elif default and choice == "":
                    return default
                else:
                    print("âŒ Invalid choice. Please try again.")
            else:
                answer = input(f"\n{question}: ").strip()
                if required and not answer:
                    print("âŒ This field is required.")
                    continue
                return answer or default

    def format_yaml_with_comments(self, pipeline_data):
        """Convert pipeline data to YAML with proper formatting and comments"""
        yaml_str = yaml.dump(pipeline_data, default_flow_style=False, sort_keys=False, indent=2, width=1000)
        
        # Add comments and better formatting
        lines = yaml_str.split('\n')
        formatted_lines = []
        
        # Header comment
        formatted_lines.append("# =============================================================================")
        formatted_lines.append("# ğŸš€ Enhanced DevSecOps Pipeline - Auto-generated by Pipeline Generator")
        formatted_lines.append("# ğŸ“… Generated on: {}".format(datetime.now().strftime("%Y-%m-%d %H:%M:%S")))
        formatted_lines.append("# ğŸ”§ Technology: {}".format(self.pipeline_config.get('language', 'Unknown')))
        formatted_lines.append("# ğŸ”’ Security Features: OIDC, SAST, SCA, Container Scanning")
        formatted_lines.append("# =============================================================================")
        formatted_lines.append("")
        
        for line in lines:
            if line.strip():
                # Add comments based on context
                if line.startswith('name:'):
                    formatted_lines.append("# Pipeline Name")
                elif line.startswith("'on':"):
                    formatted_lines.append("")
                    formatted_lines.append("# Trigger Events - When to run this pipeline")
                elif line.startswith('env:'):
                    formatted_lines.append("")
                    formatted_lines.append("# Environment Variables")
                elif line.startswith('permissions:'):
                    formatted_lines.append("")
                    formatted_lines.append("# Security Permissions - OIDC and repository access")
                elif line.startswith('concurrency:'):
                    formatted_lines.append("")
                    formatted_lines.append("# Concurrency Control - Prevent overlapping runs")
                elif line.startswith('jobs:'):
                    formatted_lines.append("")
                    formatted_lines.append("# Pipeline Jobs - Execution sequence")
                
                # Job-specific comments
                elif any(job in line for job in ['setup:', 'security-scan:', 'build-test:', 'code-quality:', 'docker-build-scan:', 'deploy:']):
                    formatted_lines.append("")
                    job_name = line.replace(':', '').strip()
                    job_comments = {
                        'setup': "# 1ï¸âƒ£ SETUP - Initialize environment and dependencies",
                        'security-scan': "# 2ï¸âƒ£ SECURITY SCAN - Comprehensive security analysis",
                        'build-test': "# 3ï¸âƒ£ BUILD & TEST - Compile, test with coverage",
                        'code-quality': "# 4ï¸âƒ£ CODE QUALITY - SonarQube analysis and quality gate",
                        'docker-build-scan': "# 5ï¸âƒ£ DOCKER BUILD & SCAN - Secure container creation",
                        'deploy': "# 6ï¸âƒ£ DEPLOYMENT - Production deployment"
                    }
                    if job_name in job_comments:
                        formatted_lines.append(job_comments[job_name])
                
                # Step-specific comments
                elif 'name: ' in line and 'steps:' not in line:
                    step_name = line.split('name: ')[1].strip()
                    if 'Checkout' in step_name:
                        formatted_lines.append("    # ğŸ“¥ Source code checkout")
                    elif 'Setup' in step_name or 'Set up' in step_name:
                        formatted_lines.append("    # âš™ï¸ Environment setup")
                    elif 'Cache' in step_name:
                        formatted_lines.append("    # ğŸ’¾ Dependency caching for faster builds")
                    elif 'Trivy' in step_name:
                        formatted_lines.append("    # ğŸ” Vulnerability scanning")
                    elif 'Gitleaks' in step_name:
                        formatted_lines.append("    # ğŸ”’ Secret detection")
                    elif 'Bandit' in step_name:
                        formatted_lines.append("    # ğŸ” SAST analysis (Bandit)")
                    elif 'Build' in step_name and 'Docker' in step_name:
                        formatted_lines.append("    # ğŸ³ Docker image building with Buildx")
                    elif 'Scan' in step_name and 'Docker' in step_name:
                        formatted_lines.append("    # ğŸ” Container image security scan")
                    elif 'Push' in step_name and 'Docker' in step_name:
                        formatted_lines.append("    # ğŸ“¤ Push image to container registry")
                    elif 'SonarQube' in step_name:
                        formatted_lines.append("    # ğŸ“Š Code quality analysis")
                    elif 'Test' in step_name:
                        formatted_lines.append("    # ğŸ§ª Run automated tests with coverage")
                    elif 'Deploy' in step_name:
                        formatted_lines.append("    # ğŸš€ Production deployment")
                    elif 'Login' in step_name:
                        formatted_lines.append("    # ğŸ” OIDC authentication")
                    elif 'Configure AWS' in step_name:
                        formatted_lines.append("    # ğŸ”‘ AWS credentials via OIDC")
                
                formatted_lines.append(line)
        
        return '\n'.join(formatted_lines)

    def get_tech_stack(self):
        """Get technology stack details"""
        print("\nğŸ”§ TECHNOLOGY STACK CONFIGURATION")
        print("=" * 50)
        
        self.pipeline_config['language'] = self.ask_question(
            "Which programming language?",
            ["Java", "Python", "Node.js", "Go", "DotNet", "Other"]
        )
        
        if self.pipeline_config['language'] == "Java":
            self.pipeline_config['build_tool'] = self.ask_question(
                "Which build tool?",
                ["Maven", "Gradle"]
            )
            self.pipeline_config['java_version'] = self.ask_question(
                "Java version?",
                ["8", "11", "17", "21"], 
                "17"
            )
        
        elif self.pipeline_config['language'] == "Python":
            self.pipeline_config['python_version'] = self.ask_question(
                "Python version?",
                ["3.8", "3.9", "3.10", "3.11", "3.12"],
                "3.10"
            )
            self.pipeline_config['framework'] = self.ask_question(
                "Which framework?",
                ["FastAPI", "Django", "Flask", "None"]
            )
            # Add SAST tool for Python
            self.pipeline_config['use_bandit'] = self.ask_question(
                "Use Bandit for Python SAST?",
                ["Yes", "No"],
                "Yes"
            ) == "Yes"
        
        elif self.pipeline_config['language'] == "Node.js":
            self.pipeline_config['node_version'] = self.ask_question(
                "Node.js version?",
                ["16", "18", "20", "21"],
                "18"
            )
            self.pipeline_config['package_manager'] = self.ask_question(
                "Package manager?",
                ["npm", "yarn", "pnpm"]
            )
    
    def get_containerization(self):
        """Get containerization preferences"""
        print("\nğŸ³ CONTAINERIZATION CONFIGURATION")
        print("=" * 50)
        
        self.pipeline_config['use_docker'] = self.ask_question(
            "Use Docker for containerization?",
            ["Yes", "No"], 
            "Yes"
        ) == "Yes"
        
        if self.pipeline_config['use_docker']:
            self.pipeline_config['registry'] = self.ask_question(
                "Which container registry?",
                ["AWS ECR", "Docker Hub", "Google GCR", "Azure ACR", "GitHub Packages", "None"]
            )
            
            if self.pipeline_config['registry'] != "None":
                self.pipeline_config['multi_arch'] = self.ask_question(
                    "Build multi-architecture images?",
                    ["Yes", "No"],
                    "Yes"
                ) == "Yes"
                
                self.pipeline_config['use_buildx'] = self.ask_question(
                    "Use Docker Buildx for better caching?",
                    ["Yes", "No"],
                    "Yes"
                ) == "Yes"
    
    def get_security_checks(self):
        """Get security scanning preferences"""
        print("\nğŸ›¡ï¸ SECURITY CONFIGURATION")
        print("=" * 50)
        
        self.pipeline_config['use_sonarqube'] = self.ask_question(
            "Use SonarQube for code quality?",
            ["Yes", "No"],
            "Yes"
        ) == "Yes"
        
        self.pipeline_config['use_trivy'] = self.ask_question(
            "Use Trivy for vulnerability scanning?",
            ["Yes", "No"], 
            "Yes"
        ) == "Yes"
        
        self.pipeline_config['use_gitleaks'] = self.ask_question(
            "Use Gitleaks for secret detection?",
            ["Yes", "No"],
            "Yes"
        ) == "Yes"
        
        # Language-specific SAST tools
        if self.pipeline_config['language'] == "Java":
            self.pipeline_config['use_spotbugs'] = self.ask_question(
                "Use SpotBugs for Java SAST?",
                ["Yes", "No"],
                "Yes"
            ) == "Yes"
        
        if self.pipeline_config['use_trivy']:
            self.pipeline_config['trivy_severity'] = self.ask_question(
                "Fail pipeline on which severity levels?",
                ["CRITICAL", "CRITICAL,HIGH", "CRITICAL,HIGH,MEDIUM"],
                "CRITICAL,HIGH"
            )
        
        # OIDC configuration
        self.pipeline_config['use_oidc'] = self.ask_question(
            "Use OIDC for cloud authentication (recommended)?",
            ["Yes", "No"],
            "Yes"
        ) == "Yes"
    
    def get_deployment(self):
        """Get deployment preferences"""
        print("\nğŸš€ DEPLOYMENT CONFIGURATION")
        print("=" * 50)
        
        self.pipeline_config['deployment_target'] = self.ask_question(
            "Deployment target?",
            ["AWS ECS", "AWS EKS", "Kubernetes", "AWS Lambda", "VM/Server", "None"]
        )
        
        self.pipeline_config['environment'] = self.ask_question(
            "Environment strategy?",
            ["Single environment", "Dev/Stage/Prod", "Feature branches"]
        )
    
    def get_advanced_options(self):
        """Get advanced pipeline options"""
        print("\nâš™ï¸ ADVANCED OPTIONS")
        print("=" * 50)
        
        self.pipeline_config['cache_dependencies'] = self.ask_question(
            "Cache dependencies for faster builds?",
            ["Yes", "No"],
            "Yes"
        ) == "Yes"
        
        self.pipeline_config['parallel_jobs'] = self.ask_question(
            "Run jobs in parallel where possible?",
            ["Yes", "No"], 
            "Yes"
        ) == "Yes"
        
        self.pipeline_config['notifications'] = self.ask_question(
            "Enable pipeline notifications?",
            ["Slack", "Email", "Teams", "None"],
            "None"
        )
        
        self.pipeline_config['timeout_minutes'] = self.ask_question(
            "Job timeout in minutes?",
            ["30", "60", "90", "120"],
            "60"
        )
        
        self.pipeline_config['concurrency_control'] = self.ask_question(
            "Enable concurrency control?",
            ["Yes", "No"],
            "Yes"
        ) == "Yes"
    
    def generate_pipeline_name(self):
        """Generate a meaningful pipeline name"""
        lang = self.pipeline_config.get('language', 'app').lower()
        return f"{lang}-devsecops-pipeline"
    
    def generate_pipeline_yaml(self):
        """Generate the final pipeline YAML"""
        pipeline_name = self.generate_pipeline_name()
        
        # Base pipeline structure
        pipeline = {
            'name': pipeline_name,
            'on': {
                'push': {
                    'branches': ['main', 'develop']
                },
                'pull_request': {
                    'branches': ['main', 'develop']
                }
            },
            'env': self.generate_environment_vars(),
            'jobs': self.generate_jobs()
        }
        
        # Add permissions for OIDC
        if self.pipeline_config.get('use_oidc', False):
            pipeline['permissions'] = {
                'id-token': 'write',
                'contents': 'read'
            }
        
        # Add concurrency control
        if self.pipeline_config.get('concurrency_control', False):
            pipeline['concurrency'] = {
                'group': f"${{{{ github.workflow }}}}-${{{{ github.ref }}}}",
                'cancel-in-progress': True
            }
        
        return pipeline
    
    def generate_environment_vars(self):
        """Generate environment variables based on configuration"""
        env_vars = {
            'AWS_REGION': 'us-east-1'
        }
        
        if self.pipeline_config['language'] == "Java":
            env_vars['JAVA_VERSION'] = self.pipeline_config.get('java_version', '17')
        elif self.pipeline_config['language'] == "Python":
            env_vars['PYTHON_VERSION'] = self.pipeline_config.get('python_version', '3.10')
        elif self.pipeline_config['language'] == "Node.js":
            env_vars['NODE_VERSION'] = self.pipeline_config.get('node_version', '18')
        
        if self.pipeline_config['use_docker'] and self.pipeline_config['registry'] != "None":
            env_vars['IMAGE_TAG'] = '${{ github.sha }}'
            env_vars['ECR_REPO'] = f"{self.pipeline_config['language'].lower()}-app"
            if self.pipeline_config['registry'] == "AWS ECR":
                env_vars['ECR_REGISTRY'] = '${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com'
        
        return env_vars
    
    def generate_jobs(self):
        """Generate jobs based on configuration"""
        jobs = {}
        
        # Setup job
        jobs['setup'] = self.generate_setup_job()
        
        # Security jobs
        if any([self.pipeline_config['use_trivy'], self.pipeline_config['use_gitleaks'], 
                self.pipeline_config.get('use_bandit', False), self.pipeline_config.get('use_spotbugs', False)]):
            jobs['security-scan'] = self.generate_security_job()
        
        # Build and test jobs
        jobs['build-test'] = self.generate_build_test_job()
        
        # Code quality job
        if self.pipeline_config['use_sonarqube']:
            jobs['code-quality'] = self.generate_code_quality_job()
        
        # Docker build and scan job
        if self.pipeline_config['use_docker'] and self.pipeline_config['registry'] != "None":
            jobs['docker-build-scan'] = self.generate_docker_job()
        
        # Deployment job
        if self.pipeline_config['deployment_target'] != "None":
            jobs['deploy'] = self.generate_deployment_job()
        
        return jobs
    
    def generate_setup_job(self):
        """Generate setup job configuration"""
        steps = [
            {
                'name': 'Checkout Code',
                'uses': 'actions/checkout@v4'
            },
            {
                'name': 'Setup Build Environment',
                'run': f"echo 'Setting up environment for {self.pipeline_config['language']}'"
            }
        ]
        
        # Add dependency caching if enabled
        if self.pipeline_config['cache_dependencies']:
            cache_step = self.generate_cache_step()
            if cache_step:
                steps.append(cache_step)
        
        return {
            'runs-on': 'ubuntu-latest',
            'timeout-minutes': int(self.pipeline_config.get('timeout_minutes', 60)),
            'steps': steps
        }
    
    def generate_cache_step(self):
        """Generate cache step based on language"""
        if self.pipeline_config['language'] == "Java":
            return {
                'name': 'Cache Maven Dependencies',
                'uses': 'actions/cache@v3',
                'with': {
                    'path': '~/.m2',
                    'key': f"maven-${{{{ hashFiles('**/pom.xml') }}}}",
                    'restore-keys': 'maven-'
                }
            }
        elif self.pipeline_config['language'] == "Python":
            return {
                'name': 'Cache Pip Dependencies',
                'uses': 'actions/cache@v3',
                'with': {
                    'path': '~/.cache/pip',
                    'key': f"pip-${{{{ hashFiles('**/requirements.txt') }}}}"
                }
            }
        elif self.pipeline_config['language'] == "Node.js":
            return {
                'name': 'Cache Node Modules',
                'uses': 'actions/cache@v3',
                'with': {
                    'path': '**/node_modules',
                    'key': f"node-${{{{ hashFiles('**/package-lock.json') }}}}"
                }
            }
        return None
    
    def generate_security_job(self):
        """Generate security scanning job"""
        steps = [
            {
                'name': 'Checkout Code',
                'uses': 'actions/checkout@v4'
            }
        ]
        
        # Language-specific SAST tools
        if self.pipeline_config['language'] == "Python" and self.pipeline_config.get('use_bandit', False):
            steps.extend([
                {
                    'name': 'Run Bandit SAST',
                    'run': 'pip install bandit && bandit -r . -f json -o bandit-results.json || true'
                },
                {
                    'name': 'Upload Bandit Report',
                    'uses': 'actions/upload-artifact@v4',
                    'if': 'always()',
                    'with': {
                        'name': 'bandit-report',
                        'path': 'bandit-results.json',
                        'retention-days': 30
                    }
                }
            ])
        
        elif self.pipeline_config['language'] == "Java" and self.pipeline_config.get('use_spotbugs', False):
            steps.append({
                'name': 'Run SpotBugs Analysis',
                'run': 'mvn spotbugs:check || true'
            })
        
        if self.pipeline_config['use_trivy']:
            steps.extend([
                {
                    'name': 'Run Trivy FS Scan',
                    'uses': 'aquasecurity/trivy-action@master',
                    'with': {
                        'scan-type': 'fs',
                        'scan-ref': '.',
                        'format': 'sarif',
                        'output': 'trivy-results.sarif',
                        'exit-code': '1',
                        'severity': self.pipeline_config.get('trivy_severity', 'CRITICAL,HIGH')
                    }
                },
                {
                    'name': 'Upload Trivy Scan Results',
                    'uses': 'github/codeql-action/upload-sarif@v3',
                    'if': 'always()',
                    'with': {
                        'sarif_file': 'trivy-results.sarif'
                    }
                }
            ])
        
        if self.pipeline_config['use_gitleaks']:
            steps.append({
                'name': 'Run Gitleaks Secret Detection',
                'uses': 'gitleaks/gitleaks-action@v2',
                'with': {
                    'config-path': '.gitleaks.toml'
                }
            })
        
        return {
            'runs-on': 'ubuntu-latest',
            'needs': 'setup',
            'timeout-minutes': int(self.pipeline_config.get('timeout_minutes', 60)),
            'steps': steps
        }
    
    def generate_build_test_job(self):
        """Generate build and test job with coverage"""
        steps = [
            {
                'name': 'Checkout Code',
                'uses': 'actions/checkout@v4'
            }
        ]
        
        # Language-specific setup
        if self.pipeline_config['language'] == "Java":
            steps.extend([
                {
                    'name': 'Set up JDK',
                    'uses': 'actions/setup-java@v4',
                    'with': {
                        'java-version': self.pipeline_config.get('java_version', '17'),
                        'distribution': 'temurin',
                        'cache': self.pipeline_config.get('build_tool', 'maven').lower()
                    }
                },
                {
                    'name': 'Build with Coverage',
                    'run': 'mvn clean test jacoco:report' if self.pipeline_config.get('build_tool') == 'Maven' else 'gradle test jacocoTestReport'
                }
            ])
        
        elif self.pipeline_config['language'] == "Python":
            steps.extend([
                {
                    'name': 'Set up Python',
                    'uses': 'actions/setup-python@v4',
                    'with': {
                        'python-version': self.pipeline_config.get('python_version', '3.10')
                    }
                },
                {
                    'name': 'Install Dependencies',
                    'run': 'pip install -r requirements.txt pytest-cov'
                },
                {
                    'name': 'Run Tests with Coverage',
                    'run': 'python -m pytest --junitxml=test-results.xml --cov=./ --cov-report=xml --cov-report=html || true'
                }
            ])
        
        elif self.pipeline_config['language'] == "Node.js":
            steps.extend([
                {
                    'name': 'Set up Node.js',
                    'uses': 'actions/setup-node@v4',
                    'with': {
                        'node-version': self.pipeline_config.get('node_version', '18'),
                        'cache': self.pipeline_config.get('package_manager', 'npm')
                    }
                },
                {
                    'name': 'Install Dependencies',
                    'run': f"{self.pipeline_config.get('package_manager', 'npm')} install"
                },
                {
                    'name': 'Run Tests with Coverage',
                    'run': f"{self.pipeline_config.get('package_manager', 'npm')} run test:coverage"
                }
            ])
        
        # Upload test results and coverage
        test_artifact_config = self.get_test_artifact_config()
        steps.append({
            'name': 'Upload Test Results',
            'uses': 'actions/upload-artifact@v4',
            'if': 'always()',
            'with': test_artifact_config
        })
        
        return {
            'runs-on': 'ubuntu-latest',
            'needs': 'security-scan' if any([self.pipeline_config['use_trivy'], self.pipeline_config['use_gitleaks']]) else 'setup',
            'timeout-minutes': int(self.pipeline_config.get('timeout_minutes', 60)),
            'steps': steps
        }
    
    def get_test_artifact_config(self):
        """Get test artifact configuration based on language"""
        if self.pipeline_config['language'] == "Java":
            return {
                'name': 'test-results',
                'path': '**/target/surefire-reports/,**/target/jacoco-reports/',
                'retention-days': 30
            }
        elif self.pipeline_config['language'] == "Python":
            return {
                'name': 'test-results',
                'path': 'test-results.xml,coverage.xml,htmlcov/',
                'retention-days': 30
            }
        else:
            return {
                'name': 'test-results',
                'path': 'test-results.xml',
                'retention-days': 30
            }
    
    def generate_code_quality_job(self):
        """Generate SonarQube code quality job"""
        steps = [
            {
                'name': 'Checkout Code',
                'uses': 'actions/checkout@v4',
                'with': {
                    'fetch-depth': 0
                }
            }
        ]
        
        # Add language-specific setup for SonarQube
        if self.pipeline_config['language'] == "Java":
            steps.append({
                'name': 'Set up JDK',
                'uses': 'actions/setup-java@v4',
                'with': {
                    'java-version': self.pipeline_config.get('java_version', '17'),
                    'distribution': 'temurin'
                }
            })
        elif self.pipeline_config['language'] == "Python":
            steps.append({
                'name': 'Set up Python',
                'uses': 'actions/setup-python@v4',
                'with': {
                    'python-version': self.pipeline_config.get('python_version', '3.10')
                }
            })
        
        # SonarQube analysis with coverage
        sonar_steps = [
            {
                'name': 'SonarQube Scan',
                'uses': 'SonarSource/sonarqube-scan-action@v5.0.0',
                'env': {
                    'SONAR_TOKEN': '${{ secrets.SONAR_TOKEN }}',
                    'SONAR_HOST_URL': '${{ vars.SONAR_HOST_URL }}'
                }
            },
            {
                'name': 'SonarQube Quality Gate Check',
                'uses': 'sonarsource/sonarqube-quality-gate-action@master',
                'timeout-minutes': 10,
                'env': {
                    'SONAR_TOKEN': '${{ secrets.SONAR_TOKEN }}'
                }
            }
        ]
        
        steps.extend(sonar_steps)
        
        return {
            'runs-on': 'ubuntu-latest',
            'needs': 'build-test',
            'timeout-minutes': int(self.pipeline_config.get('timeout_minutes', 60)),
            'steps': steps
        }
    
    def generate_docker_job(self):
        """Generate Docker build and scan job with optimizations"""
        steps = [
            {
                'name': 'Checkout Code',
                'uses': 'actions/checkout@v4'
            }
        ]
        
        # AWS authentication with OIDC
        if self.pipeline_config['registry'] == "AWS ECR":
            if self.pipeline_config.get('use_oidc', False):
                steps.extend([
                    {
                        'name': 'Configure AWS Credentials via OIDC',
                        'uses': 'aws-actions/configure-aws-credentials@v4',
                        'with': {
                            'role-to-assume': '${{ secrets.AWS_ROLE_ARN }}',
                            'aws-region': '${{ env.AWS_REGION }}',
                            'role-session-name': 'GitHubActions-OIDC'
                        }
                    }
                ])
            else:
                steps.extend([
                    {
                        'name': 'Configure AWS credentials',
                        'uses': 'aws-actions/configure-aws-credentials@v4',
                        'with': {
                            'aws-access-key-id': '${{ secrets.AWS_ACCESS_KEY_ID }}',
                            'aws-secret-access-key': '${{ secrets.AWS_SECRET_ACCESS_KEY }}',
                            'aws-region': '${{ env.AWS_REGION }}'
                        }
                    }
                ])
            
            steps.append({
                'name': 'Login to AWS ECR',
                'id': 'login-ecr',
                'uses': 'aws-actions/amazon-ecr-login@v2'
            })
        
        # Docker setup with Buildx and caching
        if self.pipeline_config.get('use_buildx', False):
            steps.extend([
                {
                    'name': 'Set up Docker Buildx',
                    'uses': 'docker/setup-buildx-action@v3'
                },
                {
                    'name': 'Cache Docker layers',
                    'uses': 'actions/cache@v3',
                    'with': {
                        'path': '/tmp/.buildx-cache',
                        'key': f"${{{{ runner.os }}}}-buildx-${{{{ github.sha }}}}",
                        'restore-keys': f"${{{{ runner.os }}}}-buildx-"
                    }
                }
            ])
        
        # Build steps
        if self.pipeline_config.get('use_buildx', False):
            build_steps = [
                {
                    'name': 'Build and Push Docker Image',
                    'uses': 'docker/build-push-action@v5',
                    'with': {
                        'context': '.',
                        'push': True,
                        'tags': '$ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG',
                        'cache-from': 'type=local,src=/tmp/.buildx-cache',
                        'cache-to': 'type=local,dest=/tmp/.buildx-cache-new,mode=max',
                        'platform': 'linux/amd64,linux/arm64' if self.pipeline_config.get('multi_arch', False) else 'linux/amd64'
                    }
                }
            ]
        else:
            build_steps = [
                {
                    'name': 'Build Docker Image',
                    'run': f"docker build -t $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG ."
                }
            ]
        
        steps.extend(build_steps)
        
        # Security scanning
        if self.pipeline_config['use_trivy']:
            steps.append({
                'name': 'Scan Docker Image',
                'run': f"trivy image --exit-code 1 --severity {self.pipeline_config.get('trivy_severity', 'CRITICAL,HIGH')} --format sarif -o trivy-image.sarif $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG"
            })
            
            steps.append({
                'name': 'Upload Trivy Image Scan',
                'uses': 'github/codeql-action/upload-sarif@v3',
                'if': 'always()',
                'with': {
                    'sarif_file': 'trivy-image.sarif'
                }
            })
        
        return {
            'runs-on': 'ubuntu-latest',
            'needs': 'code-quality' if self.pipeline_config['use_sonarqube'] else 'build-test',
            'timeout-minutes': int(self.pipeline_config.get('timeout_minutes', 60)),
            'steps': steps
        }
    
    def generate_deployment_job(self):
        """Generate deployment job with OIDC"""
        steps = [
            {
                'name': 'Checkout Code',
                'uses': 'actions/checkout@v4'
            }
        ]
        
        # AWS authentication with OIDC
        if self.pipeline_config['deployment_target'] in ["AWS ECS", "AWS EKS", "AWS Lambda"]:
            if self.pipeline_config.get('use_oidc', False):
                steps.append({
                    'name': 'Configure AWS Credentials via OIDC',
                    'uses': 'aws-actions/configure-aws-credentials@v4',
                    'with': {
                        'role-to-assume': '${{ secrets.AWS_ROLE_ARN }}',
                        'aws-region': '${{ env.AWS_REGION }}',
                        'role-session-name': 'GitHubActions-Deploy'
                    }
                })
            else:
                steps.append({
                    'name': 'Configure AWS credentials',
                    'uses': 'aws-actions/configure-aws-credentials@v4',
                    'with': {
                        'aws-access-key-id': '${{ secrets.AWS_ACCESS_KEY_ID }}',
                        'aws-secret-access-key': '${{ secrets.AWS_SECRET_ACCESS_KEY }}',
                        'aws-region': '${{ env.AWS_REGION }}'
                    }
                })
        
        steps.append({
            'name': 'Deploy Application',
            'run': f"echo 'Deploying to {self.pipeline_config['deployment_target']}'"
        })
        
        needs_job = 'docker-build-scan' if self.pipeline_config['use_docker'] and self.pipeline_config['registry'] != "None" else 'code-quality' if self.pipeline_config['use_sonarqube'] else 'build-test'
        
        return {
            'runs-on': 'ubuntu-latest',
            'needs': needs_job,
            'environment': 'production',
            'timeout-minutes': int(self.pipeline_config.get('timeout_minutes', 60)),
            'steps': steps
        }
    
    def save_pipeline(self, formatted_yaml, filename):
        """Save generated pipeline to file"""
        os.makedirs('generated-pipelines', exist_ok=True)
        filepath = os.path.join('generated-pipelines', filename)
        
        with open(filepath, 'w', encoding='utf-8') as file:
            file.write(formatted_yaml)
        
        return filepath
    
    def validate_pipeline(self, pipeline_yaml):
        """Validate the generated pipeline for common errors"""
        errors = []
        pipeline_str = str(pipeline_yaml)
        
        # Check for required secrets based on configuration
        if self.pipeline_config.get('use_oidc', False):
            if 'AWS_ROLE_ARN' not in pipeline_str:
                errors.append("âŒ AWS_ROLE_ARN secret required for OIDC authentication")
        else:
            if 'AWS_ACCESS_KEY_ID' in pipeline_str and 'secrets.AWS_ACCESS_KEY_ID' not in pipeline_str:
                errors.append("âŒ AWS_ACCESS_KEY_ID secret required")
        
        if 'SONAR_TOKEN' in pipeline_str and 'secrets.SONAR_TOKEN' not in pipeline_str:
            errors.append("âŒ SonarQube token secret is missing")
        
        # Check job dependencies
        jobs = pipeline_yaml.get('jobs', {})
        for job_name, job_config in jobs.items():
            if 'needs' in job_config:
                needs = job_config['needs']
                if isinstance(needs, str) and needs not in jobs:
                    errors.append(f"âŒ Job '{job_name}' depends on non-existent job '{needs}'")
                elif isinstance(needs, list):
                    for needed_job in needs:
                        if needed_job not in jobs:
                            errors.append(f"âŒ Job '{job_name}' depends on non-existent job '{needed_job}'")
        
        return errors
    
    def run(self):
        """Main execution method"""
        self.clear_screen()
        self.print_banner()
        
        print("ğŸ¯ Let's create your Enhanced Secure DevSecOps Pipeline!")
        print("   I'll ask you a few questions to customize it...\n")
        
        # Collect all configuration
        self.get_tech_stack()
        self.get_containerization()
        self.get_security_checks()
        self.get_deployment()
        self.get_advanced_options()
        
        # Generate pipeline
        pipeline_data = self.generate_pipeline_yaml()
        formatted_yaml = self.format_yaml_with_comments(pipeline_data)
        
        # Validate pipeline
        validation_errors = self.validate_pipeline(pipeline_data)
        
        # Ask for filename
        default_filename = f"{self.generate_pipeline_name()}.yaml"
        filename = self.ask_question(
            f"What should be the pipeline filename?",
            default=default_filename,
            required=True
        )
        
        if not filename.endswith('.yaml') and not filename.endswith('.yml'):
            filename += '.yaml'
        
        # Save pipeline
        saved_path = self.save_pipeline(formatted_yaml, filename)
        
        # Show summary
        self.clear_screen()
        self.print_banner()
        
        print("âœ… ENHANCED SECURE PIPELINE GENERATED SUCCESSFULLY!")
        print("=" * 60)
        print(f"ğŸ“ File: {saved_path}")
        print(f"ğŸ”§ Language: {self.pipeline_config['language']}")
        print(f"ğŸ³ Docker: {'Yes' if self.pipeline_config['use_docker'] else 'No'}")
        print(f"ğŸ”’ OIDC Auth: {'Yes' if self.pipeline_config.get('use_oidc', False) else 'No'}")
        print(f"ğŸ›¡ï¸ Security Scans: {sum([self.pipeline_config['use_sonarqube'], self.pipeline_config['use_trivy'], self.pipeline_config['use_gitleaks'], self.pipeline_config.get('use_bandit', False), self.pipeline_config.get('use_spotbugs', False)])}")
        print(f"ğŸš€ Deployment: {self.pipeline_config['deployment_target']}")
        
        if validation_errors:
            print(f"\nâš ï¸  Validation Warnings:")
            for error in validation_errors:
                print(f"   {error}")
        
        print("\nğŸ†• Enhanced Security Features:")
        print("   âœ… OIDC authentication for AWS (recommended)")
        print("   âœ… Bandit SAST for Python code")
        print("   âœ… Docker Buildx with layer caching")
        print("   âœ… Test coverage integration")
        print("   âœ… SARIF report uploads")
        print("   âœ… Job timeouts and concurrency control")
        print("   âœ… Multi-architecture Docker builds")
        
        print("\nğŸ”‘ Required Secrets:")
        required_secrets = []
        
        if self.pipeline_config.get('use_oidc', False):
            required_secrets.append("AWS_ROLE_ARN")
        else:
            if self.pipeline_config['use_docker'] and self.pipeline_config['registry'] == "AWS ECR":
                required_secrets.extend(["AWS_ACCOUNT_ID", "AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"])
            if self.pipeline_config['deployment_target'] in ["AWS ECS", "AWS EKS", "AWS Lambda"]:
                required_secrets.extend(["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"])
        
        if self.pipeline_config['use_sonarqube']:
            required_secrets.append("SONAR_TOKEN")
        
        for secret in set(required_secrets):
            print(f"   - {secret}")
        
        print("\nâš¡ Performance Optimizations:")
        print("   âœ… Dependency caching")
        print("   âœ… Docker layer caching")
        print("   âœ… Buildx for parallel builds")
        print("   âœ… Concurrency control")
        
        print("\nğŸ‰ Happy coding! Your enhanced secure pipeline is ready!")

def main():
    """Main function"""
    try:
        generator = PipelineGenerator()
        generator.run()
    except KeyboardInterrupt:
        print("\n\nâŒ Pipeline generation cancelled.")
    except Exception as e:
        print(f"\n\nğŸ’¥ An error occurred: {e}")

if __name__ == "__main__":
    main()