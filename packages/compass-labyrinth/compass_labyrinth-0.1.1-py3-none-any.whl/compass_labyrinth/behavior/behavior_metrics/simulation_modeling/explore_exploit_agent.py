"""
EXPLORATION-EXPLOITATION AGENT MODELING AND ANALYSIS
Author: Shreya Bangera
"""

import pandas as pd
import numpy as np
import random
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

from .simulated_agent import trim_to_common_epochs


###############################################################
# Exploration-Exploitation Agent Evaluation
###############################################################
def track_valid_and_optimal_transitions_EE(
    df: pd.DataFrame,
    decision_label: str,
    reward_label: str,
) -> tuple[dict, dict]:
    """
    Tracks valid and optimal transitions for an exploration-exploitation agent.

    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame containing maze navigation data.
    decision_label : str
        Label indicating decision nodes.
    reward_label : str
        Label indicating reward paths.

    Returns:
    --------
    valid_transitions : dict
        Dictionary of valid transitions per session.
    optimal_transitions : dict
        Dictionary of optimal transitions per session.
    """
    valid_transitions, optimal_transitions = {}, {}

    for session, group in df.groupby("Session"):
        session_valid, session_optimal = {}, {}

        for i in range(len(group) - 1):
            if group.iloc[i]["NodeType"] == decision_label:
                current = group.iloc[i]["Grid Number"]
                next_grid = group.iloc[i + 1]["Grid Number"]
                next_region = group.iloc[i + 1]["Region"]

                session_valid.setdefault(current, set()).add(next_grid)
                if next_region == reward_label:
                    session_optimal.setdefault(current, set()).add(next_grid)

        valid_transitions[session] = session_valid
        optimal_transitions[session] = session_optimal

    return valid_transitions, optimal_transitions


# ------------------------------
# Agent Simulation Function
# ------------------------------
def simulate_exploration_agent_EE(
    segment: pd.DataFrame,
    valid_dict: dict,
    optimal_dict: dict,
    exploration_rate: float,
    n_simulations: int,
    decision_label: str,
) -> tuple[list, list]:
    """
    Simulates the behavior of an exploration-exploitation agent.

    Parameters:
    -----------
    segment : pd.DataFrame
        DataFrame segment containing maze navigation data.
    valid_dict : dict
        Dictionary of valid transitions.
    optimal_dict : dict
        Dictionary of optimal transitions.
    exploration_rate : float
        Probability of exploring a non-optimal path.
    n_simulations : int
        Number of simulations to run per decision point.
    decision_label : str
        Label indicating decision nodes.

    Returns:
    --------
    actual : list
        List of actual outcomes (1 for optimal, 0 for non-optimal).
    simulated : list
        List of simulated outcomes (mean proportion of optimal choices).
    """
    actual, simulated = [], []

    for i in range(len(segment) - 1):
        if segment.iloc[i]["NodeType"] == decision_label:
            curr = segment.iloc[i]["Grid Number"]
            actual_next = segment.iloc[i + 1]["Grid Number"]

            actual.append(1 if actual_next in optimal_dict.get(curr, set()) else 0)
            trials = []
            for _ in range(n_simulations):
                if curr in valid_dict:
                    if random.random() > exploration_rate and curr in optimal_dict:
                        choice = random.choice(list(optimal_dict[curr]))
                    else:
                        choice = random.choice(list(valid_dict[curr]))

                    trials.append(1 if choice in optimal_dict.get(curr, set()) else 0)
            simulated.append(np.mean(trials))

    return actual, simulated


# ------------------------------
# Metric Calculation Function
# ------------------------------
def calculate_segment_metrics_EE(
    segment: pd.DataFrame,
    valid_dict: dict,
    optimal_dict: dict,
    exploration_rate: float,
    n_bootstrap: int,
    n_simulations: int,
    decision_label: str,
) -> pd.Series:
    """
    Calculates performance metrics for a segment of maze navigation data.

    Parameters:
    -----------
    segment : pd.DataFrame
        DataFrame segment containing maze navigation data.
    valid_dict : dict
        Dictionary of valid transitions.
    optimal_dict : dict
        Dictionary of optimal transitions.
    exploration_rate : float
        Probability of exploring a non-optimal path.
    n_bootstrap : int
        Number of bootstrap samples for confidence intervals.
    n_simulations : int
        Number of simulations to run per decision point.
    decision_label : str
        Label indicating decision nodes.

    Returns:
    --------
    pd.Series
        Series containing calculated metrics.
    """
    if segment.empty or decision_label not in segment["NodeType"].values:
        return pd.Series(
            {
                k: np.nan
                for k in [
                    "Actual Reward Path %",
                    "Agent Reward Path %",
                    "Actual Reward Path % CI Lower",
                    "Actual Reward Path % CI Upper",
                    "Agent Reward Path % CI Lower",
                    "Agent Reward Path % CI Upper",
                    "Relative Performance",
                ]
            }
        )

    actual, simulated = simulate_exploration_agent_EE(
        segment, valid_dict, optimal_dict, exploration_rate, n_simulations, decision_label
    )
    if not actual or not simulated:
        return pd.Series(
            {
                k: np.nan
                for k in [
                    "Actual Reward Path %",
                    "Agent Reward Path %",
                    "Actual Reward Path % CI Lower",
                    "Actual Reward Path % CI Upper",
                    "Agent Reward Path % CI Lower",
                    "Agent Reward Path % CI Upper",
                    "Relative Performance",
                ]
            }
        )

    def bootstrap(data):
        return np.random.choice(data, (n_bootstrap, len(data)), replace=True)

    actual_means = np.mean(bootstrap(actual), axis=1)
    agent_means = np.mean(bootstrap(simulated), axis=1)

    return pd.Series(
        {
            "Actual Reward Path %": np.mean(actual_means),
            "Agent Reward Path %": np.mean(agent_means),
            "Actual Reward Path % CI Lower": np.percentile(actual_means, 5),
            "Actual Reward Path % CI Upper": np.percentile(actual_means, 95),
            "Agent Reward Path % CI Lower": np.percentile(agent_means, 5),
            "Agent Reward Path % CI Upper": np.percentile(agent_means, 95),
            "Relative Performance": (
                np.mean(actual_means) / np.mean(agent_means) if np.mean(agent_means) > 0 else np.nan
            ),
        }
    )


# ------------------------------
# Data Split Utility
# ------------------------------
def split_sessions_into_segments_EE(df: pd.DataFrame, segment_size: int) -> list[tuple]:
    segments = []
    for _, group in df.groupby(["Genotype", "Session"]):
        n_parts = len(group) // segment_size + 1
        for i in range(n_parts):
            part = group.iloc[i * segment_size : (i + 1) * segment_size]
            if not part.empty:
                segments.append((group["Session"].iloc[0], i + 1, part))
    return segments


# ------------------------------
# Analysis Runner
# ------------------------------
def run_exploration_agent_analysis_EE(
    df: pd.DataFrame,
    exploration_rate: float,
    segment_size: int = 1000,
    n_bootstrap: int = 10000,
    n_simulations: int = 100,
    decision_label: str = "Decision (Reward)",
    reward_label: str = "reward_path",
    trim: bool = True,
) -> pd.DataFrame:
    """
    Run exploration agent analysis on the given DataFrame.

    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame containing maze navigation data.
    exploration_rate : float
        Probability of exploring a non-optimal path.
    segment_size : int, optional
        Size of each segment for analysis (default is 1000).
    n_bootstrap : int, optional
        Number of bootstrap samples for confidence intervals (default is 10000).
    n_simulations : int, optional
        Number of simulations to run per decision point (default is 100).
    decision_label : str, optional
        Label indicating decision nodes (default is "Decision (Reward)").
    reward_label : str, optional
        Label indicating reward paths (default is "reward_path").
    trim : bool, optional
        Whether to trim the DataFrame to common epochs (default is True).

    Returns:
    --------
    pd.DataFrame
        DataFrame containing analysis results for each segment.
    """
    valid_dict, optimal_dict = track_valid_and_optimal_transitions_EE(df, decision_label, reward_label)
    segments = split_sessions_into_segments_EE(df, segment_size)
    results = []

    for session, seg_num, segment in segments:
        metrics = calculate_segment_metrics_EE(
            segment,
            valid_dict.get(session, {}),
            optimal_dict.get(session, {}),
            exploration_rate,
            n_bootstrap,
            n_simulations,
            decision_label,
        )
        metrics["Session"] = session
        metrics["Epoch Number"] = seg_num
        results.append(metrics)

    results = pd.DataFrame(results)
    if trim:
        results = trim_to_common_epochs(results)

    return results


###############################################################
## Plot 7: Agent Performance Across Varying Exploration Rates
###############################################################
def plot_exploration_rate_performance_EE(
    config: dict,
    df_source: pd.DataFrame,
    exploration_rates: list[float],
    segment_size: int = 1000,
    decision_label: str = "Decision (Reward)",
    reward_label: str = "reward_path",
    trim: bool = True,
    save_fig: bool = True,
    show_fig: bool = True,
    return_fig: bool = False,
) -> None | plt.Figure:
    """
    Plots the performance of an exploration-exploitation agent across varying exploration rates.

    Parameters:
    -----------
    config : dict
        Configuration dictionary containing project settings.
    df_source : pd.DataFrame
        DataFrame containing maze navigation data.
    exploration_rates : list of float
        List of exploration rates to evaluate.
    segment_size : int, optional
        Size of each segment for analysis (default is 1000).
    decision_label : str, optional
        Label indicating decision nodes (default is "Decision (Reward)").
    reward_label : str, optional
        Label indicating reward paths (default is "reward_path").
    trim : bool, optional
        Whether to trim the DataFrame to common epochs (default is True).
    save_fig : bool, optional
        Whether to save the figure (default is True).
    show_fig : bool, optional
        Whether to display the figure (default is True).
    return_fig : bool, optional
        Whether to return the figure object (default is False).

    Returns:
    --------
    None or plt.Figure
        Returns the figure if return_fig is True, otherwise None.
    """
    fig = plt.figure(figsize=(15, 8))

    for er in exploration_rates:
        er_rounded = round(er, 1)
        print("Exploration rate = ", er_rounded, " being processed....")
        result_df = run_exploration_agent_analysis_EE(
            df_source,
            exploration_rate=er_rounded,
            segment_size=segment_size,
            decision_label=decision_label,
            reward_label=reward_label,
            trim=trim,
        )
        sns.lineplot(
            data=result_df,
            x="Epoch Number",
            y="Agent Reward Path %",
            linestyle="--",
            label=f"Agent (ER={er_rounded})",
        )

    # Plot actual performance
    last_df = run_exploration_agent_analysis_EE(
        df_source,
        exploration_rate=exploration_rates[-1],
        segment_size=segment_size,
        decision_label=decision_label,
        reward_label=reward_label,
        trim=trim,
    )
    sns.lineplot(
        data=last_df,
        x="Epoch Number",
        y="Actual Reward Path %",
        marker="o",
        label="Mouse",
        color="black",
    )

    plt.xlabel("Epochs (in maze)")
    plt.ylabel("Proportion of Reward Path Transitions")
    plt.title("Mouse vs. Exploration Agent Reward Path Transition Proportion")
    plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
    plt.grid(True)
    plt.tight_layout()

    # Save figure
    fig = plt.gcf()
    if save_fig:
        save_path = Path(config["project_path_full"]) / "figures" / "ee_agent.pdf"
        plt.savefig(save_path, bbox_inches="tight", dpi=300)
        print(f"Figure saved at: {save_path}")

    # Show figure
    if show_fig:
        plt.show()

    # Return figure
    if return_fig:
        return fig
