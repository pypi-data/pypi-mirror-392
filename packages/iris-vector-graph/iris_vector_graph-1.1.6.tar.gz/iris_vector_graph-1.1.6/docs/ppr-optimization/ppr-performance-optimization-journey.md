# PPR Performance Optimization Journey

**Date**: 2025-11-08
**Objective**: Optimize Personalized PageRank computation from 14ms baseline to sub-millisecond performance
**Status**: In Progress (T020-T025 Complete)

---

## Executive Summary

Successfully deployed PPR Functional Index to IRIS with real-time graph adjacency maintenance synchronized with SQL DML operations. Investigation of three implementation approaches (Pure Python, External Client with Functional Index, Embedded Python) revealed that **Pure Python remains the best production choice at 14ms for 1K nodes** until ObjectScript native implementation is completed.

### Key Findings

| Implementation | Performance | Status | Notes |
|---|---|---|---|
| **Pure Python** | 14ms | ‚úÖ Production | Baseline - SQL extraction + Python computation |
| **External Client** | 20,013ms | ‚úÖ Works | 1,400x slower due to API overhead |
| **Embedded Python** | 5ms (projected) | ‚ùå Blocked | Namespace isolation prevents Global access |
| **ObjectScript** | <10ms (target) | üîÑ Next | Native implementation recommended |

---

## Journey Timeline

### Phase 1: Functional Index Deployment (T020-T021) ‚úÖ

**Goal**: Deploy ObjectScript Functional Index to maintain ^PPR Globals synchronized with SQL

**Challenges Overcome**:
1. `Language = python` incompatibility with Functional Index callbacks
2. `New` variable declarations not allowed in generator context
3. Correct `CodeMode = objectgenerator` pattern implementation

**Result**: ‚úÖ **SUCCESS**
- Functional Index deployed and operational
- 6/6 integration tests passing
- Real-time ^PPR Global maintenance working correctly
- All 5 regression tests passing with both implementations

**Files Created**:
- `src/iris/Graph/KG/PPRFunctionalIndex.cls` (142 lines)
- `iris_vector_graph_core/ppr_functional_index.py` (175 lines)
- `tests/integration/test_ppr_functional_index_live.py` (361 lines, 6/6 passing)

### Phase 2: Performance Benchmarking (T022-T024) ‚úÖ

**Goal**: Measure performance improvement from Functional Index

**Benchmark Results** (1000 nodes, 5067 edges):
```
Pure Python (Baseline):    14.18ms
Functional Index:       20,013.42ms  (1,400x SLOWER ‚ùå)
```

**Root Cause Analysis**:
- **NOT a bug in the Functional Index** (which works correctly)
- Issue is in Python traversal code using **external client API**
- `intersystems_irispython` has high network/IPC overhead:
  - Each `irispy.iterator()` call involves separate request
  - Each `irispy.get()` call is independent network operation
  - No batching or caching available

**Recommendation**: Use embedded Python or ObjectScript for zero-copy access

### Phase 3: Embedded Python Attempt (T025) ‚ùå BLOCKED

**Goal**: Rewrite PPR using embedded Python (`iris.gref()`) for zero-copy Global access

**Expected Performance**: 2.62x faster than Pure Python (5.19ms vs 13.60ms based on initial test)

**What We Tried** (following IRIS development guidance on branch node traversal):
1. ‚úÖ NumPy removal - use pure Python lists instead
2. ‚úÖ `.keys()` method - **WORKS** but 4,000x slower (59,026ms vs 14ms baseline)
3. ‚ùå `.orderiter()` method - Returns zero results (empty iterator)
4. ‚ùå `.query()` method - Returns zero results (empty iterator)
5. ‚ùå Extended global references (`^|"USER"|PPR`, `^["USER"]PPR`) - Still zero results

**Performance Results** (1000 nodes, 5067 edges):
```
Pure Python (Baseline):         14ms      ‚úÖ BEST
Embedded Python (.keys()):   59,026ms    ‚ùå 4,000x SLOWER
Embedded Python (.query()):        0 results ‚ùå BROKEN
Embedded Python (.orderiter()):    0 results ‚ùå BROKEN
External Client:             20,013ms    ‚ùå 1,400x SLOWER
```

**Root Cause Analysis**:
- `.keys()` traverses entire subtree recursively ‚Üí terrible performance
- `.orderiter()` and `.query()` appear non-functional in embedded Python context
- External client `irispy.iterator()` works perfectly but has network/IPC overhead
- Only `.keys()` method works but defeats the purpose (slower than baseline)

**IRIS expert's Guidance Applied**:
- Understood that `^PPR("deg")` is branch node (data() returns 10, no scalar value)
- Used correct patterns: `ppr['deg'].query()` and `ppr['deg'].keys()`
- Tried extended global references for namespace qualification
- **Result**: Only `.keys()` works, but impractically slow

**Conclusion**: Embedded Python `iris.gref()` API is not viable for performance-critical Global traversal. The `.keys()` method works but is 4,000x slower than Pure Python baseline, defeating the optimization purpose.

**Documentation Created**:
- `docs/embedded-python-issues.md` - Complete API investigation for IRIS dev team
- Includes 6 specific API issues, performance measurements, and recommendations

---

## Lessons Learned

### 1. Functional Index Pattern (Production-Ready)

**Correct Pattern** for ObjectScript Functional Index:
```objectscript
ClassMethod InsertIndex(pID As %RawString, pArg... As %Binary)
    [ CodeMode = objectgenerator, ServerOnly = 1 ]
{
    If (%mode '= "method") {
        // NO New statements!
        Do %code.WriteLine(" Set s=$Get(pArg(1)), d=$Get(pArg(2))")
        Do %code.WriteLine(" Quit:s=\"\"\"\"  Quit:d=\"\"\"\"")
        Do %code.WriteLine(" Set ^PPR(\"out\",s,d)=1, ^PPR(\"in\",d,s)=1")
        Do %code.WriteLine(" Set ^PPR(\"deg\",s)=$Get(^PPR(\"deg\",s))+1")
    }
    Quit $$$OK
}
```

**Key Points**:
- MUST use `CodeMode = objectgenerator`
- NO `New` statements (causes "Private variable not allowed" error)
- Use `$Get(pArg(n))` directly
- Empty string checks: `Quit:s="""""` (4 quotes = escaped empty)

### 2. intersystems_irispython API (External Client)

**Correct Pattern** for Global iteration:
```python
import iris
conn = iris.connect('localhost', 1972, 'USER', '_SYSTEM', 'SYS')
irispy = iris.createIRIS(conn)

# Iterator API (not nextSubscript!)
for node_id, deg in irispy.iterator('^PPR', 'deg'):
    # Process...

# Nested iteration for incoming edges
for src, val in irispy.iterator('^PPR', 'in', target_id):
    # Process...
```

**Gotchas**:
- Use `iterator()` NOT `nextSubscript()`
- No keyword arguments - all positional
- `.get()` returns mixed types (int or str)
- Sink nodes (zero outdegree) don't appear in `^PPR("deg", *)`

### 3. Embedded Python Limitations (Use with Caution)

**Issues Discovered**:
1. No `.iterator()` method on `iris.gref()` objects
2. Subscript access returns None when level doesn't exist (no `.order()` method available)
3. Namespace isolation prevents cross-namespace Global access
4. No `iris.eval()` for ObjectScript interop
5. No documented pattern for calling ObjectScript $ORDER from embedded Python

**When to Use Embedded Python**:
- ‚úÖ Class methods that don't need Global access
- ‚úÖ Data transformation on objects
- ‚úÖ Integration with Python libraries (NumPy, etc.)
- ‚ùå Direct Global traversal (use ObjectScript instead)

---

## Current Production Recommendation

**Use Pure Python** (14ms for 1K nodes) because:
1. ‚úÖ Excellent performance for most use cases
2. ‚úÖ Simple, maintainable code
3. ‚úÖ No IRIS-specific dependencies
4. ‚úÖ Portable to other graph databases
5. ‚úÖ All tests passing (11/11)

**Functional Index** is deployed and operational:
- Maintains ^PPR Globals correctly in real-time
- Available via `use_functional_index=True` flag
- Useful for debugging and ObjectScript integration
- Not recommended for Python-based PPR due to external client overhead

---

## ObjectScript Native Implementation with Packed Lists (T026-T028) ‚úÖ COMPLETE

**Goal**: Achieve sub-10ms performance using ObjectScript with packed list optimization

**Implementation**:
1. ‚úÖ Updated `PPRFunctionalIndex.cls` to maintain packed lists
   - `^PPR("outL", src)` - Packed outgoing neighbors with `$LISTBUILD`
   - `^PPR("inL", dst)` - Packed incoming neighbors for fast iteration
   - `^PPR("dang", v)` - Dangling node set for O(#dangling) accumulation
2. ‚úÖ Updated `PPRNative.cls` to use `$LISTNEXT` for neighbor iteration
   - Replaced `$Order(inEdges(v, u))` loops with `$LISTNEXT(inList, ptr, u)`
   - Reduced ~87K `$ORDER` calls to ~1K Global gets + ~5K in-memory `$LISTNEXT` steps
3. ‚úÖ Deployed and tested at 1K nodes

**Performance Results** (1000 nodes, 5067 edges):
```
Pure Python (Baseline):               14.47ms  ‚úÖ BEST (simple, portable)
ObjectScript Native (Packed Lists):   14.33ms  ‚úÖ MATCHES Pure Python!
ObjectScript Native (Old):            20.16ms  ‚ö†Ô∏è  1.4x slower (local array overhead)
```

**Key Findings**:
- ‚úÖ **Packed lists + $LISTNEXT optimization WORKS** - reduced from 20ms to 14ms
- ‚úÖ **Matches Pure Python's excellent 14ms performance**
- ‚úÖ **IRIS expert's optimization delivered exactly as predicted**: turning 87K order() calls into ~1K gets + 5K in-memory steps
- üéØ **At 1K nodes, both implementations tie** - Pure Python's single SQL bulk extract is equally efficient

---

## Files Summary

### Production Files (Deployed)
1. `src/iris/Graph/KG/PPRFunctionalIndex.cls` - Functional Index (working)
2. `iris_vector_graph_core/ppr_functional_index.py` - External client PPR (slow but works)
3. `iris_vector_graph_core/engine.py` - Feature flag integration
4. `tests/integration/test_ppr_functional_index_live.py` - Integration tests (6/6 passing)

### Investigation Files (For Reference)
1. `src/iris/Graph/KG/PPRCompute.cls` - Embedded Python attempt (non-functional)
2. `scripts/performance/benchmark_embedded_ppr.py` - Benchmark script
3. `docs/embedded-python-issues.md` - Issue documentation for IRIS team
4. `docs/ppr-functional-index-deployment-summary.md` - Deployment journey
5. `docs/ppr-performance-optimization-journey.md` - This document

---

## Conclusion

Successfully implemented the InterSystems' packed list optimization in both the Functional Index and ObjectScript Native PPR:

### Key Achievements:
1. ‚úÖ **Functional Index with Packed Lists** - maintains `^PPR("outL", *)` and `^PPR("inL", *)` synchronized with SQL DML
2. ‚úÖ **ObjectScript Native with $LISTNEXT** - reduced from 20ms to 14ms by eliminating repeated Global traversals
3. ‚úÖ **Matched Pure Python Performance** - 14.33ms vs 14.47ms at 1K nodes
4. ‚úÖ **Proved IRIS expert's Optimization Pattern** - packed lists + $LISTNEXT dramatically reduces API overhead

### Scaling Analysis:

**Validated Performance** (actual PPR computation with 100 iterations):

| Graph Size | Pure Python | ObjectScript Native | Winner |
|---|---|---|---|
| **1K nodes** (5K edges) | 14.47ms | 14.33ms | **Tie** (both excellent!) |
| **10K nodes** (50K edges) | **1,631ms** | **184ms** | **ObjectScript 8.89x FASTER!** ‚úÖ |

**CRITICAL DISCOVERY**: The documented result of "140ms" for Pure Python at 10K was based on a **flawed benchmark** that only measured SQL extraction time, not full PPR computation. When both implementations run **full 100-iteration PPR**:

**Key Insights**:
- ‚úÖ **At 1K nodes**: Both implementations tie at ~14ms (Pure Python's SQL bulk extract is excellent at small scale)
- üöÄ **At 10K nodes**: ObjectScript **DOMINATES** - 8.89x faster than Pure Python!
- üéØ **IRIS expert's optimization validated**: Packed lists + $LISTNEXT eliminate Global traversal overhead
- üìä **ObjectScript scales BETTER**: Speedup increases with graph size (1.0x @ 1K ‚Üí 8.89x @ 10K)
- üí° **Crossover point**: Somewhere between 1K-10K nodes, ObjectScript Native becomes the clear winner

### Production Recommendation:

**Use ObjectScript Native** for production PPR because:
1. ‚úÖ **8.89x faster at 10K nodes** - dramatic performance advantage at scale
2. ‚úÖ **Zero-copy Global access** - no SQL extraction overhead
3. ‚úÖ **IRIS expert's packed list optimization** - $LISTNEXT beats Python iteration
4. ‚úÖ **Scaling advantage** - speedup INCREASES with graph size
5. ‚úÖ **Production-ready** - all tests passing, Functional Index operational

**Use Pure Python** for:
- Small graphs (<5K nodes) where 14ms is acceptable
- Prototyping and debugging
- Reference implementation
- Portability to other databases

**Status**: Optimization journey COMPLETE.

**ANSWER TO "does objectscript ever pull away?"**: **YES!** ObjectScript Native achieves **8.89x speedup** at 10K nodes. The packed list optimization ($LISTNEXT) delivers exactly as the expected - turning 87K order() calls into ~1K gets + 5K in-memory steps makes ObjectScript the clear winner at scale.
