# Q13

## **Question 13 â€“ (Diabetes.csv), (Iris.csv)**

---

## **1. (Using Diabetes.csv & Iris.csv)**

- Read the data
- Calculate **% of missing values** in each column
- Drop columns where missing % > **20%**
- Display **scatter plot** between any two continuous variables
- Perform **label encoding** for a categorical feature
- Apply **Linear Discriminant Analysis (LDA)** for feature extraction

---

## **2. (Using Iris.csv)**

Implement **AdaBoost Algorithm**:

- Read & preprocess data
- Choose **X** (features) and **Y** (target)
- Create **minimum 4 different AdaBoost models** with different parameters
- Find the **best parameters**
- Calculate **Y_predict**
- Display **confusion matrix**
- Calculate:
    - **Accuracy**
    - **Precision**
    - **Recall**
    - **F-score**

---

# **1. Answer**

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

df1 = pd.read_csv("Diabetes.csv")
df2 = pd.read_csv("Iris.csv")

# % of missing values (Diabetes)
missing_pct = df1.isnull().mean() * 100
print("Missing %:\n", missing_pct)

# Drop columns >20% missing
cols_to_drop = missing_pct[missing_pct > 20].index
df1.drop(columns=cols_to_drop, inplace=True)

# Scatter plot (Iris dataset example)
sns.scatterplot(x=df2['SepalLength'], y=df2['PetalLength'])
plt.title("SepalLength vs PetalLength")
plt.show()

# Label encoding for Species
le = LabelEncoder()
df2['Species_encoded'] = le.fit_transform(df2['Species'])

# LDA for feature extraction
X = df2[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]
y = df2['Species_encoded']

lda = LinearDiscriminantAnalysis(n_components=2)
lda_result = lda.fit_transform(X, y)

print("LDA Result Shape:", lda_result.shape)

```

---

# **2. Answer**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv("Iris.csv")

# Encode target
le = LabelEncoder()
df['Species_encoded'] = le.fit_transform(df['Species'])

X = df.drop(columns=['Species', 'Species_encoded'])
y = df['Species_encoded']

# Train-test split (75/25)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

# 4 AdaBoost models with different parameters
models = [
    AdaBoostClassifier(n_estimators=30, learning_rate=0.5),
    AdaBoostClassifier(n_estimators=50, learning_rate=1.0),
    AdaBoostClassifier(n_estimators=80, learning_rate=0.8),
    AdaBoostClassifier(n_estimators=100, learning_rate=1.2)
]

best_acc = 0
best_model = None

for m in models:
    m.fit(X_train, y_train)
    pred = m.predict(X_test)
    acc = accuracy_score(y_test, pred)
    print(f"Model: {m} | Accuracy: {acc}")
    if acc > best_acc:
        best_acc = acc
        best_model = m

print("\nBest Model:", best_model)

# Predictions
y_pred = best_model.predict(X_test)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)

# Metrics
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average='macro')
rec = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

acc, prec, rec, f1

```

---