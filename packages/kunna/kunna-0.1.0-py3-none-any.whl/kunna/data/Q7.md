# Q7

## **Question 7 â€“ (IRIS.csv), (Diabetes.csv)**

---

## **1. (Using IRIS.csv)**

- Read the data
- Display features with **high negative correlation** and **no correlation** *(Python code)*
- Perform **multivariate analysis** using **pair plot**
- Perform **one-hot encoding** of a categorical feature *(Python code)*
- Apply **Pearson** or **Spearman** correlation and display a **heatmap**

---

## **2. (Using Diabetes.csv)**

Develop a **Multiple Layer Perceptron (MLP) model** to classify **Outcome**:

- Train-test split (**75% training**, **25% testing**)
- Perform preprocessing
- Train MLP
- Evaluate performance (Accuracy)
- Display **Confusion matrix**
- Optimize with suitable techniques
- Plot results

---

# **1. Answer**

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("IRIS.csv")

# Correlation matrix (numerical only)
corr = df.corr(numeric_only=True)

# High negative correlation (< -0.5)
high_neg = corr[corr < -0.5].stack().index.tolist()

# No correlation (-0.1 < corr < 0.1)
no_corr = corr[(corr > -0.1) & (corr < 0.1)].stack().index.tolist()

print("High Negative Correlation:", high_neg)
print("No Correlation:", no_corr)

# Pair plot (multivariate)
sns.pairplot(df, hue='Species')
plt.show()

# One-hot encoding
df_encoded = pd.get_dummies(df, columns=['Species'])
df_encoded.head()

# Heatmap with Pearson correlation
plt.figure(figsize=(10, 6))
sns.heatmap(df_encoded.corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

```

---

# **2. Answer**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler

df = pd.read_csv("Diabetes.csv")

X = df.drop(columns=["Outcome"])
y = df["Outcome"]

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split (75/25)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.25, random_state=42
)

# Base MLP model
mlp = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000)
mlp.fit(X_train, y_train)

y_pred = mlp.predict(X_test)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)

# Accuracy
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

# Optimization example
optimized = MLPClassifier(
    hidden_layer_sizes=(100, 50),
    activation='relu',
    learning_rate_init=0.001,
    max_iter=1500
)
optimized.fit(X_train, y_train)
opt_pred = optimized.predict(X_test)

opt_acc = accuracy_score(y_test, opt_pred)
print("Optimized Accuracy:", opt_acc)

# Plot results
plt.plot(y_test.values, label="Actual")
plt.plot(opt_pred, label="Predicted")
plt.title("MLP Classification Results")
plt.legend()
plt.show()

```

---