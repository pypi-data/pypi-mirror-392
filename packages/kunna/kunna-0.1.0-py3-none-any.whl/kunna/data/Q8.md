# Q8

## **Question 8 – (Diabetes.csv), (Iris.csv)**

---

## **1. (Using Diabetes.csv)**

- Read the data
- Display outlier values for numerical columns using **Z-score**
- Perform **univariate analysis** for continuous variables using **violin plot**
- Perform **nearest interpolation** for missing values (if missing <10%)
- Apply **PCA (Principal Component Analysis)** for matrix factorization

---

## **2. (Using Iris.csv)**

Implement **Agglomerative Clustering**:

- Perform preprocessing
- Cluster data using **different distance metrics** (Euclidean, Manhattan)
- Use **different linkage methods** (single, complete)
- Plot **dendrograms**
- Evaluate with:
    - **Silhouette Score**
    - **Davies–Bouldin Index**

---

# **1. Answer**

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.decomposition import PCA

df = pd.read_csv("Diabetes.csv")

# Z-score outliers
num_cols = df.select_dtypes(include='number')
z_scores = np.abs(stats.zscore(num_cols))
outliers = np.where(z_scores > 3)
print("Outlier positions:", outliers)

# Violin plots for continuous variables
for col in num_cols.columns:
    sns.violinplot(y=df[col])
    plt.title(f"Violin Plot of {col}")
    plt.show()

# Nearest interpolation for missing values (<10%)
for col in num_cols.columns:
    if df[col].isnull().mean() < 0.10 and df[col].isnull().mean() > 0:
        df[col] = df[col].interpolate(method='nearest')

# PCA for dimensionality reduction
pca = PCA(n_components=2)
pca_result = pca.fit_transform(num_cols.fillna(num_cols.mean()))
print("PCA Result Shape:", pca_result.shape)

```

---

# **2. Answer**

```python
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.metrics import silhouette_score, davies_bouldin_score

df = pd.read_csv("Iris.csv")

X = df.select_dtypes(include='number')  # only numerical for clustering

# Dendrograms (Euclidean + Single)
plt.figure(figsize=(7, 4))
Z = linkage(X, method='single', metric='euclidean')
dendrogram(Z)
plt.title("Dendrogram (Euclidean, Single Linkage)")
plt.show()

# Dendrograms (Manhattan + Complete)
plt.figure(figsize=(7, 4))
Z = linkage(X, method='complete', metric='cityblock')
dendrogram(Z)
plt.title("Dendrogram (Manhattan, Complete Linkage)")
plt.show()

# Agglomerative Clustering
model = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='single')
labels = model.fit_predict(X)

# Metrics
sil_score = silhouette_score(X, labels)
db_score = davies_bouldin_score(X, labels)

print("Silhouette Score:", sil_score)
print("Davies-Bouldin Index:", db_score)

```

---