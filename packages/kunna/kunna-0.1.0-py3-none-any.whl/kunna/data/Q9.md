# Q9

## **Question 9 – (IRIS.csv)**

---

## **1. (Using IRIS.csv)**

- Read the data
- Calculate **5-number summary** for a numerical column & correlate with **box plot**
- Perform **multivariate analysis** using **pair plot**
- Perform **min–max normalization** on a numerical feature (e.g., *Age*, but for iris use any numeric column)
- Apply **LDA (Linear Discriminant Analysis)** for feature extraction

---

## **2. (Using IRIS.csv)**

Apply **Fuzzy C-Means Clustering**:

- Perform necessary preprocessing
- Determine **optimal number of clusters**
- Print & plot **cluster centroids** and **cluster labels**
- Compute:
    - **Partition Coefficient (PC)**
    - **Classification Entropy (CE)**

---

# **1. Answer**

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

df = pd.read_csv("IRIS.csv")

# 5-number summary for a numerical column (example: SepalLength)
summary = df['SepalLength'].describe()[['min','25%','50%','75%','max']]
print(summary)

# Box plot
sns.boxplot(x=df['SepalLength'])
plt.title("Box Plot of SepalLength")
plt.show()

# Pair plot (multivariate analysis)
sns.pairplot(df, hue='Species')
plt.show()

# Min-max normalization (example: SepalWidth)
scaler = MinMaxScaler()
df['SepalWidth_norm'] = scaler.fit_transform(df[['SepalWidth']])

df.head()

# LDA for feature extraction
X = df.drop(columns=['Species'])
y = df['Species']

lda = LinearDiscriminantAnalysis(n_components=2)
lda_result = lda.fit_transform(X, y)

print("LDA Output Shape:", lda_result.shape)
```

---

# **2. Answer**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import skfuzzy as fuzz

df = pd.read_csv("IRIS.csv")

X = df.select_dtypes(include='number').values

# Standardize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Try different cluster counts to find optimal
pc_values = []
ce_values = []
cluster_range = range(2, 7)

for c in cluster_range:
    cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(
        X_scaled.T, c, 2, error=0.005, maxiter=1000
    )
    pc = fuzz.partition_coefficient(u)
    ce = fuzz.classification_entropy(u)
    pc_values.append(pc)
    ce_values.append(ce)

optimal_clusters = cluster_range[np.argmax(pc_values)]
print("Optimal Clusters Based on PC:", optimal_clusters)

# Final model
cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(
    X_scaled.T, optimal_clusters, 2, error=0.005, maxiter=1000
)

labels = np.argmax(u, axis=0)

# Plot cluster labels
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis')
plt.title("Fuzzy C-Means Clustering")
plt.show()

# Plot centroids
plt.scatter(cntr[:, 0], cntr[:, 1], c='red', s=200, marker='X')
plt.title("Cluster Centroids")
plt.show()

# Partition Coefficient & Classification Entropy
print("Partition Coefficient (PC):", fuzz.partition_coefficient(u))
print("Classification Entropy (CE):", fuzz.classification_entropy(u))
```

---