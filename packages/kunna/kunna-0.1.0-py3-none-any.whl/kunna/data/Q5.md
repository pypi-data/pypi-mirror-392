# Q5

## **Question 5 â€“ (Solar-Regression.csv)**

---

## **1. (Using Solar-Regression.csv)**

- Read the data
- Display features with **high positive correlation** and **no correlation**
- Display a **scatter plot** showing relationship between two continuous variables
- Perform **median imputation** for numerical columns with missing values > 10%
- Remove features with missing values

---

## **2. (Using Solar-Regression.csv)**

Develop a **multiple-layer perceptron regression model** predicting **Solar Radiation**:

- Split data into **75% training** and **25% testing**
- Perform necessary preprocessing
- Train MLP model
- Evaluate using **performance metrics (RMSE, etc.)**
- Improve using **Randomized Search CV** + **Grid Search CV**
- Plot the results

---

# **1. Answer**

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("Solar-Regression.csv")

# Correlation matrix
corr = df.corr(numeric_only=True)

high_pos = corr[corr > 0.5].stack().index.tolist()
no_corr = corr[(corr > -0.1) & (corr < 0.1)].stack().index.tolist()

print("High Positive Correlation:", high_pos)
print("No Correlation:", no_corr)

# Scatter plot for two continuous variables (example: 'Temperature' vs 'Solar Radiation')
sns.scatterplot(x=df['Temperature'], y=df['Solar Radiation'])
plt.title("Temperature vs Solar Radiation")
plt.show()

# Median imputation for >10% missing
num_cols = df.select_dtypes(include='number').columns
for col in num_cols:
    if df[col].isnull().mean() > 0.10:
        df[col].fillna(df[col].median(), inplace=True)

# Remove columns still having missing values
df.dropna(axis=1, inplace=True)

df.head()

```

---

# **2. Answer**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

df = pd.read_csv("Solar-Regression.csv")

# Drop rows with missing Solar Radiation
df = df.dropna(subset=["Solar Radiation"])

X = df.drop(columns=["Solar Radiation"])
y = df["Solar Radiation"]

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split 75/25
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.25, random_state=42
)

# Base MLP model
mlp = MLPRegressor(max_iter=1000, random_state=42)
mlp.fit(X_train, y_train)

y_pred = mlp.predict(X_test)

# Metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print("MSE:", mse, "RMSE:", rmse)

# Randomized Search CV
param_dist = {
    "hidden_layer_sizes": [(50,), (100,), (50,50), (100,50)],
    "activation": ["relu", "tanh"],
    "solver": ["adam", "sgd"],
    "learning_rate_init": [0.001, 0.01, 0.1]
}

rand_search = RandomizedSearchCV(
    mlp, param_distributions=param_dist, n_iter=5, cv=3
)
rand_search.fit(X_train, y_train)

print("Best Params (Randomized Search):", rand_search.best_params_)

# Grid Search CV
param_grid = {
    "hidden_layer_sizes": [(50,), (100,), (100,50)],
    "activation": ["relu"],
}

grid_search = GridSearchCV(mlp, param_grid=param_grid, cv=3)
grid_search.fit(X_train, y_train)

print("Best Params (Grid Search):", grid_search.best_params_)

# Plot results
plt.plot(y_test.values, label="Actual")
plt.plot(y_pred, label="Predicted")
plt.title("MLP Regression - Actual vs Predicted")
plt.legend()
plt.show()

```

---