# Q6

## **Question 6 â€“ (Precipitation.csv), (Diabetes.csv)**

---

## **1. (Using Precipitation.csv)**

- Read the data
- Display outlier values for numerical columns using **Z-score** *(Python code)*
- Perform a **bivariate analysis** between two categorical variables using **count plot**
- Identify columns with **variance < 10** and drop them
- Perform **label encoding** for a categorical feature (Python code)

---

## **2. (Using Diabetes.csv)**

Develop a **Random Forest model** to classify **Outcome**:

- Split data into **75% training** & **25% testing**
- Perform required preprocessing
- Train Random Forest
- Evaluate using **accuracy**
- Display **confusion matrix**
- Optimize using suitable techniques and compare results
- Plot outcomes

---

# **1. Answer**

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv("Precipitation.csv")

# Outliers using Z-score
num_cols = df.select_dtypes(include='number')
z_scores = np.abs(stats.zscore(num_cols))
outliers = np.where(z_scores > 3)
print("Outlier positions:", outliers)

# Bivariate analysis (categorical vs categorical)
cat_cols = df.select_dtypes(exclude='number').columns
sns.countplot(x=df[cat_cols[0]], hue=df[cat_cols[1]])
plt.title("Bivariate Analysis")
plt.show()

# Drop low variance columns (<10)
low_var_cols = num_cols.var()[num_cols.var() < 10].index
df.drop(columns=low_var_cols, inplace=True)

# Label encoding
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

df.head()

```

---

# **2. Answer**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler

df = pd.read_csv("Diabetes.csv")

X = df.drop(columns=["Outcome"])
y = df["Outcome"]

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split (75/25)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.25, random_state=42
)

# Base Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)

# Accuracy
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

# Optimization (example hyperparameters)
best_rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=8,
    min_samples_split=4,
    min_samples_leaf=2
)
best_rf.fit(X_train, y_train)
best_pred = best_rf.predict(X_test)

best_acc = accuracy_score(y_test, best_pred)
print("Optimized Accuracy:", best_acc)

# Plot
plt.plot(y_test.values, label="Actual")
plt.plot(best_pred, label="Predicted")
plt.title("Random Forest Classification")
plt.legend()
plt.show()

```

---