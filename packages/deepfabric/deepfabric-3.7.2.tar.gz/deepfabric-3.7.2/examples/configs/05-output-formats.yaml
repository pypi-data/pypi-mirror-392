# ============================================================================
# OUTPUT FORMATTERS - Transform datasets to different formats
# ============================================================================
# Purpose: Demonstrate how to use formatters to transform generated data
# Usage: deepfabric start examples/configs/05-output-formats.yaml
# ============================================================================
#
# DeepFabric separates data generation from formatting:
#
# 1. GENERATION - Always produces standard Conversation objects
#    - Controlled by conversation_type, reasoning_style, agent_mode
#    - Stored in universal DeepFabric format
#
# 2. FORMATTING - Transforms data to target formats
#    - Applied post-generation using formatters
#    - Multiple output formats from single dataset
#    - Supported formats: conversations, alpaca, chatml, openai, xlam_v2, etc.
#
# ============================================================================

dataset_system_prompt: |
  You are a helpful AI assistant that provides accurate responses.

topic_tree:
  topic_prompt: "Customer support scenarios and troubleshooting"
  provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.7
  degree: 2
  depth: 2
  save_as: "topics.jsonl"

# ============================================================================
# GENERATION CONFIGURATION
# ============================================================================
# All data is generated in standard Conversation format, then transformed
# by formatters to target formats.
# ============================================================================

data_engine:
  generation_system_prompt: "Generate helpful customer support conversations."
  instructions: "Create realistic customer support scenarios."

  # Conversation style
  conversation_type: "basic"

  provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.7
  max_retries: 3  # Retry on API failures

# ============================================================================
# FORMATTING OPTIONS
# ============================================================================
# Use formatters to transform the generated data to different formats.
# You can apply multiple formatters to get multiple output formats.
# ============================================================================

dataset:
  save_as: "dataset_raw.jsonl"  # Raw DeepFabric format
  creation:
    num_steps: 2
    batch_size: 2
    sys_msg: true

  # Apply formatters to transform to different formats
  formatters:
    # Standard conversation format (compatible with most frameworks)
    - name: "standard_format"
      template: "builtin://conversations"
      output: "dataset_standard.jsonl"
      config:
        include_system: true

    # Alpaca instruction format
    - name: "alpaca_format"
      template: "builtin://alpaca"
      output: "dataset_alpaca.jsonl"

    # ChatML format (for models using ChatML)
    - name: "chatml_format"
      template: "builtin://chatml"
      output: "dataset_chatml.jsonl"
      config:
        output_format: "text"
        include_system: true

    # OpenAI Schema format for HuggingFace training
    - name: "openai_format"
      template: "builtin://openai"
      output: "dataset_openai.jsonl"

# ============================================================================
# ADVANCED: MULTI-TURN AGENT DATA WITH XLAM FORMATTING
# ============================================================================
# For agent training data, generate multi-turn conversations with tools,
# then format to XLAM v2 specification.
# ============================================================================

# data_engine:
#   generation_system_prompt: |
#     Generate multi-turn agent conversations with tool usage.
#
#   instructions: "Create complex scenarios requiring multiple tool interactions."
#
#   # Generate multi-turn agent conversations
#   conversation_type: "chain_of_thought"
#   reasoning_style: "hybrid"
#   agent_mode: "multi_turn"
#
#   # Tools for agent to use
#   available_tools: ["get_weather", "search_web", "calculate"]
#   max_tools_per_query: 3
#   max_tools_strict: false
#
#   # Multi-turn conversation range
#   min_turns: 2
#   max_turns: 6
#
#   provider: "openai"
#   model: "gpt-4o"
#   temperature: 0.8
#   max_retries: 3
#
# dataset:
#   save_as: "dataset_agent_raw.jsonl"
#   creation:
#     num_steps: 10
#     batch_size: 1
#     sys_msg: true
#
#   formatters:
#     # Transform to XLAM v2 format for agent training
#     - name: "xlam_format"
#       template: "builtin://xlam_v2"
#       output: "dataset_xlam.jsonl"
#       config:
#         validate_strict: true
#         include_system_prompt: true
#         min_turns: 3
#         max_turns: 15

# ============================================================================
# CHOOSING THE RIGHT APPROACH:
#
# GENERATION (conversation_type, reasoning_style, agent_mode):
# - Controls WHAT content is generated
# - Determines conversation structure, reasoning patterns, tool usage
# - Examples: basic dialog, chain-of-thought, multi-turn agents
#
# FORMATTING (formatters):
# - Controls HOW data is structured for training
# - Transforms to framework-specific or model-specific formats
# - Examples: xlam_v2 for agents, alpaca for instruction-following, chatml for chat models
#
# WORKFLOW:
# 1. Configure generation to create desired conversation style
# 2. Apply formatters to transform to target training format
# 3. Use same dataset with multiple formatters for different platforms
# ============================================================================
