from typing import TypedDict, Annotated, List, Dict, Any, Optional, Literal

from langgraph.graph import add_messages, StateGraph, END
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, BaseMessage
from langchain_core.runnables import RunnableConfig
from loguru import logger
from pydantic import BaseModel, Field

from neco.llm.chain.entity import BasicLLMRequest, BasicLLMResponse, ToolsServer
from neco.llm.chain.graph import BasicGraph
from neco.llm.chain.node import ToolsNodes
from neco.core.utils.template_loader import TemplateLoader


class AgentConfig(BaseModel):
    """å•ä¸ª Agent é…ç½®"""
    name: str = Field(..., description="Agent åç§°ï¼Œç”¨äºè¯†åˆ«å’Œè·¯ç”±")
    description: str = Field(..., description="Agent åŠŸèƒ½æè¿°ï¼Œç”¨äº Supervisor å†³ç­–")
    system_message_prompt: str = Field(default="", description="Agent ä¸“å±ç³»ç»Ÿæç¤ºè¯")
    tools_servers: List[ToolsServer] = Field(
        default_factory=list, description="Agent ä¸“å±å·¥å…·æœåŠ¡")
    temperature: float = Field(default=0.7, description="Agent æ¸©åº¦å‚æ•°")
    context_window_size: Optional[int] = Field(
        default=None,
        description="ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆæ¶ˆæ¯æ•°é‡ï¼‰ã€‚None è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ¶ˆæ¯"
    )


class SupervisorMultiAgentRequest(BasicLLMRequest):
    """Supervisor Multi-Agent è¯·æ±‚é…ç½®"""

    # Supervisor é…ç½®
    supervisor_system_prompt: str = Field(
        default="ä½ æ˜¯ä¸€ä¸ªå›¢é˜Ÿä¸»ç®¡ï¼Œè´Ÿè´£åè°ƒå¤šä¸ªä¸“ä¸š Agent å®Œæˆä»»åŠ¡ã€‚",
        description="Supervisor çš„ç³»ç»Ÿæç¤ºè¯"
    )
    supervisor_model: Optional[str] = Field(
        default=None,
        description="Supervisor ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨å…¨å±€ model"
    )

    # Agent é…ç½®
    agents: List[AgentConfig] = Field(
        default_factory=list,
        description="æ‰€æœ‰ Agent çš„é…ç½®åˆ—è¡¨"
    )

    # æ‰§è¡Œç­–ç•¥
    max_iterations: int = Field(
        default=10,
        description="æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯"
    )

    output_mode: Literal["full_history", "last_message"] = Field(
        default="last_message",
        description="è¾“å‡ºæ¨¡å¼ï¼šfull_history åŒ…å«å®Œæ•´å†å²ï¼Œlast_message ä»…åŒ…å«æœ€ç»ˆå“åº”"
    )

    # ä¸Šä¸‹æ–‡ç®¡ç†
    default_context_window_size: Optional[int] = Field(
        default=None,
        description="é»˜è®¤ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆæ¶ˆæ¯æ•°é‡ï¼‰ã€‚None è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ¶ˆæ¯ï¼Œä¼˜å…ˆçº§ä½äº Agent çº§é…ç½®"
    )
    supervisor_context_window_size: Optional[int] = Field(
        default=None,
        description="Supervisor å†³ç­–æ—¶çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°ã€‚None è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ¶ˆæ¯"
    )


class SupervisorMultiAgentResponse(BasicLLMResponse):
    """Supervisor Multi-Agent å“åº”"""

    executed_agents: List[str] = Field(
        default_factory=list,
        description="æ‰§è¡Œè¿‡çš„ Agent åç§°åˆ—è¡¨"
    )
    iterations: int = Field(
        default=0,
        description="å®é™…è¿­ä»£æ¬¡æ•°"
    )


class SupervisorMultiAgentState(TypedDict):
    """Supervisor Multi-Agent çŠ¶æ€"""
    messages: Annotated[list, add_messages]
    graph_request: SupervisorMultiAgentRequest
    active_agent: Optional[str]  # å½“å‰æ´»è·ƒçš„ Agent
    executed_agents: List[str]  # å·²æ‰§è¡Œçš„ Agent åˆ—è¡¨
    iterations: int  # å½“å‰è¿­ä»£æ¬¡æ•°
    next_action: Optional[str]  # Supervisor å†³ç­–ï¼šagent_name æˆ– "FINISH"


class SupervisorMultiAgentNode(ToolsNodes):
    """Supervisor Multi-Agent èŠ‚ç‚¹æ„å»ºå™¨"""

    def __init__(self):
        super().__init__()
        # Agent åç§° -> ToolsNodes æ˜ å°„
        self.agent_tools_map: Dict[str, ToolsNodes] = {}

    async def setup_supervisor(self, request: SupervisorMultiAgentRequest):
        """åˆå§‹åŒ– Supervisorï¼ˆä»…ä½¿ç”¨ Supervisor è‡ªå·±çš„å·¥å…·ï¼‰"""
        await self.setup(request)

    async def setup_agents(self, request: SupervisorMultiAgentRequest):
        """åˆå§‹åŒ–æ‰€æœ‰ Agent"""
        logger.info("ğŸ”§ å¼€å§‹åˆå§‹åŒ–æ‰€æœ‰ Agent...")

        for agent_config in request.agents:
            # ä¸ºæ¯ä¸ª Agent åˆ›å»ºç‹¬ç«‹çš„ ToolsNodes
            agent_node = ToolsNodes()

            # æ„å»º Agent ä¸“å±è¯·æ±‚ï¼ˆç»§æ‰¿å…¨å±€é…ç½® + Agent é…ç½®ï¼‰
            agent_request = BasicLLMRequest(
                openai_api_base=request.openai_api_base,
                openai_api_key=request.openai_api_key,
                model=request.model,
                system_message_prompt=agent_config.system_message_prompt,
                temperature=agent_config.temperature,
                tools_servers=agent_config.tools_servers,
                user_id=request.user_id,
                thread_id=request.thread_id
            )

            await agent_node.setup(agent_request)
            self.agent_tools_map[agent_config.name] = agent_node

            logger.info(
                f"  âœ“ Agent [{agent_config.name}] åˆå§‹åŒ–å®Œæˆ - "
                f"å·¥å…·æ•°: {len(agent_node.tools)}, "
                f"æ¸©åº¦: {agent_config.temperature}"
            )

        logger.info(f"âœ… å…±åˆå§‹åŒ– {len(request.agents)} ä¸ª Agent")

    async def supervisor_node(self, state: SupervisorMultiAgentState, config: RunnableConfig) -> Dict[str, Any]:
        """Supervisor å†³ç­–èŠ‚ç‚¹ï¼šé€‰æ‹©ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„ Agent æˆ–ç»“æŸ"""
        request: SupervisorMultiAgentRequest = config["configurable"]["graph_request"]

        current_iteration = state.get("iterations", 0) + 1
        executed_agents = state.get("executed_agents", [])

        logger.info("=" * 80)
        logger.info(
            f"ğŸ¯ Supervisor ç¬¬ {current_iteration} è½®å†³ç­–ï¼ˆä¸Šé™: {request.max_iterations}ï¼‰")
        logger.info(
            f"ğŸ“Š å·²æ‰§è¡Œ Agent: {executed_agents if executed_agents else 'æ— '}")
        logger.info(f"ï¿½ å·²å®Œæˆ {len(executed_agents)} æ¬¡ Agent è°ƒç”¨")

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
        if state.get("iterations", 0) >= request.max_iterations:
            logger.warning(f"âš ï¸  è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {request.max_iterations}ï¼Œå¼ºåˆ¶ç»“æŸ")
            logger.info("=" * 80)
            return {
                "next_action": "FINISH",
                "iterations": current_iteration
            }

        # å‡†å¤‡ Supervisor æç¤ºè¯
        supervisor_prompt = self._build_supervisor_prompt(request, state)
        logger.debug(f"ğŸ“ Supervisor æç¤ºè¯å·²æ„å»ºï¼Œé•¿åº¦: {len(supervisor_prompt)} å­—ç¬¦")

        # è°ƒç”¨ LLM åšå†³ç­–
        logger.info("ğŸ¤” æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œå†³ç­–...")
        llm = self.get_llm_client(request, disable_stream=True)
        decision_messages = [
            SystemMessage(content=supervisor_prompt),
            HumanMessage(content="è¯·å†³ç­–ä¸‹ä¸€æ­¥ï¼šé€‰æ‹©ä¸€ä¸ª Agent æ‰§è¡Œä»»åŠ¡ï¼Œæˆ–è€…è¿”å› FINISH ç»“æŸã€‚")
        ]

        response = llm.invoke(decision_messages)
        decision = response.content.strip()

        logger.info(
            f"ğŸ’­ Supervisor åŸå§‹å†³ç­–: {decision[:200]}{'...' if len(decision) > 200 else ''}")

        # è§£æå†³ç­–
        next_action = self._parse_supervisor_decision(decision, request)

        if next_action == "FINISH":
            logger.info("âœ… Supervisor å†³å®š: ä»»åŠ¡å®Œæˆï¼Œç»“æŸæ‰§è¡Œ")
        else:
            logger.info(f"ğŸ‘‰ Supervisor å†³å®š: å§”æ´¾ç»™ [{next_action}] Agent")

        logger.info("=" * 80)

        return {
            "next_action": next_action,
            "iterations": current_iteration,
            "messages": [response]  # ä¿ç•™ Supervisor çš„æ€è€ƒè¿‡ç¨‹
        }

    def _build_supervisor_prompt(self, request: SupervisorMultiAgentRequest, state: SupervisorMultiAgentState) -> str:
        """æ„å»º Supervisor æç¤ºè¯"""
        # æ„å»º Agent åˆ—è¡¨æè¿°
        agents_desc = "\n".join([
            f"- {agent.name}: {agent.description}"
            for agent in request.agents
        ])

        # å·²æ‰§è¡Œçš„ Agent åˆ—è¡¨
        executed = state.get("executed_agents", [])
        executed_desc = ", ".join(executed) if executed else "æ— "

        # æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨æ™ºèƒ½é€‰æ‹©ç­–ç•¥ï¼‰
        all_messages = state.get("messages", [])
        recent_messages = self._select_context_messages(
            all_messages,
            request.supervisor_context_window_size
        )

        context_desc = "\n".join([
            f"{msg.__class__.__name__}: {msg.content[:100]}..."
            for msg in recent_messages
        ])

        template_data = {
            "supervisor_system_prompt": request.supervisor_system_prompt,
            "agents_desc": agents_desc,
            "executed_desc": executed_desc,
            "context_desc": context_desc,
            "user_message": request.user_message
        }

        return TemplateLoader.render_template(
            'prompts/graph/supervisor_decision_prompt',
            template_data
        )

    def _parse_supervisor_decision(self, decision: str, request: SupervisorMultiAgentRequest) -> str:
        """è§£æ Supervisor å†³ç­–ç»“æœ"""
        decision_upper = decision.upper().strip()

        # æ£€æŸ¥æ˜¯å¦æ˜¯ FINISH
        if "FINISH" in decision_upper:
            logger.debug("ğŸ” å†³ç­–è§£æ: åŒ¹é…åˆ° FINISH å…³é”®è¯")
            return "FINISH"

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…æŸä¸ª Agent åç§°
        for agent_config in request.agents:
            if agent_config.name.upper() in decision_upper or agent_config.name in decision:
                logger.debug(f"ğŸ” å†³ç­–è§£æ: åŒ¹é…åˆ° Agent [{agent_config.name}]")
                return agent_config.name

        # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª Agentï¼ˆé™çº§ç­–ç•¥ï¼‰
        fallback_agent = request.agents[0].name if request.agents else "FINISH"
        logger.warning(
            f"âš ï¸  æ— æ³•è§£æ Supervisor å†³ç­– [{decision[:100]}]ï¼Œé™çº§é€‰æ‹©: {fallback_agent}")
        return fallback_agent

    async def agent_executor_node(self, agent_name: str):
        """ç”ŸæˆæŒ‡å®š Agent çš„æ‰§è¡ŒèŠ‚ç‚¹"""
        # ä¿å­˜å¯¹ self çš„å¼•ç”¨ï¼Œä¾›å†…éƒ¨å‡½æ•°ä½¿ç”¨
        node_builder = self

        async def _execute_agent(state: SupervisorMultiAgentState, config: RunnableConfig) -> Dict[str, Any]:
            """æ‰§è¡ŒæŒ‡å®š Agent"""
            request: SupervisorMultiAgentRequest = config["configurable"]["graph_request"]

            logger.info("")
            logger.info("ğŸ¤–" + "=" * 78)
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œ Agent: [{agent_name}]")
            logger.info("=" * 80)

            # è·å– Agent é…ç½®
            agent_config = next(
                (a for a in request.agents if a.name == agent_name), None)
            if not agent_config:
                logger.error(f"âŒ æœªæ‰¾åˆ° Agent é…ç½®: {agent_name}")
                return {
                    "messages": [AIMessage(content=f"é”™è¯¯ï¼šæœªæ‰¾åˆ° Agent {agent_name}")],
                    "executed_agents": state.get("executed_agents", []) + [agent_name]
                }

            logger.info(f"ğŸ“‹ Agent æè¿°: {agent_config.description}")
            logger.info(
                f"ğŸ› ï¸  å·¥å…·åˆ—è¡¨: {[ts.name for ts in agent_config.tools_servers]}")

            # è·å– Agent ä¸“å±çš„ ToolsNodes
            agent_node = node_builder.agent_tools_map.get(agent_name)
            if not agent_node:
                logger.error(f"âŒ æœªåˆå§‹åŒ– Agent: {agent_name}")
                return {
                    "messages": [AIMessage(content=f"é”™è¯¯ï¼šAgent {agent_name} æœªåˆå§‹åŒ–")],
                    "executed_agents": state.get("executed_agents", []) + [agent_name]
                }

            # åˆ›å»ºä¸´æ—¶ StateGraph ç”¨äº ReAct Agent
            temp_graph_builder = StateGraph(dict)

            # æ„å»º Agent ä¸“å±çš„ç³»ç»Ÿæç¤º
            agent_system_prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„ {agent_name} Agentã€‚
{agent_config.description}

{agent_config.system_message_prompt}
"""

            logger.info("âš™ï¸  æ­£åœ¨ç¼–è¯‘ Agent æ‰§è¡Œå›¾...")
            # ä½¿ç”¨å¯å¤ç”¨çš„ ReAct èŠ‚ç‚¹æ„å»º
            react_entry_node = await agent_node.build_react_nodes(
                graph_builder=temp_graph_builder,
                composite_node_name=f"{agent_name}_react",
                additional_system_prompt=agent_system_prompt,
                next_node=END
            )

            temp_graph_builder.set_entry_point(react_entry_node)
            temp_graph_builder.add_edge(react_entry_node, END)

            # ç¼–è¯‘å¹¶æ‰§è¡Œ
            temp_graph = temp_graph_builder.compile()

            # å‡†å¤‡æ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨æ™ºèƒ½é€‰æ‹©ç­–ç•¥ï¼‰
            all_messages = state.get("messages", [])

            # ä¼˜å…ˆä½¿ç”¨ Agent çº§é…ç½®ï¼Œå…¶æ¬¡ä½¿ç”¨å…¨å±€é…ç½®
            window_size = agent_config.context_window_size
            if window_size is None:
                window_size = request.default_context_window_size

            context_messages = node_builder._select_context_messages(
                all_messages, window_size
            )

            logger.info(
                f"ğŸ’¬ ä¸Šä¸‹æ–‡æ¶ˆæ¯: åŸå§‹ {len(all_messages)} æ¡ -> "
                f"é€‰æ‹© {len(context_messages)} æ¡"
                f"{f' (çª—å£: {window_size})' if window_size else ' (æ— é™åˆ¶)'}"
            )
            logger.info("â–¶ï¸  å¼€å§‹æ‰§è¡Œ Agent ä»»åŠ¡...")

            result = await temp_graph.ainvoke(
                {"messages": context_messages},
                config=config
            )

            # è·å–å®Œæ•´çš„å“åº”æ¶ˆæ¯åˆ—è¡¨
            result_messages = result.get("messages", [])
            if not result_messages:
                logger.warning(f"âš ï¸  Agent [{agent_name}] æœªè¿”å›ä»»ä½•æ¶ˆæ¯")
                return {
                    "messages": [AIMessage(content=f"[Agent: {agent_name}]\n{agent_name} æœªäº§ç”Ÿæœ‰æ•ˆå“åº”")],
                    "active_agent": agent_name,
                    "executed_agents": state.get("executed_agents", []) + [agent_name]
                }

            # æ‰¾å‡ºæ–°å¢çš„æ¶ˆæ¯ï¼ˆæ’é™¤è¾“å…¥çš„ä¸Šä¸‹æ–‡æ¶ˆæ¯ï¼‰
            # æ³¨æ„ï¼šresult_messages å¯èƒ½åŒ…å«è¾“å…¥æ¶ˆæ¯ + æ–°æ¶ˆæ¯
            new_messages = []

            # ä»ç»“æœä¸­æ‰¾å‡ºä¸åœ¨è¾“å…¥ä¸Šä¸‹æ–‡ä¸­çš„æ¶ˆæ¯
            for msg in result_messages:
                # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åœ¨è¾“å…¥ä¸Šä¸‹æ–‡ä¸­ï¼ˆé€šè¿‡å¯¹è±¡å¼•ç”¨æˆ–å†…å®¹ï¼‰
                is_input_msg = False
                for ctx_msg in context_messages:
                    if msg is ctx_msg:  # åŒä¸€ä¸ªå¯¹è±¡
                        is_input_msg = True
                        break

                if not is_input_msg:
                    new_messages.append(msg)

            if not new_messages:
                logger.warning(f"âš ï¸  Agent [{agent_name}] æœªäº§ç”Ÿæ–°çš„å“åº”")
                return {
                    "messages": [AIMessage(content=f"[Agent: {agent_name}]\n{agent_name} æœªäº§ç”Ÿæ–°çš„å“åº”")],
                    "active_agent": agent_name,
                    "executed_agents": state.get("executed_agents", []) + [agent_name]
                }

            logger.info(
                f"âœ… Agent [{agent_name}] æ‰§è¡Œå®Œæˆï¼Œäº§ç”Ÿ {len(new_messages)} æ¡æ–°æ¶ˆæ¯")

            # ä¸ºæœ€åä¸€æ¡ AIMessage æ·»åŠ  Agent æ¥æºæ ‡è®°
            # ä¿æŒå·¥å…·è°ƒç”¨æ¶ˆæ¯ä¸å˜ï¼Œè¿™æ ·å¯ä»¥å®æ—¶çœ‹åˆ°å·¥å…·æ‰§è¡Œè¿‡ç¨‹
            marked_messages = []
            last_ai_msg_idx = None

            # æ‰¾åˆ°æœ€åä¸€ä¸ª AIMessage çš„ç´¢å¼•
            for i in range(len(new_messages) - 1, -1, -1):
                if isinstance(new_messages[i], AIMessage):
                    last_ai_msg_idx = i
                    break

            for i, msg in enumerate(new_messages):
                if i == last_ai_msg_idx and isinstance(msg, AIMessage) and msg.content:
                    # åªæ ‡è®°æœ€åä¸€ä¸ª AIMessage
                    marked_content = f"[Agent: {agent_name}]\n{msg.content}"
                    marked_messages.append(AIMessage(
                        content=marked_content,
                        response_metadata=getattr(
                            msg, 'response_metadata', {}),
                        tool_calls=getattr(msg, 'tool_calls', []),
                        usage_metadata=getattr(msg, 'usage_metadata', None)
                    ))
                else:
                    # ä¿ç•™å…¶ä»–æ‰€æœ‰æ¶ˆæ¯ï¼ˆå·¥å…·è°ƒç”¨ã€å·¥å…·ç»“æœç­‰ï¼‰
                    marked_messages.append(msg)

            logger.info("=" * 80)

            return {
                "messages": marked_messages,
                "active_agent": agent_name,
                "executed_agents": state.get("executed_agents", []) + [agent_name]
            }

        return _execute_agent

    def should_continue(self, state: SupervisorMultiAgentState) -> str:
        """æ¡ä»¶è¾¹ï¼šæ ¹æ® Supervisor å†³ç­–è·¯ç”±åˆ°å¯¹åº” Agent æˆ–ç»“æŸ"""
        next_action = state.get("next_action")

        if next_action == "FINISH":
            return "FINISH"

        # è¿”å› Agent åç§°ä½œä¸ºè·¯ç”±ç›®æ ‡
        return next_action or "FINISH"

    def _select_context_messages(
        self,
        messages: List[BaseMessage],
        window_size: Optional[int] = None
    ) -> List[BaseMessage]:
        """
        æ™ºèƒ½é€‰æ‹©ä¸Šä¸‹æ–‡æ¶ˆæ¯

        ç­–ç•¥ï¼š
        1. å¦‚æœ window_size ä¸º Noneï¼Œè¿”å›å…¨éƒ¨æ¶ˆæ¯
        2. å¦‚æœæ¶ˆæ¯æ€»æ•° <= window_sizeï¼Œè¿”å›å…¨éƒ¨æ¶ˆæ¯
        3. å¦åˆ™ï¼Œä¿ç•™æœ€è¿‘çš„ window_size æ¡æ¶ˆæ¯ï¼Œä½†å°½é‡ä¿è¯å¯¹è¯è½®æ¬¡å®Œæ•´æ€§
           ï¼ˆå³ HumanMessage å’Œç´§éšå…¶åçš„ AIMessage æˆå¯¹ä¿ç•™ï¼‰

        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            window_size: çª—å£å¤§å°ï¼ˆæ¶ˆæ¯æ•°é‡ï¼‰ï¼ŒNone è¡¨ç¤ºä¸é™åˆ¶

        Returns:
            é€‰æ‹©åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if not messages:
            return []

        # ä¸é™åˆ¶çª—å£å¤§å°
        if window_size is None:
            logger.debug("ä¸Šä¸‹æ–‡çª—å£æ— é™åˆ¶ï¼Œä½¿ç”¨å…¨éƒ¨æ¶ˆæ¯")
            return messages

        # æ¶ˆæ¯æ•°é‡åœ¨é™åˆ¶å†…
        if len(messages) <= window_size:
            logger.debug(f"æ¶ˆæ¯æ•° {len(messages)} <= çª—å£ {window_size}ï¼Œä½¿ç”¨å…¨éƒ¨æ¶ˆæ¯")
            return messages

        # éœ€è¦æˆªæ–­ï¼Œä½†ä¼˜å…ˆä¿æŒå¯¹è¯å®Œæ•´æ€§
        selected = messages[-window_size:]

        # å¦‚æœç¬¬ä¸€æ¡æ˜¯ AIMessageï¼Œå°è¯•å‘å‰æ‰©å±•æ‰¾åˆ°é…å¯¹çš„ HumanMessage
        if selected and isinstance(selected[0], AIMessage):
            start_idx = len(messages) - window_size
            # å‘å‰æŸ¥æ‰¾æœ€è¿‘çš„ HumanMessage
            for i in range(start_idx - 1, -1, -1):
                if isinstance(messages[i], HumanMessage):
                    selected = messages[i:]
                    logger.debug(
                        f"ä¸ºä¿æŒå¯¹è¯å®Œæ•´æ€§ï¼Œå‘å‰æ‰©å±•åˆ° HumanMessageï¼Œæœ€ç»ˆé€‰æ‹© {len(selected)} æ¡æ¶ˆæ¯"
                    )
                    break

        logger.debug(
            f"ä¸Šä¸‹æ–‡æˆªæ–­ï¼šåŸå§‹ {len(messages)} æ¡ -> é€‰æ‹© {len(selected)} æ¡"
        )
        return selected


class SupervisorMultiAgentGraph(BasicGraph):
    """Supervisor Multi-Agent å›¾æ‰§è¡Œå™¨"""

    async def compile_graph(self, request: SupervisorMultiAgentRequest):
        """ç¼–è¯‘ Supervisor Multi-Agent æ‰§è¡Œå›¾"""

        logger.info("=" * 80)
        logger.info("ğŸ—ï¸  å¼€å§‹ç¼–è¯‘ Supervisor Multi-Agent å›¾")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Œ ç”¨æˆ·ä»»åŠ¡: {request.user_message}")
        logger.info(f"ğŸ¤– Agent æ•°é‡: {len(request.agents)}")
        logger.info(f"ğŸ“Š æœ€å¤§è¿­ä»£: {request.max_iterations}")
        logger.info(f"ğŸ“¤ è¾“å‡ºæ¨¡å¼: {request.output_mode}")
        logger.info("")

        # åˆå§‹åŒ–èŠ‚ç‚¹æ„å»ºå™¨
        node_builder = SupervisorMultiAgentNode()

        # åˆå§‹åŒ– Supervisor å’Œæ‰€æœ‰ Agent
        logger.info("ğŸ¯ åˆå§‹åŒ– Supervisor...")
        await node_builder.setup_supervisor(request)
        await node_builder.setup_agents(request)

        # åˆ›å»ºçŠ¶æ€å›¾
        logger.info("ğŸ“ æ„å»ºçŠ¶æ€å›¾...")
        graph_builder = StateGraph(SupervisorMultiAgentState)

        # æ·»åŠ åŸºç¡€å›¾ç»“æ„ï¼ˆpromptã€chat_historyã€ragã€user_message ç­‰ï¼‰
        last_edge = self.prepare_graph(graph_builder, node_builder)

        # æ·»åŠ  Supervisor èŠ‚ç‚¹
        graph_builder.add_node("supervisor", node_builder.supervisor_node)
        logger.info("  âœ“ æ·»åŠ  Supervisor èŠ‚ç‚¹")

        # æ·»åŠ æ‰€æœ‰ Agent èŠ‚ç‚¹
        for agent_config in request.agents:
            agent_executor = await node_builder.agent_executor_node(agent_config.name)
            graph_builder.add_node(agent_config.name, agent_executor)
            logger.info(f"  âœ“ æ·»åŠ  Agent èŠ‚ç‚¹: {agent_config.name}")

        # è¿æ¥åŸºç¡€å›¾åˆ° Supervisor
        graph_builder.add_edge(last_edge, "supervisor")
        logger.info(f"  âœ“ è¿æ¥åŸºç¡€å›¾ -> Supervisor")

        # æ·»åŠ æ¡ä»¶è¾¹ï¼šSupervisor -> Agent æˆ– END
        agent_routes = {agent.name: agent.name for agent in request.agents}
        agent_routes["FINISH"] = END

        graph_builder.add_conditional_edges(
            "supervisor",
            node_builder.should_continue,
            agent_routes
        )
        logger.info(f"  âœ“ æ·»åŠ æ¡ä»¶è·¯ç”±: Supervisor -> Agents/END")

        # æ‰€æœ‰ Agent æ‰§è¡Œå®Œåè¿”å› Supervisor
        for agent_config in request.agents:
            graph_builder.add_edge(agent_config.name, "supervisor")
            logger.info(f"  âœ“ è¿æ¥ {agent_config.name} -> Supervisor")

        # ç¼–è¯‘å¹¶è¿”å›
        compiled_graph = graph_builder.compile()

        logger.info("")
        logger.info("âœ… Supervisor Multi-Agent å›¾ç¼–è¯‘å®Œæˆ")
        logger.info("=" * 80)

        return compiled_graph

    async def execute(self, request: SupervisorMultiAgentRequest) -> SupervisorMultiAgentResponse:
        """æ‰§è¡Œå›¾å¹¶è¿”å›å¢å¼ºçš„å“åº”"""
        graph = await self.compile_graph(request)
        result = await self.invoke(graph, request)

        # ç»Ÿè®¡ token ä½¿ç”¨
        prompt_token = 0
        completion_token = 0

        for message in result.get("messages", []):
            if isinstance(message, AIMessage) and hasattr(message, 'response_metadata'):
                token_usage = message.response_metadata.get('token_usage', {})
                prompt_token += token_usage.get('prompt_tokens', 0)
                completion_token += token_usage.get('completion_tokens', 0)

        # æ ¹æ® output_mode å¤„ç†æœ€ç»ˆæ¶ˆæ¯
        final_message = self._extract_final_message(
            result, request.output_mode)

        return SupervisorMultiAgentResponse(
            message=final_message,
            total_tokens=prompt_token + completion_token,
            prompt_tokens=prompt_token,
            completion_tokens=completion_token,
            executed_agents=result.get("executed_agents", []),
            iterations=result.get("iterations", 0)
        )

    def _extract_final_message(self, result: Dict[str, Any], output_mode: str) -> str:
        """æ ¹æ® output_mode æå–æœ€ç»ˆæ¶ˆæ¯"""
        messages = result.get("messages", [])

        if not messages:
            return "æœªç”Ÿæˆä»»ä½•å“åº”"

        if output_mode == "last_message":
            # ä»…è¿”å›æœ€åä¸€ä¸ª AI æ¶ˆæ¯
            for msg in reversed(messages):
                if isinstance(msg, AIMessage):
                    return msg.content
            return "æœªæ‰¾åˆ°æœ‰æ•ˆçš„ AI å“åº”"

        elif output_mode == "full_history":
            # è¿”å›æ‰€æœ‰ AI æ¶ˆæ¯çš„ç»„åˆ
            ai_messages = [
                msg.content for msg in messages
                if isinstance(msg, AIMessage)
            ]
            return "\n\n---\n\n".join(ai_messages)

        return "æœªçŸ¥çš„ output_mode"
