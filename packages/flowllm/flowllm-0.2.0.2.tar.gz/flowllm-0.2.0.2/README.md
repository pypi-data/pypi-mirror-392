<p align="center">
  <img src="docs/figure/logo.png" alt="FlowLLM Logo" width="50%">
</p>

<p align="center">
  <strong>FlowLLMï¼šè®©åŸºäºLLMçš„HTTP/MCPæœåŠ¡å¼€å‘æ›´ç®€å•</strong><br>
  <em><sub>å¦‚æœè§‰å¾—æœ‰ç”¨ï¼Œæ¬¢è¿ç»™ä¸ª â­ Starï¼Œæ‚¨çš„æ”¯æŒæ˜¯æˆ‘ä»¬æŒç»­æ”¹è¿›çš„åŠ¨åŠ›</sub></em>
</p>

<p align="center">
  <a href="https://pypi.org/project/flowllm/"><img src="https://img.shields.io/badge/python-3.10+-blue" alt="Python Version"></a>
  <a href="https://pypi.org/project/flowllm/"><img src="https://img.shields.io/badge/pypi-0.2.0.0-blue?logo=pypi" alt="PyPI Version"></a>
  <a href="LICENSE"><img src="https://img.shields.io/badge/license-Apache--2.0-black" alt="License"></a>
  <a href="https://github.com/flowllm-ai/flowllm"><img src="https://img.shields.io/github/stars/flowllm-ai/flowllm?style=social" alt="GitHub Stars"></a>
</p>

<p align="center">
  <a href="./README_EN.md">English</a> | ç®€ä½“ä¸­æ–‡
</p>

---

## ğŸ“– ç®€ä»‹

FlowLLM å°† LLM/Embedding/vector_store èƒ½åŠ›å°è£…ä¸º HTTP/MCP æœåŠ¡ï¼Œé€‚ç”¨äº AI å¯¹è¯åŠ©æ‰‹ã€RAG åº”ç”¨ã€å·¥ä½œæµæœåŠ¡ç­‰åœºæ™¯ï¼Œå¹¶å¯é›†æˆåˆ°æ”¯æŒ
MCP çš„å®¢æˆ·ç«¯å·¥å…·ä¸­ã€‚

### ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

<p align="center">
  <img src="docs/figure/framework.png" alt="FlowLLM Framework" width="100%">
</p>

### ğŸŒŸ åŸºäºFlowLLMçš„åº”ç”¨

| é¡¹ç›®å                                           | æè¿°            |
|-----------------------------------------------|---------------|
| [ReMe](https://github.com/agentscope-ai/ReMe) | é¢å‘æ™ºèƒ½ä½“çš„è®°å¿†ç®¡ç†å·¥å…·åŒ… |

### ğŸ“š å­¦ä¹ èµ„æ–™åˆ†äº«

é¡¹ç›®å¼€å‘è€…ä¼šåœ¨è¿™é‡Œåˆ†äº«æœ€è¿‘çš„å­¦ä¹ èµ„æ–™ã€‚

| æ—¥æœŸ         | æ ‡é¢˜                                                                                | æè¿°                                          |
|------------|-----------------------------------------------------------------------------------|---------------------------------------------|
| 2025-11-14 | [HaluMemè§£è¯»](./docs/zh/reading/20251114-halumem.md)                                 | HaluMem: Evaluating Hallucinations in Memory Systems of Agents è§£è¯» |
| 2025-11-13 | [Gemini CLI ä¸Šä¸‹æ–‡ç®¡ç†æœºåˆ¶](./docs/zh/reading/20251113-gemini-cli-context-management.md) | Gemini CLI çš„å¤šå±‚ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥                       |
| 2025-11-10 | [ä¸Šä¸‹æ–‡ç®¡ç†æŒ‡å—](./docs/zh/reading/20251110-manus-context-report.md)                     | ä¸Šä¸‹æ–‡ç®¡ç†æŒ‡å—                                     |
| 2025-11-10 | [LangChain&Manusè§†é¢‘èµ„æ–™](./docs/zh/reading/20251110-manus-context-raw.md)            | LangChain & Manus Context Management  Video |

### â­ æ ¸å¿ƒç‰¹æ€§

- **ç®€å•æ˜“ç”¨çš„ Op å¼€å‘**ï¼šç»§æ‰¿ BaseOp æˆ– BaseAsyncOp åŸºç±»ï¼Œå®ç°ä¸šåŠ¡é€»è¾‘å³å¯ã€‚FlowLLMæä¾›äº†å»¶è¿Ÿåˆå§‹åŒ–çš„ LLMã€Embedding æ¨¡å‹å’Œå‘é‡åº“ï¼Œå¼€å‘è€…åªéœ€é€šè¿‡ `self.llm`ã€`self.embedding_model`ã€`self.vector_store` å³å¯è½»æ¾ä½¿ç”¨è¿™äº›èµ„æºã€‚åŒæ—¶FlowLLMæä¾›äº†å®Œæ•´çš„ Prompt æ¨¡æ¿ç®¡ç†èƒ½åŠ›ï¼Œé€šè¿‡ `prompt_format()` å’Œ `get_prompt()` æ–¹æ³•è¿›è¡Œæ ¼å¼åŒ–å’Œä½¿ç”¨ã€‚

- **çµæ´»çš„ Flow ç¼–æ’**ï¼šé€šè¿‡ YAML é…ç½®æ–‡ä»¶å°† Op ç»„åˆæˆ Flowï¼Œæ”¯æŒçµæ´»çš„ç¼–æ’æ–¹å¼ã€‚`>>` è¡¨ç¤ºä¸²è¡Œç»„åˆï¼Œ`|` è¡¨ç¤ºå¹¶è¡Œç»„åˆï¼Œä¾‹å¦‚ `SearchOp() >> (AnalyzeOp() | TranslateOp()) >> FormatOp()` å¯æ„å»ºå¤æ‚çš„å·¥ä½œæµã€‚å®šä¹‰è¾“å…¥è¾“å‡º Schema åï¼Œä½¿ç”¨ `flowllm config=your_config` å‘½ä»¤å³å¯å¯åŠ¨æœåŠ¡ã€‚

- **è‡ªåŠ¨ç”ŸæˆæœåŠ¡**ï¼šé…ç½®å®Œæˆåï¼ŒFlowLLM ä¼šè‡ªåŠ¨ç”Ÿæˆ HTTPã€MCP å’Œ CMD æœåŠ¡ã€‚HTTP æœåŠ¡æä¾›æ ‡å‡†çš„ RESTful APIï¼Œæ”¯æŒåŒæ­¥ JSON å“åº”å’Œ HTTP Stream æµå¼å“åº”ã€‚MCP æœåŠ¡ä¼šè‡ªåŠ¨æ³¨å†Œä¸º Model Context Protocol å·¥å…·ï¼Œå¯é›†æˆåˆ°æ”¯æŒ MCP çš„å®¢æˆ·ç«¯ä¸­ã€‚CMD æœåŠ¡æ”¯æŒå‘½ä»¤è¡Œæ¨¡å¼æ‰§è¡Œå•ä¸ª Opï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•å’Œè°ƒè¯•ã€‚

---

## âš¡ å¿«é€Ÿå¼€å§‹

### ğŸ“¦ Step0 å®‰è£…

#### ğŸ“¥ From PyPI

```bash
pip install flowllm
```

#### ğŸ”§ From Source

```bash
git clone https://github.com/flowllm-ai/flowllm.git
cd flowllm
pip install -e .
```

è¯¦ç»†å®‰è£…ä¸é…ç½®æ–¹æ³•è¯·å‚è€ƒ [å®‰è£…æŒ‡å—](docs/zh/guide/installation.md)ã€‚

### âš™ï¸ é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼Œé…ç½® API Keyã€‚ä½ å¯ä»¥ä» `example.env` å¤åˆ¶å¹¶ä¿®æ”¹ï¼š

```bash
cp example.env .env
```

ç„¶ååœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ä½ çš„ API Keyï¼š

```bash
FLOW_LLM_API_KEY=sk-xxxx
FLOW_LLM_BASE_URL=https://xxxx/v1
FLOW_EMBEDDING_API_KEY=sk-xxxx
FLOW_EMBEDDING_BASE_URL=https://xxxx/v1
```

è¯¦ç»†é…ç½®è¯´æ˜è¯·å‚è€ƒ [é…ç½®æŒ‡å—](docs/zh/guide/config_guide.md)ã€‚

### ğŸ› ï¸ Step1 æ„å»ºOp

```python
from flowllm.core.context import C
from flowllm.core.op import BaseAsyncOp
from flowllm.core.schema import Message
from flowllm.core.enumeration import Role

@C.register_op()
class SimpleChatOp(BaseAsyncOp):
    async def async_execute(self):
        query = self.context.get("query", "")
        messages = [Message(role=Role.USER, content=query)]
        response = await self.llm.achat(messages=messages)
        self.context.response.answer = response.content.strip()
```

è¯¦ç»†å†…å®¹è¯·å‚è€ƒ [ç®€å• Op æŒ‡å—](docs/zh/guide/async_op_minimal_guide.md)ã€[LLM Op æŒ‡å—](docs/zh/guide/async_op_llm_guide.md) å’Œ [é«˜çº§ Op æŒ‡å—](docs/zh/guide/async_op_advance_guide.md)ï¼ˆåŒ…å« Embeddingã€VectorStore å’Œå¹¶å‘æ‰§è¡Œç­‰é«˜çº§åŠŸèƒ½ï¼‰ã€‚

### ğŸ“ Step2 é…ç½®config

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºå¦‚ä½•æ„å»ºä¸€ä¸ª MCPï¼ˆModel Context Protocolï¼‰æœåŠ¡ã€‚åˆ›å»ºé…ç½®æ–‡ä»¶ `my_mcp_config.yaml`ï¼š

```yaml
backend: mcp

mcp:
  transport: sse
  host: "0.0.0.0"
  port: 8001

flow:
  demo_mcp_flow:
    flow_content: MockSearchOp()
    description: "Search results for a given query."
    input_schema:
      query:
        type: string
        description: "User query"
        required: true

llm:
  default:
    backend: openai_compatible
    model_name: qwen3-30b-a3b-instruct-2507
    params:
      temperature: 0.6
```

### ğŸš€ Step3 å¯åŠ¨ MCP æœåŠ¡

```bash
flowllm \
  config=my_mcp_config \
  backend=mcp \  # å¯é€‰ï¼Œè¦†ç›–configé…ç½®
  mcp.transport=sse \  # å¯é€‰ï¼Œè¦†ç›–configé…ç½®
  mcp.port=8001 \  # å¯é€‰ï¼Œè¦†ç›–configé…ç½®
  llm.default.model_name=qwen3-30b-a3b-thinking-2507  # å¯é€‰ï¼Œè¦†ç›–configé…ç½®
```

æœåŠ¡å¯åŠ¨åå¯ä»¥å‚è€ƒ[Client Guide](docs/zh/guide/client_guide.md)æ¥ä½¿ç”¨æœåŠ¡ï¼Œå¯ä»¥ç›´æ¥è·å–æ¨¡å‹æ‰€éœ€è¦çš„tool_callã€‚

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

### ğŸš€ å…¥é—¨æŒ‡å—
- [å®‰è£…æŒ‡å—](docs/zh/guide/installation.md)
- [é…ç½®æŒ‡å—](docs/zh/guide/config_guide.md)

### ğŸ”§ Op å¼€å‘
- [Op ä»‹ç»](docs/zh/guide/op_introduction.md)
- [ç®€å• Op æŒ‡å—](docs/zh/guide/async_op_minimal_guide.md)
- [LLM Op æŒ‡å—](docs/zh/guide/async_op_llm_guide.md)
- [é«˜çº§ Op æŒ‡å—](docs/zh/guide/async_op_advance_guide.md)
- [Tool Op æŒ‡å—](docs/zh/guide/async_tool_op_guide.md)
- [Vector Store æŒ‡å—](docs/zh/guide/vector_store_guide.md)

### ğŸ”€ Flow ç¼–æ’
- [Flow æŒ‡å—](docs/zh/guide/flow_guide.md)

### ğŸŒ æœåŠ¡ä½¿ç”¨
- [HTTP æœåŠ¡æŒ‡å—](docs/zh/guide/http_service_guide.md)
- [HTTP Stream æŒ‡å—](docs/zh/guide/http_stream_guide.md)
- [MCP æœåŠ¡æŒ‡å—](docs/zh/guide/mcp_service_guide.md)
- [CMD æœåŠ¡æŒ‡å—](docs/zh/guide/cmd_service_guide.md)
- [å®¢æˆ·ç«¯æŒ‡å—](docs/zh/guide/client_guide.md)

---

## ğŸ¤ å‚ä¸è´¡çŒ®

æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼å…·ä½“å‚ä¸æ–¹å¼è¯·å‚è€ƒ [è´¡çŒ®æŒ‡å—](docs/zh/guide/contribution.md)ã€‚

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [Apache 2.0](LICENSE) è®¸å¯è¯ã€‚

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=flowllm-ai/flowllm&type=Date)](https://www.star-history.com/#flowllm-ai/flowllm&Date)

---

<p align="center">
  <a href="https://github.com/flowllm-ai/flowllm">GitHub</a> â€¢
  <a href="https://flowllm-ai.github.io/flowllm/">æ–‡æ¡£</a> â€¢
  <a href="https://pypi.org/project/flowllm/">PyPI</a>
</p>
