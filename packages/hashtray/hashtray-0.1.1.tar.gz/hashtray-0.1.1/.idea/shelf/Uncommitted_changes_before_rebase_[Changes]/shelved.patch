Index: hashtray/get_gravatar.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import hashlib\r\nimport logging\r\nimport re\r\n\r\nimport httpx\r\nfrom rich.console import Console\r\nfrom rich.table import Table\r\nfrom rich.theme import Theme\r\nfrom scrapling.fetchers import AsyncFetcher\r\n\r\nlogging.getLogger(\"scrapling\").setLevel(logging.CRITICAL)\r\n\r\nclass Gravatar:\r\n    def __init__(self, email=None, ghash: str = None, account: str = None):\r\n        self.rich = Console(\r\n            highlight=False, theme=Theme({\"repr.url\": \"not underline white\"})\r\n        )\r\n        self.gravatar_url = \"https://gravatar.com/\"\r\n        self.email = email\r\n        self.account = account\r\n        if account:\r\n            self.account_url = self.gravatar_url + account\r\n        elif ghash:\r\n            self.ghash = ghash\r\n            self.account_url = self.gravatar_url + ghash\r\n            self.hash = ghash\r\n        else:\r\n            self.check_email()\r\n            self.hash = hashlib.md5(email.encode()).hexdigest()\r\n            self.account_url = self.gravatar_url + self.hash\r\n        self.json_hash = None\r\n        self.is_exists = False\r\n\r\n\r\n    def check_email(self) -> bool:\r\n        \"\"\"\r\n        Check if a string is a valid email\r\n        \"\"\"\r\n        if re.match(r\"(^[a-zA-Z0-9_.%+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", self.email):\r\n            return True\r\n        else:\r\n            self.rich.print(f\"[red]Invalid email address: {self.email}.[/red]\\n\")\r\n            exit()\r\n\r\n    async def get_gravatar_json(self) -> dict | None:\r\n        \"\"\"\r\n        Get the user's json data from Gravatar\r\n        \"\"\"\r\n        async with httpx.AsyncClient() as client:\r\n            try:\r\n                res = await client.get(self.account_url + \".json\")\r\n                res.raise_for_status()\r\n                self.is_exists = True\r\n                self.hash = res.json()[\"entry\"][0][\"hash\"]\r\n                return res.json()[\"entry\"][0]\r\n            except httpx.HTTPError:\r\n                if res.status_code == 404:\r\n                    self.rich.print(f\"[red]Gravatar profile not found (404 HTTP status error)[/red]\")\r\n                elif res.status_code == 429:\r\n                    self.rich.print(\r\n                        f\"[red]Too many requests. Please try again later or with another IP (429 HTTP status error)[/red]\")\r\n                else:\r\n                    self.rich.print(f\"[red]An error occurred. Try again.[/red]\")\r\n                return None\r\n\r\n            except Exception as e:\r\n                self.rich.print(f\"[red]An error occurred: {e}[/red]\")\r\n            return None\r\n\r\n    async def scrap_account(self) -> dict:\r\n        \"\"\"\r\n        Scrap the user account page to retrieve all infos as the json/API is now limited\r\n        \"\"\"\r\n        def find_accounts(page):\r\n            if verified := page.find(\".is-verified-accounts\"):\r\n                accounts_list = []\r\n                for account in verified.find_all(\".card-item__info\"):\r\n                    network = account.find(\".card-item__label-text\").text.clean()\r\n                    urls = account.find_all(\"a\")\r\n                    for url in urls:\r\n                        if url.attrib.get(\"class\") != \"card-item__checkmark-icon\":\r\n                            account_url = url.attrib[\"href\"]\r\n                            accounts_list.append({\"account\": network, \"url\": account_url})\r\n                return accounts_list\r\n            return None\r\n\r\n        def find_images(page):\r\n            if gallery := page.find(\".g-profile__photo-gallery\"):\r\n                images_list = []\r\n                for image in gallery.find_all(\"img\"):\r\n                    url = image.attrib[\"data-url\"] + \"?size=666\"\r\n                    images_list.append(url)\r\n                return images_list\r\n            return None\r\n\r\n        def find_payments(page):\r\n            if payment := page.find(\".payments-drawer\"):\r\n                payment_list = []\r\n                for item in payment.find_all(\".card-item\"):\r\n                    title = item.find(\".card-item__label-text\").text.clean()\r\n                    try:\r\n                        asset = item.find(\"a\").attrib[\"href\"]\r\n                    except:\r\n                        asset = item.find(\".card-item__info span:not(.card-item__label-text)\").text.clean()\r\n                    payment_list.append({\"title\": title, \"asset\": asset})\r\n                return payment_list if len(payment_list) > 0 else None\r\n            return None\r\n\r\n        def find_interests(page):\r\n            if interests := page.find(\".g-profile__interests-list\"):\r\n                interests_list = []\r\n                for interest in interests.find_all(\"li a\"):\r\n                    interests_list.append(interest.text.clean())\r\n                for interest in interests.find_all(\"li span\"):\r\n                    interests_list.append(interest.text.clean())\r\n                return interests_list\r\n            return None\r\n\r\n        def find_links(page):\r\n            if links := page.find(\".g-profile__links\"):\r\n                links_list = []\r\n                for link in links.find_all(\".card-item__info\"):\r\n                    description = None\r\n                    a = link.find(\"a\")\r\n                    name = a.text.clean()[:-2]\r\n                    url = a.attrib[\"href\"]\r\n                    if desc := link.find(\"p\"):\r\n                        description = desc.text\r\n                    links_list.append({\"name\": name, \"url\": url, \"description\": description})\r\n                return links_list\r\n            return None\r\n\r\n        gravatar_page = await AsyncFetcher().get(self.account_url)\r\n\r\n        scrapped_infos = {\r\n            \"accounts\": find_accounts(gravatar_page),\r\n            \"photos\": find_images(gravatar_page),\r\n            \"payments\": find_payments(gravatar_page),\r\n            \"interests\": find_interests(gravatar_page),\r\n            \"links\": find_links(gravatar_page),\r\n        }\r\n        return scrapped_infos\r\n\r\n    async def aggregate_gravatar_infos(self) -> dict | None:\r\n        \"\"\"\r\n        Aggregate the account json data and scrapped data\r\n        \"\"\"\r\n        if json_data := await self.get_gravatar_json():\r\n            scrapped_data = await self.scrap_account()\r\n\r\n            infos = {\r\n                \"Hash\": self.hash or self.json_hash,\r\n                \"Profile URL\": self.account_url,\r\n                \"Avatar\": json_data.get(\"thumbnailUrl\") + \"?size=666\",\r\n                \"Last edit\": json_data.get(\"lastProfileEdit\"),\r\n                \"Location\": json_data.get(\"currentLocation\"),\r\n                \"Preferred username\": json_data.get(\"preferredUsername\"),\r\n                \"Display name\": json_data.get(\"displayName\"),\r\n                \"Pronunciation\": json_data.get(\"pronunciation\"),\r\n                \"Name\": json_data.get(\"name\"),\r\n                \"Pronouns\": json_data.get(\"pronouns\"),\r\n                \"About me\": json_data.get(\"aboutMe\"),\r\n                \"Job Title\": json_data.get(\"jobTitle\"),\r\n                \"Company\": json_data.get(\"company\"),\r\n                \"Emails\": [email[\"value\"] for email in json_data.get(\"emails\")] if json_data.get(\"emails\") else None,\r\n                \"Contact Info\": json_data.get(\"contactInfo\"),\r\n                \"Phone Numbers\": json_data.get(\"phoneNumbers\"),\r\n                \"Verified accounts\": scrapped_data[\"accounts\"],\r\n                \"Payments\": scrapped_data[\"payments\"],\r\n                \"Photos\": scrapped_data[\"photos\"],\r\n                \"Interests\": scrapped_data[\"interests\"],\r\n                \"Links\": scrapped_data[\"links\"],\r\n            }\r\n            return infos\r\n        else:\r\n            return None\r\n\r\n    async def show_gravatar_infos(self, data: dict = None) -> None:\r\n        \"\"\"\r\n        Print the gravatar infos in a table format\r\n        \"\"\"\r\n        # Print data in list format\r\n        def print_list(key: str, value: list) -> None:\r\n            all_values = []\r\n            for item in value:\r\n                all_values.append(str(item))\r\n            table.add_row(key, \"\\n\".join(all_values))\r\n        # Print data in list of dicts format\r\n        def print_list_of_dicts(key: str, value: list) -> None:\r\n            all_values = []\r\n            for item in value:\r\n                if isinstance(item, dict) and len(item) == 2:\r\n                    keys = list(item.keys())\r\n                    left = item[keys[0]]\r\n                    right = item[keys[1]]\r\n                    all_values.append(\"{:<13s}{}\".format(left, right))\r\n\r\n                else:\r\n                    for sub_key, sub_value in item.items():\r\n                        all_values.append(sub_value)\r\n\r\n            table.add_row(key, \"\\n\".join(all_values))\r\n\r\n        # Get gravatar data\r\n        with self.rich.status(\"Retrieving and scraping profile...\", spinner=\"dots\", spinner_style=\"turquoise2\") as status:\r\n            data = await self.aggregate_gravatar_infos()\r\n            if not data:\r\n                exit(\"\\n\")\r\n\r\n        # Build the table\r\n        table = Table(title=f\"[b turquoise2]{data['Preferred username']}[/b turquoise2]\", show_header=False, show_lines=True)\r\n        table.add_column(\"\", justify=\"right\", style=\"turquoise2\")\r\n        table.add_column(\"\", style=\"bold bright_white\")\r\n\r\n        if data:\r\n            for key, value in data.items():\r\n                if value:\r\n                    if isinstance(value, list) and all(isinstance(i, dict) for i in value):\r\n                        print_list_of_dicts(key, value)\r\n                    elif isinstance(value, list):\r\n                        print_list(key, value)\r\n                    else:\r\n                        table.add_row(key, str(value))\r\n\r\n        # Print the table\r\n        self.rich.print(table)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hashtray/get_gravatar.py b/hashtray/get_gravatar.py
--- a/hashtray/get_gravatar.py	(revision 690d780a3ddde67a387eef3d8c8f85ee814f9f70)
+++ b/hashtray/get_gravatar.py	(date 1763232748864)
@@ -31,7 +31,6 @@
         self.json_hash = None
         self.is_exists = False
 
-
     def check_email(self) -> bool:
         """
         Check if a string is a valid email
@@ -130,7 +129,10 @@
                 return links_list
             return None
 
-        gravatar_page = await AsyncFetcher().get(self.account_url)
+        # gravatar_page = await AsyncFetcher().get(self.account_url)
+        async with httpx.AsyncClient() as client:
+            gravatar_page = await client.get(self.account_url)
+
 
         scrapped_infos = {
             "accounts": find_accounts(gravatar_page),
Index: hashtray/permutator.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import itertools\r\nfrom typing import Any, Generator\r\n\r\n\r\nclass Permute:\r\n    def __init__(self, chunks: list, domains: list, crazy: bool = False):\r\n\r\n        self.chunks = chunks\r\n        self.len_chunks = len(self.chunks)\r\n        self.crazy = crazy\r\n        self.separators = [\"\", \".\", \"_\", \"-\"]\r\n        self.domains = domains\r\n        self.len_domains = len(self.domains)\r\n\r\n    def get_combination_count(self) -> int:\r\n        # Calculate the total number of combinations for tdqm bar progress\r\n        total = 0\r\n        for r in range(1, self.len_chunks + 1):\r\n            if r == 1:\r\n                # Add single chunks\r\n                total += self.len_chunks\r\n            else:\r\n                # Calc. combinations\r\n                combinations = itertools.combinations(range(self.len_chunks), r)\r\n                # Calc. permutations\r\n                permutations = itertools.permutations(range(r))\r\n                # Total possibilities for n chunks\r\n                combination_count = len(list(combinations)) * len(list(permutations))\r\n                # x number of special chars\r\n                if self.crazy:\r\n                    # crazy mode\r\n                    total += combination_count * len(self.separators) ** (r - 1)\r\n                else:\r\n                    # normal mode\r\n                    total += combination_count * len(self.separators)\r\n        # Multiply by the number of domains\r\n        return total * self.len_domains\r\n\r\n    def combinator(self) -> Generator[str, Any, None]:\r\n        # Generate all possible email combinations for unique elements\r\n\r\n        # Generate all permutations/combinations of elements\r\n        # Per chunk\r\n        for r in range(1, len(self.chunks) + 1):\r\n            # Per chunk permutation\r\n            for permutation in itertools.permutations(self.chunks, r):\r\n                # Per domain\r\n                for domain in self.domains:\r\n                    # No need of separator for single chunks\r\n                    if len(permutation) == 1:\r\n                        email_local_part = permutation[0]\r\n                        yield f\"{email_local_part}@{domain}\"\r\n                    else:\r\n                        # Crazy mode: per separator, any kind of separator in each combination at any place\r\n                        if self.crazy:\r\n                            for separators in itertools.product(\r\n                                self.separators, repeat=r - 1\r\n                            ):\r\n                                email_local_part = \"\".join(\r\n                                    f\"{e}{s}\"\r\n                                    for e, s in itertools.zip_longest(\r\n                                        permutation, separators, fillvalue=\"\"\r\n                                    )\r\n                                )\r\n                                yield f\"{email_local_part}@{domain}\"\r\n                        else:\r\n                            # Normal mode: per separator, unique separator in each combination at any place\r\n                            for separator in self.separators:\r\n                                email_local_part = separator.join(permutation)\r\n                                yield f\"{email_local_part}@{domain}\"\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hashtray/permutator.py b/hashtray/permutator.py
--- a/hashtray/permutator.py	(revision 690d780a3ddde67a387eef3d8c8f85ee814f9f70)
+++ b/hashtray/permutator.py	(date 1763232542256)
@@ -20,9 +20,9 @@
                 # Add single chunks
                 total += self.len_chunks
             else:
-                # Calc. combinations
+                # Combinations
                 combinations = itertools.combinations(range(self.len_chunks), r)
-                # Calc. permutations
+                # Permutations
                 permutations = itertools.permutations(range(r))
                 # Total possibilities for n chunks
                 combination_count = len(list(combinations)) * len(list(permutations))
