import atexit
import pickle
import threading
from datetime import datetime, timedelta
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

import click
from loguru import logger

from .betterer import subprocess_run


class TimeBasedCache:
    _instance = None
    _lock = threading.Lock()

    def __init__(self, cache_file: str = "time_data.pkl", allowed_directories: list = None):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            cache_file: ç¼“å­˜æ•°æ®ä¿å­˜çš„æ–‡ä»¶å
            allowed_directories: å…è®¸æ¸…ç†çš„ç›®å½•åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸é™åˆ¶
        """
        self.cache_file: Path = Path(cache_file)
        self.lock_file = self.cache_file.with_suffix('.lock')  # é”æ–‡ä»¶
        self.allowed_directories: list = allowed_directories if allowed_directories is not None else []
        self.cache: dict = self._load_cache()
        self._internal_lock = threading.Lock()  # âœ… æ‰€æœ‰è®¿é—®éƒ½é è¿™ä¸ªä¸²è¡Œé”ï¼

        # æ³¨å†Œç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°
        atexit.register(self._save_cache)

    @classmethod
    def get_instance(cls):
        with cls._lock:  # åªåœ¨å®ä¾‹åˆ›å»ºæ—¶åŠ é”
            if cls._instance is None:
                cls._instance = cls()
        return cls._instance

    def _load_cache(self) -> dict:
        """ä»æ–‡ä»¶åŠ è½½ç¼“å­˜æ•°æ®"""
        if self.cache_file.exists():
            with self.cache_file.open('rb') as f:
                return pickle.load(f)
        return {}

    def _save_cache(self) -> None:
        """ä¿å­˜ç¼“å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        with self.cache_file.open('wb') as f:
            pickle.dump(self.cache, f)

    def update(self, items: list, timestamp: datetime = None) -> None:
        """
        æ›´æ–°åˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ çš„æœ€è¿‘å‡ºç°æ—¶é—´

        Args:
            items: è¦æ›´æ–°çš„å…ƒç´ åˆ—è¡¨
            timestamp: å¯é€‰çš„æ—¶é—´æˆ³ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å½“å‰æ—¶é—´
        """
        with self._internal_lock:  # ğŸ‘ˆ æ‰€æœ‰è®¿é—®éƒ½æ’é˜Ÿ
            if timestamp is None:
                timestamp = datetime.now()

            for item in items:
                item_path = Path(item)
                # ä¿ç•™æ—§çš„æ—¶é—´æˆ³ï¼Œå¦‚æœæ–°æ—¶é—´æˆ³æ›´æ—©åˆ™ä¸æ›´æ–°
                save_timestamp = timestamp.timestamp()
                if str(item) in self.cache:
                    old_timestamp = self.cache[str(item)]['last_access']
                    if old_timestamp > save_timestamp:
                        save_timestamp = old_timestamp
                if item_path.exists():
                    self.cache[str(item)] = {
                        'last_access': save_timestamp,
                        'file_path': str(item_path),
                    }
                else:
                    logger.warning(f"æ›´æ–°ç¼“å­˜æ—¶å‘ç°æ–‡ä»¶ä¸å­˜åœ¨ï¼š{item_path}")

            # ç«‹å³ä¿å­˜ç¼“å­˜
            self._save_cache()

    def clearcache(self, time_diff: timedelta, dry_run: bool = False, check_corruption: bool = False) -> None:
        """
        æ¸…ç†æ—©äºæŒ‡å®šæ—¶é—´å·®çš„å…ƒç´ åŠå…¶å¯¹åº”çš„æ–‡ä»¶

        Args:
            time_diff: æ—¶é—´å·®å¯¹è±¡ï¼Œç”¨äºåˆ¤æ–­å“ªäº›å…ƒç´ éœ€è¦è¢«æ¸…ç†
            dry_run: å¦‚æœä¸ºTrueï¼Œåˆ™åªæ‰“å°å°†è¦åˆ é™¤çš„å…ƒç´ å’Œæ–‡ä»¶ï¼Œè€Œä¸å®é™…åˆ é™¤
            check_corruption: å¦‚æœä¸ºTrueï¼Œåˆ™æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦æŸå
        """
        current_time = datetime.now()
        items_to_remove = []
        items_to_delete = []
        count = 0
        size = 0

        pool = ThreadPoolExecutor()
        futures = []

        def task(info_: dict) -> tuple[str | None, str | None]:
            if info_['file_path'] and Path(info_['file_path']).exists() and info_['exists']:
                result = subprocess_run(['ffmpeg', '-hwaccel', 'cuda', '-v', 'error', '-i', info_['file_path'], '-f', 'null', '-'])
                return result.stderr, info_['file_path']
            return None, None

        for item, info in self.cache.items():
            last_access = info['last_access']
            last_access = datetime.fromtimestamp(last_access)
            if not info['file_path']:
                logger.warning(f"ç¼“å­˜é¡¹ç¼ºå°‘æ–‡ä»¶è·¯å¾„ï¼š{item}")
                items_to_remove.append(item)
                continue
            file_path = Path(info['file_path'])
            if not file_path.exists():
                logger.warning(f"ç¼“å­˜é¡¹å¯¹åº”çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼š{info['file_path']}")
                items_to_remove.append(item)
                continue

            # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•èŒƒå›´å†…
            if self.allowed_directories:
                # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•åˆ—è¡¨ä¸­
                allowed = False
                for allowed_dir in self.allowed_directories:
                    allowed_path = Path(allowed_dir)
                    if file_path.is_relative_to(allowed_path):
                        allowed = True
                        break
                if not allowed:
                    # è‹¥ä¸åœ¨å½“å‰ç›®å½•åˆ™ç§»é™¤
                    if not file_path.is_relative_to(Path.cwd()):
                        items_to_remove.append(item)
                        logger.info(f"ç§»é™¤ä¸åœ¨å½“å‰ç›®å½•çš„ç¼“å­˜ï¼š{info['file_path']}")
                        continue
                    continue  # è·³è¿‡ä¸åœ¨å…è®¸ç›®å½•ä¸­çš„æ–‡ä»¶
                if current_time - last_access > time_diff:
                    items_to_delete.append(item)
                    continue

            count += 1
            size += Path(info['file_path']).stat().st_size
            if check_corruption:
                future = pool.submit(task, info)
                futures.append(future)

        for item in items_to_remove:
            # ä»…ä»ç¼“å­˜ä¸­ç§»é™¤
            del self.cache[item]
            print(f"å·²ä»ç¼“å­˜ä¸­ç§»é™¤ï¼š{item}")

        for item in items_to_delete:
            # å¦‚æœå¯¹åº”çš„æ˜¯æ–‡ä»¶ï¼Œå°è¯•åˆ é™¤
            if self.cache[item]['file_path'] and Path(self.cache[item]['file_path']).exists():
                if dry_run:
                    print(f"[æ¨¡æ‹Ÿè¿è¡Œ] å°†åˆ é™¤æ–‡ä»¶ï¼š{self.cache[item]['file_path']}")
                    continue
                Path(self.cache[item]['file_path']).unlink()
                print(f"å·²åˆ é™¤æ–‡ä»¶ï¼š{self.cache[item]['file_path']}")

            # ä»ç¼“å­˜ä¸­ç§»é™¤
            del self.cache[item]
            print(f"å·²ä»ç¼“å­˜ä¸­ç§»é™¤ï¼š{item}")

        print(f"æ€»å…±åˆ é™¤é¡¹ï¼š{count}ï¼Œé‡Šæ”¾ç©ºé—´ï¼š{size / (1024 * 1024):.2f} MB")

        # ä¿å­˜æ›´æ–°åçš„ç¼“å­˜
        self._save_cache()

        for future in futures:
            stderr, file_path = future.result()
            if stderr:
                print(f"æ–‡ä»¶å¯èƒ½æŸåæˆ–ä¸å¯ç”¨ï¼š{file_path}\né”™è¯¯ä¿¡æ¯ï¼š{stderr}")

        # ç»Ÿè®¡å‰©ä½™ç¼“å­˜ä¿¡æ¯
        remaining_count = len(self.cache)
        remaining_size = 0
        seen_inodes = set()  # å­˜å‚¨ (device_id, inode) å…ƒç»„ï¼Œç”¨äºå»é‡
        for info in self.cache.values():
            p = Path(info['file_path'])
            if not p.exists():
                logger.warning(f"ç»Ÿè®¡ç¼“å­˜å¤§å°æ—¶å‘ç°æ–‡ä»¶ä¸å­˜åœ¨ï¼š{p}")
                continue
            stat_info = p.stat()
            inode_key = (stat_info.st_dev, stat_info.st_ino)
            if inode_key in seen_inodes:
                # print(f"è·³è¿‡é‡å¤æ–‡ä»¶ï¼š{p}")
                continue
            seen_inodes.add(inode_key)
            remaining_size += stat_info.st_size
        print(f"å‰©ä½™ç¼“å­˜é¡¹ï¼š{remaining_count}ï¼Œå‰©ä½™å¤§å°ï¼š{remaining_size / (1024 * 1024):.2f} MB")

        # æŸ¥è¯¢åœ¨ç›®å½•ä¸­ä½†ä¸åœ¨ç¼“å­˜ä¸­çš„æ–‡ä»¶
        for allowed_dir in self.allowed_directories:
            allowed_path = Path(allowed_dir)
            for file in allowed_path.rglob('*'):
                if file.is_file():
                    if str(file) not in self.cache:
                        file_size = file.stat().st_size
                        print(f"ç›®å½•ä¸­ä½†ä¸åœ¨ç¼“å­˜ä¸­çš„æ–‡ä»¶ï¼š{file}ï¼Œå¤§å°ï¼š{file_size / (1024 * 1024):.2f} MB, ä¿®æ”¹æ—¶é—´ï¼š{datetime.fromtimestamp(file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')}")
                        file.unlink()

    def get_cache_info(self) -> dict:
        """è·å–ç¼“å­˜ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
        readable_cache = {}
        for item, info in self.cache.items():
            readable_info = info.copy()
            readable_info['last_access'] = datetime.fromtimestamp(info['last_access']).strftime('%Y-%m-%d %H:%M:%S')
            readable_cache[item] = readable_info
        return readable_cache

    def __del__(self) -> None:
        """ææ„å‡½æ•°ï¼Œç¡®ä¿ç¼“å­˜è¢«ä¿å­˜"""
        self._save_cache()


@click.command()
@click.argument('cache_dir', default=Path('./cache_dir'), type=click.Path(exists=True, file_okay=False, path_type=Path))
@click.option('--days', default=30, type=float, help='æ¸…ç†æ—©äºå¤šå°‘å¤©å‰çš„æ–‡ä»¶', show_default=True)
@click.option('--dry-run', is_flag=True, help='ä»…æ‰“å°å°†è¦åˆ é™¤çš„æ–‡ä»¶ï¼Œè€Œä¸å®é™…åˆ é™¤')
@click.option('--check-corruption', is_flag=True, help='æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦æŸå')
def cli(cache_dir: Path, days: float, dry_run: bool, check_corruption: bool) -> None:
    """å‘½ä»¤è¡Œæ¥å£ï¼Œæ¸…ç†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­æ—©äºæŒ‡å®šå¤©æ•°çš„ç¼“å­˜æ–‡ä»¶"""
    cache = TimeBasedCache(allowed_directories=[str(cache_dir)])
    cache.clearcache(timedelta(days=days), dry_run=dry_run, check_corruption=check_corruption)


if __name__ == '__main__':
    pass
