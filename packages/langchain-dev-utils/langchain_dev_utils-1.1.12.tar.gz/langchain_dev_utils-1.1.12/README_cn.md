# ğŸ¦œï¸ğŸ§° langchain-dev-utils

<p align="center">
    <em>ç”¨äº LangChain å’Œ LangGraph å¼€å‘çš„å®ç”¨å·¥å…·åº“ã€‚</em>
</p>

<p align="center">
  ğŸ“š <a href="https://tbice123123.github.io/langchain-dev-utils-docs/en/">English</a> â€¢ 
  <a href="https://tbice123123.github.io/langchain-dev-utils-docs/zh/">ä¸­æ–‡</a>
</p>

[![PyPI](https://img.shields.io/pypi/v/langchain-dev-utils.svg?color=%2334D058&label=pypi%20package)](https://pypi.org/project/langchain-dev-utils/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/python-3.11|3.12|3.13|3.14-%2334D058)](https://www.python.org/downloads)
[![Downloads](https://static.pepy.tech/badge/langchain-dev-utils/month)](https://pepy.tech/project/langchain-dev-utils)
[![Documentation](https://img.shields.io/badge/docs-latest-blue)](https://tbice123123.github.io/langchain-dev-utils-docs/zh/)

> å½“å‰ä¸ºä¸­æ–‡ç‰ˆï¼Œè‹±æ–‡ç‰ˆè¯·è®¿é—®[English Documentation](https://github.com/TBice123123/langchain-dev-utils/blob/master/README.md)

**langchain-dev-utils** æ˜¯ä¸€ä¸ªä¸“æ³¨äºæå‡ LangChain å’Œ LangGraph å¼€å‘ä½“éªŒçš„å®ç”¨å·¥å…·åº“ã€‚å®ƒæä¾›äº†ä¸€ç³»åˆ—å¼€ç®±å³ç”¨çš„å·¥å…·å‡½æ•°ï¼Œæ—¢èƒ½å‡å°‘é‡å¤ä»£ç ç¼–å†™ï¼Œåˆèƒ½æé«˜ä»£ç çš„ä¸€è‡´æ€§å’Œå¯è¯»æ€§ã€‚é€šè¿‡ç®€åŒ–å¼€å‘å·¥ä½œæµç¨‹ï¼Œè¿™ä¸ªåº“å¯ä»¥å¸®åŠ©ä½ æ›´å¿«åœ°æ„å»ºåŸå‹ã€æ›´é¡ºç•…åœ°è¿›è¡Œè¿­ä»£ï¼Œå¹¶åˆ›å»ºæ›´æ¸…æ™°ã€æ›´å¯é çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ AI åº”ç”¨ã€‚

## ğŸš€ å®‰è£…

```bash
pip install -U langchain-dev-utils

# å®‰è£…å®Œæ•´åŠŸèƒ½ç‰ˆï¼š
pip install -U langchain-dev-utils[standard]
```

## ğŸ“¦ æ ¸å¿ƒåŠŸèƒ½

### 1. **æ¨¡å‹ç®¡ç†**

åœ¨ `langchain` ä¸­ï¼Œ`init_chat_model`/`init_embeddings` å‡½æ•°å¯ç”¨äºåˆå§‹åŒ–å¯¹è¯æ¨¡å‹å®ä¾‹/åµŒå…¥æ¨¡å‹å®ä¾‹ï¼Œä½†å…¶æ”¯æŒçš„æ¨¡å‹æä¾›å•†è¾ƒä¸ºæœ‰é™ã€‚æœ¬æ¨¡å—æä¾›äº†ä¸€ä¸ªæ³¨å†Œå‡½æ•°ï¼ˆ`register_model_provider`/`register_embeddings_provider`ï¼‰ï¼Œæ–¹ä¾¿æ³¨å†Œä»»æ„æ¨¡å‹æä¾›å•†ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ `load_chat_model` / `load_embeddings` è¿›è¡Œæ¨¡å‹åŠ è½½ã€‚

#### 1.1 å¯¹è¯æ¨¡å‹ç®¡ç†

ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ä¸ªå‡½æ•°ï¼š

- `register_model_provider`ï¼šæ³¨å†Œå¯¹è¯æ¨¡å‹æä¾›å•†
- `load_chat_model`ï¼šåŠ è½½å¯¹è¯æ¨¡å‹

`register_model_provider` å‚æ•°è¯´æ˜ï¼š

- `provider_name`ï¼šæ¨¡å‹æä¾›å•†åç§°ï¼Œä½œä¸ºåç»­æ¨¡å‹åŠ è½½çš„æ ‡è¯†
- `chat_model`ï¼šå¯¹è¯æ¨¡å‹ï¼Œå¯ä»¥æ˜¯ ChatModel æˆ–å­—ç¬¦ä¸²ï¼ˆç›®å‰æ”¯æŒ "openai-compatible"ï¼‰
- `base_url`ï¼šæ¨¡å‹æä¾›å•†çš„ API åœ°å€ï¼ˆå¯é€‰ï¼Œå½“ `chat_model` ä¸ºå­—ç¬¦ä¸²ä¸”æ˜¯"openai-compatible"æ—¶æœ‰æ•ˆï¼‰
- `provider_config`ï¼šæ¨¡å‹æä¾›å•†çš„ç›¸å…³é…ç½®ï¼ˆå¯é€‰ï¼Œå½“ `chat_model` ä¸ºå­—ç¬¦ä¸²ä¸”æ˜¯ "openai-compatible" æ—¶æœ‰æ•ˆï¼‰ï¼Œå¯ä»¥é…ç½®ä¸€äº›æä¾›å•†çš„ç›¸å…³å‚æ•°ï¼Œä¾‹å¦‚æ˜¯å¦æ”¯æŒ json_mode çš„ç»“æ„åŒ–è¾“å‡ºæ–¹å¼ã€æ”¯æŒçš„ tool_choice åˆ—è¡¨ç­‰

`load_chat_model` å‚æ•°è¯´æ˜ï¼š

- `model`ï¼šå¯¹è¯æ¨¡å‹åç§°ï¼Œç±»å‹ä¸º str
- `model_provider`ï¼šå¯¹è¯æ¨¡å‹æä¾›å•†åç§°ï¼Œç±»å‹ä¸º strï¼Œå¯é€‰
- `kwargs`ï¼šä¼ é€’ç»™å¯¹è¯æ¨¡å‹ç±»çš„é¢å¤–çš„å‚æ•°ï¼Œä¾‹å¦‚ temperatureã€top_p ç­‰

å‡è®¾æ¥å…¥ä½¿ç”¨`vllm`éƒ¨ç½²çš„ qwen3-4b æ¨¡å‹ï¼Œåˆ™å‚è€ƒä»£ç å¦‚ä¸‹ï¼š

```python
from langchain_dev_utils.chat_models import (
    register_model_provider,
    load_chat_model,
)

# æ³¨å†Œæ¨¡å‹æä¾›å•†
register_model_provider(
    provider_name="vllm",
    chat_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)

# åŠ è½½æ¨¡å‹
model = load_chat_model("vllm:qwen3-4b")
print(model.invoke("Hello"))
```

#### 1.2 åµŒå…¥æ¨¡å‹ç®¡ç†

ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ä¸ªå‡½æ•°ï¼š

- `register_embeddings_provider`ï¼šæ³¨å†ŒåµŒå…¥æ¨¡å‹æä¾›å•†
- `load_embeddings`ï¼šåŠ è½½åµŒå…¥æ¨¡å‹

`register_embeddings_provider` å‚æ•°è¯´æ˜ï¼š

- `provider_name`ï¼šåµŒå…¥æ¨¡å‹æä¾›å•†åç§°ï¼Œä½œä¸ºåç»­æ¨¡å‹åŠ è½½çš„æ ‡è¯†
- `embeddings_model`ï¼šåµŒå…¥æ¨¡å‹ï¼Œå¯ä»¥æ˜¯ Embeddings æˆ–å­—ç¬¦ä¸²ï¼ˆç›®å‰æ”¯æŒ "openai-compatible"ï¼‰
- `base_url`ï¼šæ¨¡å‹æä¾›å•†çš„ API åœ°å€ï¼ˆå¯é€‰ï¼Œå½“ `embeddings_model` ä¸ºå­—ç¬¦ä¸²ä¸”æ˜¯"openai-compatible"æ—¶æœ‰æ•ˆï¼‰

`load_embeddings` å‚æ•°è¯´æ˜ï¼š

- `model`ï¼šåµŒå…¥æ¨¡å‹åç§°ï¼Œç±»å‹ä¸º str
- `provider`ï¼šåµŒå…¥æ¨¡å‹æä¾›å•†åç§°ï¼Œç±»å‹ä¸º strï¼Œå¯é€‰
- `kwargs`ï¼šå…¶å®ƒé¢å¤–çš„å‚æ•°

å‡è®¾æ¥å…¥ä½¿ç”¨`vllm`éƒ¨ç½²çš„ qwen3-embedding-4b æ¨¡å‹ï¼Œåˆ™å‚è€ƒä»£ç å¦‚ä¸‹ï¼š

```python
from langchain_dev_utils.embeddings import register_embeddings_provider, load_embeddings

# æ³¨å†ŒåµŒå…¥æ¨¡å‹æä¾›å•†
register_embeddings_provider(
    provider_name="vllm",
    embeddings_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)

# åŠ è½½åµŒå…¥æ¨¡å‹
embeddings = load_embeddings("vllm:qwen3-embedding-4b")
emb = embeddings.embed_query("Hello")
print(emb)
```

**å¯¹äºæ›´å¤šå…³äºæ¨¡å‹ç®¡ç†çš„ç›¸å…³ä»‹ç»ï¼Œè¯·å‚è€ƒ**: [å¯¹è¯æ¨¡å‹ç®¡ç†](https://tbice123123.github.io/langchain-dev-utils-docs/zh/model-management/chat.html)ã€[åµŒå…¥æ¨¡å‹ç®¡ç†](https://tbice123123.github.io/langchain-dev-utils-docs/zh/model-management/embedding.html)

### 2. **æ¶ˆæ¯è½¬æ¢**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- å°†æ€ç»´é“¾å†…å®¹åˆå¹¶åˆ°æœ€ç»ˆå“åº”ä¸­
- æµå¼å†…å®¹åˆå¹¶
- å†…å®¹æ ¼å¼åŒ–å·¥å…·

#### 2.1 æµå¼å†…å®¹åˆå¹¶

å¯¹äºä½¿ç”¨`stream()`å’Œ`astream()`æ‰€è·å¾—çš„æµå¼å“åº”ï¼Œå¯ä»¥ä½¿ç”¨`merge_ai_message_chunk`è¿›è¡Œåˆå¹¶ä¸ºä¸€ä¸ªæœ€ç»ˆçš„ AIMessageã€‚

`merge_ai_message_chunk` å‚æ•°è¯´æ˜ï¼š

- `chunks`ï¼šAIMessageChunk åˆ—è¡¨

```python
chunks = list(model.stream("Hello"))
merged = merge_ai_message_chunk(chunks)
```

#### 2.2 æ ¼å¼åŒ–åˆ—è¡¨å†…å®¹

å¯¹äºä¸€ä¸ªåˆ—è¡¨ï¼Œå¯ä»¥ä½¿ç”¨`format_sequence`è¿›è¡Œæ ¼å¼åŒ–ã€‚

`format_sequence` å‚æ•°è¯´æ˜ï¼š

- `inputs`ï¼šåŒ…å«ä»¥ä¸‹ä»»æ„ç±»å‹çš„åˆ—è¡¨ï¼š
  - langchain_core.messagesï¼šHumanMessageã€AIMessageã€SystemMessageã€ToolMessage
  - langchain_core.documents.Document
  - str
- `separator`ï¼šç”¨äºè¿æ¥å†…å®¹çš„å­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸º "-"ã€‚
- `with_num`ï¼šå¦‚æœä¸º Trueï¼Œä¸ºæ¯ä¸ªé¡¹ç›®æ·»åŠ æ•°å­—å‰ç¼€ï¼ˆä¾‹å¦‚ "1. ä½ å¥½"ï¼‰ï¼Œé»˜è®¤ä¸º Falseã€‚

```python
text = format_sequence([
    "str1",
    "str2",
    "str3"
], separator="\n", with_num=True)
```

**å¯¹äºæ›´å¤šå…³äºæ¶ˆæ¯è½¬æ¢çš„ç›¸å…³ä»‹ç»ï¼Œè¯·å‚è€ƒ**: [æ¶ˆæ¯å¤„ç†](https://tbice123123.github.io/langchain-dev-utils-docs/zh/message-conversion/message.html),[æ ¼å¼åŒ–åˆ—è¡¨å†…å®¹](https://tbice123123.github.io/langchain-dev-utils-docs/zh/message-conversion/format.html)

### 3. **å·¥å…·è°ƒç”¨**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- æ£€æŸ¥å’Œè§£æå·¥å…·è°ƒç”¨
- æ·»åŠ äººæœºäº¤äº’åŠŸèƒ½

#### 3.1 æ£€æŸ¥å’Œè§£æå·¥å…·è°ƒç”¨

`has_tool_calling`å’Œ`parse_tool_calling`ç”¨äºæ£€æŸ¥å’Œè§£æå·¥å…·è°ƒç”¨ã€‚

`has_tool_calling` å‚æ•°è¯´æ˜ï¼š

- `message`ï¼šAIMessage å¯¹è±¡

`parse_tool_calling` å‚æ•°è¯´æ˜ï¼š

- `message`ï¼šAIMessage å¯¹è±¡
- `first_tool_call_only`ï¼šæ˜¯å¦åªæ£€æŸ¥ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨

```python
import datetime
from langchain_core.tools import tool
from langchain_dev_utils.tool_calling import has_tool_calling, parse_tool_calling

@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return str(datetime.datetime.now().timestamp())

response = model.bind_tools([get_current_time]).invoke("ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ")

if has_tool_calling(response):
    name, args = parse_tool_calling(
        response, first_tool_call_only=True
    )
    print(name, args)
```

#### 3.2 æ·»åŠ äººæœºäº¤äº’åŠŸèƒ½

- `human_in_the_loop`ï¼šç”¨äºåŒæ­¥å·¥å…·å‡½æ•°
- `human_in_the_loop_async`ï¼šç”¨äºå¼‚æ­¥å·¥å…·å‡½æ•°

å…¶ä¸­éƒ½å¯ä»¥ä¼ é€’`handler`å‚æ•°ï¼Œç”¨äºè‡ªå®šä¹‰æ–­ç‚¹è¿”å›å’Œå“åº”å¤„ç†é€»è¾‘ã€‚

```python
from langchain_dev_utils import human_in_the_loop
from langchain_core.tools import tool
import datetime

@human_in_the_loop
@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return str(datetime.datetime.now().timestamp())
```

**å¯¹äºæ›´å¤šå…³äºå·¥å…·è°ƒç”¨çš„ç›¸å…³ä»‹ç»ï¼Œè¯·å‚è€ƒ**: [æ·»åŠ äººåœ¨å›è·¯æ”¯æŒ](https://tbice123123.github.io/langchain-dev-utils-docs/zh/tool-calling/human-in-the-loop.html),[å·¥å…·è°ƒç”¨å¤„ç†](https://tbice123123.github.io/langchain-dev-utils-docs/zh/tool-calling/tool.html)

### 4. **æ™ºèƒ½ä½“å¼€å‘**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- é¢„è®¾çš„æ™ºèƒ½ä½“å·¥å‚å‡½æ•°
- å¸¸ç”¨çš„ä¸­é—´ä»¶ç»„ä»¶

#### 4.1 æ™ºèƒ½ä½“å·¥å‚å‡½æ•°

LangChain v1 ç‰ˆæœ¬ä¸­ï¼Œå®˜æ–¹æä¾›çš„ `create_agent` å‡½æ•°å¯ä»¥ç”¨äºåˆ›å»ºå•æ™ºèƒ½ä½“ï¼Œå…¶ä¸­ model å‚æ•°æ”¯æŒä¼ å…¥ BaseChatModel å®ä¾‹æˆ–ç‰¹å®šå­—ç¬¦ä¸²ï¼ˆå½“ä¼ å…¥å­—ç¬¦ä¸²æ—¶ï¼Œä»…é™äº `init_chat_model` æ”¯æŒçš„æ¨¡å‹ï¼‰ã€‚ä¸ºæ‰©å±•å­—ç¬¦ä¸²æŒ‡å®šæ¨¡å‹çš„çµæ´»æ€§ï¼Œæœ¬åº“æä¾›äº†åŠŸèƒ½ç›¸åŒçš„ `create_agent` å‡½æ•°ï¼Œä½¿æ‚¨èƒ½ç›´æ¥ä½¿ç”¨ `load_chat_model` æ”¯æŒçš„æ¨¡å‹ï¼ˆéœ€è¦æå–æ³¨å†Œï¼‰ã€‚

ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
from langchain_dev_utils.agents import create_agent
from langchain.agents import AgentState

agent = create_agent("vllm:qwen3-4b", tools=[get_current_time], name="time-agent")
response = agent.invoke({"messages": [{"role": "user", "content": "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ"}]})
print(response)
```

#### 4.2 ä¸­é—´ä»¶

æä¾›äº†ä¸€äº›å¸¸ç”¨çš„ä¸­é—´ä»¶ç»„ä»¶ã€‚ä¸‹é¢ä»¥`SummarizationMiddleware`å’Œ`PlanMiddleware`ä¸ºä¾‹ã€‚

`SummarizationMiddleware`ç”¨äºæ™ºèƒ½ä½“çš„æ€»ç»“ã€‚

`PlanMiddleware`ç”¨äºæ™ºèƒ½ä½“çš„è®¡åˆ’ã€‚

```python
from langchain_dev_utils.agents.middleware import (
    SummarizationMiddleware,
    PlanMiddleware,
)

agent=create_agent(
    "vllm:qwen3-4b",
    name="plan-agent",
    middleware=[PlanMiddleware(), SummarizationMiddleware(model="vllm:qwen3-4b")]
)
response = agent.invoke({"messages": [{"role": "user", "content": "ç»™æˆ‘ä¸€ä¸ªå»çº½çº¦æ—…è¡Œçš„è®¡åˆ’"}]}))
print(response)
```

**å¯¹äºæ›´å¤šå…³äºæ™ºèƒ½ä½“å¼€å‘ä»¥åŠæ‰€æœ‰çš„å†…ç½®ä¸­é—´ä»¶çš„ç›¸å…³ä»‹ç»ï¼Œè¯·å‚è€ƒ**: [é¢„æ„å»ºæ™ºèƒ½ä½“å‡½æ•°](https://tbice123123.github.io/langchain-dev-utils-docs/zh/agent-development/prebuilt.html),[ä¸­é—´ä»¶](https://tbice123123.github.io/langchain-dev-utils-docs/zh/agent-development/middleware.html)

### 5. **çŠ¶æ€å›¾ç¼–æ’**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- é¡ºåºå›¾ç¼–æ’
- å¹¶è¡Œå›¾ç¼–æ’

#### 5.1 é¡ºåºå›¾ç¼–æ’

é¡ºåºå›¾ç¼–æ’ï¼š
é‡‡ç”¨`sequential_pipeline`ï¼Œæ”¯æŒçš„å‚æ•°å¦‚ä¸‹:

- `sub_graphs`: è¦ç»„åˆçš„çŠ¶æ€å›¾åˆ—è¡¨ï¼ˆå¿…é¡»æ˜¯ StateGraph å®ä¾‹ï¼‰
- `state_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„ State Schema
- `graph_name`: æœ€ç»ˆç”Ÿæˆå›¾çš„åç§°ï¼ˆå¯é€‰ï¼‰
- `context_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„ Context Schemaï¼ˆå¯é€‰ï¼‰
- `input_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„è¾“å…¥ Schemaï¼ˆå¯é€‰ï¼‰
- `output_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„è¾“å‡º Schemaï¼ˆå¯é€‰ï¼‰
- `checkpoint`: LangGraph çš„æŒä¹…åŒ– Checkpointï¼ˆå¯é€‰ï¼‰
- `store`: LangGraph çš„æŒä¹…åŒ– Storeï¼ˆå¯é€‰ï¼‰
- `cache`: LangGraph çš„ Cacheï¼ˆå¯é€‰ï¼‰

```python
from langchain.agents import AgentState
from langchain_core.messages import HumanMessage
from langchain_dev_utils.agents import create_agent
from langchain_dev_utils.pipeline import sequential_pipeline
from langchain_dev_utils.chat_models import register_model_provider

register_model_provider(
    provider_name="vllm",
    chat_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)

# æ„å»ºé¡ºåºç®¡é“ï¼ˆæ‰€æœ‰å­å›¾é¡ºåºæ‰§è¡Œï¼‰
graph = sequential_pipeline(
    sub_graphs=[
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_time],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ—¶é—´æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰æ—¶é—´,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œæ—¶é—´æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="time_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_weather],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰å¤©æ°”,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œå¤©æ°”æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="weather_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_user],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰ç”¨æˆ·,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œç”¨æˆ·æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="user_agent",
        ),
    ],
    state_schema=AgentState,
)

response = graph.invoke({"messages": [HumanMessage("ä½ å¥½")]})
print(response)
```

#### 5.2 å¹¶è¡Œå›¾ç¼–æ’

å¹¶è¡Œå›¾ç¼–æ’ï¼š
é‡‡ç”¨`parallel_pipeline`ï¼Œæ”¯æŒçš„å‚æ•°å¦‚ä¸‹:

- `sub_graphs`: è¦ç»„åˆçš„çŠ¶æ€å›¾åˆ—è¡¨
- `state_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„ State Schema
- `branches_fn`: å¹¶è¡Œåˆ†æ”¯å‡½æ•°ï¼Œè¿”å› Send å¯¹è±¡åˆ—è¡¨æ§åˆ¶å¹¶è¡Œæ‰§è¡Œ
- `graph_name`: æœ€ç»ˆç”Ÿæˆå›¾çš„åç§°ï¼ˆå¯é€‰ï¼‰
- `context_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„ Context Schemaï¼ˆå¯é€‰ï¼‰
- `input_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„è¾“å…¥ Schemaï¼ˆå¯é€‰ï¼‰
- `output_schema`: æœ€ç»ˆç”Ÿæˆå›¾çš„è¾“å‡º Schemaï¼ˆå¯é€‰ï¼‰
- `checkpoint`: LangGraph çš„æŒä¹…åŒ– Checkpointï¼ˆå¯é€‰ï¼‰
- `store`: LangGraph çš„æŒä¹…åŒ– Storeï¼ˆå¯é€‰ï¼‰
- `cache`: LangGraph çš„ Cacheï¼ˆå¯é€‰ï¼‰

```python
from langchain_dev_utils.pipeline import parallel_pipeline

# æ„å»ºå¹¶è¡Œç®¡é“ï¼ˆæ‰€æœ‰å­å›¾å¹¶è¡Œæ‰§è¡Œï¼‰
graph = parallel_pipeline(
    sub_graphs=[
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_time],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ—¶é—´æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰æ—¶é—´,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œæ—¶é—´æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="time_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_weather],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰å¤©æ°”,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œå¤©æ°”æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="weather_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_user],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰ç”¨æˆ·,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œç”¨æˆ·æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="user_agent",
        ),
    ],
    state_schema=AgentState,
)
response = graph.invoke({"messages": [HumanMessage("ä½ å¥½")]})
print(response)
```

**å¯¹äºæ›´å¤šå…³äºçŠ¶æ€å›¾ç¼–æ’çš„ç›¸å…³ä»‹ç»ï¼Œè¯·å‚è€ƒ**: [çŠ¶æ€å›¾ç¼–æ’ç®¡é“](https://tbice123123.github.io/langchain-dev-utils-docs/zh/graph-orchestration/pipeline.html)

## ğŸ’¬ åŠ å…¥ç¤¾åŒº

- [GitHub ä»“åº“](https://github.com/TBice123123/langchain-dev-utils) â€” æµè§ˆæºä»£ç ï¼Œæäº¤ Pull Request
- [é—®é¢˜è¿½è¸ª](https://github.com/TBice123123/langchain-dev-utils/issues) â€” æŠ¥å‘Š Bug æˆ–æå‡ºæ”¹è¿›å»ºè®®
- æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ® â€”â€” æ— è®ºæ˜¯ä»£ç ã€æ–‡æ¡£è¿˜æ˜¯ä½¿ç”¨ç¤ºä¾‹ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ„å»ºä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´å®ç”¨çš„ LangChain å¼€å‘ç”Ÿæ€ç³»ç»Ÿï¼
