# pyproject.toml

[build-system]
requires      = ["setuptools", "setuptools_scm"]
build-backend = "setuptools.build_meta"

[project]
name            = "kn-dataset-tools"
description     = "A Simple Viewer for EXIF and AI Metadata."
authors         = [{ name = "Ktiseos Nyx", email = "Dataset-Tools@noreply.github.com" }]
requires-python = ">= 3.10"
license         = "GPL-3.0-or-later"
readme          = "README.md"
urls            = { source = "https://github.com/Ktiseos-Nyx/Dataset-Tools" } # Corrected from your previous example to non-orgs
dynamic         = ["version"]

keywords = [
    "training", "text", "images", "AI", "editing", "dataset",
    "metadata", "generative", "art",
]
classifiers = [
    "Topic :: Multimedia :: Graphics",
    "Topic :: Multimedia :: Graphics :: Viewers",
    "Topic :: Text Processing :: General",
    "Topic :: Artistic Software",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Intended Audience :: Other Audience",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Operating System :: OS Independent",
    "Environment :: X11 Applications :: Qt", # This implies Linux focus for X11
]
dependencies = [
    "rich",
    "pydantic",
    "pydantic-core",
    "pillow",
    "PyQt6", # Confirmed this is what you are using
    "toml",
    "typing-extensions", # Good for broader Python 3.x compatibility for newer typing features
    "pyexiv2",
    "pypng",  # Better PNG chunk reading for large ComfyUI workflows
    "cryptography",  # Fernet encryption for API key storage 
    "exif", # Consider if this is still needed with piexif and pyexiv2
    "numpy", #advanced algorithms
    # "sd-prompt-reader", # REMOVE - You have vendored this.
    # "qt-material", # REMOVED - Overstyled QSS caused glitches; replaced with compatible custom themes inspired by UN-AM/qt-material
    "piexif",
    "defusedxml",
    "requests",
    "jsonpath-ng",  # Proper JSONPath implementation for parser detection rules (PyPI up-to-date: v1.7.0, Oct 2024)
]

[project.optional-dependencies]
dev = [
    "pytest",
    "mypy",
    "types-toml",       # Stubs for toml
    "types-defusedxml", # Stubs for defusedxml
    # PyQt6 aims to ship with its own stubs, so no separate types-PyQt6 or PyQt6-stubs from pip usually
]
kn  = ["ruff", "pylint"] # For your personal linting/tooling

[project.scripts]
dataset-tools = "dataset_tools.main:main"
dataset-tools-parse = "dataset_tools.cli_parse:cli_parse"  # Headless CLI parser for bots/serverless

[tool.setuptools.packages.find]
include = ["dataset_tools*"]
exclude = ["logs*", "config*", "tests*", "debug-analysis*", "dev-screenshots*"]

[tool.setuptools_scm]
write_to = "_version.py"
# For releases, you want the version to be exactly the tag if you're on a tag.
# If you're not on an exact tag, it will still try to guess and add a dev marker,
# but the local_scheme = "no-local-version" will prevent the +localpart.
version_scheme = "guess-next-dev" # This is often a good default for general use
local_scheme = "no-local-version"   # <<< THIS IS THE KEY FOR PYPI RELEASES
                                    # It prevents the +g<hash>.d<date> part.
# Personal preferences
[tool.uv]
dev-dependencies = ["pytest"]

# --- PYTEST Configuration ---
[tool.pytest.ini_options]
filterwarnings = [
    "ignore::DeprecationWarning",
]

# --- RUFF Configuration ---
[tool.ruff] # General Ruff settings
line-length    = 120
include        = ["*.py", "*.pyi", "**/pyproject.toml"]
extend-exclude = [
    ".venv",
    "dataset_tools/debug_tools/",
    "debug-analysis/",
    "analyze_missing_nodes.py",
    "convert_icons_to_theme_compatible.py",
    # "tests/", # I recommend REMOVING this line to lint/format your tests
    # "test_*.py", # And this one too
]
# Move formatter settings into their own table
# format.quote-style = "double" # Moved to [tool.ruff.format]
# format.indent-style = "space"  # Moved to [tool.ruff.format]
# format.skip-magic-trailing-comma = false # Moved to [tool.ruff.format]
# format.line-ending = "lf" # Moved to [tool.ruff.format]

[tool.ruff.lint] # Lint-specific settings
select = [
    "E", "W", # pycodestyle errors and warnings
    "F",      # Pyflakes
    "I",      # isort (import sorting)
    "C90",    # McCabe complexity
    "N",      # pep8-naming
    "D",      # pydocstyle (docstrings)
    "UP",     # pyupgrade
    "ANN",    # flake8-annotations (for type hint enforcement)
    "S",      # flake8-bandit (security)
    "BLE",    # flake8-blind-except
    "B",      # flake8-bugbear
    "A",      # flake8-builtins
    "COM",    # flake8-commas (COM812 is the one to consider ignoring)
    "ISC",    # flake8-implicit-str-concat
    "T20",    # flake8-print
    "PYI",    # flake8-pyi
    "PT",     # flake8-pytest-style
    "Q",      # flake8-quotes
    "RSE",    # flake8-raise
    "RET",    # flake8-return
    "SLF",    # flake8-self
    "SIM",    # flake8-simplify
    "TID",    # flake8-tidy-imports
    "ARG",    # flake8-unused-arguments
    "PTH",    # flake8-use-pathlib
    "PGH",    # pygrep-hooks
    "PLC", "PLE", "PLR", "PLW", # Pylint equivalents
    "RUF",    # Ruff-specific rules
]
ignore = [
    "D100", "D101", "D102", "D103", "D104", "D105", "D106", "D107", # Ignore missing docstrings initially
    "D203", # Incompatible with D211 (no blank line before class docstring)
    "D213", # Incompatible with D212 (multi-line summary on first line)
    # ANN101, ANN102 were removed by Ruff as deprecated/handled differently
    "COM812", # Add this to ignore the formatter conflict with trailing commas
    "S101",   # Temporarily ignore assert statements
    "S310",   # Audit URL open for permitted schemes (false positive for trusted GitHub URLs)
    "PLR2004",  # Magic value used in comparison
    "B008",   # Do not perform function call in argument defaults
    "B007",   # Loop control variable not used within loop body
    "C901",   # Function is too complex (McCabe complexity)
]
# fix = true # If you want `ruff check` to also attempt fixes without --fix flag

# ADD/MODIFY THIS SECTION:
# For your vendored code, be more lenient, especially with complexity, length, args, statements,
# and potentially some annotation/docstring rules if they are too noisy for code you didn't write.
[tool.ruff.lint.per-file-ignores]
"dataset_tools/vendored_sdpr/format/*.py" = [
    "C901", "PLR0912", "PLR0913", "PLR0915", "PLW0603", # Example: PLW0603 is global statement
    "D100", "D101", "D102", "D103", "D104", "D105", "D107",
    "ANN001", "ANN002", "ANN003", "ANN201", "ANN202", "ANN204", "ANN205", "ANN401",
    "BLE001", # Allow blind excepts if they are guarded by logging exc_info
    "SIM102", # If you don't like its nested if simplification everywhere
    "B007",   # Unused loop variable (if it's being picky about your error handlers)
    "PLR0911", # Too many return statements
    "RUF012", # Mutable class attributes should be annotated with `typing.ClassVar`
    "PLR1714", # Consider merging multiple comparisons
    "PLW2901", # `for` loop variable overwritten by assignment target
    "PLR2004", # Magic value used in comparison
    "E501", # Line too long
]
"dataset_tools/vendored_sdpr/image_data_reader.py" = [
    "C901", "PLR0912", "PLR0913", "PLR0915", "PLW0603",
    "D100", "D101", "D102", "D103", "D107",
    "ANN001", "ANN002", "ANN003", "ANN201", "ANN202", "ANN204", "ANN205", "ANN401",
    "BLE001",
    "SIM102",
    "RUF012", "UP038", "PLR2004", "E501", "F841", "PTH123"
]
"dataset_tools/vendored_sdpr/logger.py" = ["D103", "D203", "D213", "D214", "D215", "PT009", "T201", "PLR2004", "S101", "ANN001", "ANN201", "ANN401", "ARG002", "N803", "PTH118", "D401", "ANN202"]
"dataset_tools/widgets.py" = [
    "PTH118", # BECAUSE WHY NOT
    "PLR2004", # ugh
    "C901", # mega ugh
    "PLR0912", "PLR0913", "PLR0915", "PLW0603", "PTH208",
    "ANN201", "ANN202", "ANN204", "ANN205", "ANN401",
    "B007",   # Unused loop variable (if it's being picky about your error handlers)
    "D203", # Missing docstring in public function
    "D213", # Missing docstring in public class
    "D214", # Missing docstring in public module
    "D215", # Missing docstring in public package
    "PT009", # Allow missing docstrings in public function
    "T201",      # Allow print statements
    "PLR2004",   # Allow magic value comparisons
    "S101",      # Allow `assert`
    "ANN001",    # Missing type hint for function argument (e.g. for self, mock objects)
    "ANN201",    # Missing return type hint for public function (test methods)
    "ANN401",    # if you use `Any` a lot in tests for mocks
    "ARG002", # Allow unused arguments
    "N803", # Allow case mismatches because i'm a dumbass
    "PTH118", # Allow errors with pathlib because i'm a dumbass dum!
    "BLE001", # blegh
    "SIM102", # If you don't like its nested if simplification everywhere
    "D415", # because emet selch said so
    "D205", # because i have a shark!
    ]
# For debug/test files that legitimately use print statements
"debug-analysis/*" = ["T201"] # Ignore print statements in debug analysis files
"dataset_tools/model_parsers/__init__.py" = ["T201", "BLE001", "PLE0605"]  # Bootstrap debugging
"dataset_tools/main.py" = ["T201", "D400", "D415", "ANN201", "ANN001"]  # CLI debugging
"dataset_tools/test_comfyui_analyzer.py" = ["T201", "E501", "ANN201"]  # Test file
"dataset_tools/ui_widgets.py" = ["T201", "ANN204", "ANN001", "D400", "D401", "D415", "ARG002", "BLE001", "N802", "ANN201", "ANN202", "PLC0415"]  # Test UI file
"dataset_tools/vendored_sdpr/format/novelai.py" = ["T201", "PLR0911", "D401", "PLR2004", "UP038", "E501"]  # Vendored code

# For your tests, you might want to ignore missing docstrings for test methods,
# print statements, and magic value comparisons.
"tests/*" = [
    "D100", "D101", "D102", "D103", "D104", "D400", "D415", # Missing docstrings
    "D203", # Missing docstring in public function
    "D213", # Missing docstring in public class
    "D214", # Missing docstring in public module
    "D215", # Missing docstring in public package
    "PT009", # Allow missing docstrings in public function
    "T201",      # Allow print statements
    "PLR2004",   # Allow magic value comparisons
    "S101",      # Allow `assert`
    "ANN001",    # Missing type hint for function argument (e.g. for self, mock objects)
    "ANN201",    # Missing return type hint for public function (test methods)
    "ANN401",    # if you use `Any` a lot in tests for mocks
    "ARG002", # Allow unused arguments
    "N803", # Allow case mismatches because i'm a dumbass
    "PTH118", # Allow errors with pathlib because i'm a dumbass dum!
    "PGH003", # Use specific rule codes when ignoring type issues
]
"dataset_tools/file_readers/__init__.py" = ["PLR0911", "TID252", "UP035", "F401", "BLE001", "PTH123", "SLF001", "PLW0603", "D401", "D205", "ANN201", "ANN204", "SIM118", "PLC0415"]
"dataset_tools/file_readers/schema_file_reader.py" = ["C901", "PLR0911", "BLE001", "PTH123", "RUF015", "ARG002", "ANN401", "UP038", "N817", "TID252", "ANN204", "D401", "D205", "F821"]
"dataset_tools/metadata_engine/context_preparation.py" = ["C901", "BLE001", "E501", "UP007", "ANN204", "PLR2004", "UP038", "S110", "E722", "ARG002", "ANN401", "TID252", "PGH003", "PLC0415"]
"dataset_tools/metadata_engine/engine.py" = ["C901", "PLR0911", "PLR0912", "PLR0915", "BLE001", "E501", "UP007", "ANN201", "ANN204", "ANN001", "ANN002", "ANN003", "ARG002", "ANN401", "S318", "N806", "PTH123", "TID252", "PYI056", "D400", "D415", "PLC0415"]
"dataset_tools/metadata_engine/extractors/comfyui_extractors.py" = ["C901", "PLR0911", "PLR0912", "PLR0915", "B007", "PLR2004", "SIM102", "ARG002", "ANN401", "D205", "D401", "E722", "S110", "PLC0415"]
"dataset_tools/metadata_engine/extractors/comfyui_traversal.py" = ["PLR0912"]
"dataset_tools/metadata_engine/extractors/json_extractors.py" = ["PLR0911", "BLE001", "ARG002", "ANN401", "TID252", "ANN204"]
"dataset_tools/metadata_engine/rule_engine.py" = ["C901", "PLR0911", "PLR0912", "PLR0915", "BLE001", "UP038", "ARG002", "ANN401", "ANN204", "ANN001", "RUF013", "SIM110", "PLR1714"]
"dataset_tools/metadata_engine/utils.py" = ["C901", "PLR0911"]
"dataset_tools/model_parsers/gguf_parser.py" = ["C901", "PLR2004", "ANN401", "B904", "E501", "PTH123", "ANN204", "TID252"]
"dataset_tools/model_parsers/safetensors_parser.py" = ["C901", "PLR2004", "E501", "PTH123", "N806", "SLF001", "ANN204"]
"dataset_tools/rule_evaluator.py" = ["C901", "PLR0911", "PLR0912", "PLR0915", "S603", "S607", "E722", "S110", "E501", "SIM102", "PLC0415"]
"dataset_tools/ui/widgets_old.py" = ["C901", "PLR2004", "BLE001", "PTH208", "PTH118", "ANN201", "ANN204", "ANN001", "ARG002", "N802", "PGH003", "D205", "D401", "D400", "D415"]
"dataset_tools/ui_layout.py" = ["PLR0915", "ANN201", "D205", "D401"]
"dataset_tools/vendored_sdpr/format/drawthings.py" = ["PLR0911", "D401", "D205"]
"dataset_tools/vendored_sdpr/format/easydiffusion.py" = ["PLR0911", "D401", "E501", "F841"]
"dataset_tools/vendored_sdpr/format/swarmui.py" = ["PLR0911", "D205", "D401", "E501"]
"dataset_tools/vendored_sdpr/format/invokeai.py" = ["RUF012"]
"dataset_tools/vendored_sdpr/format/midjourney.py" = ["D400", "D415", "D205", "PLR2004", "SIM103", "SLF001"]
"dataset_tools/vendored_sdpr/format/mochi_diffusion.py" = ["RUF012", "E501", "PLW2901", "PLR2004"]
"dataset_tools/vendored_sdpr/format/tensorart.py" = ["D400", "D415", "D205", "PLR2004", "SIM103", "RUF015"]
"dataset_tools/vendored_sdpr/format/utility.py" = ["D401", "D205"]
"dataset_tools/vendored_sdpr/format/yodayo.py" = ["RUF012", "D205", "D401", "E501", "PLW2901"]
"dataset_tools/access_disk.py" = ["D400", "D415", "ANN204", "BLE001", "E501", "PTH123", "PGH003", "PLR0911", "PLC0415"]
"dataset_tools/analysis/features.py" = ["SIM102", "D205"]
"dataset_tools/background_operations.py" = ["ANN204", "ANN001", "ANN401", "BLE001", "F821", "ARG002", "D401", "ANN201", "ANN202", "PTH109", "PLC0415"]
"dataset_tools/correct_types.py" = ["PLR2004"]
"dataset_tools/display_formatter.py" = ["D205", "D401", "ANN202"]
"dataset_tools/event_handlers.py" = ["ANN201", "PTH118", "ANN202", "D401", "ARG002", "PLC0415"]
"dataset_tools/file_operations.py" = ["ANN204", "BLE001", "PLR2004", "PTH208", "PTH118", "ARG002", "D401", "ANN201"]
"dataset_tools/file_readers/text_file_reader.py" = ["TID252", "ANN204", "BLE001", "PTH123", "PLR0911", "PLR2004", "PLW2901", "D401", "D205", "ANN201", "E501"]
"dataset_tools/logger.py" = ["ANN201", "PLW0603", "ANN001", "ANN202", "ANN002", "ANN003", "D205", "D401", "RUF013"]
"dataset_tools/metadata_engine/__init__.py" = ["RUF022", "PYI056", "ANN202", "ANN001", "D401", "PLC0415"]
"dataset_tools/metadata_engine/extractors/a1111_extractors.py" = ["ANN204", "ANN401", "ARG002", "TID252"]
"dataset_tools/metadata_engine/extractors/civitai_extractors.py" = ["ANN204", "N802", "ARG002", "ANN401", "TID252"]
"dataset_tools/metadata_engine/extractors/direct_extractors.py" = ["ANN204", "ANN401", "ARG002", "TID252"]
"dataset_tools/metadata_engine/extractors/regex_extractors.py" = ["ANN204", "ANN401", "ARG002", "SIM108", "TID252"]
"dataset_tools/metadata_engine/field_extraction.py" = ["ANN204", "ANN202", "ANN401", "ARG002", "ANN201", "TID252"]
"dataset_tools/metadata_engine/parser_registry.py" = ["TID252"]
"dataset_tools/metadata_engine/template_system.py" = ["TID252", "UP007", "ANN204", "ANN401", "ANN003", "D401", "D205", "SIM103", "PLC0415"]
"dataset_tools/metadata_parser.py" = ["D404", "ANN202", "D401", "BLE001", "F841"]
"dataset_tools/model_parsers/base_model_parser.py" = ["TID252", "ANN204", "E501"]
"dataset_tools/metadata_engine/extractors/comfyui_extractor_manager.py" = ["PLC0415"]
"dataset_tools/metadata_engine/extractors/comfyui_workflow_analyzer.py" = ["PLC0415"]
"dataset_tools/ui/dialogs.py" = ["PLC0415"]
"dataset_tools/ui/enhanced_theme_manager.py" = ["PLC0415"]
"dataset_tools/ui/main_window.py" = ["PLC0415"]
"dataset_tools/ui/managers.py" = ["PLC0415"]
"dataset_tools/numpy_scorers/advanced_comfyui_numpy_scorer.py" = [
    "T201",    # Print statements (debug output) - cleaned up
    "E501",    # Line too long (complex parsing logic)
    "C901",    # Complex functions (graph traversal algorithms)
    "PLR0915", # Too many statements (detailed parsing)
    "PLR0912", # Too many branches (workflow analysis)
    "PLR0911", # Too many return statements
    "ANN001", "ANN201", "ANN202", "ANN204", # Missing type annotations
    "BLE001",  # Blind except (error recovery patterns)
    "S112",    # Try-except-continue (expected in parsing)
    "ARG001", "ARG002", # Unused arguments (helper methods)
    "D400", "D415", "D205", # Docstring formatting
    "RET505", "RET503", # Return statement issues
    "SIM110", "SIM102", # Simplification suggestions
    "PLW0602", "PLW0603", # Global variable usage (caching)
    "UP007", "UP035", # Type hint modernization
    "F541", # F-string without placeholders
    "PTH123", # Path.open() vs open() (gradual migration)
    "F811", # Function redefinition (refactoring in progress)
    "B015", # Pointless comparison (debug code)
    "D401", # Docstring imperative mood
]


[tool.ruff.format] # Formatter specific settings
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "lf"

[tool.ruff.lint.pycodestyle]
max-line-length               = 120
ignore-overlong-task-comments = true

[tool.ruff.lint.pylint]
max-args = 15       # Increased to handle very complex methods
max-branches = 50   # Increased to silence complexity warnings
max-statements = 120 # Increased to handle complex parsing logic
max-locals = 35     # Increased to handle complex data processing

[tool.ruff.lint.flake8-annotations]
allow-star-arg-any = true # Allows *args: Any and **kwargs: Any

[tool.typos]
files.extend-exclude = [
    # "tests/",     # If you want to check typos in tests, remove this
    # "test_*.py", # and this
]

# --- MARKDOWNLINT Configuration ---
[tool.markdownlint]
# Common rules to disable that are often annoying:
disable = [
    "MD001",  # Heading levels should only increment by one level at a time
    "MD003",  # Heading style (## vs # {.unnumbered})
    "MD007",  # Unordered list indentation (often conflicts with prettier)
    "MD010",  # Hard tabs (some people prefer tabs)
    "MD012",  # Multiple consecutive blank lines
    "MD013",  # Line length (often too strict for links/code)
    "MD022",  # Headings should be surrounded by blank lines
    "MD024",  # Multiple headings with the same content
    "MD025",  # Multiple top level headings in the same document
    "MD026",  # Trailing punctuation in heading
    "MD029",  # Ordered list item prefix (1. vs 1))
    "MD030",  # Spaces after list markers
    "MD032",  # Lists should be surrounded by blank lines
    "MD033",  # Inline HTML (often needed for GitHub badges, formatting)
    "MD034",  # Bare URL used (auto-linking often preferred)
    "MD036",  # Emphasis used instead of a heading
    "MD040",  # Fenced code blocks should have a language specified
    "MD041",  # First line in file should be a top level heading
    "MD042",  # No empty links
    "MD045",  # Images should have alternate text (alt text)
    "MD046",  # Code block style (fenced vs indented)
    "MD049",  # Emphasis style (_ vs *)
    "MD050",  # Strong style (** vs __)
]

# Alternative: If you want to be more specific, you can configure individual rules
[tool.markdownlint.MD013]
# Line length - increase the limit instead of disabling
line_length = 120
tables = false          # Don't apply to tables
code_blocks = false     # Don't apply to code blocks
headings = false        # Don't apply to headings

[tool.markdownlint.MD007]
# Unordered list indentation - allow both 2 and 4 spaces
indent = 2

[tool.markdownlint.MD024]
# Allow duplicate headings if they're in different sections
siblings_only = true

# --- MYPY Configuration ---
[tool.mypy]
python_version = "3.10" # Match your requires-python lower bound
warn_unused_configs = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_return_any = true
# For stricter checking later, uncomment these:
# disallow_untyped_defs = true
# disallow_incomplete_defs = true
check_untyped_defs = true # Good to enable

plugins = "pydantic.mypy"

# Per-module settings for ignoring missing stubs or specific errors
[[tool.mypy.overrides]]
module = [
    "piexif.*",
    "pyexiv2.*",
    # "qt_material.*", # REMOVED - No longer using qt-material dependency
    "defusedxml.*", # types-defusedxml should provide stubs
    "dataset_tools.version", # Your _version.py
    "PyQt6.*",
    "dataset_tools.vendored_sdpr.*", # Enable if vendored code is too noisy initially
]
ignore_missing_imports = true

# PyQt6 should provide its own stubs. If MyPy still has issues with it
# specifically for 'no attribute' errors that are false positives,
# you might need to add ignores for those specific attributes in code using `# type: ignore[attr-defined]`
# Or, if there are many, consider:
# [[tool.mypy.overrides]]
# module = "PyQt6.*"
# ignore_errors = true # Use this as a last resort for problematic C extensions
