Metadata-Version: 2.4
Name: daft
Version: 0.6.14
Requires-Dist: pyarrow>=8.0.0
Requires-Dist: fsspec
Requires-Dist: tqdm
Requires-Dist: typing-extensions>=4.0.0 ; python_full_version < '3.11'
Requires-Dist: packaging
Requires-Dist: daft[aws,azure,clickhouse,deltalake,gcp,hudi,huggingface,iceberg,lance,numpy,openai,pandas,postgres,ray,sentence-transformers,spark,sql,transformers,turbopuffer,unity,video] ; extra == 'all'
Requires-Dist: boto3 ; extra == 'aws'
Requires-Dist: clickhouse-connect ; extra == 'clickhouse'
Requires-Dist: deltalake ; extra == 'deltalake'
Requires-Dist: pyarrow>=8.0.0 ; extra == 'hudi'
Requires-Dist: huggingface-hub ; extra == 'huggingface'
Requires-Dist: pyiceberg>=0.7.0,<0.9.1 ; extra == 'iceberg'
Requires-Dist: pylance ; extra == 'lance'
Requires-Dist: numpy ; extra == 'numpy'
Requires-Dist: openai ; extra == 'openai'
Requires-Dist: pandas ; extra == 'pandas'
Requires-Dist: psycopg ; extra == 'postgres'
Requires-Dist: pgvector ; extra == 'postgres'
Requires-Dist: ray[data,client]>=2.0.0 ; platform_system != 'Windows' and extra == 'ray'
Requires-Dist: ray[data,client]>=2.10.0 ; platform_system == 'Windows' and extra == 'ray'
Requires-Dist: transformers ; extra == 'transformers'
Requires-Dist: sentence-transformers ; extra == 'transformers'
Requires-Dist: torch ; extra == 'transformers'
Requires-Dist: torchvision ; extra == 'transformers'
Requires-Dist: googleapis-common-protos>=1.56.4 ; extra == 'spark'
Requires-Dist: grpcio>=1.48 ; extra == 'spark'
Requires-Dist: grpcio-status>=1.48 ; extra == 'spark'
Requires-Dist: numpy>=1.15 ; extra == 'spark'
Requires-Dist: pandas>=1.0.5 ; extra == 'spark'
Requires-Dist: py4j>=0.10.9.7 ; extra == 'spark'
Requires-Dist: pyspark==3.5.5 ; extra == 'spark'
Requires-Dist: connectorx>=0.4.4 ; extra == 'sql'
Requires-Dist: sqlalchemy ; extra == 'sql'
Requires-Dist: sqlglot ; extra == 'sql'
Requires-Dist: turbopuffer ; extra == 'turbopuffer'
Requires-Dist: httpx<=0.27.2 ; extra == 'unity'
Requires-Dist: unitycatalog ; extra == 'unity'
Requires-Dist: av>=15.0.0 ; extra == 'video'
Provides-Extra: all
Provides-Extra: aws
Provides-Extra: azure
Provides-Extra: clickhouse
Provides-Extra: deltalake
Provides-Extra: gcp
Provides-Extra: hudi
Provides-Extra: huggingface
Provides-Extra: iceberg
Provides-Extra: lance
Provides-Extra: numpy
Provides-Extra: openai
Provides-Extra: pandas
Provides-Extra: postgres
Provides-Extra: ray
Provides-Extra: transformers
Provides-Extra: spark
Provides-Extra: sql
Provides-Extra: turbopuffer
Provides-Extra: unity
Provides-Extra: video
Provides-Extra: viz
License-File: LICENSE
Summary: Distributed Dataframes for Multimodal Data
Author-email: Eventual Inc <daft@eventualcomputing.com>
Maintainer-email: Sammy Sidhu <sammy@eventualcomputing.com>, Jay Chia <jay@eventualcomputing.com>
Requires-Python: >=3.10
Description-Content-Type: text/x-rst; charset=UTF-8
Project-URL: homepage, https://www.daft.ai
Project-URL: repository, https://github.com/Eventual-Inc/Daft

|Banner|

|CI| |PyPI| |Latest Tag| |Coverage| |Slack|

`Website <https://www.daft.ai>`_ • `Docs <https://docs.daft.ai>`_ • `Installation <https://docs.daft.ai/en/stable/install/>`_ • `Daft Quickstart <https://docs.daft.ai/en/stable/quickstart/>`_ • `Community and Support <https://github.com/Eventual-Inc/Daft/discussions>`_

Daft: Unified Engine for Data Analytics, Engineering & ML/AI
============================================================

|TrendShift|

`Daft <https://www.daft.ai>`_ is a distributed query engine for large-scale data processing using Python or SQL, implemented in Rust.

* **Familiar interactive API:** Lazy Python Dataframe for rapid and interactive iteration, or SQL for analytical queries
* **Focus on the what:** Powerful Query Optimizer that rewrites queries to be as efficient as possible
* **Data Catalog integrations:** Integration with data catalogs (AWS Glue, Unity Catalog) and table formats like Apache Iceberg
* **Rich multimodal type-system:** Supports multimodal types such as Images, URLs, Tensors and more
* **Seamless Interchange**: Built on the `Apache Arrow <https://arrow.apache.org/docs/index.html>`_ In-Memory Format
* **Built for the cloud:** `Record-setting <https://www.daft.ai/blog/announcing-daft-02>`_ I/O performance for integrations with S3 cloud storage

**Table of Contents**

* `About Daft`_
* `Getting Started`_
* `Benchmarks`_
* `Contributing`_
* `Telemetry`_
* `Related Projects`_
* `License`_

About Daft
----------

Daft was designed with the following principles in mind:

1. **Any Data**: Beyond the usual strings/numbers/dates, Daft columns can also hold complex or nested multimodal data such as Images, Embeddings and Python objects efficiently with its Arrow based memory representation. Ingestion and basic transformations of multimodal data is extremely easy and performant in Daft.
2. **Interactive Computing**: Daft is built for the interactive developer experience through notebooks or REPLs - intelligent caching/query optimizations accelerates your experimentation and data exploration.
3. **Distributed Computing**: Some workloads can quickly outgrow your local laptop's computational resources - Daft integrates natively with `Ray <https://www.ray.io>`_ for running dataframes on large clusters of machines with thousands of CPUs/GPUs.

Getting Started
---------------

Installation
^^^^^^^^^^^^

Install Daft with ``pip install daft``.

For more advanced installations (e.g. installing from source or with extra dependencies such as Ray and AWS utilities), please see our `Installation Guide <https://docs.daft.ai/en/stable/install/>`_

Quickstart
^^^^^^^^^^

  Check out our `quickstart <https://docs.daft.ai/en/stable/quickstart/>`_!

In this example, we load images from an AWS S3 bucket's URLs and resize each image in the dataframe:

.. code:: python

    import daft

    # Load a dataframe from filepaths in an S3 bucket
    df = daft.from_glob_path("s3://daft-public-data/laion-sample-images/*")

    # 1. Download column of image URLs as a column of bytes
    # 2. Decode the column of bytes into a column of images
    df = df.with_column("image", df["path"].url.download().image.decode())

    # Resize each image into 32x32
    df = df.with_column("resized", df["image"].image.resize(32, 32))

    df.show(3)


|Quickstart Image|


Benchmarks
----------
|Benchmark Image|

To see the full benchmarks, detailed setup, and logs, check out our `benchmarking page. <https://docs.daft.ai/en/stable/benchmarks>`_


More Resources
^^^^^^^^^^^^^^

* `Daft Quickstart <https://docs.daft.ai/en/stable/quickstart/>`_ - learn more about Daft's full range of capabilities including dataloading from URLs, joins, user-defined functions (UDF), groupby, aggregations and more.
* `Examples <https://docs.daft.ai/en/stable/examples/>`_ - see Daft in action with use cases across text, images, audio, and more
* `User Guide <https://docs.daft.ai/en/stable/>`_ - take a deep-dive into each topic within Daft
* `API Reference <https://docs.daft.ai/en/stable/api/>`_ - API reference for public classes/functions of Daft
* `SQL Reference <https://docs.daft.ai/en/stable/sql/>`_ - Daft SQL reference

Contributing
------------

We <3 developers! To start contributing to Daft, please read `CONTRIBUTING.md <https://github.com/Eventual-Inc/Daft/blob/main/CONTRIBUTING.md>`_. This document describes the development lifecycle and toolchain for working on Daft. It also details how to add new functionality to the core engine and expose it through a Python API.

Here's a list of `good first issues <https://github.com/Eventual-Inc/Daft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22>`_ to get yourself warmed up with Daft. Comment in the issue to pick it up, and feel free to ask any questions!

Telemetry
---------

To help improve Daft, we collect non-identifiable data via Scarf (https://scarf.sh).

To disable this behavior, set the environment variable ``DO_NOT_TRACK=true``.

The data that we collect is:

1. **Non-identifiable:** Events are keyed by a session ID which is generated on import of Daft
2. **Metadata-only:** We do not collect any of our users’ proprietary code or data
3. **For development only:** We do not buy or sell any user data

Please see our `documentation <https://docs.daft.ai/en/stable/resources/telemetry/>`_ for more details.

.. image:: https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6

Related Projects
----------------

+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+
| Engine                                            | Query Optimizer | Multimodal    | Distributed | Arrow Backed    | Vectorized Execution Engine | Out-of-core |
+===================================================+=================+===============+=============+=================+=============================+=============+
| Daft                                              | Yes             | Yes           | Yes         | Yes             | Yes                         | Yes         |
+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+
| `Pandas <https://github.com/pandas-dev/pandas>`_  | No              | Python object | No          | optional >= 2.0 | Some(Numpy)                 | No          |
+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+
| `Polars <https://github.com/pola-rs/polars>`_     | Yes             | Python object | No          | Yes             | Yes                         | Yes         |
+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+
| `Modin <https://github.com/modin-project/modin>`_ | Yes             | Python object | Yes         | No              | Some(Pandas)                | Yes         |
+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+
| `Ray Data <https://github.com/ray-project/ray>`_  | No              | Yes           | Yes         | Yes             | Some(PyArrow)               | Yes         |
+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+
| `PySpark <https://github.com/apache/spark>`_      | Yes             | No            | Yes         | Pandas UDF/IO   | Pandas UDF                  | Yes         |
+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+
| `Dask DF <https://github.com/dask/dask>`_         | No              | Python object | Yes         | No              | Some(Pandas)                | Yes         |
+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+

License
-------

Daft has an Apache 2.0 license - please see the LICENSE file.

.. |Quickstart Image| image:: https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8
   :alt: Dataframe code to load a folder of images from AWS S3 and create thumbnails
   :height: 256

.. |Benchmark Image| image:: https://raw.githubusercontent.com/Eventual-Inc/Daft/refs/heads/main/assets/benchmark.png
   :alt: AI Benchmarks

.. |Banner| image:: https://daft.ai/images/diagram.png
   :target: https://www.daft.ai
   :alt: Daft dataframes can load any data such as PDF documents, images, protobufs, csv, parquet and audio files into a table dataframe structure for easy querying

.. |CI| image:: https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg
   :target: https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main
   :alt: GitHub Actions tests

.. |PyPI| image:: https://img.shields.io/pypi/v/daft.svg?label=pip&logo=PyPI&logoColor=white
   :target: https://pypi.org/project/daft
   :alt: PyPI

.. |Latest Tag| image:: https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&logo=GitHub
   :target: https://github.com/Eventual-Inc/Daft/tags
   :alt: latest tag

.. |Coverage| image:: https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89
   :target: https://codecov.io/gh/Eventual-Inc/Daft
   :alt: Coverage

.. |Slack| image:: https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack
   :target: https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg
   :alt: slack community

.. |TrendShift| image:: https://trendshift.io/api/badge/repositories/8239
   :target: https://trendshift.io/repositories/8239
   :alt: Eventual-Inc/Daft | Trendshift
   :width: 250px
   :height: 55px

