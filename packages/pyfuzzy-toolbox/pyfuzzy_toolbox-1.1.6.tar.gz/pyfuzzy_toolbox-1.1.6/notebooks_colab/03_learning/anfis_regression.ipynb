{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ANFIS Regression Example: Nonlinear Function Approximation\n",
    "# ============================================================================\n",
    "# Function: y = 2*sin(2πx) + 1.5*cos(4πx) + 0.5*x + noise\n",
    "# ============================================================================\n",
    "\n",
    "from fuzzy_systems.learning import ANFIS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# 1. Generate Synthetic Data\n",
    "# ============================================================================\n",
    "def target_function(x):\n",
    "    \"\"\"\n",
    "    Nonlinear function combining sine, cosine and linear terms.\n",
    "    y = 2*sin(2πx) + 1.5*cos(4πx) + 0.5*x\n",
    "    \"\"\"\n",
    "    return 2 * np.sin(2 * np.pi * x) + 1.5 * np.cos(4 * np.pi * x) + 0.5 * x\n",
    "\n",
    "# Training data\n",
    "n_train = 200\n",
    "X_train = np.random.uniform(0, 2, n_train).reshape(-1, 1)\n",
    "y_train = target_function(X_train.ravel()) + np.random.normal(0, 0.1, n_train)\n",
    "\n",
    "# Test data (evenly spaced for smooth curve)\n",
    "n_test = 50\n",
    "X_test = np.linspace(0, 2, n_test).reshape(-1, 1)\n",
    "y_test = target_function(X_test.ravel())\n",
    "\n",
    "# Validation data\n",
    "n_val = 50\n",
    "X_val = np.random.uniform(0, 2, n_val).reshape(-1, 1)\n",
    "y_val = target_function(X_val.ravel()) + np.random.normal(0, 0.1, n_val)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"  Training:   X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Validation: X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"  Test:       X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45105248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create and Configure ANFIS Model\n",
    "# ============================================================================\n",
    "anfis = ANFIS(\n",
    "    n_inputs=1,                    # Single input variable\n",
    "    n_mfs=7,                       # 7 membership functions\n",
    "    mf_type='gaussmf',             # Gaussian membership functions\n",
    "    learning_rate=0.001,           # Learning rate\n",
    "    lambda_l1=0.0,                 # L1 regularization (Lasso)\n",
    "    lambda_l2=0.001,               # L2 regularization (Ridge)\n",
    "    batch_size=128,                # Mini-batch training\n",
    "    use_adaptive_lr=True,          # Adaptive learning rate\n",
    "    classification=False,          # Regression task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train the Model\n",
    "# ============================================================================\n",
    "print(\"\\nTraining ANFIS model...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "anfis.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=500,\n",
    "    verbose=True,\n",
    "    train_premises=True,           # Train MF parameters\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    early_stopping_patience=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8829d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the Model\n",
    "# ============================================================================\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = anfis.predict(X_train)\n",
    "y_pred_test = anfis.predict(X_test)\n",
    "y_pred_val = anfis.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "val_r2 = r2_score(y_val, y_pred_val)\n",
    "\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  MAE:  {train_mae:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "print()\n",
    "print(f\"Validation Set:\")\n",
    "print(f\"  RMSE: {val_rmse:.4f}\")\n",
    "print(f\"  MAE:  {val_mae:.4f}\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "print()\n",
    "print(f\"Test Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  MAE:  {test_mae:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualizations\n",
    "# ============================================================================\n",
    "\n",
    "# 5.1 Function Approximation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Predictions vs True Function\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(X_train, y_train, alpha=0.3, s=20, label='Training Data', color='blue')\n",
    "ax.plot(X_test, y_test, 'g-', linewidth=2, label='True Function', alpha=0.7)\n",
    "ax.plot(X_test, y_pred_test, 'r--', linewidth=2, label='ANFIS Prediction')\n",
    "ax.set_xlabel('X', fontsize=12)\n",
    "ax.set_ylabel('Y', fontsize=12)\n",
    "ax.set_title('ANFIS Function Approximation', fontsize=14, weight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "ax = axes[0, 1]\n",
    "residuals_train = y_train - y_pred_train\n",
    "residuals_test = y_test - y_pred_test\n",
    "ax.scatter(y_pred_train, residuals_train, alpha=0.5, s=20, label='Train', color='blue')\n",
    "ax.scatter(y_pred_test, residuals_test, alpha=0.5, s=20, label='Test', color='red')\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Predicted Values', fontsize=12)\n",
    "ax.set_ylabel('Residuals', fontsize=12)\n",
    "ax.set_title('Residual Plot', fontsize=14, weight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: True vs Predicted\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(y_train, y_pred_train, alpha=0.5, s=30, label='Train', color='blue')\n",
    "ax.scatter(y_test, y_pred_test, alpha=0.5, s=30, label='Test', color='red')\n",
    "min_val = min(y_train.min(), y_test.min())\n",
    "max_val = max(y_train.max(), y_test.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label='Perfect Fit')\n",
    "ax.set_xlabel('True Values', fontsize=12)\n",
    "ax.set_ylabel('Predicted Values', fontsize=12)\n",
    "ax.set_title(f'True vs Predicted (R² = {test_r2:.4f})', fontsize=14, weight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Error Distribution\n",
    "ax = axes[1, 1]\n",
    "errors = y_test - y_pred_test\n",
    "ax.hist(errors, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "ax.set_xlabel('Prediction Error', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title(f'Error Distribution (μ={np.mean(errors):.4f}, σ={np.std(errors):.4f})', \n",
    "            fontsize=14, weight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.2 Training Metrics Evolution\n",
    "anfis.plot_metrics(['rmse', 'mae', 'r2'])\n",
    "\n",
    "# 5.3 Learned Membership Functions\n",
    "anfis.plot_membership_functions()\n",
    "\n",
    "# 5.4 Regularization Evolution\n",
    "anfis.plot_regularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c28b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Extract and Display Learned Rules\n",
    "# ============================================================================\n",
    "print(\"\\nFuzzy Rules:\")\n",
    "print(\"=\" * 70)\n",
    "rules_df = anfis.rules_to_dataframe(\n",
    "    input_names=['X'],\n",
    "    output_name='Y'\n",
    ")\n",
    "rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rules in table format\n",
    "fig = anfis.show_rules_table(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44680e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save Trained Model\n",
    "# ============================================================================\n",
    "# anfis.save('anfis_regression_model')\n",
    "print(\"Model saved to 'anfis_regression_model.npz'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44269b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Compare with Baseline Models\n",
    "# ============================================================================\n",
    "print(\"\\nComparison with Baseline Models:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "lr_r2 = r2_score(y_test, y_pred_lr)\n",
    "print(f\"Linear Regression R²:     {lr_r2:.4f}\")\n",
    "\n",
    "# Polynomial Regression (degree 3)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "poly_r2 = r2_score(y_test, y_pred_poly)\n",
    "print(f\"Polynomial Regression R²: {poly_r2:.4f}\")\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train.ravel())\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest R²:         {rf_r2:.4f}\")\n",
    "\n",
    "# ANFIS\n",
    "print(f\"ANFIS R²:                 {test_r2:.4f}  ← Best!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nANFIS Regression Example Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (generico)",
   "language": "python",
   "name": "generico"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
