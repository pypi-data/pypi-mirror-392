# MÃ³dulo Learning - Aprendizado e OtimizaÃ§Ã£o Fuzzy

## ğŸ“š VisÃ£o Geral

O mÃ³dulo `learning` implementa algoritmos de aprendizado e otimizaÃ§Ã£o para sistemas fuzzy:

- **ANFIS** (Adaptive Neuro-Fuzzy Inference System)
- **Wang-Mendel** (ExtraÃ§Ã£o de regras a partir de dados)
- **Mamdani Learning** (Neuro-fuzzy com gradiente e metaheurÃ­sticas)
- **MetaheurÃ­sticas** (PSO, DE, GA)

---

## ğŸ§  ANFIS - Adaptive Neuro-Fuzzy Inference System

### CaracterÃ­sticas

- **Arquitetura hÃ­brida**: TSK + aprendizado
- **Algoritmo de treinamento**: LSE (consequentes) + Gradiente (antecedentes)
- **Estabilidade de Lyapunov**: Taxa de aprendizado adaptativa
- **RegularizaÃ§Ã£o**: L1/L2 apenas nas larguras (sigmas), nÃ£o nos centros
- **FunÃ§Ãµes de pertinÃªncia**: Gaussiana, Bell Generalizada, Sigmoide
- **Gradientes analÃ­ticos**: Implementados para todas as MFs
- **MÃ©tricas**: RMSE, MAE, RÂ², MAPE, learning_rate

### Uso BÃ¡sico

```python
from fuzzy_systems.learning import ANFIS
import numpy as np

# Dados de treinamento
X_train = np.random.uniform(0, 10, (100, 2))
y_train = X_train[:, 0] * 0.5 + X_train[:, 1] * 0.3

# Criar ANFIS
anfis = ANFIS(
    n_inputs=2,
    n_rules=9,
    mf_type='gaussian'
)

# Treinar
history = anfis.fit(
    X_train, y_train,
    epochs=100,
    learning_rate=0.01,
    verbose=True
)

# Predizer
y_pred = anfis.predict(X_test)

# Avaliar
score = anfis.score(X_test, y_test)  # RÂ²
```

### Estabilidade de Lyapunov

Taxa de aprendizado adaptativa para garantir convergÃªncia:

```
Î·_adaptativo = min(1.99 / ||âˆ‡E||Â², Î·_max)
```

Garante que a funÃ§Ã£o de energia (erro) sempre decresce.

**ReferÃªncia**: Wang, L. X., & Mendel, J. M. (1992). "Fuzzy basis functions, universal approximation, and orthogonal least-squares learning"

### RegularizaÃ§Ã£o Simplificada

- **L1/L2 aplicada APENAS nas larguras (sigmas)**
- **Centros NÃƒO sÃ£o regularizados** (decisÃ£o baseada em teoria fuzzy)

```python
anfis = ANFIS(
    n_inputs=2,
    n_rules=9,
    regularization='l2',
    lambda_reg=0.01  # Apenas para sigmas
)
```

### Gradientes AnalÃ­ticos

Implementados para todas as funÃ§Ãµes de pertinÃªncia:

- **Gaussiana**: `âˆ‚Î¼/âˆ‚mean`, `âˆ‚Î¼/âˆ‚sigma`
- **Bell Generalizada**: `âˆ‚Î¼/âˆ‚a`, `âˆ‚Î¼/âˆ‚b`, `âˆ‚Î¼/âˆ‚c`
- **Sigmoide**: `âˆ‚Î¼/âˆ‚a`, `âˆ‚Î¼/âˆ‚c`

Permite treinamento rÃ¡pido e estÃ¡vel.

### Salvar/Carregar Modelo

```python
# Salvar
anfis.save('modelo_anfis.npz')

# Carregar
anfis_loaded = ANFIS.load('modelo_anfis.npz')
```

---

## ğŸ“Š Wang-Mendel - ExtraÃ§Ã£o de Regras

### Algoritmo

1. **FuzzificaÃ§Ã£o**: Particiona domÃ­nio das variÃ¡veis
2. **GeraÃ§Ã£o de regras**: Uma regra por amostra
3. **ResoluÃ§Ã£o de conflitos**: Regra com maior grau vence
4. **Base de regras**: Conjunto final de regras

### Uso

```python
from fuzzy_systems.learning import WangMendelRuleExtractor

# Criar extrator
wm = WangMendelRuleExtractor(
    n_mfs_per_input=[5, 5],  # 5 MFs para cada entrada
    mf_type='triangular'
)

# Extrair regras
wm.extract_rules(X_train, y_train)

# Converter para FIS
fis = wm.to_mamdani_system(
    input_names=['temperatura', 'umidade'],
    output_name='ventilador'
)

# Usar
resultado = fis.evaluate(temperatura=25, umidade=60)
```

---

## ğŸ¯ Mamdani Learning - Neuro-Fuzzy

### CaracterÃ­sticas

- **Arquitetura**: 4 camadas (FuzzificaÃ§Ã£o â†’ Regras â†’ DefuzzificaÃ§Ã£o â†’ SaÃ­da)
- **MFs de entrada**: Gaussianas (aprendÃ­veis)
- **MFs de saÃ­da**: Singletons (centroides aprendÃ­veis)
- **Aprendizado**: Gradiente (batch, online, mini-batch) + MetaheurÃ­sticas
- **DefuzzificaÃ§Ã£o**: COG ou COS
- **OtimizaÃ§Ã£o**: Caching de ativaÃ§Ãµes para eficiÃªncia

### Aprendizado por Gradiente

```python
from fuzzy_systems.learning.mamdani import MamdaniLearning

# Criar
mamdani = MamdaniLearning(
    n_inputs=2,
    n_mfs_input=[3, 3],
    n_mfs_output=3,
    defuzz_method='cog'
)

# Treinar
mamdani.fit(
    X_train, y_train,
    epochs=100,
    learning_rate=0.01,
    batch_size=32,  # mini-batch
    mode='batch'    # ou 'online', 'mini-batch'
)

# Predizer
y_pred = mamdani.predict(X_test)
```

### OtimizaÃ§Ã£o MetaheurÃ­stica

TrÃªs estratÃ©gias:

1. **`consequents_only`**: Otimiza apenas Ã­ndices dos consequentes (rÃ¡pido)
2. **`output_only`**: Otimiza apenas centroides de saÃ­da
3. **`hybrid`**: Otimiza consequentes + centroides simultaneamente

```python
# PSO - Otimizar apenas consequentes (mais rÃ¡pido)
mamdani.fit_metaheuristic(
    X_train, y_train,
    optimizer='pso',
    optimize_params='consequents_only',
    n_particles=30,
    n_iterations=50
)

# Differential Evolution - Modo hÃ­brido
mamdani.fit_metaheuristic(
    X_train, y_train,
    optimizer='de',
    optimize_params='hybrid',
    n_particles=30,
    n_iterations=100
)

# Genetic Algorithm
mamdani.fit_metaheuristic(
    X_train, y_train,
    optimizer='ga',
    optimize_params='output_only',
    n_particles=50,
    n_iterations=100
)
```

### Modo HÃ­brido (Hybrid)

Otimiza **consequentes** + **centroides** simultaneamente com caching parcial:

**CaracterÃ­sticas:**
- PrÃ©-computa ativaÃ§Ãµes das regras (cache)
- Otimiza mapeamento consequentes + valores dos centroides
- ~2-3x mais lento que `consequents_only`
- ~2x mais rÃ¡pido que `output_only`
- Melhor balanÃ§o flexibilidade/performance

**Funcionamento:**
```python
# Vetor de parÃ¢metros: [consequent_indices, centroids]
# Exemplo: [2, 1, 0, 1, 2, ..., 10.5, 50.2, 89.7]
#          â””â”€â”€â”€â”€â”€regrasâ”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€centroidesâ”€â”€â”˜
```

### Caching de AtivaÃ§Ãµes

Quando os conjuntos de entrada sÃ£o fixos (nÃ£o mudam durante otimizaÃ§Ã£o):

```python
# PrÃ©-computa ativaÃ§Ãµes UMA VEZ
membership_values = self._fuzzify_inputs(X)
firing_strengths = self._fire_rules(membership_values)
self._cached_activations = firing_strengths

# Reutiliza cache (nÃ£o recalcula fuzzificaÃ§Ã£o)
predictions = self._defuzzify_cog(
    self._cached_activations,  # CACHE!
    consequent_indices
)
```

**Speedup**: ~10-100x em otimizaÃ§Ã£o metaheurÃ­stica

### IntegraÃ§Ã£o com MamdaniSystem

**Learning â†’ FIS:**
```python
# Treinar modelo
mamdani.fit(X_train, y_train, epochs=100)

# Exportar como FIS
fis = mamdani.to_mamdani_system(
    input_names=['temperatura', 'umidade'],
    output_name='ventilador'
)

# Usar FIS
resultado = fis.evaluate(temperatura=25, umidade=60)
```

**FIS â†’ Learning:**
```python
# Importar FIS existente
fis = criar_fis_manual()  # Com MFs gaussianas

# Converter para MamdaniLearning
mamdani = MamdaniLearning.from_mamdani_system(fis)

# Otimizar com dados
mamdani.fit(X_train, y_train, epochs=50)

# Exportar FIS otimizado
fis_otimizado = mamdani.to_mamdani_system(...)
```

**Consulte**: `MAMDANI_LEARNING_INTEGRATION.md` na raiz para exemplos completos

---

## âš™ï¸ MetaheurÃ­sticas

### PSO - Particle Swarm Optimization

```python
from fuzzy_systems.learning.metaheuristics import PSO

pso = PSO(
    n_particles=30,
    n_iterations=100,
    w=0.7,         # InÃ©rcia
    c1=1.5,        # Cognitivo
    c2=1.5,        # Social
    w_decay=0.99   # Decaimento de inÃ©rcia
)

best_params, best_fitness, history = pso.optimize(
    objective_func,
    bounds,
    minimize=True
)
```

### DE - Differential Evolution

```python
from fuzzy_systems.learning.metaheuristics import DE

de = DE(
    pop_size=30,
    max_iter=100,
    F=0.8,          # Fator de mutaÃ§Ã£o
    CR=0.9,         # Crossover
    strategy='best1' # ou 'rand1', 'rand2', 'best2'
)

best_params, best_fitness, history = de.optimize(
    objective_func,
    bounds,
    minimize=True
)
```

### GA - Genetic Algorithm

```python
from fuzzy_systems.learning.metaheuristics import GA

ga = GA(
    pop_size=50,
    max_gen=100,
    crossover_rate=0.8,
    mutation_rate=0.1,
    elitism_size=5  # Preserva os 5 melhores
)

best_params, best_fitness, history = ga.optimize(
    objective_func,
    bounds,
    minimize=True
)
```

---

## ğŸ“ Arquivos do MÃ³dulo

```
learning/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ anfis.py              # ANFIS implementaÃ§Ã£o
â”œâ”€â”€ wang_mendel.py        # ExtraÃ§Ã£o de regras
â”œâ”€â”€ mamdani.py            # Mamdani Learning
â”œâ”€â”€ metaheuristics.py     # PSO, DE, GA
â””â”€â”€ README.md             # Este arquivo
```

---

## ğŸ“š Exemplos

Consulte a pasta `examples/02_learning/`:

- `15_anfis_exemplo.py` - ANFIS bÃ¡sico
- `13_wang_mendel.py` - Wang-Mendel
- `14_wang_mendel_iris.py` - Wang-Mendel com Iris dataset
- `example_anfis.ipynb` - Notebook ANFIS
- `wang_mendel_iris.ipynb` - Notebook Wang-Mendel

**Testes:**
- `examples/tests/test_mamdani_learning.py`
- `examples/tests/test_mamdani_hybrid.py`
- `examples/tests/test_metaheuristics.py`

---

## ğŸ“ ReferÃªncias

### ANFIS
- Jang, J. S. (1993). "ANFIS: adaptive-network-based fuzzy inference system"
- Wang, L. X., & Mendel, J. M. (1992). "Fuzzy basis functions, universal approximation, and orthogonal least-squares learning"

### Wang-Mendel
- Wang, L. X., & Mendel, J. M. (1992). "Generating fuzzy rules by learning from examples"

### MetaheurÃ­sticas
- Kennedy, J., & Eberhart, R. (1995). "Particle swarm optimization" (PSO)
- Storn, R., & Price, K. (1997). "Differential evolution" (DE)
- Holland, J. H. (1975). "Adaptation in natural and artificial systems" (GA)

### Estabilidade
- Lyapunov, A. M. (1892). "The general problem of the stability of motion"
- Slotine, J. J. E., & Li, W. (1991). "Applied Nonlinear Control"

---

**VersÃ£o**: 1.1
**Data**: 2025-10-25
**Status**: âœ… Completo e testado
