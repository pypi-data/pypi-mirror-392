import re
import asyncio
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from concurrent.futures import ThreadPoolExecutor
import threading
from datetime import datetime

from siada.services.fix_result_check import FixResultChecker
from siada.services.strict_fix_result_check import StrictFixResultChecker
from siada.services.enhanced_fix_result_check import EnhancedFixResultChecker
from siada.services.bug_desc_optimizer import BugDescOptimizer


class FixResultCheckerValidator:
    """Fix Result CheckeréªŒè¯å·¥å…·ï¼Œç”¨äºéªŒè¯åˆ†æfix_result_checkerçš„ç»“æœã€‚"""

    def __init__(self):
        self.fix_result_checker = FixResultChecker()
        self.opt = BugDescOptimizer()
        self.output_lock = threading.Lock()
        self.output_file = None

    @staticmethod
    def filter_patch_exclude_tests(patch_content: str) -> str:
        """
        ä»patchå†…å®¹ä¸­è¿‡æ»¤æ‰æµ‹è¯•æ–‡ä»¶ç›¸å…³çš„ä¿®æ”¹ï¼Œç±»ä¼¼äºget_git_diff_exclude_test_filesçš„é€»è¾‘ã€‚
        
        Args:
            patch_content: åŸå§‹patchå†…å®¹
            
        Returns:
            str: è¿‡æ»¤åçš„patchå†…å®¹
        """
        if not patch_content:
            return ""
        
        lines = patch_content.split('\n')
        filtered_lines = []
        current_file = None
        skip_current_file = False
        
        i = 0
        while i < len(lines):
            line = lines[i]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ–‡ä»¶çš„å¼€å§‹
            if line.startswith('diff --git'):
                # æå–æ–‡ä»¶è·¯å¾„
                match = re.search(r'diff --git a/(.*?) b/', line)
                if match:
                    current_file = match.group(1)
                    # åˆ¤æ–­æ˜¯å¦æ˜¯æµ‹è¯•æ–‡ä»¶
                    skip_current_file = (
                        'test' in current_file.lower() or
                        current_file.startswith('tests/') or
                        '/test' in current_file or
                        current_file.endswith('_test.py') or
                        current_file.endswith('test.py') or
                        current_file.endswith('_tests.py') or
                        'test_' in current_file
                    )
                else:
                    skip_current_file = False
                
                if not skip_current_file:
                    filtered_lines.append(line)
            elif not skip_current_file:
                filtered_lines.append(line)
            
            i += 1
        
        filtered_content = '\n'.join(filtered_lines)
        
        # å¦‚æœè¿‡æ»¤åå†…å®¹ä¸ºç©ºæˆ–åªæœ‰å¾ˆå°‘å†…å®¹ï¼Œå°è¯•ä¿ç•™src/ç›®å½•çš„ä¿®æ”¹
        if not filtered_content.strip() or len(filtered_content.strip()) < 50:
            # é‡æ–°å¤„ç†ï¼Œåªä¿ç•™src/ç›®å½•çš„ä¿®æ”¹
            lines = patch_content.split('\n')
            src_lines = []
            current_file = None
            include_current_file = False
            
            for line in lines:
                if line.startswith('diff --git'):
                    match = re.search(r'diff --git a/(.*?) b/', line)
                    if match:
                        current_file = match.group(1)
                        include_current_file = current_file.startswith('src/')
                    else:
                        include_current_file = False
                    
                    if include_current_file:
                        src_lines.append(line)
                elif include_current_file:
                    src_lines.append(line)
            
            if src_lines:
                filtered_content = '\n'.join(src_lines)
        
        return filtered_content

    def log_to_file(self, message: str):
        """çº¿ç¨‹å®‰å…¨åœ°å†™å…¥æ—¥å¿—æ–‡ä»¶ï¼Œç¡®ä¿æ¯è¡Œä¸è¶…è¿‡100ä¸ªå­—ç¬¦"""
        if self.output_file:
            with self.output_lock:
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                prefix = f"[{timestamp}] "
                max_content_length = 100 - len(prefix)
                
                # å¦‚æœæ¶ˆæ¯å¤ªé•¿ï¼Œåˆ†è¡Œå¤„ç†
                if len(message) <= max_content_length:
                    self.output_file.write(f"{prefix}{message}\n")
                else:
                    # åˆ†å‰²é•¿æ¶ˆæ¯
                    words = message.split(' ')
                    current_line = ""
                    
                    for word in words:
                        if len(current_line + word + " ") <= max_content_length:
                            current_line += word + " "
                        else:
                            if current_line:
                                self.output_file.write(f"{prefix}{current_line.strip()}\n")
                                prefix = " " * len(f"[{timestamp}] ")  # åç»­è¡Œä½¿ç”¨ç©ºæ ¼å¯¹é½
                                current_line = word + " "
                            else:
                                # å•ä¸ªè¯å¤ªé•¿ï¼Œå¼ºåˆ¶æˆªæ–­
                                self.output_file.write(f"{prefix}{word[:max_content_length]}\n")
                                prefix = " " * len(f"[{timestamp}] ")
                                current_line = ""
                    
                    if current_line:
                        self.output_file.write(f"{prefix}{current_line.strip()}\n")
                
                self.output_file.flush()

    def display_validation_progress(self, completed_count: int, total_count: int, 
                                   instance_id: str, status: str, result: Dict[str, Any]):
        """
        ç»Ÿä¸€çš„éªŒè¯è¿›åº¦æ˜¾ç¤ºæ–¹æ³•ï¼Œé›†ä¸­ç®¡ç†æ‰€æœ‰è¿›åº¦æ‰“å°ä¿¡æ¯ã€‚
        
        Args:
            completed_count: å·²å®Œæˆæ•°é‡
            total_count: æ€»æ•°é‡
            instance_id: å®ä¾‹ID
            status: çŠ¶æ€ (success/warning/error/exception)
            result: éªŒè¯ç»“æœ
        """
        progress_prefix = f"[{completed_count}/{total_count}]"
        
        if status == "success":
            analysis = result["analysis_result"]
            is_fixed = analysis.get("is_fixed", False)
            message = f"{progress_prefix} âœ“ æˆåŠŸ - {instance_id}: ä¿®å¤çŠ¶æ€={is_fixed}"
        elif status == "warning":
            warning_msg = result.get('warning', 'æœªçŸ¥è­¦å‘Š')
            message = f"{progress_prefix} âš  è­¦å‘Š - {instance_id}: {warning_msg}"
        elif status == "error":
            error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
            message = f"{progress_prefix} âœ— é”™è¯¯ - {instance_id}: {error_msg}"
        elif status == "exception":
            error_msg = result.get('error', 'æœªçŸ¥å¼‚å¸¸')
            message = f"{progress_prefix} âœ— å¼‚å¸¸ - {instance_id}: {error_msg}"
        else:
            message = f"{progress_prefix} ? æœªçŸ¥çŠ¶æ€ - {instance_id}: {status}"
        
        # ç»Ÿä¸€æ‰“å°å¹¶è®°å½•åˆ°æ—¥å¿—
        print(message)
        if status in ["error", "exception"]:
            self.log_to_file(f"å¼‚å¸¸ - {instance_id}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    def _display_progress_summary(self, progress_results: List[Dict[str, Any]], total_count: int):
        """
        ç»Ÿä¸€æ˜¾ç¤ºæ‰€æœ‰è¿›åº¦ç»“æœçš„æ±‡æ€»æ–¹æ³•ã€‚
        
        Args:
            progress_results: è¿›åº¦ç»“æœåˆ—è¡¨
            total_count: æ€»å®ä¾‹æ•°
        """
        if not progress_results:
            return
        
        print("\n" + "=" * 60)
        print("ğŸ“Š éªŒè¯è¿›åº¦æ±‡æ€»:")
        print("=" * 60)
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        success_results = [r for r in progress_results if r["status"] == "success"]
        warning_results = [r for r in progress_results if r["status"] == "warning"]
        error_results = [r for r in progress_results if r["status"] == "error"]
        
        # æ˜¾ç¤ºæˆåŠŸçš„å®ä¾‹
        if success_results:
            print(f"\nâœ… æˆåŠŸéªŒè¯ ({len(success_results)} ä¸ª):")
            fixed_count = 0
            for result in success_results:
                if result.get("is_fixed", False):
                    fixed_count += 1
                    status_icon = "ğŸ”§"
                else:
                    status_icon = "âŒ"
                print(f"   {result['order']:2d}. {status_icon} {result['instance_id']}: ä¿®å¤çŠ¶æ€={result.get('is_fixed', False)}")
            print(f"   â†’ å…¶ä¸­ {fixed_count} ä¸ªå®ä¾‹ä¿®å¤æˆåŠŸ")
        
        # æ˜¾ç¤ºè­¦å‘Šçš„å®ä¾‹
        if warning_results:
            print(f"\nâš ï¸  è­¦å‘Š ({len(warning_results)} ä¸ª):")
            for result in warning_results:
                print(f"   {result['order']:2d}. {result['instance_id']}: {result['message']}")
        
        # æ˜¾ç¤ºé”™è¯¯çš„å®ä¾‹
        if error_results:
            print(f"\nâŒ é”™è¯¯ ({len(error_results)} ä¸ª):")
            for result in error_results:
                # æˆªæ–­è¿‡é•¿çš„é”™è¯¯ä¿¡æ¯
                error_msg = result['message']
                if len(error_msg) > 50:
                    error_msg = error_msg[:47] + "..."
                print(f"   {result['order']:2d}. {result['instance_id']}: {error_msg}")
        
        print("=" * 60)

    async def validate_single_instance(
        self, 
        instance_id: str, 
        base_dir: str = "/Users/caoxin/Projects/latest_agent/logs/checker_link/gold/"
    ) -> Dict[str, Any]:
        """
        éªŒè¯å•ä¸ªå®ä¾‹çš„fix_result_checkerç»“æœã€‚
        
        Args:
            instance_id: å®ä¾‹ID
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„
            
        Returns:
            Dict[str, Any]: éªŒè¯ç»“æœ
        """
        self.log_to_file(f"å¼€å§‹éªŒè¯å®ä¾‹: {instance_id}")
        
        instance_dir = Path(base_dir) / instance_id
        
        if not instance_dir.exists():
            error_msg = f"å®ä¾‹ç›®å½•ä¸å­˜åœ¨: {instance_dir}"
            self.log_to_file(f"é”™è¯¯ - {instance_id}: {error_msg}")
            return {
                "instance_id": instance_id,
                "status": "error",
                "error": error_msg
            }
        
        # è¯»å–problem_statement.txt
        problem_file = instance_dir / "problem_statement.txt"
        if not problem_file.exists():
            error_msg = f"problem_statement.txtæ–‡ä»¶ä¸å­˜åœ¨: {problem_file}"
            self.log_to_file(f"é”™è¯¯ - {instance_id}: {error_msg}")
            return {
                "instance_id": instance_id,
                "status": "error",
                "error": error_msg
            }
        
        try:
            with open(problem_file, 'r', encoding='utf-8') as f:
                problem_statement = f.read().strip()
        except Exception as e:
            error_msg = f"è¯»å–problem_statement.txtå¤±è´¥: {str(e)}"
            self.log_to_file(f"é”™è¯¯ - {instance_id}: {error_msg}")
            return {
                "instance_id": instance_id,
                "status": "error",
                "error": error_msg
            }
        
        # è¯»å–patch.diff
        patch_file = instance_dir / "patch.diff"
        if not patch_file.exists():
            error_msg = f"patch.diffæ–‡ä»¶ä¸å­˜åœ¨: {patch_file}"
            self.log_to_file(f"é”™è¯¯ - {instance_id}: {error_msg}")
            return {
                "instance_id": instance_id,
                "status": "error",
                "error": error_msg
            }
        
        try:
            with open(patch_file, 'r', encoding='utf-8') as f:
                patch_content = f.read().strip()
        except Exception as e:
            error_msg = f"è¯»å–patch.diffå¤±è´¥: {str(e)}"
            self.log_to_file(f"é”™è¯¯ - {instance_id}: {error_msg}")
            return {
                "instance_id": instance_id,
                "status": "error",
                "error": error_msg
            }
        
        # è¿‡æ»¤æ‰æµ‹è¯•æ–‡ä»¶
        filtered_patch = self.filter_patch_exclude_tests(patch_content)
        
        if not filtered_patch.strip():
            warning_msg = "è¿‡æ»¤åçš„patchå†…å®¹ä¸ºç©ºï¼Œå¯èƒ½åªåŒ…å«æµ‹è¯•æ–‡ä»¶ä¿®æ”¹"
            self.log_to_file(f"è­¦å‘Š - {instance_id}: {warning_msg}")
            return {
                "instance_id": instance_id,
                "status": "warning",
                "warning": warning_msg,
                "original_patch_size": len(patch_content),
                "filtered_patch_size": 0
            }
        
        # åˆ›å»ºcontextï¼Œå‚è€ƒTestAnomalyCheckerRealMethod
        class SimpleContext:
            def __init__(self):
                self.provider = "li"
        
        context = SimpleContext()
        
        try:
            self.log_to_file(f"å¼€å§‹è°ƒç”¨FixResultCheckeråˆ†æ - {instance_id}")
            problem_statement=await self.opt.optimize(problem_statement, context, project_type="core_libraries")
            # è°ƒç”¨fix_result_checkerè¿›è¡Œåˆ†æï¼Œä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•
            result = await self.fix_result_checker.check(
                issue_desc=problem_statement,
                fix_code=filtered_patch,
                context=context
            )
            
            is_fixed = result.get("is_fixed", False)
            check_summary = result.get("check_summary", "")
            analysis = result.get("analysis", "")
            
            self.log_to_file(f"åˆ†æå®Œæˆ - {instance_id}: ä¿®å¤çŠ¶æ€={is_fixed}")
            self.log_to_file(f"æ£€æŸ¥æ‘˜è¦ - {instance_id}: {check_summary}")
            self.log_to_file(f"è¯¦ç»†åˆ†æ - {instance_id}: {analysis[:200]}...")
            
            return {
                "instance_id": instance_id,
                "status": "success",
                "problem_statement_length": len(problem_statement),
                "original_patch_size": len(patch_content),
                "filtered_patch_size": len(filtered_patch),
                "problem_statement": problem_statement,
                "filtered_patch": filtered_patch,
                "analysis_result": result
            }
            
        except Exception as e:
            error_msg = f"fix_result_checkeråˆ†æå¤±è´¥: {str(e)}"
            self.log_to_file(f"é”™è¯¯ - {instance_id}: {error_msg}")
            return {
                "instance_id": instance_id,
                "status": "error",
                "error": error_msg,
                "problem_statement_length": len(problem_statement),
                "original_patch_size": len(patch_content),
                "filtered_patch_size": len(filtered_patch)
            }

    async def validate_instance_wrapper(self, instance_id: str, base_dir: str) -> Dict[str, Any]:
        """åŒ…è£…å™¨å‡½æ•°ï¼Œç”¨äºçº¿ç¨‹æ± æ‰§è¡Œ"""
        return await self.validate_single_instance(instance_id, base_dir)

    async def validate_all_instances_concurrent(
        self, 
        base_dir: str = "/Users/caoxin/Projects/latest_agent/logs/checker_link/gold/",
        max_workers: int = 5
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ThreadPoolExecutorå¹¶å‘éªŒè¯base_dirç›®å½•ä¸­æ‰€æœ‰å®ä¾‹çš„fix_result_checkerç»“æœã€‚
        
        Args:
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„ï¼Œå°†æ‰«ææ­¤ç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹åç§°ä½œä¸ºinstance_idåˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
            
        Returns:
            Dict[str, Any]: æ‰€æœ‰å®ä¾‹çš„éªŒè¯ç»“æœæ±‡æ€»
        """
        base_path = Path(base_dir)
        
        # æ£€æŸ¥åŸºç¡€ç›®å½•æ˜¯å¦å­˜åœ¨
        if not base_path.exists():
            error_msg = f"åŸºç¡€ç›®å½•ä¸å­˜åœ¨: {base_path}"
            print(f"âŒ {error_msg}")
            return {
                "total_instances": 0,
                "success_count": 0,
                "warning_count": 0,
                "error_count": 1,
                "success_rate": 0.0,
                "detailed_results": {},
                "error": error_msg
            }
        
        # æ‰«æåŸºç¡€ç›®å½•ï¼Œè·å–æ‰€æœ‰å­æ–‡ä»¶å¤¹åç§°ä½œä¸ºinstance_id
        target_instances = []
        for item in base_path.iterdir():
            if item.is_dir():
                instance_id = item.name
                # éªŒè¯æ–‡ä»¶å¤¹åç§°æ˜¯å¦ç¬¦åˆinstance_idæ ¼å¼ï¼ˆåŒ…å«åŒä¸‹åˆ’çº¿ï¼‰
                if '__' in instance_id:
                    target_instances.append(instance_id)
                else:
                    print(f"âš ï¸  è·³è¿‡ä¸ç¬¦åˆæ ¼å¼çš„æ–‡ä»¶å¤¹: {instance_id}")
        
        if not target_instances:
            error_msg = "åœ¨åŸºç¡€ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¬¦åˆæ ¼å¼çš„instance_idæ–‡ä»¶å¤¹"
            print(f"âŒ {error_msg}")
            print("æç¤º: instance_idæ–‡ä»¶å¤¹æ ¼å¼åº”ä¸º 'project__repo-number'ï¼Œä¾‹å¦‚ 'django__django-12308'")
            return {
                "total_instances": 0,
                "success_count": 0,
                "warning_count": 0,
                "error_count": 1,
                "success_rate": 0.0,
                "detailed_results": {},
                "error": error_msg
            }
        
        # æŒ‰å­—æ¯é¡ºåºæ’åº
        target_instances.sort()
        
        print(f"ğŸ“ ä»åŸºç¡€ç›®å½•æ‰«æåˆ° {len(target_instances)} ä¸ªinstance_id:")
        for i, instance_id in enumerate(target_instances, 1):
            if i <= 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"   {i:2d}. {instance_id}")
            elif i == 11:
                print(f"   ... è¿˜æœ‰ {len(target_instances) - 10} ä¸ªå®ä¾‹")
        
        print(f"\nå¼€å§‹å¹¶å‘éªŒè¯ {len(target_instances)} ä¸ªå®ä¾‹çš„fix_result_checkerç»“æœ...")
        print(f"åŸºç¡€ç›®å½•: {base_dir}")
        print(f"å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")
        print("-" * 80)
        
        self.log_to_file(f"å¼€å§‹å¹¶å‘éªŒè¯ {len(target_instances)} ä¸ªå®ä¾‹ï¼Œä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹")
        
        results = {}
        success_count = 0
        error_count = 0
        warning_count = 0
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œå¹¶å‘å¤„ç†
        loop = asyncio.get_event_loop()
        
        def run_validation_sync(instance_id: str) -> Dict[str, Any]:
            """åŒæ­¥åŒ…è£…å™¨ï¼Œåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œå¼‚æ­¥éªŒè¯"""
            try:
                # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)
                try:
                    return new_loop.run_until_complete(
                        self.validate_single_instance(instance_id, base_dir)
                    )
                finally:
                    new_loop.close()
            except Exception as e:
                return {
                    "instance_id": instance_id,
                    "status": "error",
                    "error": f"çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                }
        
        # ä½¿ç”¨ThreadPoolExecutoræ‰§è¡Œä»»åŠ¡
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_instance = {
                executor.submit(run_validation_sync, instance_id): instance_id 
                for instance_id in target_instances
            }
            
            # æ”¶é›†ç»“æœï¼ˆä¸åœ¨å¤„ç†è¿‡ç¨‹ä¸­æ‰“å°ï¼Œç»Ÿä¸€æ±‡æ€»åæ˜¾ç¤ºï¼‰
            completed_count = 0
            progress_results = []  # å­˜å‚¨è¿›åº¦ä¿¡æ¯
            
            for future in future_to_instance:
                instance_id = future_to_instance[future]
                completed_count += 1
                
                try:
                    result = future.result()
                    results[instance_id] = result
                    
                    # æ”¶é›†è¿›åº¦ä¿¡æ¯ï¼Œç¨åç»Ÿä¸€æ˜¾ç¤º
                    if result["status"] == "success":
                        success_count += 1
                        analysis = result["analysis_result"]
                        is_fixed = analysis.get("is_fixed", False)
                        progress_results.append({
                            "order": completed_count,
                            "status": "success",
                            "instance_id": instance_id,
                            "is_fixed": is_fixed,
                            "message": f"ä¿®å¤çŠ¶æ€={is_fixed}"
                        })
                    elif result["status"] == "warning":
                        warning_count += 1
                        progress_results.append({
                            "order": completed_count,
                            "status": "warning", 
                            "instance_id": instance_id,
                            "message": result.get('warning', 'æœªçŸ¥è­¦å‘Š')
                        })
                    else:
                        error_count += 1
                        progress_results.append({
                            "order": completed_count,
                            "status": "error",
                            "instance_id": instance_id, 
                            "message": result.get('error', 'æœªçŸ¥é”™è¯¯')
                        })
                        
                except Exception as e:
                    error_count += 1
                    error_msg = f"çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                    results[instance_id] = {
                        "instance_id": instance_id,
                        "status": "error",
                        "error": error_msg
                    }
                    progress_results.append({
                        "order": completed_count,
                        "status": "error",
                        "instance_id": instance_id,
                        "message": error_msg
                    })
                    self.log_to_file(f"å¼‚å¸¸ - {instance_id}: {error_msg}")
            
            # ç»Ÿä¸€æ˜¾ç¤ºæ‰€æœ‰è¿›åº¦ç»“æœ
            self._display_progress_summary(progress_results, len(target_instances))
        
        # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
        summary = {
            "total_instances": len(target_instances),
            "success_count": success_count,
            "warning_count": warning_count,
            "error_count": error_count,
            "success_rate": success_count / len(target_instances) * 100,
            "detailed_results": results
        }
        
        # åˆ†ææˆåŠŸçš„å®ä¾‹
        if success_count > 0:
            successful_results = [r for r in results.values() if r["status"] == "success"]
            
            # ç»Ÿè®¡ä¿®å¤çŠ¶æ€
            fixed_count = sum(1 for r in successful_results if r["analysis_result"].get("is_fixed", False))
            not_fixed_count = success_count - fixed_count
            
            summary.update({
                "analysis_statistics": {
                    "fixed_count": fixed_count,
                    "not_fixed_count": not_fixed_count,
                    "fix_rate": fixed_count / success_count * 100 if success_count > 0 else 0
                }
            })
        
        print("\n" + "=" * 80)
        print("éªŒè¯ç»“æœæ±‡æ€»:")
        print(f"æ€»å®ä¾‹æ•°: {summary['total_instances']}")
        print(f"æˆåŠŸéªŒè¯: {summary['success_count']} ({summary['success_rate']:.1f}%)")
        print(f"è­¦å‘Š: {summary['warning_count']}")
        print(f"é”™è¯¯: {summary['error_count']}")
        
        if "analysis_statistics" in summary:
            stats = summary["analysis_statistics"]
            print(f"\nåˆ†æç»Ÿè®¡:")
            print(f"ä¿®å¤æˆåŠŸ: {stats['fixed_count']}/{success_count} ({stats['fix_rate']:.1f}%)")
        
        self.log_to_file(f"éªŒè¯å®Œæˆ - æ€»æ•°: {summary['total_instances']}, æˆåŠŸ: {summary['success_count']}, è­¦å‘Š: {summary['warning_count']}, é”™è¯¯: {summary['error_count']}")
        
        return summary

    # ä¿æŒåŸæœ‰çš„ä¸²è¡Œæ–¹æ³•ä½œä¸ºå¤‡é€‰
    async def validate_all_instances(
        self, 
        base_dir: str = "/Users/caoxin/Projects/latest_agent/logs/checker_link/gold/"
    ) -> Dict[str, Any]:
        """
        ä¸²è¡ŒéªŒè¯æ‰€æœ‰30ä¸ªå®ä¾‹çš„fix_result_checkerç»“æœï¼ˆå¤‡é€‰æ–¹æ³•ï¼‰ã€‚
        """
        return await self.validate_all_instances_concurrent(base_dir, max_workers=1)

    def save_results_to_file(self, results: Dict[str, Any], output_file: str = "validation_results.json"):
        """
        å°†éªŒè¯ç»“æœä¿å­˜åˆ°æ–‡ä»¶ã€‚
        
        Args:
            results: éªŒè¯ç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\néªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")

    async def run_validation_concurrent(
        self, 
        base_dir: str = "/Users/caoxin/Projects/latest_agent/logs/checker_link/gold/",
        save_to_file: bool = True,
        output_file: str = "validation_results.json",
        log_file: str = "validation_log.txt",
        max_workers: int = 5
    ):
        """
        è¿è¡Œå®Œæ•´çš„å¹¶å‘éªŒè¯æµç¨‹ï¼Œtxtæ—¥å¿—è¾“å‡ºã€‚
        
        Args:
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„
            save_to_file: æ˜¯å¦ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        """
        try:
            self.output_file = open(log_file, 'w', encoding='utf-8')
            self.log_to_file("=" * 80)
            self.log_to_file("Fix Result Checker éªŒè¯å¼€å§‹")
            self.log_to_file(f"åŸºç¡€ç›®å½•: {base_dir}")
            self.log_to_file(f"å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")
            self.log_to_file("=" * 80)
            
            results = await self.validate_all_instances_concurrent(base_dir, max_workers)
            
            # è®°å½•æ±‡æ€»ç»“æœåˆ°æ—¥å¿—æ–‡ä»¶
            self.log_to_file("=" * 80)
            self.log_to_file("éªŒè¯ç»“æœæ±‡æ€»:")
            self.log_to_file(f"æ€»å®ä¾‹æ•°: {results['total_instances']}")
            self.log_to_file(f"æˆåŠŸéªŒè¯: {results['success_count']} ({results['success_rate']:.1f}%)")
            self.log_to_file(f"è­¦å‘Š: {results['warning_count']}")
            self.log_to_file(f"é”™è¯¯: {results['error_count']}")
            
            if "analysis_statistics" in results:
                stats = results["analysis_statistics"]
                self.log_to_file(f"ä¿®å¤æˆåŠŸ: {stats['fixed_count']}/{results['success_count']} ({stats['fix_rate']:.1f}%)")
            
            self.log_to_file("=" * 80)
            self.log_to_file("Fix Result Checker éªŒè¯å®Œæˆ")
            
            if save_to_file:
                self.save_results_to_file(results, output_file)
            
            return results
            
        except Exception as e:
            error_msg = f"éªŒè¯è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            if self.output_file:
                self.log_to_file(f"é”™è¯¯: {error_msg}")
            return None
        finally:
            # å…³é—­æ—¥å¿—æ–‡ä»¶
            if self.output_file:
                self.output_file.close()
                self.output_file = None
                print(f"\nè¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")

    async def run_validation(
        self, 
        base_dir: str = "/Users/caoxin/Projects/latest_agent/logs/checker_link/gold/",
        save_to_file: bool = True,
        output_file: str = "validation_results.json"
    ):
        """
        è¿è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹ï¼ˆä¸²è¡Œç‰ˆæœ¬ï¼‰ã€‚
        
        Args:
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„
            save_to_file: æ˜¯å¦ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        return await self.run_validation_concurrent(
            base_dir=base_dir,
            save_to_file=save_to_file,
            output_file=output_file,
            max_workers=1
        )


# Example usage
if __name__ == "__main__":
    async def main():
        validator = FixResultCheckerValidator()
        await validator.run_validation_concurrent(max_workers=10,base_dir="/Users/caoxin/Projects/latest_agent/logs/django_41_902_1/gold/",)
    
    asyncio.run(main())
