name: Quality Gate

# Comprehensive quality checks for all PR and main branch protection
# This is the single unified workflow replacing legacy test/lint/security workflows
on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main, dev ]

concurrency:
  group: quality-gate-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  security-events: write  # Required for uploading SARIF to Code Scanning
  actions: read

jobs:
  test:
    name: Tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_USER: fraiseql
          POSTGRES_PASSWORD: fraiseql
          POSTGRES_DB: fraiseql_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        # Disable pip caching initially to avoid cache folder issues
        # cache: 'pip'
        # cache-dependency-path: '**/pyproject.toml'

    - name: Install uv
      uses: astral-sh/setup-uv@v7

    - name: Setup Rust toolchain
      uses: dtolnay/rust-toolchain@stable
      with:
        toolchain: stable

    - name: Install maturin
      run: uv tool install maturin

    - name: Setup environment and install dependencies
      run: |
        # Create virtual environment with uv
        uv venv

        # Install build dependencies first (required for some packages like thrift)
        uv pip install setuptools wheel

        # Install all dependencies
        uv pip install ".[dev,all]"

        # Build and install Rust extension with modern maturin+uv integration
        uv run maturin develop --uv

    - name: Verify Environment
      run: |
        echo "=== Environment Verification ==="
        uv run python --version
        uv --version
        uv run pytest --version
        rustc --version
        pg_isready -h localhost -p 5432 -U fraiseql && echo '‚úÖ PostgreSQL Ready' || echo '‚ùå PostgreSQL Not Ready'
        uv run python -c "import psycopg; conn = psycopg.connect('postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test'); print('‚úÖ DB connection successful'); conn.close()" || echo "‚ùå DB connection failed"
        echo "=== Rust Extension Verification ==="
        uv run python -c "from fraiseql import fraiseql_rs; print(f'‚úÖ fraiseql_rs module imported'); print(f'   Has build_graphql_response: {hasattr(fraiseql_rs, \"build_graphql_response\")}'); print(f'   Functions available: {[f for f in dir(fraiseql_rs) if not f.startswith(\"_\")]}')" || echo "‚ùå fraiseql_rs import failed"

    - name: Run core tests
      env:
        DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        TEST_DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: fraiseql
        DB_PASSWORD: fraiseql
        # Environment variables for pytest configuration
        PYTEST_CURRENT_TEST: ""
      run: |
        echo "=== Starting Core Tests ==="
        echo "Environment variables:"
        printenv | grep -E "(DATABASE_URL|DB_|PYTEST_)" || echo "No relevant env vars"
        echo "Running pytest with explicit configuration..."

        uv run pytest tests/ \
          --cov=src/fraiseql \
          --cov-report=xml \
          --cov-report=term-missing \
          -v \
          -m "not blog_simple and not blog_enterprise" \
          --tb=short \
          --disable-warnings \
          || {
            echo "‚ùå Core tests failed with exit code $?"
            exit 1
          }
        echo "‚úÖ Core tests completed successfully"

    - name: Validate Network Filtering Fix
      env:
        DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        TEST_DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: fraiseql
        DB_PASSWORD: fraiseql
      run: |
        echo "=== Validating Network Filtering Bug Fix ==="
        echo "This validates the core bug fix from PR #25"

        echo "Testing JSONB network filtering bug fix..."
        uv run pytest tests/integration/database/sql/test_jsonb_network_filtering_bug.py -v --tb=short || {
          echo "‚ùå CRITICAL: Network filtering tests failed!"
          echo "This indicates the core bug fix from PR #25 is broken"
          exit 1
        }

        echo "Testing network address filtering functionality..."
        uv run pytest tests/integration/database/sql/test_network_address_filtering.py -v --tb=short || {
          echo "‚ùå CRITICAL: Network address filtering tests failed!"
          echo "This indicates the core bug fix from PR #25 is broken"
          exit 1
        }

        echo "‚úÖ Network filtering bug fix validated successfully - all 25 tests passed"

    - name: Run example integration tests
      env:
        DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        TEST_DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_test
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: fraiseql
        DB_PASSWORD: fraiseql
        FRAISEQL_ENVIRONMENT: ci
        FRAISEQL_AUTO_INSTALL: false
        FRAISEQL_LOG_LEVEL: INFO
      run: |
        echo "=== Running Example Integration Tests ==="
        uv run pytest tests/integration/examples/ -v --tb=short || {
          echo "‚ùå Example integration tests failed"
          echo "This may indicate issues with example configurations or database setup"
          exit 1
        }
        echo "‚úÖ Example integration tests completed successfully"

    - name: Upload coverage
      uses: codecov/codecov-action@v5
      with:
        files: ./coverage.xml
        flags: unittests
        name: Python-3.13
        fail_ci_if_error: false
        token: ${{ secrets.CODECOV_TOKEN }}

  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
    - name: Install uv
      uses: astral-sh/setup-uv@v7
    - name: Install dependencies
      run: |
        uv venv
        uv pip install ruff
    - name: Run ruff check (includes type checking)
      run: uv run ruff check .
    - name: Run ruff format check
      run: uv run ruff format --check .

  security:
    name: Security
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
    - name: Install uv
      uses: astral-sh/setup-uv@v7
    - name: Install dependencies
      run: |
        uv venv
        uv pip install bandit safety
    - name: Run bandit security scan
      run: uv run bandit -r src/ -f json -o bandit-results.json || true
    - name: Run safety dependency vulnerability scan
      run: uv run safety check --output json --save-json safety-results.json || true
    - name: Run OWASP Dependency Check
      uses: dependency-check/Dependency-Check_Action@main
      with:
        project: 'FraiseQL'
        path: '.'
        format: 'ALL'
        args: >
          --enableRetired
          --enableExperimental
          --nvdValidForHours 24
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH'
      continue-on-error: true
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'
    - name: Archive security scan results
      uses: actions/upload-artifact@v5
      if: always()
      with:
        name: security-scan-results
        path: |
          bandit-results.json
          safety-results.json
          reports/

  performance:
    name: Performance Regression
    runs-on: ubuntu-latest

    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_USER: fraiseql
          POSTGRES_PASSWORD: fraiseql
          POSTGRES_DB: fraiseql_perf
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'

    - name: Install uv
      uses: astral-sh/setup-uv@v7

    - name: Setup environment and install dependencies
      run: |
        uv venv
        uv pip install setuptools wheel psycopg

    - name: Run CI performance benchmarks
      env:
        DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_perf
        TEST_DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_perf
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: fraiseql
        DB_PASSWORD: fraiseql
        BENCHMARK_OUTPUT: current-results.json
        BENCHMARK_BASELINE: performance-baseline.json
      run: |
        echo "=== Running CI Performance Benchmarks ==="
        uv run python scripts/ci-cd/performance_benchmark.py

    - name: Check for performance regressions
      env:
        DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_perf
        TEST_DATABASE_URL: postgresql://fraiseql:fraiseql@localhost:5432/fraiseql_perf
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: fraiseql
        DB_PASSWORD: fraiseql
      run: |
        echo "=== Checking for Performance Regressions ==="
        if [ -f "performance-baseline.json" ]; then
          uv run python scripts/ci-cd/check_performance_regression.py current-results.json performance-baseline.json
        else
          echo "‚ÑπÔ∏è  No baseline found - establishing new baseline for future comparisons"
          cp current-results.json performance-baseline.json
        fi

    - name: Update performance baseline (main branch only)
      if: github.ref == 'refs/heads/main'
      run: |
        echo "=== Updating Performance Baseline ==="
        # Only update baseline on main branch to establish new performance expectations
        cp current-results.json performance-baseline.json
        echo "‚úÖ Performance baseline updated for main branch"

    - name: Upload performance results
      uses: actions/upload-artifact@v5
      with:
        name: performance-results
        path: |
          current-results.json
          performance-baseline.json

  # Quality gate summary job - this job fails if any quality check fails
  quality-gate:
    name: Quality Gate ‚úÖ
    runs-on: ubuntu-latest
    needs: [test, lint, security, performance]
    if: always()
    steps:
      - name: Check quality gate status
        run: |
          # This job will fail if any of the required jobs failed
          if [[ "${{ needs.test.result }}" != "success" ]]; then
            echo "‚ùå Tests failed - Quality gate blocked"
            exit 1
          fi
          if [[ "${{ needs.lint.result }}" != "success" ]]; then
            echo "‚ùå Lint checks failed - Quality gate blocked"
            exit 1
          fi
          if [[ "${{ needs.security.result }}" != "success" ]]; then
            echo "‚ùå Security checks failed - Quality gate blocked"
            exit 1
          fi
          if [[ "${{ needs.performance.result }}" != "success" ]]; then
            echo "‚ùå Performance regression detected - Quality gate blocked"
            exit 1
          fi
          echo "‚úÖ All quality checks passed - Quality gate open"
          echo "üöÄ Code is ready for merge/release"
