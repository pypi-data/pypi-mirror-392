# ðŸ“¦ A42 Protobuf Bindings (`a42-proto`)

Dieses Python-Paket enthÃ¤lt die **Protobuf-Bindings fÃ¼r Sensordaten im A42-Format**. Es erlaubt das einfache Einlesen und Verarbeiten von LiDAR-Scans und zugehÃ¶rigen Objektinformationen.

---

## ðŸ”½ Datendownload

ðŸ‘‰ [KIT Sync & Share Download](https://bwsyncandshare.kit.edu/s/6pLYbjB9Etxe3gY)

---

## ðŸ“¥ Installation

```bash
pip install a42-proto
```

---

## ðŸ§ª Beispielskripte

- [`analyze_proto.py`](https://github.com/HSE-VSV/DataReaderA42/blob/581dea222b6871f6ef4e66ad9e998c3d5a60af08/scripts/analyze_proto.py) â€“ aggregierte Auswertung Ã¼ber Frames, Scans, Punkte, Objekte  
- [`visualize_pointcloud.py`](https://github.com/HSE-VSV/DataReaderA42/blob/581dea222b6871f6ef4e66ad9e998c3d5a60af08/scripts/visualize_pointcloud.py) â€“ zeigt eine Punktwolke in Open3D

---

## ðŸ“„ Data Structure

### Frame
- `frame_timestamp_ns` â€“ global timestamp in nanoseconds  
- `lidars[]` â€“ list of `LidarScan` messages  
- `frame_id` - unique identifier for the frame

**Example:**
```python
first_scan = frame.lidars[0]
```

---

### LidarScan
- `laser_name` â€“ sensor identifier (`LaserName` enum)  
- `scan_timestamp_ns` â€“ timestamp of this scan (ns)  
- `pointcloud` â€“ LiDAR point cloud (`PointCloud`)  
- `calibration` â€“ sensor calibration (`SensorCalibration`)  
- `object_list[]` â€“ detected objects (`ObjectBBox`)  

**Example:**
```python
objects = scan.object_list[0]
```

---

### PointCloud

All fields are stored as **byte arrays** and must be decoded into NumPy arrays.

- `cartesian` â€“ XYZ coordinates (`float32`, shape NÃ—3)  
- `intensity` â€“ intensity values (`uint16`)  
- `ambient` â€“ ambient light / signal quality (`uint16`)  
- `velocity` â€“ point-wise velocity (`float32`)  
- `reflectivity` â€“ reflectivity values (`uint16`)  
- `timestamp_offset` â€“ perâ€‘point timestamp offset (`uint64` ns)  
- `channel_id` â€“ channel index (`uint16`)  

**Example decoding:**
```python
import numpy as np
xyz = np.frombuffer(pc.cartesian, dtype=np.float32).reshape(-1, 3)
intensity = np.frombuffer(pc.intensity, dtype=np.uint16)
```

---

### ObjectBBox
- `id` â€“ object ID  
- `timestamp_ns` â€“ timestamp of the object (ns)  
- `position {x,y,z}` â€“ center position  
- `dimension {x,y,z}` â€“ object size  
- `orientation {x,y,z,w}` â€“ quaternion orientation  
- `velocity {x,y,z}` â€“ velocity vector  
- `pointcloud` â€“ subâ€‘pointcloud inside the bounding box  
- `obj_class` â€“ semantic class  
- `obj_class_score` â€“ classification confidence  

**Example:**
```python
pos = obj.position
```

---

### SensorCalibration
- `sensor_name` â€“ sensor identifier  
- `extrinsic[]` â€“ 4Ã—4 rowâ€‘major extrinsic matrix  
- `vertical_fov`, `horizontal_fov` â€“ field of view  
- `vertical_scanlines`, `horizontal_scanlines` â€“ resolution  
- `horizontal_angle_spacing` â€“ angle spacing (deg)  
- `beam_altitude_angles[]` â€“ altitude angles  
- `beam_azimuth_angles[]` â€“ azimuth angles  
- `frame_mode` â€“ scan mode  
- `scan_pattern` â€“ scan pattern identifier  

**Example:**
```python
vfov = scan.calibration.vertical_fov
```

---