import json
import logging
from pathlib import Path
from typing import Optional, Union

import mlflow
import numpy as np
import onnx
import onnxruntime as ort
from mlflow.models import infer_signature

from .base import BaseMLflowClient

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OnnxClient(BaseMLflowClient):
    def __init__(self):
        super().__init__()

    def upload(
        self,
        model: Union[onnx.ModelProto, str, bytes, Path],
    ) -> Optional[str]:
        """
        ONNX ëª¨ë¸ì„ MLflowì— ì—…ë¡œë“œí•˜ê³  í•„ìš”í•œ ê²½ìš° RabbitMQì— ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.

        Args:
            model: ONNX ëª¨ë¸ ë˜ëŠ” ëª¨ë¸ ê²½ë¡œ

        Returns:
            Optional[str]: í”„ë¡œë•ì…˜ ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš° ëª¨ë¸ ê²½ë¡œ ë°˜í™˜

        Raises:
            Exception: ëª¨ë¸ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ

        """
        try:
            logger.info("ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬ ì‹œì‘")

            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° ëª¨ë¸ ë¡œë“œ
            if isinstance(model, (str, Path)):
                logger.debug(f"ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì¤‘: {model}")
                model_proto = onnx.load(str(model))
            elif isinstance(model, onnx.ModelProto):
                model_proto = model
            else:
                raise ValueError(
                    "model must be either a file path or an ONNX ModelProto"
                )

            # ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬
            onnx.checker.check_model(model_proto)
            logger.info("âœ… ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬ ì™„ë£Œ")

            # í…ì„œ ì •ë³´ ë¡œê¹…
            self._log_tensor(model_proto)

            # MLflow 3.11.1: input_exampleì„ ì‚¬ìš©í•˜ì—¬ ìë™ signature ì¶”ë¡ 
            input_example = self._get_input_example(model_proto)

            # MLflowì— ëª¨ë¸ ë¡œê¹…
            path = self._log_model(model=model_proto, input_example=input_example)

            # í”„ë¡œë•ì…˜ ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš° RabbitMQ ê±´ë„ˆëœ€
            if not self.is_production:
                logger.info("ê°œë°œ ëª¨ë“œ: RabbitMQ ë©”ì‹œì§€ ì „ì†¡ ê±´ë„ˆëœ€")
                return path

            # RabbitMQì— ëª¨ë¸ ì—…ë¡œë“œ ì•Œë¦¼ ë°œí–‰
            self._publish_to_rabbitmq(path)
            logger.info("ğŸš€ ONNX ëª¨ë¸ ì—…ë¡œë“œ ë° RabbitMQ ë°œí–‰ ì™„ë£Œ")

            return path

        except Exception as e:
            logger.error(f"ONNX ëª¨ë¸ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e!s}", exc_info=True)
            raise

    def _get_input_example(
        self, onnx_model: onnx.ModelProto
    ) -> Union[np.ndarray, dict[str, np.ndarray]]:
        """
        ONNX ëª¨ë¸ì˜ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ë¶„ì„í•˜ì—¬ ì…ë ¥ ì˜ˆì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        ë‹¤ì¤‘ ì…ë ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.

        Args:
            onnx_model: ONNX ëª¨ë¸

        Returns:
            Union[np.ndarray, dict[str, np.ndarray]]: ë‹¨ì¼ ì…ë ¥ì¸ ê²½ìš° ë°°ì—´, ë‹¤ì¤‘ ì…ë ¥ì¸ ê²½ìš° ë”•ì…”ë„ˆë¦¬

        Raises:
            ValueError: ì…ë ¥ í…ì„œê°€ ì—†ëŠ” ê²½ìš°
            Exception: ì…ë ¥ ì˜ˆì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ

        """
        try:
            input_tensors = onnx_model.graph.input

            if not input_tensors:
                raise ValueError("ONNX ëª¨ë¸ì— ì…ë ¥ í…ì„œê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            # ë‹¨ì¼ ì…ë ¥ì¸ ê²½ìš°
            if len(input_tensors) == 1:
                input_tensor = input_tensors[0]
                input_example = self._create_tensor_example(input_tensor)
                logger.debug(
                    f"ë‹¨ì¼ ì…ë ¥ ì˜ˆì œ ìƒì„±: í˜•íƒœ={input_example.shape}, íƒ€ì…={input_example.dtype}"
                )
                return input_example

            # ë‹¤ì¤‘ ì…ë ¥ì¸ ê²½ìš°
            else:
                input_examples = {}
                for input_tensor in input_tensors:
                    input_name = input_tensor.name
                    input_example = self._create_tensor_example(input_tensor)
                    input_examples[input_name] = input_example
                    logger.debug(
                        f"ë‹¤ì¤‘ ì…ë ¥ ì˜ˆì œ ìƒì„±: {input_name}, í˜•íƒœ={input_example.shape}, íƒ€ì…={input_example.dtype}"
                    )

                logger.info(f"ë‹¤ì¤‘ ì…ë ¥ ì˜ˆì œ ìƒì„± ì™„ë£Œ: {len(input_examples)}ê°œ ì…ë ¥")
                return input_examples

        except Exception as e:
            logger.error(f"ì…ë ¥ ì˜ˆì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e!s}", exc_info=True)
            raise

    def _create_tensor_example(self, input_tensor) -> np.ndarray:
        """
        ê°œë³„ í…ì„œì— ëŒ€í•œ ì˜ˆì œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            input_tensor: ONNX ì…ë ¥ í…ì„œ

        Returns:
            np.ndarray: ì˜ˆì œ ë°ì´í„°

        Raises:
            ValueError: ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°ì´í„° íƒ€ì…

        """
        # ë°ì´í„° íƒ€ì… ë° í˜•íƒœ ì¶”ì¶œ
        dtype = self.get_triton_compatible_type(input_tensor.type.tensor_type)
        shape = [
            dim.dim_value if dim.dim_value > 0 else 1  # ë™ì  ì°¨ì›ì€ 1ë¡œ ì„¤ì •
            for dim in input_tensor.type.tensor_type.shape.dim
        ]

        # ë¹ˆ shape ì²˜ë¦¬
        if not shape:
            shape = [1]

        # NumPy ë°ì´í„° íƒ€ì… ë³€í™˜
        numpy_dtype = self._get_numpy_dtype(dtype)

        # íš¨ìœ¨ì ì¸ ì˜ˆì œ ë°ì´í„° ìƒì„± (ëœë¤ ëŒ€ì‹  zeros ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)
        if numpy_dtype in [np.bool_, np.uint8, np.int32, np.int64]:
            # ì •ìˆ˜í˜•/ë¶ˆë¦°í˜•ì€ zeros
            input_example = np.zeros(shape, dtype=numpy_dtype)
        else:
            # ì‹¤ìˆ˜í˜•ì€ ì‘ì€ ëœë¤ ê°’ (ì¼ë¶€ ëª¨ë¸ì—ì„œ zero ì…ë ¥ ì‹œ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŒ)
            input_example = np.random.rand(*shape).astype(numpy_dtype) * 0.1

        return input_example

    def _process_tensors(self, tensors) -> dict[str, np.ndarray]:
        """
        í…ì„œ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìŠ¤í‚¤ë§ˆ íŒŒë¼ë¯¸í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            tensors: í…ì„œ ë¦¬ìŠ¤íŠ¸

        Returns:
            dict[str, np.ndarray]: í…ì„œ ì´ë¦„ì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬

        """
        schema_params = {}
        for tensor in tensors:
            name = tensor.name
            dtype = self.get_triton_compatible_type(tensor.type.tensor_type)
            shape = [
                dim.dim_value if dim.dim_value > 0 else 1  # ë™ì  ì°¨ì›ì€ 1ë¡œ ì„¤ì •
                for dim in tensor.type.tensor_type.shape.dim
            ]

            numpy_dtype = self._get_numpy_dtype(dtype)
            schema_params[name] = np.ones(shape, dtype=numpy_dtype)
            logger.debug(f"í…ì„œ ì²˜ë¦¬: {name}, í˜•íƒœ: {shape}, íƒ€ì…: {dtype}")

        return schema_params

    def _publish_to_rabbitmq(self, path: str) -> None:
        """
        RabbitMQì— ëª¨ë¸ ì—…ë¡œë“œ ë©”ì‹œì§€ë¥¼ ë°œí–‰í•©ë‹ˆë‹¤.

        Args:
            path: ì—…ë¡œë“œëœ ëª¨ë¸ ê²½ë¡œ

        Raises:
            Exception: RabbitMQ ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨

        """
        channel = None
        try:
            channel = self.get_connection().channel()

            message = json.dumps(
                {"train_id": self.train_id, "full_path": path}, ensure_ascii=False
            )

            channel.basic_publish(
                exchange=self._uploadModelExchange,
                routing_key=self._uploadModelExchange,
                body=message,
            )
            logger.info(f"RabbitMQì— ëª¨ë¸ ì—…ë¡œë“œ ë©”ì‹œì§€ ë°œí–‰ ì™„ë£Œ: {message}")

        except Exception as e:
            logger.error(f"RabbitMQ ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: {e!s}", exc_info=True)
            raise
        finally:
            if channel:
                channel.close()

    def _log_model(
        self,
        model: onnx.ModelProto,
        input_example: Union[np.ndarray, dict[str, np.ndarray]],
    ) -> str:
        """
        MLflowì— ONNX ëª¨ë¸ì„ ë¡œê¹…í•©ë‹ˆë‹¤.

        Args:
            model: ONNX ëª¨ë¸
            input_example: ìë™ signature ì¶”ë¡ ì„ ìœ„í•œ ì…ë ¥ ì˜ˆì œ

        Returns:
            str: ë¡œê¹…ëœ ëª¨ë¸ì˜ ì „ì²´ ê²½ë¡œ

        Raises:
            Exception: ëª¨ë¸ ë¡œê¹… ì¤‘ ì˜¤ë¥˜ ë°œìƒ

        """
        try:
            # ONNX ëª¨ë¸ì˜ ì¶œë ¥ ì˜ˆì œë¥¼ ìƒì„±í•˜ì—¬ signature ì¶”ë¡ 
            output_example = self._create_output_example(model, input_example)

            # ëª…ì‹œì ìœ¼ë¡œ ì´ë¦„ì´ í¬í•¨ëœ signature ìƒì„±
            signature = self._create_named_signature(
                model, input_example, output_example
            )

            # ëª¨ë¸ í¬ê¸° í™•ì¸ (2GB = 2 * 1024 * 1024 * 1024 bytes)
            model_size_bytes = len(model.SerializeToString())
            model_size_gb = model_size_bytes / (1024 * 1024 * 1024)

            # í° ëª¨ë¸(2GB ì´ìƒ)ì¸ ê²½ìš°ì—ë§Œ ì™¸ë¶€ ë°ì´í„°ë¡œ ì €ì¥
            save_externally = model_size_gb >= 2.0

            logger.debug(
                f"ëª¨ë¸ í¬ê¸°: {model_size_gb:.3f}GB, ì™¸ë¶€ ì €ì¥: {save_externally}"
            )

            # MLflow 3.11.1: signatureë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
            model_info = mlflow.onnx.log_model(
                onnx_model=model,
                artifact_path=self.model_name,
                input_example=input_example,
                signature=signature,  # ëª…ì‹œì ìœ¼ë¡œ ìƒì„±ëœ signature ì „ë‹¬
                # MLflow 3.11.1 ì¶”ê°€ ì˜µì…˜ë“¤
                registered_model_name=None,  # í•„ìš”ì‹œ ë“±ë¡ëœ ëª¨ë¸ëª… ì§€ì • ê°€ëŠ¥
                await_registration_for=None,  # ë“±ë¡ ëŒ€ê¸° ì‹œê°„
                metadata={
                    "framework": "onnx",
                    "source": "pytorch_trace",
                    "model_size_gb": f"{model_size_gb:.3f}",
                },  # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                # ONNX ëª¨ë¸ íŠ¹í™” ì˜µì…˜: 2GB ì´ìƒì¼ ë•Œë§Œ ì™¸ë¶€ ì €ì¥
                save_as_external_data=save_externally,
            )

            # ì‹¤ì œ artifact URI êµ¬ì„± (MLflow 3.x í˜¸í™˜)
            logger.info(f"MLflowì— ONNX ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_info.artifact_path}")

            return model_info.artifact_path

        except Exception as e:
            logger.error(f"ONNX ëª¨ë¸ ë¡œê¹… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e!s}", exc_info=True)
            raise

    def _create_named_signature(
        self,
        model: onnx.ModelProto,
        input_example: Union[np.ndarray, dict[str, np.ndarray]],
        output_example: Union[np.ndarray, dict[str, np.ndarray]],
    ) -> "mlflow.models.signature.ModelSignature":
        """
        ONNX ëª¨ë¸ì—ì„œ ì´ë¦„ì´ í¬í•¨ëœ signatureë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            model: ONNX ëª¨ë¸
            input_example: ì…ë ¥ ì˜ˆì œ
            output_example: ì¶œë ¥ ì˜ˆì œ

        Returns:
            ModelSignature: ì´ë¦„ì´ í¬í•¨ëœ signature

        """
        from mlflow.models.signature import ModelSignature
        from mlflow.types import ColSpec, Schema, TensorSpec

        try:
            # ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì…ë ¥ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì´ˆê¸°í™” í…ì„œ ì œì™¸)
            model_bytes = model.SerializeToString()
            session = ort.InferenceSession(
                model_bytes, providers=["CPUExecutionProvider"]
            )

            # ì‹¤ì œ ì…ë ¥ ì´ë¦„ë“¤ (ì´ˆê¸°í™” í…ì„œ ì œì™¸)
            actual_input_names = [
                input_meta.name for input_meta in session.get_inputs()
            ]

            # ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì¶œë ¥ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
            actual_output_names = [
                output_meta.name for output_meta in session.get_outputs()
            ]

            logger.debug(
                f"ONNX ëª¨ë¸ì˜ ì‹¤ì œ í…ì„œ ì´ë¦„ - ì…ë ¥: {actual_input_names}, ì¶œë ¥: {actual_output_names}"
            )

            input_specs: list[ColSpec | TensorSpec] = []

            if isinstance(input_example, dict):
                # ë‹¤ì¤‘ ì…ë ¥ì¸ ê²½ìš°
                for input_name in actual_input_names:
                    if input_name in input_example:
                        example_data = input_example[input_name]
                        input_spec = TensorSpec(
                            type=example_data.dtype,
                            shape=[
                                -1,
                                *list(example_data.shape[1:]),
                            ],  # ë°°ì¹˜ ì°¨ì›ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
                            name=input_name,
                        )
                        input_specs.append(input_spec)
            else:
                # ë‹¨ì¼ ì…ë ¥ì¸ ê²½ìš°
                input_name = actual_input_names[0]
                input_spec = TensorSpec(
                    type=input_example.dtype,
                    shape=[
                        -1,
                        *list(input_example.shape[1:]),
                    ],  # ë°°ì¹˜ ì°¨ì›ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
                    name=input_name,
                )
                input_specs.append(input_spec)

            output_specs: list[ColSpec | TensorSpec] = []

            if isinstance(output_example, dict):
                # ë‹¤ì¤‘ ì¶œë ¥ì¸ ê²½ìš°
                for output_name in actual_output_names:
                    if output_name in output_example:
                        example_data = output_example[output_name]
                        output_spec = TensorSpec(
                            type=example_data.dtype,
                            shape=[
                                -1,
                                *list(example_data.shape[1:]),
                            ],  # ë°°ì¹˜ ì°¨ì›ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
                            name=output_name,
                        )
                        output_specs.append(output_spec)
            else:
                # ë‹¨ì¼ ì¶œë ¥ì¸ ê²½ìš°
                output_name = actual_output_names[0]
                output_spec = TensorSpec(
                    type=output_example.dtype,
                    shape=[
                        -1,
                        *list(output_example.shape[1:]),
                    ],  # ë°°ì¹˜ ì°¨ì›ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
                    name=output_name,
                )
                output_specs.append(output_spec)

            # Schema ìƒì„±
            input_schema = Schema(input_specs)
            output_schema = Schema(output_specs)

            # ModelSignature ìƒì„±
            signature = ModelSignature(inputs=input_schema, outputs=output_schema)

            logger.info(f"ì´ë¦„ì´ í¬í•¨ëœ signature ìƒì„± ì™„ë£Œ: {signature}")
            return signature

        except Exception as e:
            logger.error(f"Named signature ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e!s}", exc_info=True)
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ infer_signature ì‚¬ìš©
            logger.warning("ê¸°ë³¸ infer_signatureë¡œ fallback")
            return infer_signature(input_example, output_example)

    def _create_output_example(
        self,
        model: onnx.ModelProto,
        input_example: Union[np.ndarray, dict[str, np.ndarray]],
    ) -> Union[np.ndarray, dict[str, np.ndarray]]:
        """
        ONNX ëª¨ë¸ì„ ì‹¤í–‰í•˜ì—¬ ì¶œë ¥ ì˜ˆì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            model: ONNX ëª¨ë¸
            input_example: ì…ë ¥ ì˜ˆì œ

        Returns:
            Union[np.ndarray, dict[str, np.ndarray]]: ì¶œë ¥ ì˜ˆì œ

        Raises:
            Exception: ëª¨ë¸ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ

        """
        try:
            # ONNX ëª¨ë¸ì„ ë°”ì´íŠ¸ë¡œ ì§ë ¬í™”
            model_bytes = model.SerializeToString()

            # ONNX Runtime ì„¸ì…˜ ìƒì„±
            session = ort.InferenceSession(
                model_bytes, providers=["CPUExecutionProvider"]
            )

            # ì…ë ¥ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
            input_names = [input_meta.name for input_meta in session.get_inputs()]

            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            if isinstance(input_example, dict):
                # ë‹¤ì¤‘ ì…ë ¥ì¸ ê²½ìš°
                input_dict = {name: input_example[name] for name in input_names}
            else:
                # ë‹¨ì¼ ì…ë ¥ì¸ ê²½ìš°
                input_dict = {input_names[0]: input_example}

            # ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
            outputs = session.run(None, input_dict)

            # ì¶œë ¥ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
            output_names = [output_meta.name for output_meta in session.get_outputs()]

            # ì¶œë ¥ í˜•íƒœ ê²°ì •
            if len(outputs) == 1:
                # ë‹¨ì¼ ì¶œë ¥ì¸ ê²½ìš°
                output_example = outputs[0]
                logger.debug(
                    f"ë‹¨ì¼ ì¶œë ¥ ì˜ˆì œ ìƒì„±: í˜•íƒœ={output_example.shape}, íƒ€ì…={output_example.dtype}"
                )
            else:
                # ë‹¤ì¤‘ ì¶œë ¥ì¸ ê²½ìš°
                output_example = dict(zip(output_names, outputs))
                logger.debug(f"ë‹¤ì¤‘ ì¶œë ¥ ì˜ˆì œ ìƒì„±: {len(outputs)}ê°œ ì¶œë ¥")

            return output_example

        except Exception as e:
            logger.error(f"ì¶œë ¥ ì˜ˆì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e!s}", exc_info=True)
            # ì¶”ë¡  ì‹¤íŒ¨ ì‹œ ì¶œë ¥ í…ì„œ ì •ë³´ë¡œ ë”ë¯¸ ì¶œë ¥ ìƒì„±
            return self._create_dummy_output_example(model)

    def _create_dummy_output_example(
        self, model: onnx.ModelProto
    ) -> Union[np.ndarray, dict[str, np.ndarray]]:
        """
        ONNX ëª¨ë¸ì˜ ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë”ë¯¸ ì¶œë ¥ ì˜ˆì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            model: ONNX ëª¨ë¸

        Returns:
            Union[np.ndarray, dict[str, np.ndarray]]: ë”ë¯¸ ì¶œë ¥ ì˜ˆì œ

        """
        try:
            output_tensors = model.graph.output

            if len(output_tensors) == 1:
                # ë‹¨ì¼ ì¶œë ¥ì¸ ê²½ìš°
                output_tensor = output_tensors[0]
                output_example = self._create_tensor_example(output_tensor)
                logger.debug(f"ë‹¨ì¼ ë”ë¯¸ ì¶œë ¥ ì˜ˆì œ ìƒì„±: í˜•íƒœ={output_example.shape}")
                return output_example
            else:
                # ë‹¤ì¤‘ ì¶œë ¥ì¸ ê²½ìš°
                output_examples = {}
                for output_tensor in output_tensors:
                    output_name = output_tensor.name
                    output_example = self._create_tensor_example(output_tensor)
                    output_examples[output_name] = output_example
                    logger.debug(
                        f"ë‹¤ì¤‘ ë”ë¯¸ ì¶œë ¥ ì˜ˆì œ ìƒì„±: {output_name}, í˜•íƒœ={output_example.shape}"
                    )

                return output_examples

        except Exception as e:
            logger.error(f"ë”ë¯¸ ì¶œë ¥ ì˜ˆì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e!s}", exc_info=True)
            # ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ë‹¨ìˆœí•œ ë°°ì—´ ë°˜í™˜
            return np.array([0.0])

    def _log_tensor(self, onnx_model: onnx.ModelProto) -> None:
        """
        ONNX ëª¨ë¸ì˜ ì…ë ¥ ë° ì¶œë ¥ í…ì„œ ì •ë³´ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

        Args:
            onnx_model: ONNX ëª¨ë¸

        """
        logger.info("=== ONNX ëª¨ë¸ í…ì„œ ì •ë³´ ===")

        # ì…ë ¥ í…ì„œ ì •ë³´
        logger.info(f"ì…ë ¥ í…ì„œ ê°œìˆ˜: {len(onnx_model.graph.input)}")
        for i, input_tensor in enumerate(onnx_model.graph.input):
            input_name = input_tensor.name
            input_type = self.get_triton_compatible_type(input_tensor.type.tensor_type)
            input_shape = [
                dim.dim_value for dim in input_tensor.type.tensor_type.shape.dim
            ]

            logger.info(
                f"ì…ë ¥ {i + 1}: ì´ë¦„={input_name}, íƒ€ì…={input_type}, í˜•íƒœ={input_shape}"
            )

        # ì¶œë ¥ í…ì„œ ì •ë³´
        logger.info(f"ì¶œë ¥ í…ì„œ ê°œìˆ˜: {len(onnx_model.graph.output)}")
        for i, output_tensor in enumerate(onnx_model.graph.output):
            output_name = output_tensor.name
            output_type = self.get_triton_compatible_type(
                output_tensor.type.tensor_type
            )
            output_shape = [
                dim.dim_value for dim in output_tensor.type.tensor_type.shape.dim
            ]

            logger.info(
                f"ì¶œë ¥ {i + 1}: ì´ë¦„={output_name}, íƒ€ì…={output_type}, í˜•íƒœ={output_shape}"
            )

    def _get_numpy_dtype(self, triton_type: str) -> np.dtype:
        """
        Triton ë°ì´í„° íƒ€ì…ì„ NumPy ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            triton_type: Triton í˜¸í™˜ ë°ì´í„° íƒ€ì… ë¬¸ìì—´

        Returns:
            np.dtype: NumPy ë°ì´í„° íƒ€ì…

        Raises:
            ValueError: ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°ì´í„° íƒ€ì…

        """
        mapping = {
            "TYPE_BOOL": np.bool_,
            "TYPE_UINT8": np.uint8,
            "TYPE_UINT16": np.uint16,
            "TYPE_UINT32": np.uint32,
            "TYPE_UINT64": np.uint64,
            "TYPE_INT8": np.int8,
            "TYPE_INT16": np.int16,
            "TYPE_INT32": np.int32,
            "TYPE_INT64": np.int64,
            "TYPE_FP16": np.float16,
            "TYPE_FP32": np.float32,
            "TYPE_FP64": np.float64,
            "TYPE_STRING": np.str_,
            # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ë§¤í•‘
            "BOOL": np.bool_,
            "UINT8": np.uint8,
            "UINT16": np.uint16,
            "INT32": np.int32,
            "INT64": np.int64,
            "FP16": np.float16,
            "FP32": np.float32,
            "FP64": np.float64,
        }

        result = mapping.get(triton_type)
        if result is None:
            logger.warning(
                f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°ì´í„° íƒ€ì…: {triton_type}, FP32ë¡œ ê¸°ë³¸ ì„¤ì •"
            )
            return np.dtype(np.float32)

        return np.dtype(result)
