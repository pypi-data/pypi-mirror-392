Metadata-Version: 2.4
Name: keynet-train
Version: 0.8.0
Summary: Training utilities for keynet - MLflow and model training support
Project-URL: Homepage, https://github.com/WIM-Corporation/keynet
Project-URL: Bug Tracker, https://github.com/WIM-Corporation/keynet/issues
Author-email: hbjs <hbjs97@naver.com>
License: MIT
Keywords: keynet,machine-learning,mlflow,training
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.9
Requires-Dist: docker>=7.0.0
Requires-Dist: httpx>=0.27.0
Requires-Dist: keynet-core
Requires-Dist: mlflow==3.1.1
Requires-Dist: numpy<2.0,>=1.25.0
Requires-Dist: onnx
Requires-Dist: onnxruntime<1.18.0,>=1.17.0
Requires-Dist: pika>=1.3.2
Requires-Dist: pydantic-settings>=2.0
Requires-Dist: pydantic>=2.0
Requires-Dist: questionary>=2.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: torch<=2.8
Description-Content-Type: text/markdown

# keynet-train

MLflowì™€ í†µí•©ëœ ëª¨ë¸ í›ˆë ¨ ìœ í‹¸ë¦¬í‹°

## ì„¤ì¹˜

```bash
pip install keynet-train
```

## ì£¼ìš” ê¸°ëŠ¥

### ğŸš€ ìë™í™”ëœ í›ˆë ¨ API

- ëª¨ë¸ì—ì„œ ìë™ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì¶”ë¡ 
- PyTorch ëª¨ë¸ì„ ONNXë¡œ ìë™ ë³€í™˜
- MLflowì— ìë™ ë¡œê¹… ë° ë²„ì „ ê´€ë¦¬
- í”„ë ˆì„ì›Œí¬ ë…ë¦½ì ì¸ ONNX ëª¨ë¸ ë¡œê¹… ì§€ì›

### ğŸ“Š ì§€ì› í”„ë ˆì„ì›Œí¬

#### PyTorch ë„¤ì´í‹°ë¸Œ ì§€ì›

- `@trace_pytorch` ë°ì½”ë ˆì´í„°ë¡œ ìë™ ONNX ë³€í™˜ ë° ë°°í¬
- í•™ìŠµë¶€í„° ë°°í¬ê¹Œì§€ ì™„ì „ ìë™í™”

#### í”„ë ˆì„ì›Œí¬ ë…ë¦½ì  ì§€ì›

- `log_onnx_model` í•¨ìˆ˜ë¡œ **ëª¨ë“  í”„ë ˆì„ì›Œí¬**ì˜ ONNX ëª¨ë¸ ë°°í¬
- TensorFlow, JAX, MXNet, PaddlePaddle ë“± ONNX ë‚´ë³´ë‚´ê¸°ë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë“  í”„ë ˆì„ì›Œí¬
- PyTorch ì™¸ í”„ë ˆì„ì›Œí¬ ì‚¬ìš©ìë¥¼ ìœ„í•œ í†µí•© ë°°í¬ íŒŒì´í”„ë¼ì¸

### ğŸ”§ MLflow í†µí•©

- ì‹¤í—˜ ìë™ ìƒì„± ë° ê´€ë¦¬
- ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ìë™ ì €ì¥ (autolog ê¸°ë³¸ í™œì„±í™”)
- ëª¨ë¸ ìŠ¤í‚¤ë§ˆ ìë™ ì¶”ë¡ 
- ë©”íŠ¸ë¦­ ë° íŒŒë¼ë¯¸í„° ì¶”ì  API ì œê³µ

## ğŸš€ ê¸°ë³¸ ì‚¬ìš©ë²•

### PyTorch ëª¨ë¸ í•™ìŠµ

```python
from keynet_train import trace_pytorch
import torch

# ğŸ¯ decoratorì— ëª¨ë¸ ì´ë¦„ê³¼ ìƒ˜í”Œ ì…ë ¥ì„ ì œê³µí•˜ê³ , í•¨ìˆ˜ì—ì„œëŠ” ëª¨ë¸ë§Œ ë°˜í™˜
@trace_pytorch("my-model", torch.randn(1, 3, 224, 224))
def train_model():
    model = MyModel()

    # í•™ìŠµ ì½”ë“œ...
    for epoch in range(10):
        # ì‹¤ì œ í•™ìŠµ ë¡œì§
        pass

    return model  # âš ï¸ ë°˜ë“œì‹œ torch.nn.Moduleë§Œ ë°˜í™˜
# Experiment ì´ë¦„: MODEL_ID ìˆìœ¼ë©´ "{MODEL_ID}_my-model", ì—†ìœ¼ë©´ "my-model"
```

### ğŸŒ ONNX ëª¨ë¸ ì§ì ‘ ë°°í¬

`@trace_pytorch` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš°, ONNX íŒŒì¼ì„ ì§ì ‘ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### PyTorch ìˆ˜ë™ ë³€í™˜

```python
from keynet_train import log_onnx_model
import torch

# PyTorch ëª¨ë¸ì„ ìˆ˜ë™ìœ¼ë¡œ ONNX ë³€í™˜
model = MyModel()
model.load_state_dict(torch.load('model.pth'))
dummy_input = torch.randn(1, 3, 224, 224)

torch.onnx.export(model, dummy_input, "model.onnx",
                  input_names=['input'], output_names=['output'])

# ë³€í™˜ëœ ONNX ëª¨ë¸ ë°°í¬
upload_path = log_onnx_model(
    experiment_name="pytorch_manual",
    onnx_model_path="model.onnx",
    metadata={"framework": "pytorch", "conversion": "manual"}
)
```

#### ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ (TensorFlow, JAX ë“±)

```python
# ì´ë¯¸ ë³€í™˜ëœ ONNX ëª¨ë¸ ë°°í¬
upload_path = log_onnx_model(
    experiment_name="my_experiment",
    onnx_model_path="model.onnx",
    metadata={"framework": "tensorflow", "model_type": "classification"}
)
```

## ğŸ“Š MLflow ë©”íŠ¸ë¦­ ë¡œê¹…

`@trace_pytorch` ë°ì½”ë ˆì´í„°ëŠ” MLflow ëŸ° ê´€ë¦¬ì™€ ëª¨ë¸ ë¡œê¹…ì„ ìë™í™”í•˜ì§€ë§Œ, **í•™ìŠµ ë©”íŠ¸ë¦­ì€ ì‚¬ìš©ìê°€ ì§ì ‘ ë¡œê¹…**í•´ì•¼ í•©ë‹ˆë‹¤.

### keynet-train ìë™í™” ë²”ìœ„

#### âœ… ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ëŠ” ê²ƒ

- MLflow ì‹¤í—˜/ëŸ° ìƒì„± ë° ê´€ë¦¬
- ëª¨ë¸ ìŠ¤í‚¤ë§ˆ ìë™ ì¶”ë¡  (ì‹¤ì œ ëª¨ë¸ ì‹¤í–‰)
- ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ìë™ ë¡œê¹… (`enable_autolog=True` ê¸°ë³¸ê°’)
- PyTorch â†’ ONNX ìë™ ë³€í™˜
- S3/MinIO ìë™ ì—…ë¡œë“œ
- RabbitMQ ë©”ì‹œì§€ ë°œí–‰
- Triton config.pbtxt ìƒì„±

#### ğŸ“ ì‚¬ìš©ìê°€ ì§ì ‘ ì²˜ë¦¬í•˜ëŠ” ê²ƒ

- **í•™ìŠµ ë©”íŠ¸ë¦­ ë¡œê¹…** (`mlflow.log_metric()`)
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…** (`mlflow.log_params()`)
- **ì»¤ìŠ¤í…€ ì•„í‹°íŒ©íŠ¸/íƒœê·¸** (`mlflow.log_artifact()`, `mlflow.set_tag()`)

### ë©”íŠ¸ë¦­ ë¡œê¹… íŒ¨í„´

```python
import mlflow
from keynet_train import trace_pytorch
import torch

@trace_pytorch("mnist-classifier", torch.randn(1, 28, 28))
def train_mnist():
    model = MNISTModel()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
    mlflow.log_params({
        "learning_rate": 0.001,
        "batch_size": 32,
        "optimizer": "Adam",
        "epochs": 10
    })

    for epoch in range(10):
        train_loss, train_acc = train_one_epoch(model, optimizer, train_loader)

        # ë©”íŠ¸ë¦­ ë¡œê¹… (step ë‹¨ìœ„)
        mlflow.log_metrics({
            "train_loss": train_loss,
            "train_accuracy": train_acc
        }, step=epoch)

    # ìµœì¢… ë©”íŠ¸ë¦­
    mlflow.log_metric("final_accuracy", train_acc)

    return model  # ëª¨ë¸ì€ autologì— ì˜í•´ ìë™ ì €ì¥ë¨
```

### MLflow Autolog ì œì–´

ê¸°ë³¸ì ìœ¼ë¡œ `enable_autolog=True`ë¡œ ì„¤ì •ë˜ì–´ ëª¨ë¸ì´ ìë™ ë¡œê¹…ë©ë‹ˆë‹¤. í•„ìš” ì‹œ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# Autolog ë¹„í™œì„±í™” (ëª¨ë¸ë„ ìˆ˜ë™ ë¡œê¹… í•„ìš”)
@trace_pytorch(
    "custom-model",
    torch.randn(1, 784),
    enable_autolog=False  # ëª¨ë¸ ìë™ ë¡œê¹… ë¹„í™œì„±í™”
)
def train_with_manual_logging():
    model = MyModel()
    # í•™ìŠµ...

    # enable_autolog=Falseì¼ ë•Œë„ ë©”íŠ¸ë¦­ì€ ì§ì ‘ ë¡œê¹…
    mlflow.log_metric("accuracy", 0.95)

    return model
```

## ğŸ”§ í™˜ê²½ ì„¤ì •

ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë³„ë„ ì„¤ì • ì—†ì´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:

```bash
# í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜
export MLFLOW_TRACKING_URI="http://mlflow.production.com"
export MLFLOW_S3_ENDPOINT_URL="http://minio.production.com:9000"
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
```

í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ì½”ë“œ ë³€ê²½ ì—†ì´ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

## ğŸ“‹ ë°˜í™˜ê°’ ì œì•½ì‚¬í•­

**`@trace_pytorch` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ëŠ” ë°˜ë“œì‹œ `torch.nn.Module` ê°ì²´ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.**

### âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•

```python
@trace_pytorch("mnist-v1", torch.randn(1, 784))
def train_mnist():
    model = torch.nn.Sequential(
        torch.nn.Linear(784, 128),
        torch.nn.ReLU(),
        torch.nn.Linear(128, 10)
    )

    # í›ˆë ¨ ë¡œì§
    optimizer = torch.optim.Adam(model.parameters())
    for epoch in range(100):
        # ì‹¤ì œ í›ˆë ¨...
        loss = train_one_epoch(model, optimizer, train_loader)

        # ë©”íŠ¸ë¦­ì€ mlflow.log_* í•¨ìˆ˜ë¡œ ê¸°ë¡
        mlflow.log_metric("train_loss", loss, step=epoch)

    return model  # ğŸ¯ ëª¨ë¸ë§Œ ë°˜í™˜!
```

### âŒ ì˜ëª»ëœ ì‚¬ìš©ë²•ë“¤

```python
@trace_pytorch("wrong-model-1", torch.randn(1, 784))
def wrong_usage1():
    model = MyModel()
    loss = train(model)
    return model, loss  # âŒ íŠœí”Œ ë°˜í™˜ ë¶ˆê°€

@trace_pytorch("wrong-model-2", torch.randn(1, 784))
def wrong_usage2():
    model = MyModel()
    train(model)
    return {
        "model": model,
        "accuracy": 0.95
    }  # âŒ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ ë¶ˆê°€

@trace_pytorch("wrong-model-3", torch.randn(1, 784))
def wrong_usage3():
    model = MyModel()
    train(model)
    return "model_saved.pth"  # âŒ ë¬¸ìì—´ ë°˜í™˜ ë¶ˆê°€
```

### ğŸ’¡ ì™œ ì´ëŸ° ì œì•½ì´ ìˆë‚˜ìš”?

`@trace_pytorch` ë°ì½”ë ˆì´í„°ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ìë™í™”í•©ë‹ˆë‹¤:

1. **MLflow ëª¨ë¸ ë¡œê¹…**: `mlflow.pytorch.log_model(pytorch_model=model, ...)`
2. **ONNX ë³€í™˜**: `torch.onnx.export(model, ...)`
3. **Triton ë°°í¬**: ìë™ `config.pbtxt` ìƒì„±

ì´ ëª¨ë“  ì‘ì—…ì´ `torch.nn.Module` ê°ì²´ë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ, ë‹¤ë¥¸ íƒ€ì…ì˜ ë°˜í™˜ê°’ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ğŸ“ ONNX ëª¨ë¸ ì…ì¶œë ¥ íŒŒë¼ë¯¸í„°ëª… ê·œì¹™

`@trace_pytorch` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•  ë•Œ ìƒì„±ë˜ëŠ” ONNX ëª¨ë¸ì˜ ì…ì¶œë ¥ íŒŒë¼ë¯¸í„°ëª…ì€ ë‹¤ìŒê³¼ ê°™ì´ ê²°ì •ë©ë‹ˆë‹¤:

### ì…ë ¥ íŒŒë¼ë¯¸í„° (Inputs)

```python
# âœ… Dictionary í˜•íƒœë¡œ ì…ë ¥í•˜ë©´ í‚¤ ì´ë¦„ì„ ì‚¬ìš© (ê¶Œì¥)
@trace_pytorch(
    "multi-input-model",
    {"image": torch.randn(1, 3, 224, 224), "label": torch.randn(1, 10)}
)
def train_model():
    # ìƒì„±ë˜ëŠ” ONNXì˜ ì…ë ¥ëª…: "image", "label"
    ...

# âœ… ë‹¨ì¼ í…ì„œë¡œ ì…ë ¥í•˜ë©´ ìë™ ìƒì„±
@trace_pytorch("simple-model", torch.randn(1, 3, 224, 224))
def train_model():
    # ìƒì„±ë˜ëŠ” ONNXì˜ ì…ë ¥ëª…: "input_0"
    ...
```

### ì¶œë ¥ íŒŒë¼ë¯¸í„° (Outputs)

```python
# ì¶œë ¥ëª…ì€ í•­ìƒ ìë™ ìƒì„±ë©ë‹ˆë‹¤
@trace_pytorch("output-test", torch.randn(1, 3, 224, 224))
def train_model():
    # ë‹¨ì¼ ì¶œë ¥: "output_0"
    return model

# ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ì˜ ê²½ìš°
def train_multi_output_model():
    class MultiOutputModel(torch.nn.Module):
        def forward(self, x):
            return output1, output2  # íŠœí”Œ ë°˜í™˜

    # ì‹¤ì œë¡œëŠ” MLflowê°€ íŠœí”Œì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ì²˜ë¦¬í•˜ì—¬ "output_0"ë§Œ ìƒì„±ë¨
    return model
```

### âš ï¸ ì¤‘ìš”í•œ ì œí•œì‚¬í•­

- **ì§€ì›ë˜ëŠ” ì…ë ¥ í˜•íƒœ**: `torch.Tensor` ë˜ëŠ” `Dict[str, torch.Tensor]`ë§Œ ì§€ì›
- **íŠœí”Œ ì…ë ¥ ë¯¸ì§€ì›**: `(tensor1, tensor2)` í˜•íƒœì˜ íŠœí”Œ ì…ë ¥ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŒ
- **ë‹¤ì¤‘ ì¶œë ¥ ì²˜ë¦¬**: PyTorch ëª¨ë¸ì´ íŠœí”Œë¡œ ë‹¤ì¤‘ ì¶œë ¥ì„ ë°˜í™˜í•´ë„ MLflow signature ì¶”ë¡ ì— ì˜í•´ `output_0` í•˜ë‚˜ë¡œ ì²˜ë¦¬ë¨
- **MLflow ì˜ì¡´ì„±**: íŒŒë¼ë¯¸í„°ëª… ìƒì„±ì€ MLflowì˜ ìë™ signature ì¶”ë¡ ì— ì˜ì¡´í•˜ë¯€ë¡œ ì¼ë¶€ ì œí•œì‚¬í•­ì´ ìˆìŒ

### ğŸ’¡ ê¶Œì¥ì‚¬í•­

```python
# ğŸ¯ ìµœì ì˜ ì‚¬ìš©ë²•: Dictionary ì…ë ¥ìœ¼ë¡œ ëª…ì‹œì ì¸ ì´ë¦„ ì§€ì •
@trace_pytorch(
    "segmentation-model",
    {
        "image": torch.randn(1, 3, 224, 224),
        "mask": torch.randn(1, 1, 224, 224)
    }
)
def train_model():
    # ìƒì„±ë˜ëŠ” config.pbtxtì—ì„œ ëª…í™•í•œ ì…ë ¥ëª… í™•ì¸ ê°€ëŠ¥:
    # input { name: "image", data_type: TYPE_FP32, dims: [-1, 3, 224, 224] }
    # input { name: "mask", data_type: TYPE_FP32, dims: [-1, 1, 224, 224] }
    return model
```

> **Note:** ìƒì„±ëœ ONNX ëª¨ë¸ì€ Triton Inference Server ë°°í¬ ì‹œ ìë™ìœ¼ë¡œ `config.pbtxt` íŒŒì¼ì´ ìƒì„±ë˜ì–´ ì •í™•í•œ ì…ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë‹¤ì¤‘ ì…ë ¥ ëª¨ë¸

```python
@trace_pytorch(
    "multi-input-v1",
    {
        "image": torch.randn(1, 3, 224, 224),
        "mask": torch.randn(1, 1, 224, 224)
    }
)
def train_multi_input():
    model = MultiInputModel()

    # ëª¨ë¸ì´ ì—¬ëŸ¬ ì…ë ¥ì„ ë°›ëŠ” ê²½ìš°
    class MultiInputModel(torch.nn.Module):
        def forward(self, image, mask):
            # imageì™€ maskë¥¼ í•¨ê»˜ ì²˜ë¦¬
            combined = torch.cat([image, mask], dim=1)
            return self.classifier(combined)

    # í›ˆë ¨ ë¡œì§...
    return model
```

## ğŸ”„ Dynamic Axes (ê°€ë³€ í¬ê¸° ì§€ì›)

ONNX ë³€í™˜ ì‹œ ì…ì¶œë ¥ í…ì„œì˜ íŠ¹ì • ì°¨ì›ì„ ë™ì (ê°€ë³€) í¬ê¸°ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê¸°ë³¸ ë™ì‘

```python
# ê¸°ë³¸ì ìœ¼ë¡œ ë°°ì¹˜ ì°¨ì›(0ë²ˆ)ì€ ìë™ìœ¼ë¡œ ë™ì  í¬ê¸°ë¡œ ì„¤ì •ë©ë‹ˆë‹¤
@trace_pytorch("dynamic-batch-model", torch.randn(1, 3, 224, 224))
def train_model():
    # ONNX ì…ë ¥ shape: [-1, 3, 224, 224]
    # -1ì€ ê°€ë³€ ë°°ì¹˜ í¬ê¸°ë¥¼ ì˜ë¯¸
    return model
```

### ì»¤ìŠ¤í…€ Dynamic Axes

```python
# ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ê°€ë³€ì ì¸ ëª¨ë¸
@trace_pytorch(
    "sequence-model",
    torch.randn(1, 128, 768),  # [batch, seq_len, hidden]
    dynamic_axes={
        "input_0": {
            0: "batch_size",
            1: "sequence_length"  # 1ë²ˆ ì°¨ì›ë„ ê°€ë³€ìœ¼ë¡œ
        },
        "output_0": {
            0: "batch_size",
            1: "sequence_length"
        }
    }
)
def train_sequence_model():
    return SequenceModel()

# ë‹¤ì¤‘ ì…ë ¥ì—ì„œ ê°ê° ë‹¤ë¥¸ dynamic axes ì„¤ì •
@trace_pytorch(
    "multimodal-model",
    {
        "image": torch.randn(1, 3, 224, 224),
        "text": torch.randn(1, 50, 512)
    },
    dynamic_axes={
        "image": {0: "batch"},           # ì´ë¯¸ì§€ëŠ” ë°°ì¹˜ë§Œ
        "text": {0: "batch", 1: "len"}, # í…ìŠ¤íŠ¸ëŠ” ê¸¸ì´ë„
        "output_0": {0: "batch"}
    }
)
def train_multimodal():
    return MultiModalModel()
```

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

- **NLP**: ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ ì²˜ë¦¬
- **Vision**: ë‹¤ì–‘í•œ í•´ìƒë„ ì´ë¯¸ì§€ ì§€ì›
- **Detection**: ê°€ë³€ ê°œìˆ˜ì˜ ê°ì²´ ì¶œë ¥

> **Note**: ë™ì  í¬ê¸° ì„¤ì •ì´ ì‹¤íŒ¨í•˜ë©´ ìë™ìœ¼ë¡œ ê³ ì • í¬ê¸°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
