import streamlit as st
import os
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from ui_config import GRADIENT_BACKGROUND_CSS

def apply_css(css_code):

    st.markdown(css_code, unsafe_allow_html=True)

class RAGService:
    """RAGçŸ¥è¯†åº“æœåŠ¡ç±»"""

    def __init__(self, knowledge_file="products.json", index_file="my_faiss_index.index"):
        """åˆå§‹åŒ–RAGæœåŠ¡"""
        # æ¨¡å‹è·¯å¾„é…ç½®
        model_path = "./models/paraphrase-multilingual-MiniLM-L12-v2"
        model_id = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

        # æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ˜¯å¦å­˜åœ¨ä¸”å®Œæ•´
        model_exists = False
        if os.path.exists(model_path):
            config_exists = os.path.exists(os.path.join(model_path, "config.json"))
            has_weights = any(
                os.path.exists(os.path.join(model_path, f))
                for f in ["pytorch_model.bin", "model.safetensors", "tf_model.h5"]
            )
            if config_exists and has_weights:
                model_exists = True

        # åŠ è½½æ¨¡å‹
        if model_exists:
            try:
                st.info("æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹...")
                self.model = SentenceTransformer(model_path)
                st.success("æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            except Exception as e:
                st.warning(f"æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                model_exists = False

        if not model_exists:
            st.warning(f"æ­£åœ¨ä»HuggingFaceä¸‹è½½æ¨¡å‹... (çº¦500MB)")
            try:
                self.model = SentenceTransformer(model_id)
                try:
                    os.makedirs(model_path, exist_ok=True)
                    self.model.save(model_path)
                    st.success(f"æ¨¡å‹å·²ä¸‹è½½å¹¶ä¿å­˜åˆ°: {model_path}")
                except Exception as save_error:
                    st.warning(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {save_error}ï¼Œä½†å¯ä»¥ç»§ç»­ä½¿ç”¨")
            except Exception as download_error:
                st.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {download_error}")
                raise

        # è®¾ç½®æ–‡ä»¶è·¯å¾„
        self.index_file = index_file
        self.knowledge_file = knowledge_file

        # åŠ è½½çŸ¥è¯†æ–‡æ¡£
        with open(self.knowledge_file, "r", encoding="utf-8") as f:
            self.documents = json.load(f)

        # åŠ è½½å·²ä¿å­˜çš„FAISSç´¢å¼•
        if os.path.exists(self.index_file):
            self.index = faiss.read_index(self.index_file)
        else:
            self._build_knowledge_base()

    def _build_knowledge_base(self):
        """æ„å»ºå‘é‡çŸ¥è¯†åº“"""
        if not self.documents or not self.model:
            return

        contents = [doc["content"] for doc in self.documents]
        # ç”Ÿæˆæ–‡æœ¬å‘é‡
        embeddings = self.model.encode(contents, show_progress_bar=True)
        # è½¬æ¢æ•°æ®æ ¼å¼
        embeddings = np.array(embeddings).astype("float32")
        d = embeddings.shape[1] if embeddings is not None and len(embeddings) > 0 else 0
        # åˆ›å»ºFAISSç´¢å¼•
        self.index = faiss.IndexFlatL2(d)
        self.index.add(embeddings)
        # ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶
        faiss.write_index(self.index, self.index_file)

    def search(self, query: str, top_k=3) -> list:
        """å‘é‡è¯­ä¹‰æœç´¢"""
        if self.index is None or not query or not self.model:
            return []

        # å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡
        query_embedding = self.model.encode([query])
        # æ ¼å¼è½¬æ¢
        query_embedding = np.array(query_embedding).astype("float32")
        # æ‰§è¡Œå‘é‡æœç´¢
        distances, indices = self.index.search(query_embedding, top_k)
        
        results = []
        for i in indices[0]:
            if 0 <= i < len(self.documents):
                results.append(self.documents[i]["content"])
        return results


def render_page():
    apply_css(GRADIENT_BACKGROUND_CSS)
    st.title("ä»»åŠ¡äºŒï¼šçŸ¥è¯†åº“é—®ç­” (RAG)")

    with st.sidebar:
        st.subheader("âš™ï¸ RAG é…ç½®")
        st.markdown("---")


    if "rag_messages" not in st.session_state:
        st.session_state.rag_messages = []

    # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶
    index_file = "my_faiss_index.index"
    if os.path.exists(index_file):
        st.success(f"âœ… {index_file} ç´¢å¼•æ–‡ä»¶å·²å­˜åœ¨")
    else:
        st.warning(f"âš ï¸ {index_file} ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨æ„å»º")

    # åˆå§‹åŒ–RAGæœåŠ¡
    if "rag_service" not in st.session_state:
        st.session_state.rag_service = RAGService()
        
    rag_service = st.session_state.rag_service
    
    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for message in st.session_state.rag_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("æ‚¨æƒ³äº†è§£ä»€ä¹ˆï¼Ÿ"):
        # è®°å½•ç”¨æˆ·æ¶ˆæ¯
        st.session_state.rag_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # çŸ¥è¯†æ£€ç´¢
        search_results = []
        if rag_service:
            search_results = rag_service.search(prompt, top_k=3)

        # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
        with st.chat_message("assistant"):
            if search_results:
                st.markdown("### ğŸ“š æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†ï¼š\n")
                for i, result in enumerate(search_results, 1):
                    st.markdown(f"**{i}.** {result}\n")
                
                assistant_response = f"æ ¹æ®çŸ¥è¯†åº“æ£€ç´¢ï¼Œæ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n\n" + "\n\n".join([f"{i}. {r}" for i, r in enumerate(search_results, 1)])
            else:
                assistant_response = "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„çŸ¥è¯†ä¿¡æ¯ã€‚"
                st.warning(assistant_response)
            
            st.session_state.rag_messages.append({
                "role": "assistant", 
                "content": assistant_response
            })


if __name__ == "__main__":
    render_page()

