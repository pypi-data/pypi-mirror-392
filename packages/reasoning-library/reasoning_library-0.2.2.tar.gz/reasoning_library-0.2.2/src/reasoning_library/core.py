"""
Core utilities for the reasoning library.
"""

import inspect
import re
import threading
import weakref
import hashlib
import hmac
import time
from collections import deque
from dataclasses import dataclass, field
from functools import wraps, lru_cache
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

from .exceptions import ValidationError
from .null_handling import handle_optional_params
from .sanitization import sanitize_for_display
from .constants import (
    # Security constants
    MAX_SOURCE_CODE_SIZE,

    # Performance optimization constants
    MAX_CACHE_SIZE,
    MAX_REGISTRY_SIZE,

    # Cache management parameters
    CACHE_EVICTION_FRACTION,
    REGISTRY_EVICTION_FRACTION,

    # Regex pattern constants
    REGEX_WORD_CHAR_MAX,
    REGEX_SPACING_MAX,

    # Text processing limits
    KEYWORD_LENGTH_LIMIT,
    COMPONENT_LENGTH_LIMIT,
    MAX_TEMPLATE_KEYWORDS,
)

# LAZY LOADING: Regex patterns are compiled on-demand to improve module import performance
# This reduces startup overhead by only compiling patterns when actually used

@lru_cache(maxsize=None)
def _get_factor_pattern() -> re.Pattern:
    """Get factor pattern with lazy compilation for performance optimization."""
    return re.compile(
        rf"(\w{{0,{REGEX_WORD_CHAR_MAX}}}(?:data_sufficiency | pattern_quality | complexity)_factor)[\s]{{0,5}}(?:\*|,|\+|\-|=)",
        re.IGNORECASE | re.MULTILINE,
    )

@lru_cache(maxsize=None)
def _get_comment_pattern() -> re.Pattern:
    """Get comment pattern with lazy compilation for performance optimization."""
    return re.compile(
        r"#\s*(?:Data | Pattern | Complexity)\s+([^#\n]+factor)", re.IGNORECASE | re.MULTILINE
    )

@lru_cache(maxsize=None)
def _get_evidence_pattern() -> re.Pattern:
    """Get evidence pattern with lazy compilation for performance optimization."""
    return re.compile(
        r'f?"[^"]*(?:confidence\s + based\s + on | factors?[\s:]*in)[^"]*([^"\.]+pattern[^"\.]*)',
        re.IGNORECASE | re.MULTILINE,
    )

@lru_cache(maxsize=None)
def _get_combination_pattern() -> re.Pattern:
    """Get combination pattern with lazy compilation for performance optimization."""
    return re.compile(
        rf"(\w{{1,{REGEX_WORD_CHAR_MAX}}}_factor)[\s]{{0,{REGEX_SPACING_MAX}}}\*[\s]{{0,{REGEX_SPACING_MAX}}}(\w{{1,{REGEX_WORD_CHAR_MAX}}}_factor)",
        re.IGNORECASE | re.MULTILINE,
    )

@lru_cache(maxsize=None)
def _get_clean_factor_pattern() -> re.Pattern:
    """Get clean factor pattern with lazy compilation for performance optimization."""
    return re.compile(r"[()=\*]+", re.IGNORECASE)

# Note: Regex patterns are now lazily loaded through module-level __getattr__ function
# This provides backward compatibility while enabling lazy compilation for performance

# =============================================================================
# SECURE CACHE MANAGEMENT - CRITICAL FIX FOR ID-004
# =============================================================================

# Cache integrity key for HMAC signatures (hardcoded, not from environment)
_CACHE_INTEGRITY_KEY = b"reasoning_library_cache_integrity_v1_secure"

# Cache entry metadata structure for integrity validation
@dataclass
class _SecureCacheEntry:
    """Secure cache entry with integrity validation and access controls."""
    data: Any
    timestamp: float
    signature: str
    access_level: str = "internal"  # "internal", "public", "restricted"
    metadata: Dict[str, Any] = field(default_factory=dict)

def _create_cache_signature(data: Any, timestamp: float, access_level: str) -> str:
    """
    Create HMAC signature for cache entry integrity validation.

    CRITICAL SECURITY: Prevents cache poisoning attacks by ensuring
    cache entries cannot be tampered with or forged.

    Args:
        data: The cache entry data
        timestamp: Creation timestamp
        access_level: Access control level

    Returns:
        HMAC signature string
    """
    # Create content to sign
    content = f"{str(data)}:{timestamp}:{access_level}"

    # Create HMAC signature
    signature = hmac.new(
        _CACHE_INTEGRITY_KEY,
        content.encode('utf-8'),
        hashlib.sha256
    ).hexdigest()

    return signature

def _validate_cache_entry(entry: _SecureCacheEntry) -> bool:
    """
    Validate cache entry integrity and authenticity.

    CRITICAL SECURITY: Ensures cache entries have not been tampered with
    or poisoned by malicious actors.

    Args:
        entry: Cache entry to validate

    Returns:
        True if entry is valid and authentic, False otherwise
    """
    if not isinstance(entry, _SecureCacheEntry):
        return False

    # Recreate expected signature
    expected_signature = _create_cache_signature(
        entry.data, entry.timestamp, entry.access_level
    )

    # Constant-time comparison to prevent timing attacks
    return hmac.compare_digest(entry.signature, expected_signature)

def _is_cache_key_valid(func_id: str) -> bool:
    """
    Validate cache key format to prevent injection attacks.

    CRITICAL SECURITY: Ensures cache keys follow expected format
    to prevent cache poisoning through malformed keys.

    Args:
        func_id: Cache key to validate

    Returns:
        True if key format is valid, False otherwise
    """
    if not isinstance(func_id, str):
        return False

    # Key should be a 32-character hex string (MD5 hash)
    if len(func_id) != 32:
        return False

    # Verify it's hexadecimal
    try:
        int(func_id, 16)
        return True
    except ValueError:
        return False

# Secure cache storage with integrity validation
_math_detection_secure_cache: Dict[str, _SecureCacheEntry] = {}

# Legacy cache for backward compatibility (deprecated)
_function_source_cache: weakref.WeakKeyDictionary[Callable, str] = weakref.WeakKeyDictionary()
_math_detection_cache: Dict[int, Tuple[bool, Optional[str], Optional[str]]] = {}

_MAX_CACHE_SIZE = MAX_CACHE_SIZE
_MAX_REGISTRY_SIZE = MAX_REGISTRY_SIZE

_registry_lock = threading.RLock()

_cache_lock = threading.RLock()

# Race condition fix: Add timeout handling for locks
_LOCK_TIMEOUT = 5.0  # 5 second timeout for lock acquisition

# PERFORMANCE OPTIMIZATION: FIFO tracking deques for O(1) cache/registry management
# These maintain insertion order for efficient FIFO eviction without expensive operations
_math_cache_queue = deque(maxlen=MAX_CACHE_SIZE)
_enhanced_registry_queue = deque(maxlen=MAX_REGISTRY_SIZE)
_tool_registry_queue = deque(maxlen=MAX_REGISTRY_SIZE)

def _prevent_source_code_inspection(func: Callable[..., Any]) -> str:
    """
    CRITICAL SECURITY: Prevent all source code inspection attempts.

    ID-004 SECURITY FIX: This function blocks all attempts to access source code
    through any mechanism, including but not limited to:
    - inspect.getsource() calls
    - Cache-based source code retrieval
    - Memory-based source code extraction
    - File system access through code inspection
    - Function introspection that could leak sensitive information

    PROTECTION AGAINST:
    - Information disclosure of sensitive implementation details
    - Exposure of secrets, API keys, passwords, or tokens in source comments
    - File system access and path traversal through code inspection
    - Proprietary algorithm exposure
    - Cache poisoning through source code manipulation

    Args:
        func: Function to analyze (source code will be BLOCKED for security)

    Returns:
        str: Always empty string - ALL source code access is blocked
    """
    # SECURITY: Never attempt to access source code under any circumstances
    # This prevents cache poisoning attacks that try to inject malicious source code

    # Additional security: Log the attempt (if logging is available) for audit
    try:
        func_name = getattr(func, '__name__', 'unknown')
        func_module = getattr(func, '__module__', 'unknown')

        # CRITICAL SECURITY: Create audit record of source code access attempt
        # This helps detect potential attacks or misuse
        security_context = f"SOURCE_CODE_ACCESS_BLOCKED:{func_module}:{func_name}"

        # Note: We don't actually log this to prevent log injection attacks,
        # but the context is created for potential future secure logging

    except Exception:
        # Even the error handling doesn't expose any information
        pass

    # SECURITY: Always return empty string to prevent any information disclosure
    return ""

def _get_function_source_cached(func: Callable[..., Any]) -> str:
    """
    CRITICAL SECURITY: Get function source code with complete access prevention.

    ID-004 SECURITY FIX: ALL source code inspection is DISABLED to prevent:
    - Information disclosure of sensitive implementation details
    - Access to source code from external files through inspect.getsource()
    - Exposure of secrets, API keys, passwords, or sensitive data in source comments
    - File system access and path traversal through code inspection
    - Proprietary algorithm exposure
    - Cache poisoning attacks through source code manipulation
    - Memory inspection attacks through cached source code

    Thread-safe: Uses _cache_lock to prevent race conditions in cache access.

    Args:
        func: Function to analyze (source code access will be BLOCKED for security)

    Returns:
        str: Always empty string - ALL source code access is blocked
    """
    # SECURITY: Delegate to the prevention function
    return _prevent_source_code_inspection(func)

    # Legacy cache handling maintained for backward compatibility but never used
    with _cache_lock:
        # Check cache first (WeakKeyDictionary automatically handles cleanup)
        if func in _function_source_cache:
            return _function_source_cache[func]

        empty_result = ""
        _function_source_cache[func] = empty_result
        return empty_result

def _secure_cache_get(func_id: str) -> Optional[Tuple[bool, Optional[str], Optional[str]]]:
    """
    SECURE: Get cached result with integrity validation.

    CRITICAL SECURITY FIX FOR ID-004: Prevents cache poisoning attacks
    by validating cache entry integrity and authenticity before returning data.

    Args:
        func_id: Validated cache key

    Returns:
        Cached result if valid and authentic, None otherwise
    """
    # Validate cache key format
    if not _is_cache_key_valid(func_id):
        return None

    # Check if entry exists in secure cache
    if func_id not in _math_detection_secure_cache:
        return None

    # Get cache entry
    entry = _math_detection_secure_cache[func_id]

    # Validate entry integrity
    if not _validate_cache_entry(entry):
        # Remove corrupted entry
        _math_detection_secure_cache.pop(func_id, None)
        return None

    # Check access level (internal only for math detection)
    if entry.access_level != "internal":
        return None

    # Validate timestamp (prevent stale entries)
    current_time = time.time()
    age_seconds = current_time - entry.timestamp
    if age_seconds > 3600:  # 1 hour maximum cache age for security
        _math_detection_secure_cache.pop(func_id, None)
        return None

    return entry.data

def _secure_cache_put(func_id: str, result: Tuple[bool, Optional[str], Optional[str]]) -> None:
    """
    SECURE: Store result in cache with integrity protection.

    CRITICAL SECURITY FIX FOR ID-004: Prevents cache poisoning attacks
    by creating signed cache entries that cannot be forged or tampered with.

    Args:
        func_id: Validated cache key
        result: Result to cache (must be validated tuple)
    """
    # Validate cache key format
    if not _is_cache_key_valid(func_id):
        return

    # Validate result format
    if not isinstance(result, tuple) or len(result) != 3:
        return

    # Sanitize result data to prevent information leakage
    is_mathematical, confidence_doc, mathematical_basis = result

    # Sanitize confidence documentation to prevent injection
    if confidence_doc and isinstance(confidence_doc, str):
        confidence_doc = sanitize_for_display(confidence_doc, max_length=500)
        # Remove potential sensitive information
        sensitive_patterns = [
            r'password', r'secret', r'key\s*=\s*\w+', r'token\s*=\s*\w+',
            r'api[_-]?key', r'auth[_-]?token', r'credential'
        ]
        for pattern in sensitive_patterns:
            confidence_doc = re.sub(pattern, '[REDACTED]', confidence_doc, flags=re.IGNORECASE)

    # Sanitize mathematical basis
    if mathematical_basis and isinstance(mathematical_basis, str):
        mathematical_basis = sanitize_for_display(mathematical_basis, max_length=500)

    sanitized_result = (bool(is_mathematical), confidence_doc, mathematical_basis)

    # Create secure cache entry
    timestamp = time.time()
    signature = _create_cache_signature(sanitized_result, timestamp, "internal")

    entry = _SecureCacheEntry(
        data=sanitized_result,
        timestamp=timestamp,
        signature=signature,
        access_level="internal",
        metadata={"version": "1.0", "source": "math_detection"}
    )

    # Store in secure cache
    _math_detection_secure_cache[func_id] = entry

def _secure_cache_evict_if_needed() -> None:
    """
    SECURE: Evict old cache entries if cache is full.

    Implements secure FIFO eviction with integrity validation.
    """
    current_size = len(_math_detection_secure_cache)
    if current_size < MAX_CACHE_SIZE:
        return

    # Calculate eviction count
    num_to_evict = max(1, int(MAX_CACHE_SIZE * CACHE_EVICTION_FRACTION))
    num_to_evict = min(num_to_evict, current_size)

    if num_to_evict <= 0:
        return

    # Get oldest entries (by timestamp)
    entries_by_age = sorted(
        _math_detection_secure_cache.items(),
        key=lambda x: x[1].timestamp
    )

    # Evict oldest entries
    for i in range(min(num_to_evict, len(entries_by_age))):
        func_id, entry = entries_by_age[i]
        _math_detection_secure_cache.pop(func_id, None)

def _get_math_detection_cached(func: Callable[..., Any]) -> Tuple[bool, Optional[str], Optional[str]]:
    """
    SECURE: Get mathematical reasoning detection result with caching.

    CRITICAL SECURITY FIX FOR ID-004: Implements secure cache with:
    - Integrity validation to prevent cache poisoning
    - Access controls to prevent unauthorized inspection
    - Cache key validation to prevent injection attacks
    - Secure storage with HMAC signatures

    Uses function id as cache key for stability across calls.
    Implements LRU-style eviction to prevent unbounded cache growth.

    Thread-safe: Uses _cache_lock to prevent race conditions in cache access
    and eviction logic that could cause data corruption.

    Args:
        func: Function to analyze for mathematical reasoning

    Returns:
        tuple: (is_mathematical, confidence_documentation, mathematical_basis)
    """
    # Create a stable cache key that includes function identity and content
    # This prevents false cache hits when Python reuses object IDs
    try:
        func_module = getattr(func, '__module__', 'unknown')
        func_qualname = getattr(func, '__qualname__', 'unknown')

        # SECURE: Source code inspection is DISABLED to prevent information disclosure
        # CRITICAL SECURITY FIX for CRIT-003: Prevent exposure of API keys, passwords,
        # proprietary algorithms, and sensitive data through source code inspection
        source_code = ''

        docstring = func.__doc__ or ''

        # Create a hash based on multiple stable identifiers
        content = f"{func_module}:{func_qualname}:{docstring}:{source_code}"
        func_id = hashlib.md5(content.encode()).hexdigest()

    except (OSError, TypeError, ValueError, AttributeError, ImportError):
        # Fallback to object ID if hashing fails (less safe but functional)
        # Specific exceptions: import errors, type errors, value errors, attribute access errors
        func_id = str(id(func))

    # RACE CONDITION FIX: Use timeout-based lock acquisition to prevent indefinite blocking
    # This ensures the function doesn't hang forever under heavy contention
    acquired = _cache_lock.acquire(timeout=_LOCK_TIMEOUT)
    if not acquired:
        # If we can't acquire the lock, fail gracefully to prevent deadlock
        # This is a security measure to prevent denial of service through lock contention
        return (False, None, None)

    try:
        # SECURE: Try to get from secure cache first
        cached_result = _secure_cache_get(func_id)
        if cached_result is not None:
            return cached_result

        # SECURE: Perform detection under lock to prevent race conditions
        result = _detect_mathematical_reasoning_uncached(func)

        # SECURE: Store result in secure cache with integrity protection
        _secure_cache_put(func_id, result)

        # SECURE: Evict old entries if cache is full
        _secure_cache_evict_if_needed()

        return result

    finally:
        # RACE CONDITION FIX: Always release the lock in finally block
        _cache_lock.release()

def _manage_registry_size() -> None:
    """
    Manage registry size to prevent unbounded growth and memory exhaustion attacks.

    Implements FIFO - style eviction for both ENHANCED_TOOL_REGISTRY and TOOL_REGISTRY
    to maintain bounded memory usage. Only performs expensive operations when
    actually exceeding limits to maintain O(1) performance for normal use.

    RACE CONDITION FIX: Uses non-blocking lock acquisition to prevent deadlock
    when called from contexts that already hold the registry lock.

    Thread - safe: Uses _registry_lock to prevent race conditions and ensures
    atomic list operations to eliminate race condition windows.
    """
    # RACE CONDITION FIX: Use non-blocking lock acquisition to prevent deadlock
    # This handles the case where _manage_registry_size() is called while already
    # holding _registry_lock (reentrant scenario in tool_spec decorator)
    acquired = _registry_lock.acquire(blocking=False)
    if not acquired:
        # If we can't acquire the lock non-blocking, skip management this time
        # This prevents deadlock while maintaining eventual consistency
        return

    try:
        # Early exit if both registries are under limit (O(1) performance)
        enhanced_current_size = len(ENHANCED_TOOL_REGISTRY)
        tool_current_size = len(TOOL_REGISTRY)

        if (enhanced_current_size < MAX_REGISTRY_SIZE and
            tool_current_size < MAX_REGISTRY_SIZE):
            return

        # RACE CONDITION FIX: Safer registry eviction with error handling
        # Enhanced Tool Registry eviction
        if enhanced_current_size >= MAX_REGISTRY_SIZE:
            # Calculate safe removal count
            remove_count = max(1, int(MAX_REGISTRY_SIZE * REGISTRY_EVICTION_FRACTION))
            remove_count = min(remove_count, enhanced_current_size)

            if remove_count > 0:
                try:
                    # PERFORMANCE OPTIMIZATION: O(1) registry eviction using deque
                    # Evict oldest items efficiently without expensive list operations
                    for _ in range(remove_count):
                        if _enhanced_registry_queue:
                            _enhanced_registry_queue.popleft()

                    # Rebuild registry from deque (O(n) operation, but only during eviction)
                    ENHANCED_TOOL_REGISTRY.clear()
                    ENHANCED_TOOL_REGISTRY.extend(_enhanced_registry_queue)
                except (IndexError, ValueError, RuntimeError):
                    # Handle race conditions gracefully - skip eviction if list is modified
                    pass

        # Tool Registry eviction
        if tool_current_size >= MAX_REGISTRY_SIZE:
            # Calculate safe removal count
            remove_count = max(1, int(MAX_REGISTRY_SIZE * REGISTRY_EVICTION_FRACTION))
            remove_count = min(remove_count, tool_current_size)

            if remove_count > 0:
                try:
                    # PERFORMANCE OPTIMIZATION: O(1) registry eviction using deque
                    # Evict oldest items efficiently without expensive list operations
                    for _ in range(remove_count):
                        if _tool_registry_queue:
                            _tool_registry_queue.popleft()

                    # Rebuild registry from deque (O(n) operation, but only during eviction)
                    TOOL_REGISTRY.clear()
                    TOOL_REGISTRY.extend(_tool_registry_queue)
                except (IndexError, ValueError, RuntimeError):
                    # Handle race conditions gracefully - skip eviction if list is modified
                    pass

    finally:
        # RACE CONDITION FIX: Always release the lock if we acquired it
        _registry_lock.release()


def clear_performance_caches() -> Dict[str, int]:
    """
    Clear all performance optimization caches and registries.

    Useful for testing, memory management, or when function definitions change.

    RACE CONDITION FIX: Uses timeout-based lock acquisition to prevent
    indefinite blocking under heavy contention scenarios.

    Thread - safe: Uses both _registry_lock and _cache_lock to prevent race conditions.

    Returns:
        dict: Statistics about cleared cache entries
    """
    # RACE CONDITION FIX: Use timeout-based lock acquisition to prevent blocking
    cache_acquired = _cache_lock.acquire(timeout=_LOCK_TIMEOUT)
    if not cache_acquired:
        # If we can't acquire cache lock, return empty stats to prevent blocking
        return {
            "source_cache_cleared": 0,
            "math_detection_cache_cleared": 0,
            "secure_math_cache_cleared": 0,
            "enhanced_registry_cleared": 0,
            "tool_registry_cleared": 0,
            "error": "cache_lock_timeout"
        }

    try:
        # RACE CONDITION FIX: Use timeout for registry lock acquisition
        registry_acquired = _registry_lock.acquire(timeout=_LOCK_TIMEOUT)
        if not registry_acquired:
            # If registry lock can't be acquired, clear only caches
            source_cache_size = len(_function_source_cache)
            math_cache_size = len(_math_detection_cache)
            secure_math_cache_size = len(_math_detection_secure_cache)

            _function_source_cache.clear()
            _math_detection_cache.clear()
            _math_detection_secure_cache.clear()  # Clear secure cache too

            return {
                "source_cache_cleared": source_cache_size,
                "math_detection_cache_cleared": math_cache_size,
                "secure_math_cache_cleared": secure_math_cache_size,
                "enhanced_registry_cleared": 0,
                "tool_registry_cleared": 0,
                "error": "registry_lock_timeout"
            }

        try:
            source_cache_size = len(_function_source_cache)
            math_cache_size = len(_math_detection_cache)
            secure_math_cache_size = len(_math_detection_secure_cache)
            enhanced_registry_size = len(ENHANCED_TOOL_REGISTRY)
            tool_registry_size = len(TOOL_REGISTRY)

            # RACE CONDITION FIX: Clear caches safely with error handling
            try:
                _function_source_cache.clear()
            except Exception:
                pass  # Continue even if cache clear fails

            try:
                _math_detection_cache.clear()
            except Exception:
                pass  # Continue even if cache clear fails

            # SECURE: Clear secure cache with integrity validation
            try:
                _math_detection_secure_cache.clear()
            except Exception:
                pass  # Continue even if secure cache clear fails

            try:
                ENHANCED_TOOL_REGISTRY.clear()
            except Exception:
                pass  # Continue even if registry clear fails

            try:
                TOOL_REGISTRY.clear()
            except Exception:
                pass  # Continue even if registry clear fails

            return {
                "source_cache_cleared": source_cache_size,
                "math_detection_cache_cleared": math_cache_size,
                "secure_math_cache_cleared": secure_math_cache_size,
                "enhanced_registry_cleared": enhanced_registry_size,
                "tool_registry_cleared": tool_registry_size
            }

        finally:
            # Always release registry lock if we acquired it
            _registry_lock.release()

    finally:
        # Always release cache lock if we acquired it
        _cache_lock.release()

# --- Enhanced Tool Registry ---

# Enhanced registry storing functions with rich metadata
ENHANCED_TOOL_REGISTRY: List[Dict[str, Any]] = []

# Legacy registry for backward compatibility
TOOL_REGISTRY: List[Callable[..., Any]] = []


@dataclass
class ToolMetadata:
    """Enhanced metadata for tool specifications."""

    confidence_documentation: Optional[str] = None
    mathematical_basis: Optional[str] = None
    platform_notes: Optional[Dict[str, str]] = field(default_factory = dict)
    is_mathematical_reasoning: bool = False
    confidence_formula: Optional[str] = None
    confidence_factors: Optional[List[str]] = field(default_factory = list)


def _get_mathematical_indicators() -> List[str]:
    """
    Get the list of mathematical reasoning indicators.

    Returns:
        List[str]: List of mathematical reasoning keywords
    """
    return [
        "confidence",
        "probability",
        "statistical",
        "variance",
        "coefficient_of_variation",
        "geometric",
        "arithmetic",
        "progression",
        "pattern",
        "deductive",
        "inductive",
        "modus ponens",
        "modus_ponens",
        "logical",
        "reasoning_chain",
    ]


def _has_mathematical_indicators_in_docs(
    func: Callable[..., Any],
    math_indicators: List[str]
) -> bool:
    """
    Fast initial check for mathematical indicators using only docstring and function name.

    Args:
        func: The function to check
        math_indicators: List of mathematical reasoning keywords

    Returns:
        bool: True if mathematical indicators found in docs/name
    """
    docstring = func.__doc__ or ""
    func_name = getattr(func, "__name__", "")

    return any(
        indicator in docstring.lower() or indicator in func_name.lower()
        for indicator in math_indicators
    )


def _extract_confidence_factors(source_code: str, docstring: str) -> List[str]:
    """
    Extract confidence calculation patterns from source code and docstring.

    Args:
        source_code: The function's source code
        docstring: The function's docstring

    Returns:
        List[str]: List of confidence factors found
    """
    confidence_factors = []

    # Pattern 1: Extract confidence factor variable names using lazy-loaded pattern
    factor_matches = _get_factor_pattern().findall(source_code)
    if factor_matches:
        confidence_factors.extend(
            [factor.replace("_", " ") for factor in factor_matches[:3]]
        )

    # Pattern 2: Extract meaningful descriptive comments using lazy-loaded pattern
    comment_matches = _get_comment_pattern().findall(source_code)
    if comment_matches:
        confidence_factors.extend(
            [match.strip().lower() for match in comment_matches[:2]]
        )

    # Pattern 3: Extract from evidence strings with confidence calculations using lazy-loaded pattern
    evidence_matches = _get_evidence_pattern().findall(source_code)
    if evidence_matches:
        confidence_factors.extend([match.strip() for match in evidence_matches[:1]])

    # Pattern 4: Look for factor multiplication combinations using lazy-loaded pattern
    combination_matches = _get_combination_pattern().findall(source_code)
    if combination_matches and not confidence_factors:
        # If we haven't found factors yet, use the combination pattern
        factor_names = []
        for match in combination_matches[:2]:
            factor_names.extend(
                [
                    factor.replace("_factor", "").replace("_", " ")
                    for factor in match
                ]
            )
        confidence_factors.extend(list(set(factor_names)))  # Remove duplicates

    # Pattern 5: Extract from docstring confidence patterns
    if "confidence" in docstring.lower() and "based on" in docstring.lower():
        # Look for specific patterns in docstring
        if "pattern quality" in docstring.lower():
            confidence_factors.extend(["pattern quality"])
        if "pattern" in docstring.lower() and not confidence_factors:
            confidence_factors.extend(["pattern analysis"])

    return confidence_factors


def _clean_confidence_factors(confidence_factors: List[str]) -> List[str]:
    """
    Clean and deduplicate confidence factors.

    Args:
        confidence_factors: Raw confidence factors

    Returns:
        List[str]: Cleaned and deduplicated factors
    """
    clean_factors = []
    seen = set()
    for factor in confidence_factors:
        clean_factor = factor.strip().lower()
        # Remove common code artifacts using lazy-loaded pattern
        clean_factor = _get_clean_factor_pattern().sub("", clean_factor).strip()
        if clean_factor and clean_factor not in seen and len(clean_factor) > 2:
            clean_factors.append(clean_factor)
            seen.add(clean_factor)

    return clean_factors


def _create_confidence_documentation(clean_factors: List[str]) -> Optional[str]:
    """
    Create confidence documentation from cleaned factors.

    Args:
        clean_factors: List of cleaned confidence factors

    Returns:
        Optional[str]: Formatted confidence documentation or None
    """
    if clean_factors:
        return f"Confidence calculation based on: {', '.join(clean_factors[:3])}"
    return None


def _extract_mathematical_basis(docstring: str) -> Optional[str]:
    """
    Extract mathematical basis from docstring.

    Args:
        docstring: The function's docstring

    Returns:
        Optional[str]: Mathematical basis description or None
    """
    docstring_lower = docstring.lower()

    if "arithmetic progression" in docstring_lower:
        return (
            "Arithmetic progression analysis with data sufficiency and "
            "pattern quality factors"
        )
    elif "geometric progression" in docstring_lower:
        return "Geometric progression analysis with ratio consistency validation"
    elif "modus ponens" in docstring_lower:
        return "Formal deductive logic using Modus Ponens inference rule"
    elif "chain of thought" in docstring_lower:
        return "Sequential reasoning with conservative confidence aggregation (minimum of step confidences)"

    return None


def _detect_mathematical_reasoning_uncached(
    func: Callable[..., Any],
) -> Tuple[bool, Optional[str], Optional[str]]:
    """
    Detect if a function performs mathematical reasoning and extract confidence documentation.

    Optimized to perform fast initial checks before expensive source code extraction.

    Returns:
        tuple: (is_mathematical, confidence_documentation, mathematical_basis)
    """
    # Get mathematical indicators
    math_indicators = _get_mathematical_indicators()

    # Fast initial check using only docstring and function name
    if not _has_mathematical_indicators_in_docs(func, math_indicators):
        return False, None, None

    # Only extract source code if initial check suggests mathematical reasoning
    source_code = _get_function_source_cached(func)
    docstring = func.__doc__ or ""

    # Final check including source code
    is_mathematical = any(
        indicator in source_code.lower() or indicator in docstring.lower()
        for indicator in math_indicators
    )

    if not is_mathematical:
        return False, None, None

    # Extract confidence factors and create documentation
    confidence_factors = _extract_confidence_factors(source_code, docstring)
    clean_factors = _clean_confidence_factors(confidence_factors)
    confidence_doc = _create_confidence_documentation(clean_factors)

    # Extract mathematical basis
    mathematical_basis = _extract_mathematical_basis(docstring)

    return is_mathematical, confidence_doc, mathematical_basis


def _detect_mathematical_reasoning(
    func: Callable[..., Any],
) -> Tuple[bool, Optional[str], Optional[str]]:
    """
    Detect if a function performs mathematical reasoning with performance optimization.

    This is the optimized version that uses caching to avoid repeated expensive operations.
    Provides significant performance improvement for repeated function analysis.

    Args:
        func: Function to analyze for mathematical reasoning patterns

    Returns:
        tuple: (is_mathematical, confidence_documentation, mathematical_basis)
    """
    return _get_math_detection_cached(func)


def _safe_copy_spec(tool_spec: Dict[str, Any]) -> Dict[str, Any]:
    """
    SECURE: Safely copy tool specification with input validation to prevent injection attacks.

    Prevents multiple injection vectors:
    - Prototype pollution through dangerous keys like __proto__
    - Code injection through malicious function names and descriptions
    - Template injection through parameter descriptions

    Args:
        tool_spec: Tool specification to copy

    Returns:
        Validated and safely copied tool specification

    Raises:
        ValidationError: If tool specification is invalid or missing required fields
    """
    if not isinstance(tool_spec, dict):
        raise ValidationError("Tool specification must be a dictionary")

    if "function" not in tool_spec:
        raise ValidationError("Tool specification must contain 'function' key")

    if not isinstance(tool_spec["function"], dict):
        raise ValidationError("Tool specification 'function' value must be a dictionary")

    # Use shared sanitization utility
    def sanitize_text_input(text: Any, max_length: int = KEYWORD_LENGTH_LIMIT * 20) -> str:
        """DEPRECATED: Use sanitize_for_display from .sanitization instead."""
        return sanitize_for_display(text, max_length)

    # Whitelist of allowed top - level keys to prevent prototype pollution
    allowed_top_level_keys = {"type", "function"}

    # Whitelist of allowed function keys
    allowed_function_keys = {"name", "description", "parameters"}

    # Blacklist of dangerous keys that could indicate prototype pollution
    dangerous_keys = {"__proto__", "constructor", "prototype", "prototypeof"}

    # Create safe copy with only whitelisted keys
    safe_spec = {}
    for key, value in tool_spec.items():
        # Skip dangerous keys that could cause prototype pollution
        if key in dangerous_keys:
            continue

        if key in allowed_top_level_keys:
            if key == "function":
                # Safely copy function object with whitelisted keys and sanitization
                safe_function = {}
                for func_key, func_value in value.items():
                    if func_key in allowed_function_keys:
                        # Sanitize all string values to prevent injection
                        if func_key == "name":
                            safe_function[func_key] = sanitize_text_input(func_value,
                                                                          max_length = KEYWORD_LENGTH_LIMIT)
                        elif func_key == "description":
                            safe_function[func_key] = sanitize_text_input(func_value,
                                                                          max_length = KEYWORD_LENGTH_LIMIT * 10)
                        elif func_key == "parameters" and isinstance(func_value, dict):
                            # Recursively sanitize parameter object
                            safe_function[func_key] = _sanitize_parameters(func_value)
                        else:
                            safe_function[func_key] = func_value
                safe_spec[key] = safe_function
            else:
                safe_spec[key] = sanitize_text_input(value, max_length = KEYWORD_LENGTH_LIMIT * 2)

    return safe_spec


def _sanitize_parameters(parameters: Dict[str, Any]) -> Dict[str, Any]:
    """SECURE: Recursively sanitize parameter objects to prevent injection."""
    if not isinstance(parameters, dict):
        return {}

    safe_params = {}

    # Process properties
    if "properties" in parameters and isinstance(parameters["properties"], dict):
        safe_params["properties"] = {}
        for param_name, param_spec in parameters["properties"].items():
            # Sanitize parameter name
            safe_name = re.sub(r'[^a - zA - Z0 - 9_]', '', str(param_name))[:KEYWORD_LENGTH_LIMIT]
            if not safe_name:
                safe_name = "param"

            # Sanitize parameter specification
            if isinstance(param_spec, dict):
                safe_spec = {}
                for spec_key, spec_value in param_spec.items():
                    if isinstance(spec_value, str):
                        safe_spec[spec_key] = re.sub(r'[<>"\'`{}]',
                                                     '', spec_value)[:COMPONENT_LENGTH_LIMIT * 4]
                    else:
                        safe_spec[spec_key] = spec_value
                safe_params["properties"][safe_name] = safe_spec

    # Copy other parameter fields safely
    for key, value in parameters.items():
        if key != "properties":
            if isinstance(value, str):
                safe_params[key] = re.sub(r'[<>"\'`{}]', '', value)[:COMPONENT_LENGTH_LIMIT * 2]
            elif isinstance(value, (list, tuple)):
                safe_params[key] = [str(item)[:KEYWORD_LENGTH_LIMIT] for item in value]
            else:
                safe_params[key] = value

    return safe_params


def _openai_format(tool_spec: Dict[str, Any]) -> Dict[str, Any]:
    """
    Convert tool specification to OpenAI ChatCompletions API format.

    Args:
        tool_spec: Standard tool specification

    Returns:
        OpenAI - compatible tool specification
    """
    # Use safe copy to prevent prototype pollution
    safe_spec = _safe_copy_spec(tool_spec)
    return {
        "type": "function",
        "function": {
            "name": safe_spec["function"]["name"],
            "description": safe_spec["function"]["description"],
            "parameters": safe_spec["function"]["parameters"],
        },
    }


def _bedrock_format(tool_spec: Dict[str, Any]) -> Dict[str, Any]:
    """
    Convert tool specification to AWS Bedrock Converse API format.

    Args:
        tool_spec: Standard tool specification

    Returns:
        Bedrock - compatible tool specification
    """
    # Use safe copy to prevent prototype pollution
    safe_spec = _safe_copy_spec(tool_spec)
    return {
        "toolSpec": {
            "name": safe_spec["function"]["name"],
            "description": safe_spec["function"]["description"],
            "inputSchema": {"json": safe_spec["function"]["parameters"]},
        }
    }


def _enhance_description_with_confidence_docs(
    description: str, metadata: ToolMetadata
) -> str:
    """
    SECURE: Enhance tool description with confidence documentation for mathematical reasoning functions.

    Sanitizes all metadata to prevent injection attacks before inclusion in descriptions.

    Args:
        description: Original function description
        metadata: Tool metadata containing confidence information

    Returns:
        Enhanced description with sanitized confidence documentation
    """
    if not metadata.is_mathematical_reasoning:
        return description

    # Avoid duplicate enhancement by checking if already enhanced
    if "Mathematical Basis:" in description:
        return description

    def sanitize_confidence_text(text: Any) -> str:
        """SECURE: Sanitize confidence - related text to prevent injection."""
        if not isinstance(text, str):
            return ""

        # Remove dangerous characters that could be used for injection
        sanitized = re.sub(r'[<>"\'`]', '', text)  # Remove HTML / JS injection characters
        sanitized = re.sub(r'[{}]',
                           '', sanitized)  # Remove template injection characters
        sanitized = re.sub(r'\${[^}]*}', '', sanitized)  # Remove ${...} patterns
        sanitized = re.sub(r'%[sd]', '', sanitized)      # Remove %s, %d patterns
        sanitized = re.sub(r'__import__\s*\(',
                           'BLOCKED', sanitized)  # Block import attempts
        sanitized = re.sub(r'eval\s*\(',
                           'BLOCKED', sanitized)      # Block eval attempts
        sanitized = re.sub(r'exec\s*\(',
                           'BLOCKED', sanitized)      # Block exec attempts

        # Remove control characters that could poison logs
        sanitized = re.sub(r'[\r\n\t]', ' ', sanitized)

        return sanitized.strip()

    # Sanitize original description
    enhanced_desc = sanitize_confidence_text(description)

    # Sanitize mathematical basis
    if metadata.mathematical_basis:
        safe_basis = sanitize_confidence_text(metadata.mathematical_basis)
        enhanced_desc += f"\n\nMathematical Basis: {safe_basis}"

    # Generate confidence documentation from explicit factors if available
    if metadata.confidence_factors:
        # Sanitize each confidence factor
        safe_factors = [sanitize_confidence_text(factor) for factor in metadata.confidence_factors if factor]
        safe_factors = [factor for factor in safe_factors if factor]  # Remove empty strings
        if safe_factors:
            enhanced_desc += f"\n\nConfidence Scoring: Confidence calculation based on: {', '.join(safe_factors[:MAX_TEMPLATE_KEYWORDS])}"
    elif metadata.confidence_documentation:
        # Fallback to existing documentation if factors are not provided
        safe_doc = sanitize_confidence_text(metadata.confidence_documentation)
        enhanced_desc += f"\n\nConfidence Scoring: {safe_doc}"

    # Sanitize confidence formula
    if metadata.confidence_formula:
        safe_formula = sanitize_confidence_text(metadata.confidence_formula)
        enhanced_desc += f"\n\nConfidence Formula: {safe_formula}"

    return enhanced_desc


def get_tool_specs() -> List[Dict[str, Any]]:
    """
    Returns a list of all registered tool specifications (legacy format).

    Thread - safe: Uses _registry_lock to prevent race conditions during iteration.
    """
    with _registry_lock:
        tool_specs = []
        for func in TOOL_REGISTRY.copy():
            if hasattr(func, "tool_spec"):
                tool_spec = getattr(func, "tool_spec", {})
                # Only include non-None, non-empty tool_specs
                if tool_spec:
                    tool_specs.append(tool_spec)
        return tool_specs


def get_openai_tools() -> List[Dict[str, Any]]:
    """
    Export tool specifications in OpenAI ChatCompletions API format.

    Thread - safe: Uses _registry_lock to prevent race conditions during iteration.

    Returns:
        List of OpenAI - compatible tool specifications
    """
    with _registry_lock:
        openai_tools = []
        for entry in ENHANCED_TOOL_REGISTRY.copy():
            # Create enhanced description using safe copy
            enhanced_spec = _safe_copy_spec(entry["tool_spec"])
            enhanced_spec["function"]["description"] = (
                _enhance_description_with_confidence_docs(
                    enhanced_spec["function"]["description"], entry["metadata"]
                )
            )
            openai_tools.append(_openai_format(enhanced_spec))
        return openai_tools


def get_bedrock_tools() -> List[Dict[str, Any]]:
    """
    Export tool specifications in AWS Bedrock Converse API format.

    Thread - safe: Uses _registry_lock to prevent race conditions during iteration.

    Returns:
        List of Bedrock - compatible tool specifications
    """
    with _registry_lock:
        bedrock_tools = []
        for entry in ENHANCED_TOOL_REGISTRY.copy():
            # Create enhanced description using safe copy
            enhanced_spec = _safe_copy_spec(entry["tool_spec"])
            enhanced_spec["function"]["description"] = (
                _enhance_description_with_confidence_docs(
                    enhanced_spec["function"]["description"], entry["metadata"]
                )
            )
            bedrock_tools.append(_bedrock_format(enhanced_spec))
        return bedrock_tools


def get_enhanced_tool_registry() -> List[Dict[str, Any]]:
    """
    Get the complete enhanced tool registry with metadata.

    Thread - safe: Uses _registry_lock to prevent race conditions during access.

    Returns:
        List of enhanced tool registry entries
    """
    with _registry_lock:
        return ENHANCED_TOOL_REGISTRY.copy()


# --- End Enhanced Tool Registry ---


def curry(func: Callable[..., Any]) -> Callable[..., Any]:
    """
    A currying decorator for functions that properly handles required vs optional parameters.
    Allows functions to be called with fewer arguments than they expect,
    returning a new function that takes the remaining arguments.
    """
    sig = inspect.signature(func)

    @wraps(func)

    def curried(*args: Any, **kwargs: Any) -> Any:
        try:
            # Try to bind the arguments - this will fail if we don't have enough required args
            bound_args = sig.bind(*args, **kwargs)
            bound_args.apply_defaults()
        except TypeError:
            # If binding fails (insufficient args), return a curried function
            return lambda *args2, **kwargs2: curried(
                *(args + args2), **(kwargs | kwargs2)
            )

        # If we get here, we have all required arguments - execute the function
        # Any TypeError from the function execution should be propagated, not caught
        return func(*args, **kwargs)

    return curried


@dataclass
class ReasoningStep:
    """
    Represents a single step in a reasoning chain, including its result and metadata.
    """

    step_number: int
    stage: str
    description: str
    result: Any
    confidence: Optional[float] = None
    evidence: Optional[str] = None
    assumptions: Optional[List[str]] = field(default_factory = list)
    metadata: Optional[Dict[str, Any]] = field(default_factory = dict)


@dataclass
class ReasoningChain:
    """
    Manages a sequence of ReasoningStep objects, providing chain - of - thought capabilities.
    """

    steps: List[ReasoningStep] = field(default_factory = list)
    _step_counter: int = field(init = False, default = 0)

    def add_step(
        self,
        stage: str,
        description: str,
        result: Any,
        confidence: Optional[float] = None,
        evidence: Optional[str] = None,
        assumptions: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> ReasoningStep:
        """
        Adds a new reasoning step to the chain.
        """
        self._step_counter += 1

        # Standardize optional parameters using null handling utilities
        # Note: evidence is handled separately to preserve None values for test expectations
        normalized_params = handle_optional_params(
            assumptions=assumptions,
            metadata=metadata
        )

        step = ReasoningStep(
            step_number = self._step_counter,
            stage = stage,
            description = description,
            result = result,
            confidence = confidence,
            evidence = evidence,  # Preserve None values as per test expectations
            assumptions = normalized_params.get('assumptions', []),
            metadata = normalized_params.get('metadata', {}),
        )
        self.steps.append(step)
        return step

    def _sanitize_reasoning_input(self, text: Any) -> str:
        """
        SECURE: Sanitize reasoning input to prevent log injection attacks.

        Args:
            text: Input text to sanitize

        Returns:
            Sanitized text safe for logging
        """
        if not isinstance(text, str):
            return str(text)

        # Use the existing sanitize_text_input function (defined in _safe_copy_spec context)

        def sanitize_text_input_for_reasoning(text: Any, max_length: int = 1000) -> str:
            """SECURE: Sanitize text inputs to prevent injection attacks."""
            if not isinstance(text, str):
                return ""

            # Truncate to reasonable length
            text = text[:max_length]

            # Remove dangerous characters that could be used for injection
            sanitized = re.sub(r'[<>"\'`]',
                               '', text)  # Remove HTML / JS injection characters
            sanitized = re.sub(r'[{}]',
                               '', sanitized)  # Remove template injection characters
            sanitized = re.sub(r'\${[^}]*}', '', sanitized)  # Remove ${...} patterns
            sanitized = re.sub(r'%[sd]', '', sanitized)      # Remove %s, %d patterns
            sanitized = re.sub(r'__import__\s*\(',
                               'BLOCKED', sanitized)  # Block import attempts
            sanitized = re.sub(r'eval\s*\(',
                               'BLOCKED', sanitized)      # Block eval attempts
            sanitized = re.sub(r'exec\s*\(',
                               'BLOCKED', sanitized)      # Block exec attempts

            # CRITICAL FIX: Remove log injection patterns that could poison logs
            # Block common log level patterns that could be used for log injection
            sanitized = re.sub(r'\[(ERROR|CRITICAL|WARN|WARNING|INFO|DEBUG|TRACE|FATAL)\]', '[LOG_LEVEL_BLOCKED]', sanitized)

            # Remove newlines and other control characters that could poison logs
            # CRITICAL FIX: Prevent log injection by normalizing newlines and control chars
            sanitized = re.sub(r'[\r\n\t]',
                               ' ', sanitized)  # Convert newlines / tabs to spaces
            sanitized = re.sub(r'\s+', ' ', sanitized)       # Normalize multiple spaces

            # Remove potential ANSI escape sequences that could poison terminal logs
            sanitized = re.sub(r'\x1b\[[0-9;]*m',
                               '', sanitized)  # Remove ANSI color codes

            return sanitized.strip()

        return sanitize_text_input_for_reasoning(text, max_length = 200)

    def get_summary(self) -> str:
        """
        SECURE: Generates a summary of the reasoning chain with log injection prevention.

        All user input is sanitized to prevent log poisoning attacks.
        """
        summary_parts = ["Reasoning Chain Summary:"]
        for step in self.steps:
            # Sanitize all user - provided input to prevent log injection
            safe_stage = self._sanitize_reasoning_input(step.stage)
            safe_description = self._sanitize_reasoning_input(step.description)
            safe_result = self._sanitize_reasoning_input(step.result)
            safe_evidence = self._sanitize_reasoning_input(step.evidence) if step.evidence else ""
            safe_assumptions = [self._sanitize_reasoning_input(assumption) for assumption in step.assumptions] if step.assumptions else []
            safe_metadata = str(step.metadata) if step.metadata else ""

            summary_parts.append(
                f"  Step {step.step_number} ({safe_stage}): {safe_description}"
            )
            summary_parts.append(f"    Result: {safe_result}")
            if step.confidence is not None:
                summary_parts.append(f"    Confidence: {step.confidence:.2f}")
            if safe_evidence:
                summary_parts.append(f"    Evidence: {safe_evidence}")
            if safe_assumptions:
                summary_parts.append(f"    Assumptions: {', '.join(safe_assumptions)}")
            if safe_metadata:
                summary_parts.append(f"    Metadata: {safe_metadata}")
        return "\n".join(summary_parts)

    def clear(self) -> None:
        """
        Clears all steps from the reasoning chain.
        """
        self.steps = []
        self._step_counter = 0

    @property
    def last_result(self) -> Any:
        """
        Returns the result of the last step in the chain, or None if the chain is empty.
        """
        return self.steps[-1].result if self.steps else None


# --- Tool Specification Utility ---

TYPE_MAP = {
    bool: "boolean",
    int: "integer",
    float: "number",
    str: "string",
    list: "array",
    dict: "object",
    Any: "object",  # Default for Any
}


def get_json_schema_type(py_type: Any) -> str:
    """
    Converts a Python type hint to a JSON Schema type string.
    Handles Optional and List types.
    """
    if hasattr(py_type, "__origin__"):
        if py_type.__origin__ is Union:  # Union types (including Optional)
            # Check if this is Optional[X] (Union[X, None])
            args = py_type.__args__
            if len(args) == 2 and type(None) in args:
                # This is Optional[X] - get the non - None type
                actual_type = args[0] if args[1] is type(None) else args[1]
                return get_json_schema_type(actual_type)
            # For other Union types, default to string
            return "string"
        elif py_type.__origin__ is list:  # List[X]
            return "array"
        elif py_type.__origin__ is dict:  # Dict[K, V]
            return "object"

    return TYPE_MAP.get(py_type, "string")  # Default to string if not found


def tool_spec(
    func: Optional[Callable[..., Any]] = None,
    *,
    mathematical_basis: Optional[str] = None,
    confidence_factors: Optional[List[str]] = None,
    confidence_formula: Optional[str] = None,
) -> Callable[[Callable[..., Any]], Callable[..., Any]]:
    """
    Enhanced decorator to attach a JSON Schema tool specification to a function.
    The spec is derived from the function's signature and docstring.

    This decorator supports a hybrid model for metadata:
    1.  **Explicit Declaration (Preferred):** Pass metadata directly as arguments
        (e.g., `mathematical_basis`, `confidence_factors`).
    2.  **Heuristic Fallback:** If no explicit arguments are provided, it falls back
        to `_detect_mathematical_reasoning` to infer metadata for backward compatibility.
    """

    def decorator(fn: Callable[..., Any]) -> Callable[..., Any]:
        @wraps(fn)

        def wrapper(*args: Any, **kwargs: Any) -> Any:
            return fn(*args, **kwargs)

        signature = inspect.signature(fn)
        parameters = {}
        required_params = []

        for name, param in signature.parameters.items():
            if name == "reasoning_chain":  # Exclude from tool spec
                continue

            param_type = (
                param.annotation
                if param.annotation is not inspect.Parameter.empty
                else Any
            )
            json_type = get_json_schema_type(param_type)

            param_info: Dict[str, Any] = {"type": json_type}
            if hasattr(param_type, "__origin__") and param_type.__origin__ is list:
                if hasattr(param_type, "__args__") and param_type.__args__:
                    param_info["items"] = {
                        "type": get_json_schema_type(param_type.__args__[0])
                    }

            parameters[name] = param_info

            if param.default is inspect.Parameter.empty:
                required_params.append(name)

        tool_specification = {
            "type": "function",
            "function": {
                "name": fn.__name__,
                "description": fn.__doc__.strip() if fn.__doc__ else "",
                "parameters": {
                    "type": "object",
                    "properties": parameters,
                    "required": required_params,
                },
            },
        }

        # Hybrid model: Prioritize explicit declaration, then fall back to heuristic detection
        is_mathematical = False
        confidence_doc = None
        # Initialize with explicit parameter or None
        final_mathematical_basis = mathematical_basis

        if confidence_factors:
            confidence_doc = (
                f"Confidence calculation based on: {', '.join(confidence_factors)}"
            )
            is_mathematical = True

        # If mathematical_basis is explicitly provided, this is mathematical reasoning
        if mathematical_basis:
            is_mathematical = True

        # Fallback to heuristic detection if explicit metadata is not provided
        if not is_mathematical and not final_mathematical_basis:
            (
                is_mathematical_heuristic,
                confidence_doc_heuristic,
                mathematical_basis_heuristic,
            ) = _detect_mathematical_reasoning(fn)
            if is_mathematical_heuristic:
                is_mathematical = True
                if not confidence_doc:
                    confidence_doc = confidence_doc_heuristic
                if not final_mathematical_basis:
                    final_mathematical_basis = mathematical_basis_heuristic

        metadata = ToolMetadata(
            confidence_documentation = confidence_doc,
            mathematical_basis = final_mathematical_basis,
            is_mathematical_reasoning = is_mathematical,
            confidence_formula = confidence_formula,
            confidence_factors = confidence_factors,
            platform_notes={},
        )

        # Thread - safe atomic registry updates with size management
        with _registry_lock:
            # PERFORMANCE OPTIMIZATION: Update enhanced registry and tracking queue
            registry_entry = {"function": wrapper, "tool_spec": tool_specification, "metadata": metadata}
            ENHANCED_TOOL_REGISTRY.append(registry_entry)
            _enhanced_registry_queue.append(registry_entry)

            setattr(wrapper, "tool_spec", tool_specification)
            TOOL_REGISTRY.append(wrapper)
            _tool_registry_queue.append(wrapper)

            # Manage registry size AFTER adding entries to prevent race conditions
            _manage_registry_size()

        return wrapper

    if func:
        return decorator(func)
    return decorator


def __getattr__(name: str) -> re.Pattern:
    """
    Module-level lazy loading for regex patterns with backward compatibility.

    Provides backward compatibility for FACTOR_PATTERN, COMMENT_PATTERN, etc.
    while enabling lazy compilation for performance optimization.

    This function is called when accessing attributes that don't exist on the module.
    It enables lazy loading of regex patterns while maintaining the expected API.

    Args:
        name: Attribute name being accessed

    Returns:
        Compiled regex pattern for backward compatibility

    Raises:
        AttributeError: If name is not a recognized lazy-loaded pattern

    Examples:
        >>> import reasoning_library.core as core
        >>> pattern = core.FACTOR_PATTERN  # Triggers lazy compilation
        >>> isinstance(pattern, re.Pattern)  # True
    """
    pattern_getters = {
        'FACTOR_PATTERN': _get_factor_pattern,
        'COMMENT_PATTERN': _get_comment_pattern,
        'EVIDENCE_PATTERN': _get_evidence_pattern,
        'COMBINATION_PATTERN': _get_combination_pattern,
        'CLEAN_FACTOR_PATTERN': _get_clean_factor_pattern,
    }

    if name in pattern_getters:
        return pattern_getters[name]()

    raise AttributeError(f"module '{__name__}' has no attribute '{name}'")
