#!/usr/bin/env python3
"""
CRITICAL SECURITY TEST - Race Condition Vulnerability Demonstration

This test demonstrates CRITICAL race condition vulnerabilities in the reasoning_library
that can cause data corruption, crashes, and inconsistent behavior in multi-threaded environments.

Vulnerabilities demonstrated:
1. Race conditions in _math_detection_cache access/eviction
2. Concurrent access to _function_source_cache without synchronization
3. Registry read/write race conditions causing data corruption
4. Cache corruption through un-synchronized size management

Expected: Test should FAIL due to race conditions causing inconsistent/corrupted results
"""

import threading
import time
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List

# Import the vulnerable code
from reasoning_library.core import (
    _MAX_CACHE_SIZE,
    _MAX_REGISTRY_SIZE,
    ENHANCED_TOOL_REGISTRY,
    TOOL_REGISTRY,
    _function_source_cache,
    _get_function_source_cached,
    _get_math_detection_cached,
    _math_detection_cache,
    _registry_lock,
    clear_performance_caches,
    tool_spec,
)


def create_test_function(name_suffix: str) -> callable:
    """Create a unique test function for cache testing."""

    def test_function():
        return f"test_result_{name_suffix}"

    test_function.__name__ = f"test_function_{name_suffix}"
    test_function.__doc__ = f"""
    Test function {name_suffix} for confidence calculation based on pattern quality analysis.

    This function performs pattern quality factor analysis with confidence scoring.
    Mathematical reasoning: pattern recognition with data sufficiency validation.
    """

    return test_function


class RaceConditionDetector:
    """Detects race conditions through concurrent execution validation."""

    def __init__(self):
        self.errors: List[str] = []
        self.inconsistencies: List[str] = []
        self.data_corruption_events: List[str] = []
        self.lock = threading.Lock()

    def add_error(self, error: str):
        with self.lock:
            self.errors.append(error)
            print(f"‚ùå RACE CONDITION DETECTED: {error}")

    def add_inconsistency(self, inconsistency: str):
        with self.lock:
            self.inconsistencies.append(inconsistency)
            print(f"‚ö†Ô∏è INCONSISTENCY: {inconsistency}")

    def add_corruption_event(self, corruption: str):
        with self.lock:
            self.data_corruption_events.append(corruption)
            print(f"üö® DATA CORRUPTION: {corruption}")


def test_math_detection_cache_race_conditions():
    """
    CRITICAL RACE CONDITION TEST: _math_detection_cache concurrent access
    Multiple threads accessing cache simultaneously can cause corruption.
    """
    print("\nüîç Testing _math_detection_cache race conditions...")
    detector = RaceConditionDetector()

    # Clear cache to start clean
    with _registry_lock:
        _math_detection_cache.clear()

    # Create unique functions for cache testing
    test_functions = [create_test_function(f"math_test_{i}") for i in range(50)]

    def worker_function(func_idx: int) -> Dict[str, Any]:
        """Worker that accesses cache concurrently."""
        func = test_functions[func_idx]
        results = []
        errors = []

        try:
            for iteration in range(20):
                # Access cache concurrently - this should cause race conditions
                result = _get_math_detection_cached(func)
                results.append(result)

                # Simulate some processing time to increase race condition probability
                time.sleep(0.001)

                # Multiple accesses to same function to trigger race conditions
                result2 = _get_math_detection_cached(func)
                if result != result2:
                    detector.add_inconsistency(
                        f"Math detection cache returned different results for same function: "
                        f"func_{func_idx}_iter_{iteration}: {result} vs {result2}"
                    )

                # Check cache integrity during concurrent access
                with _registry_lock:
                    cache_size = len(_math_detection_cache)
                    if cache_size < 0 or cache_size > _MAX_CACHE_SIZE * 2:  # Should never exceed limit significantly
                        detector.add_corruption_event(
                            f"Math detection cache corrupted: invalid size {cache_size} (func_{func_idx})"
                        )

        except Exception as e:
            errors.append(f"Worker exception: {type(e).__name__}: {e}")
            detector.add_error(f"Math detection cache worker crashed: {type(e).__name__}: {e}")

        return {
            "func_idx": func_idx,
            "results": results,
            "errors": errors,
            "cache_hits": len(results)
        }

    # Execute with high concurrency to trigger race conditions
    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = [executor.submit(worker_function, i) for i in range(50)]

        for future in as_completed(futures):
            try:
                future.result(timeout=30)
            except Exception as e:
                detector.add_error(f"Math detection test execution failed: {type(e).__name__}: {e}")

    # Verify cache integrity after concurrent access
    with _registry_lock:
        final_cache_size = len(_math_detection_cache)

        # Check for cache corruption
        if final_cache_size < 0 or final_cache_size > _MAX_CACHE_SIZE * 2:
            detector.add_corruption_event(f"Math detection cache corrupted: final size {final_cache_size}")

        # Check for duplicate keys (should not happen with function ids)
        func_ids = list(_math_detection_cache.keys())
        if len(func_ids) != len(set(func_ids)):
            detector.add_corruption_event("Math detection cache has duplicate function IDs")

    print(f"  ‚úÖ Math detection cache test completed. Errors: {len(detector.errors)}")
    return detector


def test_function_source_cache_race_conditions():
    """
    CRITICAL RACE CONDITION TEST: _function_source_cache concurrent access
    WeakKeyDictionary concurrent access without synchronization.
    """
    print("\nüîç Testing _function_source_cache race conditions...")
    detector = RaceConditionDetector()

    # Clear cache to start clean
    _function_source_cache.clear()

    def source_cache_worker(worker_id: int) -> Dict[str, Any]:
        """Worker accessing function source cache concurrently."""
        test_funcs = [create_test_function(f"source_worker_{worker_id}_{i}") for i in range(10)]

        try:
            for iteration in range(15):
                for func_idx, func in enumerate(test_funcs):
                    # Concurrent access to WeakKeyDictionary - RACE CONDITION
                    source = _get_function_source_cached(func)

                    # Verify source consistency
                    source2 = _get_function_source_cached(func)
                    if source != source2:
                        detector.add_inconsistency(
                            f"Source cache inconsistency: worker_{worker_id}_func_{func_idx}_iter_{iteration}"
                        )

                    # Check for cache corruption
                    try:
                        cache_size = len(_function_source_cache)
                        if cache_size < 0:
                            detector.add_corruption_event(f"Source cache negative size: {cache_size}")
                    except Exception as e:
                        detector.add_error(f"Source cache size check failed: {e}")

                    time.sleep(0.001)

        except Exception as e:
            detector.add_error(f"Source cache worker {worker_id} crashed: {type(e).__name__}: {e}")

        return {"worker_id": worker_id}

    # High concurrency to trigger WeakKeyDictionary race conditions
    with ThreadPoolExecutor(max_workers=15) as executor:
        futures = [executor.submit(source_cache_worker, i) for i in range(15)]

        for future in as_completed(futures):
            try:
                future.result(timeout=30)
            except Exception as e:
                detector.add_error(f"Source cache test execution failed: {e}")

    print(f"  ‚úÖ Function source cache test completed. Errors: {len(detector.errors)}")
    return detector


def test_registry_concurrent_access_corruption():
    """
    CRITICAL RACE CONDITION TEST: Registry concurrent read/write corruption
    Reading registries while writes are happening can return corrupted data.
    """
    print("\nüîç Testing registry concurrent access corruption...")
    detector = RaceConditionDetector()

    # Clear registries
    with _registry_lock:
        ENHANCED_TOOL_REGISTRY.clear()
        TOOL_REGISTRY.clear()

    @tool_spec
    def registry_test_function(data: str) -> str:
        """Test function for registry corruption testing."""
        return f"processed: {data}"

    def registry_writer_thread(thread_id: int) -> Dict[str, Any]:
        """Thread that writes to registry concurrently."""
        writes_completed = 0
        errors = []

        try:
            for i in range(25):
                @tool_spec
                def concurrent_func(x: int) -> int:
                    """Concurrent function for testing."""
                    return x * 2

                # This creates race condition with registry size management
                writes_completed += 1
                time.sleep(0.002)

        except Exception as e:
            errors.append(f"Writer thread {thread_id} error: {e}")
            detector.add_error(f"Registry writer thread {thread_id} crashed: {e}")

        return {
            "thread_id": thread_id,
            "writes": writes_completed,
            "errors": errors
        }

    def registry_reader_thread(thread_id: int) -> Dict[str, Any]:
        """Thread that reads from registry concurrently."""
        reads_completed = 0
        inconsistencies = []
        errors = []

        try:
            for i in range(100):
                # Concurrent reads without proper locking - RACE CONDITION
                try:
                    enhanced_size = len(ENHANCED_TOOL_REGISTRY)
                    tool_size = len(TOOL_REGISTRY)

                    # Check for inconsistent registry sizes
                    if enhanced_size != tool_size and abs(enhanced_size - tool_size) > 5:
                        inconsistencies.append(
                            f"Registry size mismatch: enhanced={enhanced_size}, tool={tool_size} (iteration {i})"
                        )
                        detector.add_inconsistency(
                            f"Registry size inconsistency detected by reader {thread_id}: "
                            f"enhanced={enhanced_size}, tool={tool_size}"
                        )

                    # Try to iterate over registry (can crash if being modified)
                    try:
                        enhanced_entries = ENHANCED_TOOL_REGISTRY.copy()
                        tool_entries = TOOL_REGISTRY.copy()

                        # Check for corrupted entries
                        if enhanced_entries and len(enhanced_entries) > 0:
                            for entry in enhanced_entries[:min(5, len(enhanced_entries))]:
                                if not isinstance(entry, dict):
                                    detector.add_corruption_event(f"Corrupted enhanced registry entry: {type(entry)}")

                    except Exception as e:
                        detector.add_error(f"Registry iteration crash: {e}")

                    reads_completed += 1

                except Exception as e:
                    errors.append(f"Reader iteration {i} error: {e}")
                    detector.add_error(f"Registry reader {thread_id} iteration {i} failed: {e}")

                time.sleep(0.001)

        except Exception as e:
            errors.append(f"Reader thread {thread_id} crashed: {e}")
            detector.add_error(f"Registry reader thread {thread_id} crashed: {e}")

        return {
            "thread_id": thread_id,
            "reads": reads_completed,
            "inconsistencies": inconsistencies,
            "errors": errors
        }

    # Execute concurrent readers and writers to trigger race conditions
    with ThreadPoolExecutor(max_workers=12) as executor:
        # Start writer threads
        writer_futures = [executor.submit(registry_writer_thread, i) for i in range(4)]
        time.sleep(0.1)  # Let writers start

        # Start reader threads
        reader_futures = [executor.submit(registry_reader_thread, i) for i in range(8)]

        # Wait for all to complete
        all_futures = writer_futures + reader_futures
        for future in as_completed(all_futures):
            try:
                future.result(timeout=30)
            except Exception as e:
                detector.add_error(f"Registry concurrent test execution failed: {e}")

    # Final registry integrity check
    with _registry_lock:
        final_enhanced_size = len(ENHANCED_TOOL_REGISTRY)
        final_tool_size = len(TOOL_REGISTRY)

        if final_enhanced_size != final_tool_size:
            detector.add_inconsistency(f"Final registry size mismatch: enhanced={final_enhanced_size}, tool={final_tool_size}")

        if final_enhanced_size > _MAX_REGISTRY_SIZE * 2 or final_tool_size > _MAX_REGISTRY_SIZE * 2:
            detector.add_corruption_event(f"Registry exceeded size limits: enhanced={final_enhanced_size}, tool={final_tool_size}")

    print(f"  ‚úÖ Registry concurrent access test completed. Errors: {len(detector.errors)}")
    return detector


def test_cache_eviction_race_conditions():
    """
    CRITICAL RACE CONDITION TEST: Cache eviction logic corruption
    Cache eviction can corrupt data structures when executed concurrently.
    """
    print("\nüîç Testing cache eviction race conditions...")
    detector = RaceConditionDetector()

    # Clear caches and fill to near eviction threshold
    clear_performance_caches()

    # Fill cache to trigger eviction scenarios
    with _registry_lock:
        for i in range(_MAX_CACHE_SIZE - 10):
            func = create_test_function(f"eviction_test_{i}")
            _math_detection_cache[id(func)] = (True, f"confidence_doc_{i}", f"math_basis_{i}")

    def eviction_worker(worker_id: int) -> Dict[str, Any]:
        """Worker that triggers cache eviction concurrently."""
        cache_corruption_detected = False

        try:
            for i in range(50):
                func = create_test_function(f"eviction_worker_{worker_id}_{i}")

                # This should trigger eviction logic with race conditions
                result = _get_math_detection_cached(func)

                # Check cache integrity after eviction
                try:
                    with _registry_lock:
                        cache_size = len(_math_detection_cache)

                        # Cache should never exceed reasonable bounds
                        if cache_size > _MAX_CACHE_SIZE * 1.5:  # Allow some overshoot during eviction
                            detector.add_corruption_event(f"Cache eviction corruption: size {cache_size} (worker {worker_id})")
                            cache_corruption_detected = True

                        # Check for negative size (sign of corruption)
                        if cache_size < 0:
                            detector.add_corruption_event(f"Cache negative size: {cache_size} (worker {worker_id})")
                            cache_corruption_detected = True

                except Exception as e:
                    detector.add_error(f"Cache integrity check failed: {e}")

                time.sleep(0.001)

        except Exception as e:
            detector.add_error(f"Eviction worker {worker_id} crashed: {e}")

        return {
            "worker_id": worker_id,
            "corruption_detected": cache_corruption_detected
        }

    # Run many eviction workers concurrently
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(eviction_worker, i) for i in range(10)]

        for future in as_completed(futures):
            try:
                future.result(timeout=30)
            except Exception as e:
                detector.add_error(f"Cache eviction test execution failed: {e}")

    print(f"  ‚úÖ Cache eviction race condition test completed. Errors: {len(detector.errors)}")
    return detector


def main():
    """
    Execute CRITICAL race condition vulnerability tests.

    This test demonstrates that the reasoning_library has CRITICAL race condition
    vulnerabilities that can cause data corruption, crashes, and inconsistent behavior.

    Expected: Tests should FAIL due to race conditions being detected.
    """
    print("=" * 80)
    print("üö® CRITICAL SECURITY TEST: RACE CONDITION VULNERABILITIES üö®")
    print("=" * 80)
    print("This test demonstrates race condition vulnerabilities that can cause:")
    print("  ‚Ä¢ Data corruption in multi-threaded environments")
    print("  ‚Ä¢ Cache inconsistencies and invalid state")
    print("  ‚Ä¢ Registry corruption during concurrent access")
    print("  ‚Ä¢ Crashes due to unsynchronized data structure access")
    print("  ‚Ä¢ Memory corruption in WeakKeyDictionary operations")
    print("-" * 80)

    # Track all detected issues
    all_errors = []
    all_inconsistencies = []
    all_corruption_events = []

    try:
        # Test 1: Math detection cache race conditions
        detector1 = test_math_detection_cache_race_conditions()
        all_errors.extend(detector1.errors)
        all_inconsistencies.extend(detector1.inconsistencies)
        all_corruption_events.extend(detector1.data_corruption_events)

        # Test 2: Function source cache race conditions
        detector2 = test_function_source_cache_race_conditions()
        all_errors.extend(detector2.errors)
        all_inconsistencies.extend(detector2.inconsistencies)
        all_corruption_events.extend(detector2.data_corruption_events)

        # Test 3: Registry concurrent access corruption
        detector3 = test_registry_concurrent_access_corruption()
        all_errors.extend(detector3.errors)
        all_inconsistencies.extend(detector3.inconsistencies)
        all_corruption_events.extend(detector3.data_corruption_events)

        # Test 4: Cache eviction race conditions
        detector4 = test_cache_eviction_race_conditions()
        all_errors.extend(detector4.errors)
        all_inconsistencies.extend(detector4.inconsistencies)
        all_corruption_events.extend(detector4.data_corruption_events)

    except Exception as e:
        print(f"‚ùå CRITICAL: Test suite crashed with exception: {type(e).__name__}: {e}")
        traceback.print_exc()
        all_errors.append(f"Test suite crash: {type(e).__name__}: {e}")

    # Final vulnerability assessment
    print("\n" + "=" * 80)
    print("üö® RACE CONDITION VULNERABILITY ASSESSMENT üö®")
    print("=" * 80)

    total_issues = len(all_errors) + len(all_inconsistencies) + len(all_corruption_events)

    print(f"Total Race Conditions Detected: {total_issues}")
    print(f"  ‚Ä¢ Critical Errors: {len(all_errors)}")
    print(f"  ‚Ä¢ Data Inconsistencies: {len(all_inconsistencies)}")
    print(f"  ‚Ä¢ Corruption Events: {len(all_corruption_events)}")

    if all_errors:
        print("\n‚ùå CRITICAL ERRORS (Race Conditions Causing Crashes):")
        for i, error in enumerate(all_errors[:10]):  # Show first 10
            print(f"  {i+1}. {error}")
        if len(all_errors) > 10:
            print(f"  ... and {len(all_errors) - 10} more errors")

    if all_inconsistencies:
        print("\n‚ö†Ô∏è DATA INCONSISTENCIES (Race Conditions Causing Wrong Results):")
        for i, inconsistency in enumerate(all_inconsistencies[:10]):  # Show first 10
            print(f"  {i+1}. {inconsistency}")
        if len(all_inconsistencies) > 10:
            print(f"  ... and {len(all_inconsistencies) - 10} more inconsistencies")

    if all_corruption_events:
        print("\nüö® DATA CORRUPTION (Race Conditions Damaging System):")
        for i, corruption in enumerate(all_corruption_events[:10]):  # Show first 10
            print(f"  {i+1}. {corruption}")
        if len(all_corruption_events) > 10:
            print(f"  ... and {len(all_corruption_events) - 10} more corruption events")

    # CRITICAL: If we detected any race conditions, the test fails
    if total_issues > 0:
        print(f"\n‚ùå CRITICAL: {total_issues} race condition vulnerabilities detected!")
        print("‚ùå The reasoning_library is NOT thread-safe and will cause data corruption!")
        print("‚ùå This violates thread safety requirements and can crash applications.")

        print("\nüîß REQUIRED FIXES:")
        print("1. Add proper locking to _math_detection_cache access/eviction")
        print("2. Synchronize _function_source_cache WeakKeyDictionary operations")
        print("3. Add read-write locks for registry concurrent access")
        print("4. Implement atomic cache size management")
        print("5. Use thread-safe data structures or proper synchronization")

        return False
    else:
        print("\n‚úÖ No race conditions detected (unexpected - test should fail)")
        return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
