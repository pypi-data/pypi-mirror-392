#!/usr/bin/env python3
"""
HIGH-002 Race Condition Vulnerability Test for chain_of_thought.py

This test specifically targets the race condition vulnerability mentioned in HIGH-002
for conversation management in chain_of_thought.py lines 156-158.

The test should FAIL if race conditions exist and PASS after proper fixes are implemented.
"""

import os
import sys
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from reasoning_library.chain_of_thought import (
    _conversations,
    _conversations_lock,
    chain_of_thought_step,
    clear_chain,
    get_active_conversations,
    get_conversation_stats,
    get_chain_summary,
    _MAX_CONVERSATIONS,
)


class RaceConditionDetector:
    """Detects race conditions in conversation management."""

    def __init__(self):
        self.errors: List[str] = []
        self.inconsistencies: List[str] = []
        self.data_corruption: List[str] = []
        self.lock = threading.Lock()

    def add_error(self, error: str):
        with self.lock:
            self.errors.append(error)
            print(f"‚ùå RACE CONDITION ERROR: {error}")

    def add_inconsistency(self, inconsistency: str):
        with self.lock:
            self.inconsistencies.append(inconsistency)
            print(f"‚ö†Ô∏è INCONSISTENCY: {inconsistency}")

    def add_corruption(self, corruption: str):
        with self.lock:
            self.data_corruption.append(corruption)
            print(f"üö® DATA CORRUPTION: {corruption}")


def test_high_002_conversation_creation_race_condition():
    """
    HIGH-002: Test race condition in conversation creation/access patterns.

    This test specifically targets the vulnerability around lines 156-158 where
    multiple threads try to create/access conversations simultaneously.
    """
    print("\nüîç Testing HIGH-002: Race condition in conversation management...")
    detector = RaceConditionDetector()

    # Clear all conversations to start fresh
    with _conversations_lock:
        _conversations.clear()

    # Shared conversation ID to trigger race condition
    shared_conversation_id = "race_condition_test_conv"

    def concurrent_step_worker(worker_id: int) -> Dict[str, Any]:
        """Worker that adds steps to the same conversation concurrently."""
        steps_added = []
        errors = []

        try:
            for step_num in range(10):
                # Multiple threads adding steps to same conversation - should trigger race condition
                result = chain_of_thought_step(
                    conversation_id=shared_conversation_id,
                    stage=f"Stage_{worker_id}_{step_num}",
                    description=f"Worker {worker_id} step {step_num}",
                    result=f"result_{worker_id}_{step_num}",
                    confidence=0.8 + (step_num * 0.01)  # Slight variations
                )

                steps_added.append(result)

                # Validate response consistency
                if result["conversation_id"] != shared_conversation_id:
                    detector.add_error(
                        f"Worker {worker_id}: Wrong conversation ID: {result['conversation_id']}"
                    )

                if not result["success"]:
                    detector.add_error(
                        f"Worker {worker_id}: Step failed: {result.get('error', 'Unknown error')}"
                    )

                # Check for duplicate step numbers (sign of race condition)
                step_number = result.get("step_number", -1)
                if step_number < 0:
                    detector.add_error(f"Worker {worker_id}: Invalid step number: {step_number}")

                # Small delay to increase race condition probability
                time.sleep(0.001)

        except Exception as e:
            error_msg = f"Worker {worker_id} crashed: {type(e).__name__}: {e}"
            errors.append(error_msg)
            detector.add_error(error_msg)

        return {
            "worker_id": worker_id,
            "steps_added": len(steps_added),
            "errors": errors,
            "step_numbers": [s.get("step_number") for s in steps_added if s.get("step_number")]
        }

    # Run multiple workers concurrently to trigger race condition
    with ThreadPoolExecutor(max_workers=8) as executor:
        futures = [executor.submit(concurrent_step_worker, i) for i in range(8)]

        all_results = []
        for future in as_completed(futures):
            try:
                result = future.result(timeout=30)
                all_results.append(result)
            except Exception as e:
                detector.add_error(f"Test execution failed: {type(e).__name__}: {e}")

    # Analyze results for race conditions
    all_step_numbers = []
    for result in all_results:
        all_step_numbers.extend(result["step_numbers"])

    # Check for duplicate step numbers (indicative of race conditions)
    if len(all_step_numbers) != len(set(all_step_numbers)):
        duplicates = [num for num in set(all_step_numbers) if all_step_numbers.count(num) > 1]
        detector.add_corruption(f"Duplicate step numbers detected: {duplicates}")

    # Verify conversation integrity
    try:
        chain_summary = get_chain_summary(shared_conversation_id)
        expected_steps = sum(r["steps_added"] for r in all_results)
        actual_steps = chain_summary.get("step_count", 0)

        if actual_steps != expected_steps:
            detector.add_inconsistency(
                f"Step count mismatch: expected {expected_steps}, got {actual_steps}"
            )
    except Exception as e:
        # It's possible the conversation doesn't exist or has issues
        if "not found" not in str(e):
            detector.add_error(f"Conversation integrity check failed: {e}")

    print(f"  ‚úÖ Race condition test completed. Errors: {len(detector.errors)}")
    return detector


def test_high_002_memory_eviction_race_condition():
    """
    HIGH-002: Test race condition during conversation eviction when limit is reached.

    Tests race conditions that can occur when conversations are being evicted
    while new ones are being created.
    """
    print("\nüîç Testing HIGH-002: Memory eviction race condition...")
    detector = RaceConditionDetector()

    # Clear conversations
    with _conversations_lock:
        _conversations.clear()

    def eviction_worker(worker_id: int) -> Dict[str, Any]:
        """Worker that creates conversations to trigger eviction."""
        conversations_created = []
        errors = []

        try:
            # Create many conversations to trigger eviction
            for i in range(20):
                conv_id = f"eviction_test_worker_{worker_id}_{i}"

                # Add a step to create the conversation
                result = chain_of_thought_step(
                    conversation_id=conv_id,
                    stage="Test",
                    description=f"Eviction test conversation {conv_id}",
                    result=f"eviction_result_{worker_id}_{i}",
                    confidence=0.9
                )

                conversations_created.append(conv_id)

                if not result["success"]:
                    errors.append(f"Failed to create conversation {conv_id}: {result.get('error')}")

                # Small delay to increase concurrent eviction probability
                time.sleep(0.002)

        except Exception as e:
            error_msg = f"Eviction worker {worker_id} crashed: {type(e).__name__}: {e}"
            errors.append(error_msg)
            detector.add_error(error_msg)

        return {
            "worker_id": worker_id,
            "conversations_created": len(conversations_created),
            "errors": errors
        }

    # Run multiple workers to trigger concurrent evictions
    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = [executor.submit(eviction_worker, i) for i in range(6)]

        all_results = []
        for future in as_completed(futures):
            try:
                result = future.result(timeout=30)
                all_results.append(result)
            except Exception as e:
                detector.add_error(f"Eviction test execution failed: {type(e).__name__}: {e}")

    # Verify memory limits are respected
    try:
        active_conversations = get_active_conversations()
        if len(active_conversations) > _MAX_CONVERSATIONS:
            detector.add_corruption(
                f"Memory limit exceeded: {len(active_conversations)} > {_MAX_CONVERSATIONS}"
            )
    except Exception as e:
        detector.add_error(f"Memory limit check failed: {e}")

    print(f"  ‚úÖ Eviction race condition test completed. Errors: {len(detector.errors)}")
    return detector


def test_high_002_concurrent_clear_access_race():
    """
    HIGH-002: Test race condition between conversation clearing and access.

    Tests what happens when one thread clears a conversation while another
    is trying to access or modify it.
    """
    print("\nüîç Testing HIGH-002: Concurrent clear/access race condition...")
    detector = RaceConditionDetector()

    # Target conversation for clear/access race condition
    target_conversation = "clear_access_test"

    def clear_worker() -> Dict[str, Any]:
        """Worker that repeatedly clears the conversation."""
        clear_count = 0
        errors = []

        try:
            for i in range(15):
                # First create conversation
                chain_of_thought_step(
                    conversation_id=target_conversation,
                    stage="Setup",
                    description=f"Setup before clear {i}",
                    result=f"setup_{i}",
                    confidence=0.8
                )

                time.sleep(0.01)  # Let access worker work

                # Clear the conversation
                clear_result = clear_chain(target_conversation)
                clear_count += 1

                if not clear_result:
                    errors.append(f"Clear failed on iteration {i}")

        except Exception as e:
            error_msg = f"Clear worker crashed: {type(e).__name__}: {e}"
            errors.append(error_msg)
            detector.add_error(error_msg)

        return {
            "clear_count": clear_count,
            "errors": errors
        }

    def access_worker() -> Dict[str, Any]:
        """Worker that repeatedly accesses the conversation."""
        access_count = 0
        errors = []
        successful_accesses = []

        try:
            for i in range(50):
                result = chain_of_thought_step(
                    conversation_id=target_conversation,
                    stage=f"Access_{i}",
                    description=f"Access step {i}",
                    result=f"access_result_{i}",
                    confidence=0.7 + (i * 0.001)
                )

                access_count += 1
                successful_accesses.append(result["success"])

                # Check for unexpected failures
                if not result["success"] and "error" in result:
                    # Some failures are expected due to clearing, but not crashes
                    if "ValidationError" not in result.get("error", ""):
                        errors.append(f"Unexpected access failure: {result.get('error')}")

                time.sleep(0.002)

        except Exception as e:
            error_msg = f"Access worker crashed: {type(e).__name__}: {e}"
            errors.append(error_msg)
            detector.add_error(error_msg)

        return {
            "access_count": access_count,
            "successful_accesses": sum(successful_accesses),
            "errors": errors
        }

    # Run clear and access workers concurrently
    with ThreadPoolExecutor(max_workers=2) as executor:
        clear_future = executor.submit(clear_worker)
        access_future = executor.submit(access_worker)

        try:
            clear_result = clear_future.result(timeout=30)
            access_result = access_future.result(timeout=30)
        except Exception as e:
            detector.add_error(f"Clear/access race test failed: {type(e).__name__}: {e}")
            return detector

    # Verify no crashes occurred
    if clear_result["errors"]:
        for error in clear_result["errors"]:
            detector.add_error(f"Clear worker error: {error}")

    if access_result["errors"]:
        for error in access_result["errors"]:
            detector.add_error(f"Access worker error: {error}")

    print(f"  ‚úÖ Clear/access race condition test completed. Errors: {len(detector.errors)}")
    return detector


def main():
    """
    Execute HIGH-002 race condition vulnerability tests.

    These tests target specific race condition vulnerabilities in conversation
    management around lines 156-158 of chain_of_thought.py.

    Expected: Tests should FAIL if race conditions exist, PASS after fixes.
    """
    print("=" * 80)
    print("üö® HIGH-002: RACE CONDITION VULNERABILITY TEST üö®")
    print("=" * 80)
    print("Testing race conditions in conversation management:")
    print("  ‚Ä¢ Conversation creation/access race conditions")
    print("  ‚Ä¢ Memory eviction race conditions")
    print("  ‚Ä¢ Concurrent clear/access race conditions")
    print("-" * 80)

    all_detectors = []

    try:
        # Test 1: Conversation creation race condition
        detector1 = test_high_002_conversation_creation_race_condition()
        all_detectors.append(detector1)

        # Test 2: Memory eviction race condition
        detector2 = test_high_002_memory_eviction_race_condition()
        all_detectors.append(detector2)

        # Test 3: Concurrent clear/access race condition
        detector3 = test_high_002_concurrent_clear_access_race()
        all_detectors.append(detector3)

    except Exception as e:
        print(f"‚ùå CRITICAL: Test suite crashed: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return False

    # Aggregate results
    total_errors = sum(len(d.errors) for d in all_detectors)
    total_inconsistencies = sum(len(d.inconsistencies) for d in all_detectors)
    total_corruption = sum(len(d.data_corruption) for d in all_detectors)
    total_issues = total_errors + total_inconsistencies + total_corruption

    print("\n" + "=" * 80)
    print("üö® HIGH-002 RACE CONDITION TEST RESULTS üö®")
    print("=" * 80)

    print(f"Total Race Condition Issues Detected: {total_issues}")
    print(f"  ‚Ä¢ Critical Errors: {total_errors}")
    print(f"  ‚Ä¢ Data Inconsistencies: {total_inconsistencies}")
    print(f"  ‚Ä¢ Data Corruption: {total_corruption}")

    if total_issues > 0:
        print(f"\n‚ùå HIGH-002: {total_issues} race condition vulnerabilities detected!")
        print("‚ùå Conversation management is NOT thread-safe!")
        print("‚ùå Race conditions exist around lines 156-158 in chain_of_thought.py")

        print("\nüîß REQUIRED FIXES:")
        print("1. Ensure atomic conversation creation and step addition")
        print("2. Verify proper lock scope for all conversation operations")
        print("3. Add protection for concurrent clear/access operations")
        print("4. Implement proper memory management synchronization")

        return False
    else:
        print("\n‚úÖ HIGH-002: No race conditions detected!")
        print("‚úÖ Conversation management appears to be thread-safe!")
        return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)