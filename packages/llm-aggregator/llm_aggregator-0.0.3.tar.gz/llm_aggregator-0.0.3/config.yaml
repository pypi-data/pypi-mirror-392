# LLM Aggregator configuration
# All runtime behavior should be driven from here, not hard-coded in code.

host: "0.0.0.0"
port: 8888

brain:
  host: "http://10.7.2.100"
  # Port of the provider where the enrichment model is hosted
  port: 8080
  # Model used by the brain to enrich model metadata
  id: "unsloth/GLM-4.6-GGUF:UD-IQ2_XXS"
  # If set, send Authorization: Bearer <API-KEY> for calls to this port
  api_key: "unsloth/GLM-4.6-GGUF:UD-IQ2_XXS"
  # Maximum number of models to enrich in a single batch
  max_batch_size: 5

time:
  # Interval for fetching the list of models from all providers
  fetch_models_interval: 60
  # Timeout for fetching models from providers
  fetch_models_timeout: 10
  # Timeout for enriching models
  enrich_models_timeout: 120
  # for enrichment loop when queue is empty
  enrich_idle_sleep: 5

providers:
  - base_url: http://10.7.2.100
    port: 8080
  - base_url: http://10.7.2.100
    port: 8090
  - base_url: http://10.7.2.100
    port: 11434
