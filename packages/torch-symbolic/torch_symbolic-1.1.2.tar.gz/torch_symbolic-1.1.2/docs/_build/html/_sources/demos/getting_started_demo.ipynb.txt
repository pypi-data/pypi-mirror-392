{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f935234",
   "metadata": {},
   "source": [
    "# SymbolicMLP Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2801a7",
   "metadata": {},
   "source": [
    "In this demo, we show you how to:\n",
    "* Wrap an MLP in a PyTorch model with our `SymbolicMLP` class\n",
    "* Perform symbolic regresson on the MLP with the `distill` method \n",
    "* Switch the MLP to an equation in the forward pass of the model with the `switch_to_equation` method \n",
    "* Switch back to the MLP with the `switch_to_mlp` method\n",
    "* Loading a SymTorch model with the `load_model` method (BETA TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f4a7a",
   "metadata": {},
   "source": [
    "## Wrapping a PyTorch model\n",
    "Create a simple PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc61e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = 64):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(input_dim, output_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941215c",
   "metadata": {},
   "source": [
    "Train the model on some data.\n",
    "\n",
    "$$\n",
    "y = x_0^2 +3 \\sin(x_4)-4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f363579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset \n",
    "x = np.array([np.random.uniform(0, 1, 10_000) for _ in range(5)]).T  \n",
    "y = x[:, 0]**2 + 3*np.sin(x[:, 4]) - 4\n",
    "noise = np.array([np.random.normal(0, 0.05*np.std(y)) for _ in range(len(y))])\n",
    "y = y + noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcf89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(model, dataloader, opt, criterion, epochs = 100):\n",
    "    \"\"\"\n",
    "    Train a model for the specified number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        dataloader: DataLoader for training data\n",
    "        opt: Optimizer\n",
    "        criterion: Loss function\n",
    "        epochs: Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, loss_tracker)\n",
    "    \"\"\"\n",
    "    loss_tracker = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            \n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        loss_tracker.append(epoch_loss)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.6f}')\n",
    "    return model, loss_tracker\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleModel(input_dim=x.shape[1], output_dim=1)\n",
    "\n",
    "# Set up training\n",
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "X_train, _, y_train, _ = train_test_split(x, y.reshape(-1,1), test_size=0.2, random_state=290402)\n",
    "\n",
    "# Set up dataset\n",
    "dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add838bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Avg Loss: 0.080689\n",
      "Epoch [10/20], Avg Loss: 0.059326\n",
      "Epoch [15/20], Avg Loss: 0.048104\n",
      "Epoch [20/20], Avg Loss: 0.038434\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save the weights\n",
    "\n",
    "model, losses = train_model(model, dataloader, opt, criterion, 20)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb22ef1",
   "metadata": {},
   "source": [
    "Wrap the mlp layer in the trained model with SymbolicMLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bc4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from symtorch import SymbolicMLP\n",
    "model.mlp = SymbolicMLP(model.mlp, mlp_name = 'Sequential')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db5df8",
   "metadata": {},
   "source": [
    "## Interpret the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15a8d3",
   "metadata": {},
   "source": [
    "In this example, we pass extra parameters into the `.distill` method (complexity of operators/constants and parsimony, which is a penalisation of complexity).\\\n",
    "To see all the possible parameters, please see the `PySRRegressor` class from [PySR](https://ai.damtp.cam.ac.uk/pysr/api/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b47775",
   "metadata": {},
   "source": [
    "In this example, we turn verbosity off because we are in a Jupyter notebook. For best performance, run in IPython, as you can terminate the SR any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d637d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Running SR on output dimension 0 of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/SymTorch_project/symtorch_venv/lib/python3.11/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡Best equation for output 0 found to be (x4 + -4.004943) + ((((x4 * (x4 * -0.27583972)) + inv(x4)) * x4) * ((x4 + (x0 * x0)) + x4)).\n",
      "â¤ï¸ SR on Sequential complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: PySRRegressor.equations_ = [\n",
       " \t    pick         score                                           equation  \\\n",
       " \t0         0.000000e+00                                                 x4   \n",
       " \t1         2.600202e+00                                          -2.301479   \n",
       " \t2         4.040378e-01                                     x4 + -2.800622   \n",
       " \t3         4.821778e-01                             (x4 + x4) + -3.2995384   \n",
       " \t4         2.194239e-01                       (x4 * 2.490159) + -3.5441391   \n",
       " \t5         9.529646e-01                      (x0 + (x4 + -3.8061292)) + x4   \n",
       " \t6         9.319039e-01                 x0 + ((x4 + -1.6320255) * 2.47844)   \n",
       " \t7         1.465733e-01        ((x0 * x0) + -3.8779812) + (x4 * 2.4770215)   \n",
       " \t8         7.084829e-01             (inv(exp(x4)) * -4.158734) + (x0 * x0)   \n",
       " \t9         1.403650e-01    ((x0 * x0) + -3.972769) + (sin(x4) * 2.9010966)   \n",
       " \t10        8.077646e-02  (inv(exp(x4)) * -4.073437) + (x0 * (x0 + -0.11...   \n",
       " \t11        1.115349e-02  (((x0 + (x4 * x0)) * x0) + -4.158734) * inv(ex...   \n",
       " \t12        1.944279e-01  (sin(sin(x4)) * 3.257794) + ((x0 * x0) + -4.04...   \n",
       " \t13        9.353280e-03  (inv(exp(x4)) * -3.977397) + sin((x0 * x0) + -...   \n",
       " \t14        1.606033e-01  ((sin(sin(x4)) * 3.5838883) + ((x0 * x0) + -4....   \n",
       " \t15        6.370600e-02  ((((x4 + ((x0 * x0) + x4)) * x4) * ((x4 * -0.2...   \n",
       " \t16  >>>>  1.416759e-01  (x4 + -4.004943) + ((((x4 * (x4 * -0.27583972)...   \n",
       " \t17        8.073089e-08  inv(inv(x4 + (-4.004943 + (((((x4 * x4) * -0.2...   \n",
       " \t18        3.562809e-02  ((((x0 * (x0 * 0.97650796)) + x4) + x4) * ((((...   \n",
       " \t19        7.526650e-04  ((((x0 * (x0 * 0.9767106)) + (x4 + x4)) * (inv...   \n",
       " \t\n",
       " \t        loss  complexity  \n",
       " \t0   8.111321           1  \n",
       " \t1   0.602335           2  \n",
       " \t2   0.268470           4  \n",
       " \t3   0.102348           6  \n",
       " \t4   0.082184           7  \n",
       " \t5   0.031690           8  \n",
       " \t6   0.012480           9  \n",
       " \t7   0.009309          11  \n",
       " \t8   0.004583          12  \n",
       " \t9   0.003462          14  \n",
       " \t10  0.003193          15  \n",
       " \t11  0.003158          16  \n",
       " \t12  0.002600          17  \n",
       " \t13  0.002575          18  \n",
       " \t14  0.001868          20  \n",
       " \t15  0.001644          22  \n",
       " \t16  0.001239          24  \n",
       " \t17  0.001239          26  \n",
       " \t18  0.001195          27  \n",
       " \t19  0.001193          30  \n",
       " ]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the SR\n",
    "\n",
    "sr_params = {'complexity_of_operators':  {\"sin\":3, \"exp\":3},\n",
    "             'complexity_of_constants': 2, \n",
    "             'parsimony': 0.1,\n",
    "             'verbosity': 0,\n",
    "             'niterations': 500}\n",
    "\n",
    "model.mlp.distill(torch.FloatTensor(X_train),\n",
    "                       sr_params = sr_params, \n",
    "                       parent_model=model) #Pass in the parent model (really only required if the MLP is \n",
    "                                            #not at the start of the model but it is good practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275ed6e",
   "metadata": {},
   "source": [
    "See the full Pareto front of equations. The best equation is chosen as a balance of accuracy and complexity.\\\n",
    "Outputs from *PySR* are saved in `SR_output/MLP_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31109683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: PySRRegressor.equations_ = [\n",
      "\t    pick         score                                           equation  \\\n",
      "\t0         0.000000e+00                                                 x4   \n",
      "\t1         2.600202e+00                                          -2.301479   \n",
      "\t2         4.040378e-01                                     x4 + -2.800622   \n",
      "\t3         4.821778e-01                             (x4 + x4) + -3.2995384   \n",
      "\t4         2.194239e-01                       (x4 * 2.490159) + -3.5441391   \n",
      "\t5         9.529646e-01                      (x0 + (x4 + -3.8061292)) + x4   \n",
      "\t6         9.319039e-01                 x0 + ((x4 + -1.6320255) * 2.47844)   \n",
      "\t7         1.465733e-01        ((x0 * x0) + -3.8779812) + (x4 * 2.4770215)   \n",
      "\t8         7.084829e-01             (inv(exp(x4)) * -4.158734) + (x0 * x0)   \n",
      "\t9         1.403650e-01    ((x0 * x0) + -3.972769) + (sin(x4) * 2.9010966)   \n",
      "\t10        8.077646e-02  (inv(exp(x4)) * -4.073437) + (x0 * (x0 + -0.11...   \n",
      "\t11        1.115349e-02  (((x0 + (x4 * x0)) * x0) + -4.158734) * inv(ex...   \n",
      "\t12        1.944279e-01  (sin(sin(x4)) * 3.257794) + ((x0 * x0) + -4.04...   \n",
      "\t13        9.353280e-03  (inv(exp(x4)) * -3.977397) + sin((x0 * x0) + -...   \n",
      "\t14        1.606033e-01  ((sin(sin(x4)) * 3.5838883) + ((x0 * x0) + -4....   \n",
      "\t15        6.370600e-02  ((((x4 + ((x0 * x0) + x4)) * x4) * ((x4 * -0.2...   \n",
      "\t16  >>>>  1.416759e-01  (x4 + -4.004943) + ((((x4 * (x4 * -0.27583972)...   \n",
      "\t17        8.073089e-08  inv(inv(x4 + (-4.004943 + (((((x4 * x4) * -0.2...   \n",
      "\t18        3.562809e-02  ((((x0 * (x0 * 0.97650796)) + x4) + x4) * ((((...   \n",
      "\t19        7.526650e-04  ((((x0 * (x0 * 0.9767106)) + (x4 + x4)) * (inv...   \n",
      "\t\n",
      "\t        loss  complexity  \n",
      "\t0   8.111321           1  \n",
      "\t1   0.602335           2  \n",
      "\t2   0.268470           4  \n",
      "\t3   0.102348           6  \n",
      "\t4   0.082184           7  \n",
      "\t5   0.031690           8  \n",
      "\t6   0.012480           9  \n",
      "\t7   0.009309          11  \n",
      "\t8   0.004583          12  \n",
      "\t9   0.003462          14  \n",
      "\t10  0.003193          15  \n",
      "\t11  0.003158          16  \n",
      "\t12  0.002600          17  \n",
      "\t13  0.002575          18  \n",
      "\t14  0.001868          20  \n",
      "\t15  0.001644          22  \n",
      "\t16  0.001239          24  \n",
      "\t17  0.001239          26  \n",
      "\t18  0.001195          27  \n",
      "\t19  0.001193          30  \n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "print(model.mlp.pysr_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db788500",
   "metadata": {},
   "source": [
    "## Switch to Using the Equation Instead in the Forwards Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dbf360",
   "metadata": {},
   "source": [
    "You can choose the equation you want to switch to by choosing the desired complexity of equation. \\\n",
    "If left blank, then we choose the best equation chosen by *PySR*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abef72c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully switched Sequential to symbolic equations for all 1 dimensions:\n",
      "   Dimension 0: ((x0 * x0) + -3.972769) + (sin(x4) * 2.9010966)\n",
      "   Variables: ['x0', 'x4']\n",
      "ðŸŽ¯ All 1 output dimensions now using symbolic equations.\n"
     ]
    }
   ],
   "source": [
    "model.mlp.switch_to_equation(complexity=[14]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7cfd0",
   "metadata": {},
   "source": [
    "Now when running the forwards pass through the model, it uses the symbolic equation instead of the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e526154f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7768],\n",
       "        [-3.3793],\n",
       "        [-1.8882],\n",
       "        ...,\n",
       "        [-1.8417],\n",
       "        [-2.7306],\n",
       "        [-1.6110]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretable_outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "interpretable_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835dd8e",
   "metadata": {},
   "source": [
    "## Switch to Using the MLP in the Forwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34291a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Switched Sequential back to MLP\n"
     ]
    }
   ],
   "source": [
    "mlp_outputs = model.mlp.switch_to_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e43dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7518],\n",
       "        [-3.3348],\n",
       "        [-1.8268],\n",
       "        ...,\n",
       "        [-1.7640],\n",
       "        [-2.7127],\n",
       "        [-1.6157]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_outputs = model.mlp(torch.tensor(X_train, dtype=torch.float32))\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c6c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f07f0b",
   "metadata": {},
   "source": [
    "## Saving and loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f79773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved PyTorch model state to symtorch_data/symtorch_model_pytorch.pth\n",
      "âœ… Saved model metadata to symtorch_data/symtorch_model_metadata.pkl\n",
      "âœ… Saved regressor for dimension 0 to symtorch_data/symtorch_model_regressor_dim0.pkl\n",
      "âœ… Saved 1 PySR regressors\n",
      "ðŸŽ¯ Model save complete. Created 3 files with base name: symtorch_data/symtorch_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/SymTorch_project/symtorch_venv/lib/python3.11/site-packages/pysr/sr.py:1270: UserWarning: `extra_sympy_mappings` cannot be pickled and will be removed from the serialized instance. When loading the model, please redefine `extra_sympy_mappings` at runtime.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['symtorch_data/symtorch_model_pytorch.pth',\n",
       " 'symtorch_data/symtorch_model_metadata.pkl',\n",
       " 'symtorch_data/symtorch_model_regressor_dim0.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('symtorch_data', exist_ok = True)\n",
    "model.mlp.save_model('symtorch_data/symtorch_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47e43a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading SymbolicMLP model: Sequential\n",
      "âœ… Loaded regressor for dimension 0\n",
      "âœ… Loaded 1 PySR regressors\n",
      "ðŸŽ¯ Model loading complete: Sequential\n",
      "âœ… Successfully switched Sequential to symbolic equations for all 1 dimensions:\n",
      "   Dimension 0: (x4 + -4.004943) + ((((x4 * (x4 * -0.27583972)) + inv(x4)) * x4) * ((x4 + (x0 * x0)) + x4))\n",
      "   Variables: ['x0', 'x4']\n",
      "ðŸŽ¯ All 1 output dimensions now using symbolic equations.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = SymbolicMLP.load_model('symtorch_data/symtorch_model')\n",
    "loaded_model.switch_to_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e258b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up \n",
    "\n",
    "import shutil\n",
    "if os.path.exists('SR_output'):\n",
    "    shutil.rmtree('SR_output')\n",
    "    os.remove('model_weights.pth')\n",
    "\n",
    "if os.path.exists('symtorch_data'):\n",
    "    shutil.rmtree('symtorch_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symtorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
