# Demo Setup
#
# Starts a proxy on host port 8080 plus 2 llama.cpp servers
# Routing is based on API_KEY (OpenAI compatible)
services:

  traefik-proxy:
    image: traefik:latest
    depends_on:
      llama-server-1:
        condition: service_healthy
      llama-server-2:
        condition: service_healthy
    ports:
      - "8080:8080"
    volumes:
      - ./traefik/traefik.yml:/etc/traefik/traefik.yml:ro
      - ./traefik/mappings/:/etc/traefik/mappings/:ro
      - /tmp/log/traefik/:/tmp/log/traefik/

  llama-server-1:
    image: ghcr.io/ggml-org/llama.cpp:server
    healthcheck:
      test: [ "CMD", "curl", "-fsS", "http://127.0.0.1:8011/v1/health" ]
      start_period: 10m
    volumes:
      - llama_cpp:/models
    environment:
      LLAMA_CACHE: /models/llama-cache
    command: |
      --hf-repo TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF:Q2_K
      --n-predict 512
      --port 8011
      --host 0.0.0.0
      --alias TinyLlama_Chat

  llama-server-2:
    image: ghcr.io/ggml-org/llama.cpp:server
    healthcheck:
      test: [ "CMD", "curl", "-fsS", "http://127.0.0.1:8012/v1/health" ]
      start_period: 10m
    volumes:
      - llama_cpp:/models
    environment:
      LLAMA_CACHE: /models/llama-cache
    command: |
      --hf-repo tensorblock/mistral-1L-tiny-GGUF:Q2_K
      --n-predict 512
      --port 8012
      --host 0.0.0.0
      --alias mistral-tiny

  routheon-server:
    build:
      context: .
      args:
        ROUTHEON_VERSION: "0.0.0.dev0"
    image: routheon_routheon-server:demo
    volumes:
      - ./traefik/mappings/:/etc/traefik/mappings/:ro
      - ./stats-config.yml:/home/appuser/.routheon/stats-config.yml:ro

  create-mapping:
    image: python:slim
    depends_on:
      - routheon-server
    volumes:
      - ./traefik/create-mapping/create-mapping.sh:/usr/local/bin/create-mapping.sh:ro
      - ./traefik/mappings/:/etc/traefik/mappings/
      # simulate create-mapping.sh for 2nd llama-server
      # after start of routheon-server
      # --host llama-server-2: is the name of the docker-compose service here
      # --host 0.0.0.0: is needed here when inside docker compose as traefik is in another service
    command:
      - /bin/sh
      - -c
      - |
        rm -f /etc/traefik/mappings/llama-server-2.yml &&
        /usr/local/bin/create-mapping.sh --port 8012 --service llama-server-2 --api_key API_KEY-2 --mappings /etc/traefik/mappings --host http://llama-server-2

volumes:
  llama_cpp:
