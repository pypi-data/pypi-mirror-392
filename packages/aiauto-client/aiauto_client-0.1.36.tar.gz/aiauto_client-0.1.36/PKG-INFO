Metadata-Version: 2.1
Name: aiauto-client
Version: 0.1.36
Summary: AI Auto HPO (Hyperparameter Optimization) Client Library
Author-email: AIAuto Team <ainode@zeroone.ai>
Project-URL: Homepage, https://dashboard.common.aiauto.pangyo.ainode.ai
Project-URL: Repository, https://dashboard.common.aiauto.pangyo.ainode.ai
Project-URL: Documentation, https://dashboard.common.aiauto.pangyo.ainode.ai
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: optuna>=3.0.0
Requires-Dist: optuna-dashboard>=0.18.0
Requires-Dist: requests>=2.25.0
Requires-Dist: grpcio>=1.48.0
Requires-Dist: grpcio-status>=1.48.0

# AIAuto Client

> Kubernetes ê¸°ë°˜ ë¶„ì‚° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”(HPO) ë¼ì´ë¸ŒëŸ¬ë¦¬

AIAutoëŠ” ê¸°ì¡´ Optuna APIì™€ í˜¸í™˜ë˜ëŠ” Kubernetes ê¸°ë°˜ ë¶„ì‚° HPO í”Œë«í¼ì…ë‹ˆë‹¤. ë¡œì»¬ PCì—ì„œ ì½”ë“œë¥¼ ì‘ì„±í•˜ë©´ ZeroOneAIì˜ Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ ë³‘ë ¬ ìµœì í™”ê°€ ìë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. GPUë„ ì§€ì›í•©ë‹ˆë‹¤.

---

## ì„¤ì¹˜
- ìš”êµ¬ì‚¬í•­**: Python 3.8 ì´ìƒ
```bash
pip install aiauto-client optuna
```

---

## ì£¼ìš” ê°œë…

### [Optuna](https://optuna.org/) vs AIAuto ì°¨ì´ì 
#### AIAuto ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ 
- ë¡œì»¬ ë¦¬ì†ŒìŠ¤ ì œì•½ í•´ê²°: ë¡œì»¬ PC ì˜ CPU/GPU/ë©”ëª¨ë¦¬ í•œê³„ ì—†ì´ ZeroOneAI í´ëŸ¬ìŠ¤í„°ì˜ ìì›ì„ í™œìš©í•œ ëŒ€ê·œëª¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
- í´ë¼ìš°ë“œ GPU í™œìš©: ë¡œì»¬ì—ì„œ ëŒì•„ê°€ëŠ” ê²ƒì´ ì•„ë‹Œ ZeroOneAI í´ëŸ¬ìŠ¤í„°ì˜ GPU ì‚¬ìš©
- Optuna í˜¸í™˜: ê¸°ì¡´ Optuna ì½”ë“œì™€ Sampler/Pruner ê°ì²´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥

| í•­ëª© | Optuna        | AIAuto                |
|------|---------------|-----------------------|
| **ì‹¤í–‰ ìœ„ì¹˜** | ë¡œì»¬ PC         | Kubernetes í´ëŸ¬ìŠ¤í„°       |
| **ë³‘ë ¬í™”** | í”„ë¡œì„¸ìŠ¤/ìŠ¤ë ˆë“œ ê¸°ë°˜   | Kubernetes Pod ê¸°ë°˜     |
| **GPU ì‚¬ìš©** | ë¡œì»¬ GPU í•„ìš”     | ZeroOneAI í´ëŸ¬ìŠ¤í„° GPU ì‚¬ìš© |
| **í™•ì¥ì„±** | ë¡œì»¬ ë¦¬ì†ŒìŠ¤ í™•ì¥ ì œí•œ  | ë…¸ë“œ ê¸°ë°˜ scale out í™•ì¥ ê°€ëŠ¥ |
| **API í˜¸í™˜ì„±** | Optuna ê¸°ë³¸ API | Optuna API í˜¸í™˜         |
| **Sampler/Pruner** | ëª¨ë“  Optuna ì•Œê³ ë¦¬ì¦˜ | Optuna API í˜¸í™˜          |

### ì•„í‚¤í…ì²˜ êµ¬ì¡°
```mermaid
graph TB
    subgraph Layer1["ë¡œì»¬ í™˜ê²½"]
        User[ì‚¬ìš©ì ë¡œì»¬ PC]
        AskTell["Ask/Tell trial"]
        
        User --> AskTell
    end

    subgraph Layer2["AIAuto í”Œë«í¼"]
        Workspace[Workspace]
        Dashboard[Optuna Dashboard]
        Storage[Journal gRPC Storage]
        Store[Artifact Store]
        
        Study[Study]

        Workspace --> Dashboard
        Workspace --> Storage
        Workspace --> Store
        Workspace --> Study
    end

    subgraph Layer3["ë¶„ì‚° ì‹¤í–‰"]
        TB1[TrialBatch 1]
        TB2[TrialBatch 2]
        Pod1[Pod/Trial 1]
        Pod2[Pod/Trial 2]

        TB1 --> Pod1
        TB1 --> Pod2
    end

    User --> Workspace
    
    Study --> TB1
    Study --> TB2
    
    Pod1 -.report.-> Storage
    Pod1 -.save.-> Store
    AskTell -.report.-> Storage
    AskTell -.save.-> User
    Storage -.view.-> Dashboard
```
#### êµ¬ì¡° ì„¤ëª…
- OptunaWorkspace: ì‚¬ìš©ìë‹¹ 1ê°œ, Journal gRPC Storage ì™€ Optuna Dashboard, Artifact Store í¬í•¨
- Study: í•˜ë‚˜ì˜ maximize or minimize ìµœì í™” ì‹¤í—˜ ë‹¨ìœ„ (ex: "ResNet í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰")
- TrialBatch: Study ë‚´ì—ì„œ ë³‘ë ¬ ì‹¤í–‰ë˜ëŠ” trial ê·¸ë£¹ (í•œ ë²ˆì˜ `optimize()` í˜¸ì¶œë‹¹ 1ê°œ)
- Pod: Kubernetes ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê°œë³„ trial (GPU/CPU ë¦¬ì†ŒìŠ¤ í• ë‹¹)

---

## ë¹ ë¥¸ì‹œì‘ (5ë¶„)

### 1. í† í° ë°œê¸‰
- AIAuto Web ì ‘ì†: [https://dashboard.common.aiauto.pangyo.ainode.ai](https://dashboard.common.aiauto.pangyo.ainode.ai)
- "Generate New Token" ë²„íŠ¼ í´ë¦­
![](img/5_aiauto_dashboard_token.png)
- ìƒì„±ëœ Token ë³µì‚¬
![](img/6_aiauto_dashboard_token_copy.png)

### 2. ì²« ìµœì í™” ì‹¤í–‰
- ì•„ë˜ ì˜ˆì‹œ ì½”ë“œì— `<your-token-here>` ì— ë³µì‚¬í•œ í† í° ë¶™ì—¬ë„£ê¸° (ì£¼ì˜!! ë‘ êµ°ë° ìˆìŒì— ì£¼ì˜)
- Optuna ê¸°ë³¸ ê°œë… í•™ìŠµ: ê¸°ì¡´ Optuna ì™€ í˜¸í™˜ë˜ë¯€ë¡œ ì²˜ìŒì´ë¼ë©´ [Optuna ê³µì‹ íŠœí† ë¦¬ì–¼](https://optuna.readthedocs.io/en/stable/tutorial/index.html)ì„ ë¨¼ì € ë³´ê¸¸ ê¶Œì¥
  - AIAutoController ë¥¼ ì‚¬ìš©í•˜ì—¬ study TODO
```python
import aiauto
import optuna

# AIAuto ì´ˆê¸°í™”
# ì´ ë•Œ OptunaWorkspace ê°€ ìƒì„±ë¨
ac = aiauto.AIAutoController('<your-token-here>')
# Study ìƒì„±
study_wrapper = ac.create_study('my-first-study', direction='minimize')

# Objective í•¨ìˆ˜ ì •ì˜
def objective(trial):
    # objective í•¨ìˆ˜ ì•ˆì—ì„œ import í•˜ëŠ” ê²ƒ ì£¼ì˜
    import aiauto
    from os.path import join
    
    # log ë¥¼ ì°ê¸° ìœ„í•œ TrialController ê°ì²´ ìƒì„± 
    tc = aiauto.TrialController(trial)

    # ìµœì í™” í•¨ìˆ˜ ì‘ì„±
    x = trial.suggest_float('x', -10, 10)
    y = trial.suggest_float('y', -10, 10)
    value = (x - 2) ** 2 + (y - 3) ** 2
    
    # log
    tc.log(f'x={x:.2f}, y={y:.2f}, value={value:.4f}')
    
    # report
    trial.report(value, step=1)   # ì¤‘ê°„ ì„±ëŠ¥ ë³´ê³ 
    
    # artifact ì €ì¥ ì‹œì‘ (í•„ìˆ˜ëŠ” ì•„ë‹˜ ì½”ë“œì—ì„œ ì œì™¸í•´ë„ ë¨)
    # -------------------------------------------
    
    # ì£¼ì˜!!: artifact ì €ì¥ì„ ìœ„í•´ get_artifact_store ë‚˜ get_storage ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ
    # AIAutoController ë¥¼ objective í•¨ìˆ˜ ì•ˆì—ì„œ ë‹¤ì‹œ ì„ ì–¸í•´ì•¼ í•¨
    ac_local = aiauto.AIAutoController('<your-token-here>')
    try:
        # íŒŒì¼ëª…/ë‚´ìš©ì— trial ì‹ë³„ì í¬í•¨
        trial_id = f'{trial.study.study_name}_{trial.number}'
        filename = f'{trial_id}.txt'
        file_path = join(ac_local.get_artifact_tmp_dir(), filename)
      
        with open(file_path, 'w') as f:
          f.write(f'trial_id={trial_id}\n')
          f.write(f'final_score={value}\n')
          f.write(f'rand_value_x={x}\n')
          f.write(f'rand_value_y={y}\n')
      
        artifact_id = optuna.artifacts.upload_artifact(
          artifact_store=ac_local.get_artifact_store(),
          storage=ac_local.get_storage(),
          study_or_trial=trial,
          file_path=file_path,
        )
        trial.set_user_attr('artifact_id', artifact_id)
        tc.log(f'[artifact] saved {filename}, artifact_id={artifact_id}')
    except Exception as e:
        tc.log(f'[artifact] failed: {e}')
        
    # -------------------------------------------
    # artifact ì €ì¥ ì¢…ë£Œ (í•„ìˆ˜ëŠ” ì•„ë‹˜ ì½”ë“œì—ì„œ ì œì™¸í•´ë„ ë¨)

    return value

# ìµœì í™” ì‹¤í–‰ (Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ ë³‘ë ¬ ì‹¤í–‰)
# ë™ì‹œì— 2ê°œì”© ì´ 10ê°œ trial ìƒì„±
# í•˜ë‚˜ì˜ trial ë‹¹ 1 cpu, 500Mi memory ì˜ pod ê°€ ëœ¸
study_wrapper.optimize(
  objective, 
  n_trials=10, 
  parallelism=2,
  resources_requests={
    "cpu": "1",
    "memory": "500Mi",
  },
)

TODO
# ë°˜ë³µë¬¸ ëŒë©´ì„œ í™•ì¸ ì‹œì‘ (í•„ìˆ˜ëŠ” ì•„ë‹˜ ì½”ë“œì—ì„œ ì œì™¸í•´ë„ ë¨)
# --------------------------------------------

# --------------------------------------------
# ë°˜ë³µë¬¸ ëŒë©´ì„œ í™•ì¸ ì¢…ë£Œ (í•„ìˆ˜ëŠ” ì•„ë‹˜ ì½”ë“œì—ì„œ ì œì™¸í•´ë„ ë¨)
```

### 3. Dashboard ê²°ê³¼ í™•ì¸
- ìµœì í™”ê°€ ì™„ë£Œë˜ë©´ Optuna Dashboardì—ì„œ Study ì§„í–‰ìƒí™©, ìµœì  íŒŒë¼ë¯¸í„°, ì‹œê°í™” ê·¸ë˜í”„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  - [AIAuto Web OptunaWorkspace](https://dashboard.common.aiauto.pangyo.ainode.ai/workspace) tab ì— ì ‘ì†í•˜ì—¬ `Open Dashboard` ë§í¬ë¥¼ í´ë¦­
    ![](img/1_aiauto_dashboard_study.png)
  - Optuna Dashboard ëŠ” Study ë‹¨ìœ„ë¡œ ì§„í–‰ìƒí™©ê³¼ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤
  - ì•„ë˜ ì²˜ëŸ¼ ì—¬ëŸ¬ study ê°€ í•˜ë‚˜ì˜ Optuna Dashboard ì— ë³´ì´ë©°, í•˜ë‚˜ì˜ Studyì— ì—¬ëŸ¬ TrialBatchê°€ í¬í•¨ ë¨
    ![](img/2_optuna_dashboard_study.png)
  - ìƒì„±ëœ Study ì•ˆì—ì„œ ê·¸ë˜í”„, Hyperparameter Importance, Optimization History ë“± ì§„í–‰ ìƒí™©ê³¼ ê·¸ë˜í”„ í™•ì¸ ê°€ëŠ¥
    ![](img/3_optuna_dashboard_graph.png)
  - ê°œë³„ trial ì˜ log ë„ í™•ì¸ ê°€ëŠ¥
    ![](img/4_optuna_dashbaord_study_trialbatch.png)
  - ê°œë³„ trial ì˜ artifact ëŠ” [AIAuto Web TrialBatch](https://dashboard.common.aiauto.pangyo.ainode.ai/trialbatch) ì˜ `Pod ìƒíƒœ` ë²„íŠ¼ì„ ëˆŒëŸ¬ í™•ì¸ ê°€ëŠ¥
  - 

### 4. ì§€ì› ëŸ°íƒ€ì„ ì´ë¯¸ì§€ í™•ì¸
```python
import aiauto

# ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ëª©ë¡ í™•ì¸
for image in aiauto.RUNTIME_IMAGES:
    print(image)
```
#### ê¸°ë³¸ ì´ë¯¸ì§€ (use_gpu=False)
- `ghcr.io/astral-sh/uv:python3.8-bookworm-slim`
- `ghcr.io/astral-sh/uv:python3.9-bookworm-slim`
- `ghcr.io/astral-sh/uv:python3.10-bookworm-slim`
- `ghcr.io/astral-sh/uv:python3.11-bookworm-slim`
- `ghcr.io/astral-sh/uv:python3.12-bookworm-slim`
- `ghcr.io/astral-sh/uv:python3.13-bookworm-slim`
#### GPU ì´ë¯¸ì§€ (use_gpu=True)
- `pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime`
- `pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime`
- `pytorch/pytorch:2.2.0-cuda11.8-cudnn8-runtime`
- `tensorflow/tensorflow:2.13.0-gpu`
- `tensorflow/tensorflow:2.14.0-gpu`

### 5. ë¦¬ì†ŒìŠ¤ ì„¤ì •
#### CPU ì‚¬ìš©
```python
study.optimize(
    objective,
    resources_requests={
        "cpu": "1",
        "memory": "500Mi",
    },
)
```
#### GPU ì‚¬ìš©
```python
study.optimize(
    objective,
    use_gpu=True,
    resources_requests={
        "cpu": "8",
        "memory": "16Gi",
        "nvidia.com/gpu": "2",
    },
)
```

### 6. API ë ˆí¼ëŸ°ìŠ¤

#### AIAutoController
- token ì¸ì¦ì„ í†µí•´ ì›ê²©ìœ¼ë¡œ zerooneai kubenetes cluster ì„œë²„ì™€ í†µì‹ í•˜ê¸° ìœ„í•œ ê°ì²´ 
- ìƒì„± ì‹œ OptunaWorkspace ë¥¼ ì´ˆê¸°í™”
- create_study() ë¡œ optuna [Study](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html) ì˜ wrapper ì¸ [StudyWrapper](#studywrapper) ë¥¼ ìƒì„±
```python
import aiauto

ac = aiauto.AIAutoController('<your-token>')
study_wrapper = ac.create_study('study-name', direction='minimize')
```
##### Parameters
- `token` (str): [Front](#1-í† í°-ë°œê¸‰)ì—ì„œ ë°œê¸‰ë°›ì€ API í† í°
##### Methods
- `create_study(study_name, direction, ...)`: optuna [Study](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html) ì˜ wrapper ì¸ [StudyWrapper](#studywrapper) ë¥¼ ìƒì„±
  - `study_name` (str): Study ì´ë¦„ (unique í•´ì•¼ í•¨)
  - `direction` (str): Single-objective ì¸ ê²½ìš° ë¬¸ìì—´ ì‚¬ìš© "minimize" ë˜ëŠ” "maximize" (default: minimize), direction ê³¼ directions ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ì§€ì •í•´ì•¼ í•œë‹¤
  - `directions` (List[str]): Multi-objective ì¸ ê²½ìš° ë¬¸ìì—´ì˜ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©, direction ê³¼ directions ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ì§€ì •í•´ì•¼ í•œë‹¤
  - `sampler` (optuna.samplers.BaseSampler): Optuna Sampler ì™€ í˜¸í™˜ (default: TPESampler)
  - `pruner` (optuna.pruners.BasePruner): Optuna Pruner ì™€ í˜¸í•œ (default: MedianPruner)
- `get_storage` (): Optuna study/trial ì •ë³´ë¥¼ ì €ì¥í•  Storage ê°ì²´ ë°˜í™˜ (OptunaWorkspace ì™€ ì—°ë™ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ê¼­ ì´ ê°ì²´ë¥¼ ì‚¬ìš©í•´ì•¼í•œë‹¤) [6-checkpoint-ì €ì¥-artifact](#6-checkpoint-ì €ì¥-artifact) ì°¸ê³ 
- `get_artifact_store` (): Artifact Store ê°ì²´ ë°˜í™˜ (OptunaWorkspace ì™€ ì—°ë™ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ê¼­ ì´ ê°ì²´ë¥¼ ì‚¬ìš©í•´ì•¼í•œë‹¤) [6-checkpoint-ì €ì¥-artifact](#6-checkpoint-ì €ì¥-artifact) ì°¸ê³ 
- `get_artifact_tmp_dir` (): Artifact ì„ì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (OptunaWorkspace ì™€ ì—°ë™ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ê¼­ ì´ ê²½ë¡œì— íŒŒì¼ì„ ì €ì¥í•œ í›„ upload_artifact ë¥¼ í˜¸ì¶œí•˜ì•¼ í•œë‹¤) [6-checkpoint-ì €ì¥-artifact](#6-checkpoint-ì €ì¥-artifact) ì°¸ê³ 

#### StudyWrapper
- [Study](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html) ëŠ” ê¸°ì¡´ Optuna ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê°ì²´, StudyWrapper ëŠ” ì´ë¥¼ Wrapping í•˜ì—¬ aiauto ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê°ì²´, get_study() í†µí•˜ì—¬ wrapper ì—ì„œ ë¶€í„° ì§„ì§œ ê°ì²´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤
```python
study_wrapper.optimize(
    objective,
    n_trials=10,
    parallelism=2,
    resources_requests={
        "cpu": "1",
        "memory": "500Mi",
    },
)
status = study_wrapper.get_status()  # ì§„í–‰ ìƒí™© í™•ì¸
print(status)
```
##### Methods
- `get_study` (): study_wrapper ê°€ ì•„ë‹Œ, optuna ì˜ [Study](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html) ë¥¼ ë°˜í™˜
- `optimize` (): zerooneai ì˜ kubernetes cluster ì—ì„œ ë³‘ë ¬ ì‹¤í–‰ë˜ëŠ” ìµœì í™”ë¥¼ ì‹¤í–‰
  - `objective` (Callable[oputna.trial, None]): optuna ì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ êµ¬í˜„í•´ì„œ ì‚¬ìš©í•˜ëŠ” Objective í•¨ìˆ˜ë¥¼ ì´ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬
  - `n_trials` (int): ì‹¤í–‰í•  ì „ì²´ trial ê°œìˆ˜ (default: 10) (failed or pruned ê°¯ìˆ˜ í¬í•¨)
  - `parallelism` (int): ë™ì‹œ ì‹¤í–‰ Pod ê°œìˆ˜ (default: 2)
  - `use_gpu` (bool): GPU ì‚¬ìš© ì—¬ë¶€ (default: False)
  - `runtime_image` (str): Docker ì´ë¯¸ì§€ (default: "ghcr.io/astral-sh/uv:python3.8-bookworm-slim" / "pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime"(use_gpu))
  - `requirements_list` (List[str]): ì¶”ê°€ ì„¤ì¹˜í•  íŒ¨í‚¤ì§€ ë¦¬ìŠ¤íŠ¸ (default: list ê°€ ë¹„ì–´ìˆì–´ë„ optuna, grpcio, protobuf, aiauto-client, optuna-dashboard ëŠ” ìë™ ì„¤ì¹˜)
  - `resources_requests` (dict): Pod ë¦¬ì†ŒìŠ¤ ìš”ì²­
    - `"cpu"`: (str) CPU ì½”ì–´ ìˆ˜ (default: "1" / "2"(use_gpu))
    - `"memory"`: (str) ë©”ëª¨ë¦¬ ìš©ëŸ‰ (default: "1Gi" / "4Gi"(use_gpu))
    - `"nvidia.com/gpu"`: (str) GPU ê°œìˆ˜ (default: "1"(use_gpu)) (max: 4)
- `get_status` (): í˜„ì¬ optimize ë¡œ ìƒì„±í•œ ë§ˆì§€ë§‰ trialBatch ë§Œì˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¨ë‹¤ TODO ìˆ˜ì •í•´ì•¼í•¨

#### TrialController
- Trial ì‹¤í–‰ ì¤‘ Optuna ì˜ save_note ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ note (AIAuto Dashboard ì—ì„œ í™•ì¸ ê°€ëŠ¥) ì— ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ê²Œ ë„ì™€ì£¼ëŠ” ê°ì²´
```python
import aiauto

def objective(trial):
    tc = aiauto.TrialController(trial)
    tc.log('Training started')
    # ... training code ...
    tc.flush()  # ë¡œê·¸ ì¦‰ì‹œ ì €ì¥
```
##### Parameters
- `trial` (optuna.trial.Trial, optuna.trial.FrozenTrial): objective í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ë„˜ì–´ì˜¤ëŠ” trial ì„ Wrapping í•´ì„œ trialController ë¥¼ ë§Œë“ ë‹¤
  - ask/tell ì¸ ê²½ìš°ë„ í˜¸í™© ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— FrozenTrail ë„ ì§€ì›  
##### Methods
- `get_trial` (): TrialController ê°ì²´ ìƒì„± ì‹œ ë§¤ê°œë³€ìˆ˜ë¡œ ë„£ì—ˆë˜ trial ì„ êº¼ë‚¸ë‹¤
- `log` (str): Optuna ì˜ save_note ì— ë¡œê·¸ë¥¼ ê¸°ë¡, ì„±ëŠ¥ìƒ ì´ìŠˆë¡œ ë²„í¼ì— ì €ì¥í•´ë‘ê³  5ê°œë¡œê·¸ë§ˆë‹¤/1ë¶„ë§ˆë‹¤ ì €ì¥í•œë‹¤
- `flush` (): 5ê°œ/1ë¶„ë§ˆë‹¤ ì¡°ê±´ì„ ë¬´ì‹œí•˜ê³  ì§€ê¸ˆ ë‹¹ì¥ ë¡œê·¸ë¥¼ ì €ì¥í•œë‹¤. Optuna Callback ê¸°ëŠ¥ìœ¼ë¡œ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ í˜¸ì¶œ ë¨

---

## ì¤‘ìš” ì£¼ì˜ì‚¬í•­

### âš ï¸ Objective í•¨ìˆ˜ ì‘ì„± ê·œì¹™

**ëª¨ë“  importëŠ” í•¨ìˆ˜ ë‚´ë¶€ì— ì‘ì„±í•˜ì„¸ìš”**:
```python
# âŒ ì˜ëª»ëœ ì˜ˆ
import torch

def objective(trial):
    model = torch.nn.Linear(10, 1)  # ì‹¤íŒ¨: torchë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
```

```python
# âœ… ì˜¬ë°”ë¥¸ ì˜ˆ
def objective(trial):
    import torch  # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import
    model = torch.nn.Linear(10, 1)
```

**ì´ìœ **: Objective í•¨ìˆ˜ëŠ” Kubernetes Podì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ë¡œì»¬ PCì˜ importê°€ ì „ë‹¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

### âš ï¸ ì¸ì ì§€ì • ê·œì¹™ (XOR)

**`direction` ë˜ëŠ” `directions` ì¤‘ í•˜ë‚˜ë§Œ ì§€ì •í•˜ì„¸ìš”** (ë™ì‹œ ì§€ì • ê¸ˆì§€):

```python
# âœ… ì˜¬ë°”ë¥¸ ex: ë‹¨ì¼ ëª©ì 
study = controller.create_study('exp1', direction='minimize')

# âœ… ì˜¬ë°”ë¥¸ ex: ë‹¤ì¤‘ ëª©ì 
study = controller.create_study('exp2', directions=['minimize', 'maximize'])

# âŒ ì˜ëª»ëœ ex: ë™ì‹œ ì§€ì •
study = controller.create_study('exp3', direction='minimize', directions=['minimize', 'maximize'])
```

**`requirements_file` ë˜ëŠ” `requirements_list` ì¤‘ í•˜ë‚˜ë§Œ ì§€ì •í•˜ì„¸ìš”** (ë™ì‹œ ì§€ì • ê¸ˆì§€):

```python
# âœ… ì˜¬ë°”ë¥¸ ex: íŒŒì¼ë¡œ ì§€ì •
study.optimize(objective, n_trials=10, requirements_file='requirements.txt')

# âœ… ì˜¬ë°”ë¥¸ ex: ë¦¬ìŠ¤íŠ¸ë¡œ ì§€ì •
study.optimize(objective, n_trials=10, requirements_list=['torch', 'numpy'])

# âŒ ì˜ëª»ëœ ex: ë™ì‹œ ì§€ì •
study.optimize(objective, n_trials=10,
               requirements_file='requirements.txt',
               requirements_list=['torch', 'numpy'])
```

### âš ï¸ Jupyter Notebook ì‚¬ìš© ì‹œ

**Python REPLì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ëŠ” Serializeí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.** `%%writefile` ë§¤ì§ ì»¤ë§¨ë“œë¡œ íŒŒì¼ì— ì €ì¥í•œ í›„ importí•˜ì„¸ìš”:

```python
%%writefile my_objective.py
def objective(trial):
    import aiauto
    tc = aiauto.TrialController(trial)
    x = trial.suggest_float('x', -10, 10)
    return x ** 2
```

```python
from my_objective import objective
study.optimize(objective, n_trials=10)
```

### âš ï¸ AIAutoController ì¬ì´ˆê¸°í™”

Artifact ì €ì¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ **objective í•¨ìˆ˜ ë‚´ë¶€**ì—ì„œ `AIAutoController`ë¥¼ ì¬ì´ˆê¸°í™”í•˜ì„¸ìš”:

```python
def objective(trial):
    import aiauto
    import optuna

    # Objective ë‚´ë¶€ì—ì„œ ì¬ì´ˆê¸°í™” (singletonì´ë¼ ë¬¸ì œì—†ìŒ)
    ac = aiauto.AIAutoController('your-token')

    # Artifact ì €ì¥
    artifact_id = optuna.artifacts.upload_artifact(
        artifact_store=ac.get_artifact_store(),
        storage=ac.get_storage(),
        study_or_trial=trial,
        file_path='model.pth',
    )
```

### âš ï¸ ë¡œê·¸ ì¶œë ¥ ë°©ë²•

**AIAuto Dashboardì—ì„œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ë ¤ë©´** `TrialController.log()`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:

```python
# âŒ ì˜ëª»ëœ ex: AIAuto Dashboardì—ì„œ í™•ì¸ ë¶ˆê°€
def objective(trial):
    print('Loss: 0.5')  # Pod ë¡œê·¸ì—ë§Œ ë‚¨ìŒ
    logger.info('Epoch 1')  # Pod ë¡œê·¸ì—ë§Œ ë‚¨ìŒ
```

```python
# âœ… ì˜¬ë°”ë¥¸ ex: AIAuto Dashboardì—ì„œ í™•ì¸ ê°€ëŠ¥
def objective(trial):
    import aiauto
    tc = aiauto.TrialController(trial)
    tc.log('Loss: 0.5')  # AIAuto Dashboardì— í‘œì‹œë¨
    tc.log('Epoch 1')
```

**AIAuto Dashboard ë¡œê·¸ í™•ì¸ ë°©ë²•**:
1. https://dashboard.common.aiauto.pangyo.ainode.ai ì ‘ì†
2. Study â†’ TrialBatch â†’ Pod í´ë¦­
3. "Logs" íƒ­ì—ì„œ ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸

### âš ï¸ Artifact ì €ì¥ ì œí•œ

- **ìë™ ì •ë¦¬**: ìƒìœ„ 5ê°œ trialì˜ artifactë§Œ ë³´ì¡´ë©ë‹ˆë‹¤ (ë””ìŠ¤í¬ ìš©ëŸ‰ ì ˆì•½)
- **ìš©ëŸ‰ ì œí•œ**: Front Workspace í˜ì´ì§€ì—ì„œ í˜„ì¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ê°€ëŠ¥
- **ìë™ ì ìš©**: `CallbackTopNArtifact`ëŠ” Runnerê°€ ìë™ìœ¼ë¡œ ì ìš©í•˜ë¯€ë¡œ ì‚¬ìš©ìê°€ ì‹ ê²½ ì“¸ í•„ìš” ì—†ìŠµë‹ˆë‹¤

### âš ï¸ Ask/Tell íŒ¨í„´ ì£¼ì˜ì‚¬í•­

Ask/Tell íŒ¨í„´ìœ¼ë¡œ trialì„ ìˆ˜ë™ ì œì–´í•˜ë©´:
- **ì‹¤í–‰ ìœ„ì¹˜**: ë¡œì»¬ PC (Kubernetes Pod ìƒì„± ì•ˆ ë¨)
- **TrialBatch ì¹´ìš´íŠ¸**: `optimize()` í˜¸ì¶œë¡œ ìƒê¸´ TrialBatchì™€ ë³„ë„ë¡œ ì§‘ê³„ë¨
- **í™•ì¸ ë°©ë²•**:
  - **Optuna Dashboard**: Study í˜ì´ì§€ì—ì„œ `user_attr.trialbatch_name='ask_tell_local'` í™•ì¸
  - **AIAuto Dashboard**: Study í˜ì´ì§€ì˜ "ask/tell trial ë³´ê¸°" ë‹¤ì´ì–¼ë¡œê·¸

### âš ï¸ ì˜ˆì•½ëœ user_attr í‚¤

ë‹¤ìŒ í‚¤ëŠ” ì‹œìŠ¤í…œì´ ì‚¬ìš©í•˜ë¯€ë¡œ **ì§ì ‘ ì„¤ì •í•˜ì§€ ë§ˆì„¸ìš”**:
- `pod_name`: Pod â†” Trial ë§¤ì¹­ìš©
- `artifact_id`: Artifact ë‹¤ìš´ë¡œë“œ ë§í¬
- `artifact_removed`: Artifact ì‚­ì œ í”Œë˜ê·¸
- `trialbatch_name`: TrialBatch ì‹ë³„ì

ë˜í•œ **`study.set_user_attr('note', ...)`ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”**. `TrialController.log()`ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## ê¸°ë³¸ ì‚¬ìš©ë²•

### 1. ê°„ë‹¨í•œ ìˆ˜í•™ í•¨ìˆ˜ ìµœì í™”

**ëª©í‘œ**: AIAuto ê¸°ë³¸ íë¦„ ì´í•´ (Study ìƒì„± â†’ optimize í˜¸ì¶œ â†’ ê²°ê³¼ í™•ì¸)



- TODO maximize minimize direction ë™ì‹œ ì•ˆë˜ëŠ”ê±°, ë™ì‹œì— í•˜ë ¤ë©´ [7-multi-objective-ìµœì í™”](#7-multi-objective-ìµœì í™”) ì°¸ì¡° 

```python
import aiauto
import optuna

# AIAuto ì´ˆê¸°í™”
ac = aiauto.AIAutoController('your-token')

# Study ìƒì„±
study = ac.create_study(
    study_name="simple_quadratic",
    direction="minimize",
    sampler=optuna.samplers.TPESampler(seed=42),
)

# Objective í•¨ìˆ˜ ì •ì˜
def objective(trial):
    import aiauto

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
    x = trial.suggest_float('x', -10, 10)
    y = trial.suggest_float('y', -10, 10)

    # ëª©ì  í•¨ìˆ˜ ê³„ì‚°: (x-2)^2 + (y-3)^2 ìµœì†Œí™”
    value = (x - 2) ** 2 + (y - 3) ** 2
    return value

# ìµœì í™” ì‹¤í–‰
study.optimize(
    objective,
    n_trials=20,
    parallelism=2,  # ë™ì‹œ ì‹¤í–‰ Pod ìˆ˜
)

# ê²°ê³¼ í™•ì¸
real_study = study.get_study()
print(f'Best value: {real_study.best_value:.4f}')
print(f'Best params: {real_study.best_params}')
```

**Optuna ê³µì‹ ë¬¸ì„œ**: [Optuna Tutorial](https://optuna.readthedocs.io/en/stable/tutorial/index.html)

---

### 2. ë¡œê·¸ ì¶œë ¥í•˜ê¸° (TrialController)

**ëª©í‘œ**: AIAuto Dashboardì—ì„œ Trial ì‹¤í–‰ ì¤‘ ë¡œê·¸ í™•ì¸

```python
def objective(trial):
    import aiauto

    # TrialController ìƒì„±
    tc = aiauto.TrialController(trial)

    x = trial.suggest_float('x', -10, 10)
    y = trial.suggest_float('y', -10, 10)

    # ë¡œê·¸ ì¶œë ¥ (Dashboardì— í‘œì‹œë¨)
    tc.log(f'Trial {trial.number}: x={x:.2f}, y={y:.2f}')

    value = (x - 2) ** 2 + (y - 3) ** 2
    tc.log(f'Objective value: {value:.4f}')

    # ë¡œê·¸ ì¦‰ì‹œ ì €ì¥ (Trial ì¢…ë£Œ ì‹œ ìë™ í˜¸ì¶œë˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œ ê°€ëŠ¥)
    tc.flush()

    return value
```

**AIAuto Dashboard ë¡œê·¸ í™•ì¸ ë°©ë²•**:
1. https://dashboard.common.aiauto.pangyo.ainode.ai ì ‘ì†
2. Study â†’ TrialBatch â†’ Pod í´ë¦­
3. "Logs" íƒ­ì—ì„œ ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸

**ë¡œê·¸ ì €ì¥ ì£¼ê¸°**:
- 5ê°œ ë¡œê·¸ë§ˆë‹¤ ìë™ ì €ì¥
- 1ë¶„ë§ˆë‹¤ ìë™ ì €ì¥
- `tc.flush()` í˜¸ì¶œ ì‹œ ì¦‰ì‹œ ì €ì¥

---

### 3. PyTorch ëª¨ë¸ í•™ìŠµ (Single Objective)

**ëª©í‘œ**: GPU ì‚¬ìš©, ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (Pruning ì—†ìŒ)

```python
import aiauto
import optuna

ac = aiauto.AIAutoController('your-token')

study = ac.create_study(
    study_name="pytorch_cifar10",
    direction="maximize",  # accuracy ìµœëŒ€í™”
)

def objective(trial):
    # ========== ëª¨ë“  importëŠ” í•¨ìˆ˜ ë‚´ë¶€ ==========
    import torch
    from torch import nn, optim
    from torch.utils.data import DataLoader, Subset
    from torchvision import transforms, datasets
    import aiauto

    tc = aiauto.TrialController(trial)

    # ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§ ==========
    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
    n_features = trial.suggest_int('n_features', 16, 128, step=16)

    tc.log(f'Hyperparameters: lr={lr:.6f}, batch_size={batch_size}, n_features={n_features}')

    # ========== ëª¨ë¸ ì •ì˜ ==========
    class SimpleCNN(nn.Module):
        def __init__(self, n_features):
            super().__init__()
            self.features = nn.Sequential(
                nn.Conv2d(3, n_features, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(n_features, n_features * 2, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2),
            )
            self.classifier = nn.Sequential(
                nn.Flatten(),
                nn.Linear(n_features * 2 * 8 * 8, 128),
                nn.ReLU(),
                nn.Dropout(0.5),
                nn.Linear(128, 10),
            )

        def forward(self, x):
            x = self.features(x)
            return self.classifier(x)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SimpleCNN(n_features).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    tc.log(f'Device: {device}')

    # ========== ë°ì´í„° ë¡œë”© (ì¼ë¶€ë§Œ ì‚¬ìš©: HPOëŠ” ë¹ ë¥´ê²Œ) ==========
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])

    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    valid_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

    # HPOë¥¼ ìœ„í•´ ì¼ë¶€ ë°ì´í„°ë§Œ ì‚¬ìš©
    train_subset = Subset(train_dataset, range(5000))
    valid_subset = Subset(valid_dataset, range(1000))

    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)
    valid_loader = DataLoader(valid_subset, batch_size=batch_size, shuffle=False)

    # ========== í•™ìŠµ ==========
    n_epochs = 5
    for epoch in range(n_epochs):
        model.train()
        train_loss = 0.0
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        train_loss /= len(train_loader)

        # ê²€ì¦
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for data, target in valid_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                _, predicted = torch.max(output.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()

        accuracy = correct / total
        tc.log(f'Epoch {epoch+1}/{n_epochs}: train_loss={train_loss:.4f}, accuracy={accuracy:.4f}')

    return accuracy

# ìµœì í™” ì‹¤í–‰
study.optimize(
    objective,
    n_trials=10,
    parallelism=2,
    use_gpu=True,  # GPU ì‚¬ìš©
    runtime_image='pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime',
    requirements_list=['torchvision'],
    resources_requests={
        "cpu": "2",
        "memory": "4Gi",
        "nvidia.com/gpu": "1",
    },
)
```

**í¬ì¸íŠ¸**:
- `use_gpu=True`: GPUê°€ í• ë‹¹ëœ Podì—ì„œ ì‹¤í–‰
- `runtime_image`: PyTorchê°€ ì„¤ì¹˜ëœ Docker ì´ë¯¸ì§€ ì§€ì •
- `requirements_list`: ì¶”ê°€ë¡œ ì„¤ì¹˜í•  íŒ¨í‚¤ì§€ (torchvision)
- `resources_requests`: Podì— í• ë‹¹í•  ë¦¬ì†ŒìŠ¤ (CPU, Memory, GPU)

---

### 4. PyTorch with Pruning (ì¡°ê¸° ì¢…ë£Œ)

**ëª©í‘œ**: ì„±ëŠ¥ì´ ë‚®ì€ Trialì„ ì¡°ê¸° ì¢…ë£Œí•˜ì—¬ ë¦¬ì†ŒìŠ¤ ì ˆì•½

**Pruningì´ë€?**: í•™ìŠµ ì¤‘ê°„ì— ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì€ trialì„ ìë™ìœ¼ë¡œ ì¤‘ë‹¨í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ë¥¸ trialë“¤ì˜ median ì„±ëŠ¥ë³´ë‹¤ ë‚®ìœ¼ë©´ í•´ë‹¹ trialì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.

```python
import optuna
import aiauto

ac = aiauto.AIAutoController('your-token')

# PatientPruner + MedianPruner ì¡°í•©
study = ac.create_study(
    study_name="pytorch_with_pruning",
    direction="maximize",
    pruner=optuna.pruners.PatientPruner(
        optuna.pruners.MedianPruner(),
        patience=2,  # 2 epoch ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
    ),
)

def objective(trial):
    import torch
    from torch import nn, optim
    import aiauto
    import optuna

    tc = aiauto.TrialController(trial)

    # ... (ì´ì „ ì˜ˆì œì™€ ë™ì¼í•œ ëª¨ë¸/ë°ì´í„° ì„¤ì •) ...

    min_epochs_for_pruning = 3  # ìµœì†Œ 3 epochì€ ì‹¤í–‰
    n_epochs = 10

    for epoch in range(n_epochs):
        # ... í•™ìŠµ ì½”ë“œ ...

        # ê²€ì¦ accuracy ê³„ì‚°
        accuracy = correct / total
        tc.log(f'Epoch {epoch+1}: accuracy={accuracy:.4f}')

        # Pruning ì²´í¬
        trial.report(accuracy, step=epoch)  # ì¤‘ê°„ ì„±ëŠ¥ ë³´ê³ 

        if epoch >= min_epochs_for_pruning:
            if trial.should_prune():  # Prunerê°€ ì¤‘ë‹¨ íŒë‹¨
                tc.log(f'Trial pruned at epoch {epoch+1}')
                raise optuna.TrialPruned()  # Trial ì¤‘ë‹¨

    return accuracy

study.optimize(
    objective,
    n_trials=20,
    parallelism=4,
    use_gpu=True,
    runtime_image='pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime',
    requirements_list=['torchvision'],
)
```

**Optuna Dashboardì—ì„œ Pruning í™•ì¸ ë°©ë²•**:
1. AIAuto Dashboardì—ì„œ Study í´ë¦­ â†’ "Open Optuna Dashboard"
2. Optimization History ê·¸ë˜í”„ì—ì„œ PRUNED trial í™•ì¸ (ë¹¨ê°„ìƒ‰)
3. Intermediate Values íƒ­ì—ì„œ trial.report() ê¸°ë¡ í™•ì¸

**í¬ì¸íŠ¸**:
- `trial.report(value, step)`: ì¤‘ê°„ ì„±ëŠ¥ì„ Prunerì—ê²Œ ë³´ê³ 
- `trial.should_prune()`: Prunerê°€ ì¤‘ë‹¨ íŒë‹¨ (Trueë©´ ì¤‘ë‹¨ ê¶Œì¥)
- `raise optuna.TrialPruned()`: Trial ì¦‰ì‹œ ì¤‘ë‹¨
- `min_epochs_for_pruning`: ìµœì†Œ epoch ìˆ˜ë§Œí¼ì€ ì‹¤í–‰ (ë„ˆë¬´ ë¹¨ë¦¬ ì¤‘ë‹¨í•˜ì§€ ì•Šë„ë¡)

---

### 5. ê°„ë‹¨í•œ ë‹¤í•­ì‹ + Pruning

**ëª©í‘œ**: ìˆ˜í•™ í•¨ìˆ˜ë¡œ Pruning ë™ì‘ ì›ë¦¬ ì´í•´

```python
import aiauto
import optuna

ac = aiauto.AIAutoController('your-token')

study = ac.create_study(
    study_name="polynomial_pruning",
    direction="maximize",
    pruner=optuna.pruners.PatientPruner(
        optuna.pruners.MedianPruner(),
        patience=4,
    ),
)

def objective(trial):
    import aiauto
    import optuna
    import numpy as np
    from numpy.polynomial.chebyshev import Chebyshev

    tc = aiauto.TrialController(trial)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„°: 0~1 ì‚¬ì´ì˜ í˜¼í•© ë¹„ìœ¨
    r = trial.suggest_float('rand_value', 0.0, 1.0)
    tc.log(f'Trial {trial.number}: rand_value={r:.6f}')

    # ë³µì¡í•œ ë‹¤í•­ í•¨ìˆ˜ ì •ì˜ (Chebyshev + Wilkinson)
    Tc = Chebyshev.basis(35).convert(kind=np.polynomial.Polynomial)
    coef_A = Tc.coef

    roots = np.arange(1, 21, dtype=float)
    xroots = (roots - 10.5) / 9.5
    coef_B = np.poly(xroots)

    X = np.linspace(-1.2, 1.2, 2048)
    pA = np.polyval(coef_A[::-1], X)
    pB = np.polyval(coef_B, X)
    pA /= (np.std(pA) + 1e-12)
    pB /= (np.std(pB) + 1e-12)

    target = pA
    pred = (1.0 - r) * pA + r * pB

    rng = np.random.RandomState(trial.number + 12345)

    # 50 step ë™ì•ˆ ì ì§„ì ìœ¼ë¡œ ì„±ëŠ¥ ì¸¡ì •
    for step in range(1, 51):
        m = 32 + step * 16
        idx = rng.choice(len(X), size=min(m, len(X)), replace=False)

        err = pred[idx] - target[idx]
        mse = float(np.mean(err * err))
        noise = 0.002 * np.sin(0.5 * step) + 0.002 * rng.randn()
        score = -(mse + noise)  # maximize

        if step == 1 or step % 10 == 0 or step == 50:
            tc.log(f'Step {step}: mse={mse:.6e}, score={score:.6f}')

        # Pruning ì²´í¬
        trial.report(score, step=step)
        if trial.should_prune():
            tc.log(f'Pruned at step {step}, score={score:.6f}')
            raise optuna.TrialPruned()

    return score

study.optimize(
    objective,
    n_trials=10,
    parallelism=4,
    use_gpu=False,
    runtime_image='ghcr.io/astral-sh/uv:python3.8-bookworm-slim',
    requirements_list=['numpy'],
)
```

**ì´ ì˜ˆì œì˜ ì˜ë¯¸**: ë³µì¡í•œ ë‹¤í•­ì‹ ìµœì í™”ë¥¼ í†µí•´ Pruningì´ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ì´ ë‚®ì€ trialì€ 50 stepì„ ë‹¤ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì¤‘ê°„ì— ì¤‘ë‹¨ë©ë‹ˆë‹¤.

---

### 6. Checkpoint ì €ì¥ (Artifact)

**ëª©í‘œ**: ëª¨ë¸ íŒŒì¼ ì €ì¥ ë° Dashboardì—ì„œ ë‹¤ìš´ë¡œë“œ

ì´ì „ PyTorch ì˜ˆì œì— Artifact ì €ì¥ ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤:




- TODO ask/tell ì€ ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê²ƒì´ë¯€ë¡œ artifact ì €ì¥ ì•ˆ ë˜ë¯€ë¡œ ì£¼ì˜

```python
def objective(trial):
    import torch
    from torch import nn, optim
    import aiauto
    import optuna
    from os.path import join

    # Objective ë‚´ë¶€ì—ì„œ AIAutoController ì¬ì´ˆê¸°í™” í•„ìˆ˜
    ac = aiauto.AIAutoController('your-token')
    tc = aiauto.TrialController(trial)

    # ... (í•™ìŠµ ì½”ë“œ) ...

    # í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥
    model_filename = f'model_trial_{trial.number}.pth'
    model_path = join(ac.get_artifact_tmp_dir(), model_filename)

    # íŒŒì¼ ì„ì‹œ ì €ì¥ì‹œ get_artifact_tmp_dir() ë¡œ ì–»ì€ ê²½ë¡œì— ì €ì¥
    torch.save({
        'epoch': n_epochs,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'accuracy': accuracy,
        'hyperparameters': trial.params,
    }, model_path)

    # Artifact ì—…ë¡œë“œ
    try:
        artifact_id = optuna.artifacts.upload_artifact(
            artifact_store=ac.get_artifact_store(),
            storage=ac.get_storage(),
            study_or_trial=trial,
            file_path=model_path,
        )
        trial.set_user_attr('artifact_id', artifact_id)
        tc.log(f'Artifact saved: {model_filename}, artifact_id={artifact_id}')
    except Exception as e:
        tc.log(f'Artifact upload failed: {e}')

    return accuracy
```

**í¬ì¸íŠ¸**:
- `ac.get_artifact_tmp_dir()`: ì„ì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (Pod ë‚´ë¶€)
- `ac.get_artifact_store()`: Artifact ì €ì¥ì†Œ ê°ì²´
- `trial.set_user_attr('artifact_id', artifact_id)`: Dashboardì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ í‘œì‹œ
- **CallbackTopNArtifact ìë™ ì •ë¦¬**: ìƒìœ„ 5ê°œ trialë§Œ ìœ ì§€ (Runnerê°€ ìë™ ì ìš©)
- **artifact_removed í”Œë˜ê·¸**: ì‚­ì œëœ artifactëŠ” Dashboardì—ì„œ Download ë²„íŠ¼ ìˆ¨ê¹€

**Pruningê³¼ ì¡°í•© ì‹œ ì£¼ì˜ì‚¬í•­**:

```python
def objective(trial):
    # ... í•™ìŠµ ì½”ë“œ ...

    for epoch in range(n_epochs):
        # ... í•™ìŠµ ...

        # Pruning ì²´í¬
        trial.report(accuracy, step=epoch)
        if trial.should_prune():
            tc.log(f'Pruned at epoch {epoch}')
            # âŒ ì—¬ê¸°ì„œ artifact ì €ì¥í•˜ë©´ ì•ˆ ë¨ (PRUNED trialì€ ì €ì¥ ë¶ˆí•„ìš”)
            raise optuna.TrialPruned()

    # âœ… COMPLETE trialë§Œ ì—¬ê¸° ë„ë‹¬ â†’ artifact ì €ì¥
    artifact_id = optuna.artifacts.upload_artifact(...)
```

**AIAuto Dashboardì—ì„œ Artifact ë‹¤ìš´ë¡œë“œ**:
1. https://dashboard.common.aiauto.pangyo.ainode.ai ì ‘ì†
2. Study â†’ Trial í´ë¦­
3. "Artifacts" íƒ­ì—ì„œ `artifact_id` í™•ì¸
4. "Download" ë²„íŠ¼ í´ë¦­ (artifact_removed=trueì¸ ê²½ìš° ë²„íŠ¼ ë¹„í™œì„±í™”)

**Artifact Store ìš©ëŸ‰ í™•ì¸**:
- Dashboard â†’ Workspace í˜ì´ì§€ â†’ "Artifact Store" ì„¹ì…˜ì—ì„œ ì‚¬ìš©ëŸ‰/ì´ëŸ‰ í™•ì¸

---

### 7. Multi-Objective ìµœì í™”

**ëª©í‘œ**: Accuracyì™€ FLOPSë¥¼ ë™ì‹œì— ìµœì í™” (Pareto front íƒìƒ‰)




- TODO ì›ë˜ maximize minimize direction ë™ì‹œì— ì•ˆ ë˜ì§€ë§Œ directions ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© í•˜ë©´ ëœë‹¤

```python
import optuna
import aiauto

ac = aiauto.AIAutoController('your-token')

# Multi-objective: accuracy ìµœëŒ€í™” + FLOPS ìµœì†Œí™”
study = ac.create_study(
    study_name="pytorch_multi_objective",
    directions=["maximize", "minimize"],  # 2ê°œì˜ ëª©í‘œ
)

def objective(trial):
    import torch
    from torch import nn
    from fvcore.nn import FlopCountAnalysis
    import aiauto

    ac = aiauto.AIAutoController('your-token')
    tc = aiauto.TrialController(trial)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    n_features = trial.suggest_int('n_features', 16, 128, step=16)
    n_layers = trial.suggest_int('n_layers', 2, 5)

    # ëª¨ë¸ ì •ì˜
    class SimpleCNN(nn.Module):
        def __init__(self, n_features, n_layers):
            super().__init__()
            layers = []
            in_channels = 3
            for _ in range(n_layers):
                layers.extend([
                    nn.Conv2d(in_channels, n_features, 3, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                ])
                in_channels = n_features
            self.features = nn.Sequential(*layers)
            # ... classifier ...

        def forward(self, x):
            return self.features(x)

    model = SimpleCNN(n_features, n_layers)

    # FLOPS ê³„ì‚°
    dummy_input = torch.randn(1, 3, 32, 32)
    flops = FlopCountAnalysis(model, dummy_input)
    total_flops = flops.total()

    tc.log(f'n_features={n_features}, n_layers={n_layers}, FLOPS={total_flops/1e6:.2f}M')

    # ... í•™ìŠµ ì½”ë“œ ...
    accuracy = 0.85  # í•™ìŠµ ê²°ê³¼

    # Multi-objective: 2ê°œ ê°’ ë°˜í™˜
    return accuracy, total_flops

study.optimize(
    objective,
    n_trials=20,
    parallelism=4,
    use_gpu=True,
    runtime_image='pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime',
    requirements_list=['torchvision', 'fvcore'],
)
```

**í¬ì¸íŠ¸**:
- `directions=["maximize", "minimize"]`: 2ê°œì˜ ëª©í‘œ ë°©í–¥ ì§€ì •
- `return accuracy, total_flops`: 2ê°œ ê°’ ë°˜í™˜
- **Pruning ë¯¸ì§€ì›**: Multi-objectiveì—ì„œëŠ” Pruningì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤

**Pareto front í™•ì¸**:
Dashboardì˜ "Pareto Front" ê·¸ë˜í”„ì—ì„œ Accuracyì™€ FLOPSì˜ trade-offë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### 8. PyTorch ëª¨ë“  ê¸°ëŠ¥ í†µí•©

**ëª©í‘œ**: TrialController ë¡œê·¸ + Multi-objective + Pruning + Artifact

```python
import optuna
import aiauto

ac = aiauto.AIAutoController('your-token')

study = ac.create_study(
    study_name="pytorch_all_features",
    directions=["maximize", "minimize"],  # accuracy + FLOPS
    pruner=optuna.pruners.PatientPruner(
        optuna.pruners.MedianPruner(),
        patience=2,
    ),
)

def objective(trial):
    import torch
    from torch import nn, optim
    from fvcore.nn import FlopCountAnalysis
    import optuna
    import aiauto
    from os.path import join

    ac = aiauto.AIAutoController('your-token')
    tc = aiauto.TrialController(trial)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    n_features = trial.suggest_int('n_features', 16, 128, step=16)
    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)

    tc.log(f'Hyperparameters: n_features={n_features}, lr={lr:.6f}')

    # ëª¨ë¸ ì •ì˜
    # ... (ì´ì „ ì˜ˆì œì™€ ë™ì¼) ...

    # FLOPS ê³„ì‚°
    dummy_input = torch.randn(1, 3, 32, 32)
    flops = FlopCountAnalysis(model, dummy_input).total()
    tc.log(f'FLOPS: {flops/1e6:.2f}M')

    # í•™ìŠµ
    n_epochs = 10
    for epoch in range(n_epochs):
        # ... í•™ìŠµ ì½”ë“œ ...

        accuracy = correct / total
        tc.log(f'Epoch {epoch+1}: accuracy={accuracy:.4f}')

        # Pruning ì²´í¬ (Multi-objectiveì—ì„œëŠ” ì²« ë²ˆì§¸ ëª©í‘œë¡œ pruning)
        trial.report(accuracy, step=epoch)
        if epoch >= 3 and trial.should_prune():
            tc.log(f'Pruned at epoch {epoch+1}')
            raise optuna.TrialPruned()

    # Artifact ì €ì¥ (COMPLETE trialë§Œ)
    model_filename = f'model_trial_{trial.number}.pth'
    model_path = join(ac.get_artifact_tmp_dir(), model_filename)
    torch.save(model.state_dict(), model_path)

    artifact_id = optuna.artifacts.upload_artifact(
        artifact_store=ac.get_artifact_store(),
        storage=ac.get_storage(),
        study_or_trial=trial,
        file_path=model_path,
    )
    trial.set_user_attr('artifact_id', artifact_id)
    tc.log(f'Artifact saved: artifact_id={artifact_id}')

    return accuracy, flops

study.optimize(
    objective,
    n_trials=20,
    parallelism=4,
    use_gpu=True,
    runtime_image='pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime',
    requirements_list=['torchvision', 'fvcore'],
)
```

**í†µí•©ëœ ê¸°ëŠ¥**:
- âœ… TrialController ë¡œê·¸
- âœ… Multi-objective (accuracy + FLOPS)
- âœ… Pruning (ì¡°ê¸° ì¢…ë£Œ)
- âœ… Artifact ì €ì¥ (ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸)

---

### 9. HPO â†’ Best Trialë¡œ ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ

**ëª©í‘œ**: ì¼ë¶€ ë°ì´í„°ë¡œ ë¹ ë¥´ê²Œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ê³ , best trialì˜ ì„¤ì •ìœ¼ë¡œ ì „ì²´ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ìµœì¢… ëª¨ë¸ ì €ì¥

**ì „ëµ**:
1. **HPO ë‹¨ê³„**: ë°ì´í„° ì¼ë¶€ë§Œ ê³¨ê³ ë£¨ ì„ íƒí•˜ì—¬ ë¹ ë¥´ê²Œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ (artifact ì €ì¥ ì•ˆ í•¨)
2. **ì¬í•™ìŠµ ë‹¨ê³„**: Best trialì˜ íŒŒë¼ë¯¸í„°ë¡œ ì „ì²´ ë°ì´í„° í•™ìŠµ (artifact ì €ì¥)

```python
import optuna
import aiauto

ac = aiauto.AIAutoController('your-token')

study = ac.create_study(
    study_name="hpo_then_full_training",
    direction="maximize",
    pruner=optuna.pruners.MedianPruner(),
)

# ==================== 1ë‹¨ê³„: ì¼ë¶€ ë°ì´í„°ë¡œ HPO ====================
def objective(trial):
    from typing import List
    import torch
    from torch import nn, optim
    from torch.utils.data import DataLoader, Subset, random_split
    from torchvision import datasets, transforms
    import torch.nn.functional as F
    from os.path import join
    from optuna.artifacts import upload_artifact
    import optuna
    import aiauto

    ac = aiauto.AIAutoController('your-token')  # artifact ì ‘ê·¼ìš©
    tc = aiauto.TrialController(trial)

    # ===================== Neural Network ëª¨ë¸ ì •ì˜ ====================
    class Net(nn.Module):
        def __init__(self, features: List[int], dropout: float, dims: List[int]):
            if len(features) != 3:
                raise ValueError("Feature list must have three elements")
            if len(dims) > 3:
                raise ValueError("Dimension list must have less than three elements")

            super().__init__()

            layers = [
                nn.Conv2d(3, features[0], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
                nn.Conv2d(features[0], features[1], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
                nn.Conv2d(features[1], features[2], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
                nn.Flatten(),
            ]

            input_dim = features[2] * 4 * 4
            for dim in dims:
                layers.append(nn.Linear(input_dim, dim))
                layers.append(nn.ReLU())
                layers.append(nn.Dropout(dropout))
                input_dim = dim

            layers.append(nn.Linear(input_dim, 10))
            self.layers = nn.Sequential(*layers)

        def forward(self, x):
            logits = self.layers(x)
            return F.log_softmax(logits, dim=1)

    # ================== í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§ ====================
    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])
    lr = trial.suggest_float('learning_rate', 0.001, 0.3, log=True)
    momentum = trial.suggest_float('momentum', 0.0, 1.0, step=0.05)
    features = [trial.suggest_int(f'feature{i}', 4, 64, log=True) for i in range(3)]
    dropout = trial.suggest_float('dropout', 0.2, 0.5)
    n_layers = trial.suggest_int('n_layers', 1, 3)
    dims = [trial.suggest_int(f'dims{i}', 4, 128, log=True) for i in range(n_layers)]
    epochs = trial.suggest_int('epochs', 20, 300, step=10)

    # ğŸ”´ í•µì‹¬: ë°ì´í„° ê³¨ê³ ë£¨ ì„ íƒ (ì—¬ëŸ¬ trialì´ ë‹¤ë¥¸ êµ¬ê°„ íƒìƒ‰)
    data_fraction_number = trial.suggest_categorical('data_fraction_number', [4, 8])
    data_subset_idx = trial.suggest_int('data_subset_idx', 0, data_fraction_number - 1)

    tc.log(f'batch_size={batch_size}, lr={lr:.6f}, momentum={momentum}, features={features}, dropout={dropout}, dims={dims}, epochs={epochs}')
    tc.log(f'data_fraction_number={data_fraction_number}, data_subset_idx={data_subset_idx}')

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = Net(features, dropout, dims).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)

    # ================== CIFAR-10 ë°ì´í„° ì¤€ë¹„ ====================
    dataset = datasets.CIFAR10(
        root="/tmp/cifar10",
        train=True,
        download=True,
        transform=transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]),
    )

    # train/valid ë¶„ë¦¬ (70:30, seed ê³ ì •ìœ¼ë¡œ ì¬í˜„ì„± ë³´ì¥)
    n_total = len(dataset)
    n_valid = int(n_total * 0.3)
    n_train = n_total - n_valid
    train_set, valid_set = random_split(
        dataset,
        [n_train, n_valid],
        generator=torch.Generator().manual_seed(42),
    )

    # ğŸ”´ í•µì‹¬: ë°ì´í„°ë¥¼ ê³¨ê³ ë£¨ ì„ íƒí•˜ëŠ” ë¡œì§
    if data_fraction_number > 1:
        def get_data_subset(data_set, fraction_number, idx):
            """ë°ì´í„°ë¥¼ fraction_numberê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ idxë²ˆì§¸ êµ¬ê°„ ì„ íƒ"""
            subset_size = len(data_set) // fraction_number
            start_idx = idx * subset_size
            end_idx = start_idx + subset_size if idx < fraction_number - 1 else len(data_set)
            indices = list(range(start_idx, end_idx))
            return Subset(data_set, indices)

        train_set = get_data_subset(train_set, data_fraction_number, data_subset_idx)
        valid_set = get_data_subset(valid_set, data_fraction_number, data_subset_idx)
        tc.log(f'Subset: train={len(train_set)}, valid={len(valid_set)}')

    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)
    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=2)

    # ================== í•™ìŠµ ë° ê²€ì¦ ====================
    tc.log('Start subset dataset training...')
    min_epochs_for_pruning = max(50, epochs // 5)

    for epoch in range(epochs):
        # í•™ìŠµ
        model.train()
        for batch_idx, (inputs, targets) in enumerate(train_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            if batch_idx % (len(train_loader) // 4) == 0:
                tc.log(f'epoch: {epoch}, batch: {batch_idx}, loss: {loss.item():.4f}')
            loss.backward()
            optimizer.step()

        # ê²€ì¦
        model.eval()
        correct, total = 0, 0
        with torch.no_grad():
            for inputs, targets in valid_loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                _, pred = torch.max(outputs, 1)
                total += targets.size(0)
                correct += (pred == targets).sum().item()

        accuracy = correct / total
        tc.log(f'epoch: {epoch}, accuracy for valid: {accuracy:.4f}')

        # Pruning (ìµœì†Œ epoch í›„ë¶€í„°ë§Œ)
        trial.report(accuracy, epoch)
        if epoch >= min_epochs_for_pruning and trial.should_prune():
            tc.log(f'Trial pruned at epoch {epoch}')
            raise optuna.TrialPruned()

    # Artifact ì €ì¥ (COMPLETE trialë§Œ)
    try:
        filename = f'{trial.study.study_name}_{trial.number}.pt'
        model_path = join(ac.get_artifact_tmp_dir(), filename)
        torch.save(model.state_dict(), model_path)
        artifact_id = upload_artifact(
            artifact_store=ac.get_artifact_store(),
            storage=ac.get_storage(),
            study_or_trial=trial,
            file_path=model_path,
        )
        trial.set_user_attr('artifact_id', artifact_id)
    except Exception as e:
        tc.log(f'Fail to save model: {e}')

    return accuracy

# HPO ì‹¤í–‰
study.optimize(
    objective,
    n_trials=20,
    parallelism=4,
    use_gpu=True,
    requirements_list=['torch', 'torchvision'],
)

# ==================== 2ë‹¨ê³„: Best trialë¡œ ì „ì²´ ë°ì´í„° í•™ìŠµ ====================
def objective_detailed(trial):
    """Best trialì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì „ì²´ ë°ì´í„° í•™ìŠµ"""
    from typing import List
    import torch
    from torch import nn, optim
    from torch.utils.data import DataLoader
    from torchvision import datasets, transforms
    import torch.nn.functional as F
    from os.path import join
    from optuna.artifacts import upload_artifact
    import optuna
    import aiauto

    ac = aiauto.AIAutoController('your-token')
    tc = aiauto.TrialController(trial)

    # ===================== Neural Network ëª¨ë¸ ì •ì˜ (ë™ì¼) ====================
    class Net(nn.Module):
        def __init__(self, features: List[int], dropout: float, dims: List[int]):
            if len(features) != 3:
                raise ValueError("Feature list must have three elements")
            if len(dims) > 3:
                raise ValueError("Dimension list must have less than three elements")

            super().__init__()

            layers = [
                nn.Conv2d(3, features[0], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
                nn.Conv2d(features[0], features[1], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
                nn.Conv2d(features[1], features[2], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
                nn.Flatten(),
            ]

            input_dim = features[2] * 4 * 4
            for dim in dims:
                layers.append(nn.Linear(input_dim, dim))
                layers.append(nn.ReLU())
                layers.append(nn.Dropout(dropout))
                input_dim = dim

            layers.append(nn.Linear(input_dim, 10))
            self.layers = nn.Sequential(*layers)

        def forward(self, x):
            logits = self.layers(x)
            return F.log_softmax(logits, dim=1)

    # Best trialì˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©
    batch_size = trial.params['batch_size']
    lr = trial.params['learning_rate']
    momentum = trial.params['momentum']
    features = [trial.params[f'feature{i}'] for i in range(3)]
    dropout = trial.params['dropout']
    n_layers = trial.params['n_layers']
    dims = [trial.params[f'dims{i}'] for i in range(n_layers)]
    epochs = trial.params['epochs']

    tc.log(f'Full training with best params: lr={lr:.6f}, features={features}, dropout={dropout}, dims={dims}')

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = Net(features, dropout, dims).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)

    # ì „ì²´ ë°ì´í„° ë¡œë“œ
    full_train = datasets.CIFAR10(
        root="/tmp/cifar10",
        train=True,
        download=True,
        transform=transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]),
    )
    test_dataset = datasets.CIFAR10(
        root="/tmp/cifar10",
        train=False,
        download=True,
        transform=transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]),
    )

    tc.log(f'Full dataset: train={len(full_train)}, test={len(test_dataset)}')

    train_loader = DataLoader(full_train, batch_size=batch_size, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

    # ì „ì²´ ë°ì´í„° í•™ìŠµ
    tc.log('Start full dataset training...')
    for epoch in range(epochs):
        model.train()
        for batch_idx, (inputs, targets) in enumerate(train_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            if batch_idx % (len(train_loader) // 4) == 0:
                tc.log(f'Epoch {epoch}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')
            loss.backward()
            optimizer.step()

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    try:
        filename = f'{trial.study.study_name}_{trial.number}.pt'
        model_path = join(ac.get_artifact_tmp_dir(), filename)
        torch.save(model.state_dict(), model_path)
        artifact_id = upload_artifact(
            artifact_store=ac.get_artifact_store(),
            storage=ac.get_storage(),
            study_or_trial=trial,
            file_path=model_path,
        )
        trial.set_user_attr('artifact_id', artifact_id)
        tc.log(f'Model saved: artifact_id={artifact_id}')
    except Exception as e:
        tc.log(f'Fail to save model: {e}')

    # í…ŒìŠ¤íŠ¸ ì •í™•ë„ ê³„ì‚°
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, pred = torch.max(outputs, 1)
            total += targets.size(0)
            correct += (pred == targets).sum().item()

    accuracy = correct / total
    tc.log(f'Test accuracy: {accuracy:.4f}')

    return accuracy

# Best trialì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì „ì²´ ë°ì´í„° í•™ìŠµ
real_study = study.get_study()
study.enqueue_trial(real_study.best_trial)

study.optimize(
    objective_detailed,
    n_trials=1,
    parallelism=1,
    use_gpu=True,
    requirements_list=['torch', 'torchvision'],
)
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **ë°ì´í„° ê³¨ê³ ë£¨ íƒìƒ‰**: `data_fraction_number`(4 ë˜ëŠ” 8)ì™€ `data_subset_idx`ë¡œ ì—¬ëŸ¬ trialì´ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ë¶€ë¶„ì„ í•™ìŠµ
  - **ì´ìœ **: ëª¨ë“  trialì´ ë™ì¼í•œ ë°ì´í„° ë¶€ë¶„(ex: ì• 10%)ë§Œ í•™ìŠµí•˜ë©´ íŠ¹ì • íŒ¨í„´ì— í¸í–¥ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì²´ ë°ì´í„° ì˜ì—­ì„ ê³ ë¥´ê²Œ íƒìƒ‰í•˜ë©´ ë” ì¼ë°˜í™”ëœ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  - ex: `data_fraction_number=4, idx=0` â†’ 0~25% ë°ì´í„°, `idx=1` â†’ 25~50% ë°ì´í„°
  - ëª¨ë“  trialì´ ì• 10%ë§Œ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì „ì²´ ë°ì´í„°ë¥¼ ê³¨ê³ ë£¨ íƒìƒ‰
- **í’ë¶€í•œ íƒìƒ‰ ê³µê°„**: 3ê°œ Conv + ê°€ë³€ FC êµ¬ì¡°, dropout, SGD+momentum ë“± ì´ 9ê°œ í•˜ì´í¼íŒŒë¼ë¯¸í„°
- **train/valid ë¶„ë¦¬**: random_splitìœ¼ë¡œ 70:30 ë¶„í• , seed=42ë¡œ ì¬í˜„ì„± ë³´ì¥
- **Best trial ì¬ì‚¬ìš©**: `study.enqueue_trial(real_study.best_trial)`ë¡œ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ
- **Artifact ì €ì¥**: ì „ì²´ ë°ì´í„° í•™ìŠµ ì‹œì—ë§Œ ì €ì¥ (HPOì—ì„œëŠ” ì €ì¥ ì•ˆ í•¨)

---

### 10. Ask/Tell íŒ¨í„´ (ê³ ê¸‰)

**ëª©í‘œ**: ë¡œì»¬ PCì—ì„œ Trialì„ ìˆ˜ë™ìœ¼ë¡œ ì œì–´ (Kubernetes Pod ìƒì„± ì•ˆ ë¨)

Ask/Tell íŒ¨í„´ì€ ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤:
- ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ í•™ìŠµ ê²°ê³¼ë¥¼ ë°›ì•„ì™€ì•¼ í•  ë•Œ
- Trial ì‹¤í–‰ íƒ€ì´ë°ì„ ìˆ˜ë™ìœ¼ë¡œ ì œì–´í•˜ê³  ì‹¶ì„ ë•Œ
- ë¡œì»¬ PCì—ì„œ ë¹ ë¥¸ ì‹¤í—˜ì„ í•˜ê³  ì‹¶ì„ ë•Œ






- TODO ask/tell ì€ ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê²ƒì´ë¯€ë¡œ artifact ì €ì¥ ì•ˆ ë˜ë¯€ë¡œ ì£¼ì˜

```python
import aiauto
import optuna

ac = aiauto.AIAutoController('your-token')

# Study ìƒì„±
study_wrapper = ac.create_study('ask_tell_example', direction='minimize')
study = study_wrapper.get_study()  # Optuna Study ê°ì²´ ê°€ì ¸ì˜¤ê¸°

# âš ï¸ ê²½ê³ : study.ask() í˜¸ì¶œ ì‹œ ë¡œì»¬ì—ì„œ ì‹¤í–‰ë¨ (Kubernetes Pod ìƒì„± ì•ˆ ë¨)
# ë¡œì»¬ PCì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°€ë²¼ìš´ ì‘ì—…ì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”

# Trial ìš”ì²­ (ask)
trial = study.ask()
print(f'Trial {trial.number} started (locally)')

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
x = trial.suggest_float('x', -10, 10)
y = trial.suggest_float('y', -10, 10)

# ëª©ì  í•¨ìˆ˜ ê³„ì‚° (ë¡œì»¬ PCì—ì„œ ì‹¤í–‰)
value = (x - 2) ** 2 + (y - 3) ** 2

# ê²°ê³¼ ë³´ê³  (tell)
study.tell(trial, value)
print(f'Trial {trial.number} completed: value={value:.4f}')

# ì—¬ëŸ¬ trial ë°˜ë³µ
for _ in range(5):
    trial = study.ask()
    x = trial.suggest_float('x', -10, 10)
    y = trial.suggest_float('y', -10, 10)
    value = (x - 2) ** 2 + (y - 3) ** 2
    study.tell(trial, value)
```

**í¬ì¸íŠ¸**:
- **ë¡œì»¬ ì‹¤í–‰**: `study.ask()` í˜¸ì¶œ ì‹œ Kubernetes Podê°€ ìƒì„±ë˜ì§€ ì•Šê³  ë¡œì»¬ PCì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤
- **trialbatch_name='ask_tell_local' ìë™ ì„¤ì •**: Python clientê°€ ìë™ìœ¼ë¡œ user_attrì— ì„¤ì •í•©ë‹ˆë‹¤
- **TrialBatch countì™€ ë³„ê°œ**: `optimize()` í˜¸ì¶œë¡œ ìƒê¸´ TrialBatchì™€ ë³„ë„ë¡œ ì§‘ê³„ë©ë‹ˆë‹¤

**ask/tell Trial í™•ì¸ ë°©ë²•**:
1. **AIAuto Dashboard** (https://dashboard.common.aiauto.pangyo.ainode.ai):
   - Study í˜ì´ì§€ â†’ "Ask/Tell Trials" ë‹¤ì´ì–¼ë¡œê·¸ì—ì„œ ë¡œì»¬ ì‹¤í–‰ trial ëª©ë¡ í™•ì¸
2. **Optuna Dashboard**:
   - Study í˜ì´ì§€ì—ì„œ `user_attr.trialbatch_name='ask_tell_local'` í•„í„°ë§í•˜ì—¬ í™•ì¸

**ì£¼ì˜**: ask/tellë¡œ ìƒì„±í•œ trialì€ `optimize(n_trials=10)` ì¹´ìš´íŠ¸ì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ë¬¸ì œ í•´ê²°

### Q: "ModuleNotFoundError: No module named 'xxx'" ì—ëŸ¬
- ì›ì¸: Objective í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ importí•˜ì§€ ì•Šì•˜ê±°ë‚˜, `requirements_list`ì— íŒ¨í‚¤ì§€ë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
- í•´ê²°:
  1. Importë¥¼ í•¨ìˆ˜ ë‚´ë¶€ë¡œ ì´ë™
  2. `requirements_list`ì— íŒ¨í‚¤ì§€ ì¶”ê°€
```python
study.optimize(
    objective,
    requirements_list=['torch', 'torchvision', 'numpy'],
)
```

### Q: ë¡œê·¸ê°€ Dashboardì— í‘œì‹œë˜ì§€ ì•ŠìŒ
- ì›ì¸: `print()` ë˜ëŠ” `logger`ë¥¼ ì‚¬ìš©í•¨
- í•´ê²°: `TrialController.log()` ì‚¬ìš©
```python
def objective(trial):
    import aiauto
    tc = aiauto.TrialController(trial)
    tc.log('This will appear in Dashboard')
```

### Q: Artifact ì €ì¥ì´ ì‹¤íŒ¨í•¨
- ì›ì¸: Objective ë‚´ë¶€ì—ì„œ `AIAutoController`ë¥¼ ì¬ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
- í•´ê²°:
```python
def objective(trial):
    import aiauto
    ac = aiauto.AIAutoController('your-token')  # objective í•¨ìˆ˜ ì•ˆì—ì„œ ì¬ì´ˆê¸°í™” í•„ìˆ˜
    # ... artifact ì €ì¥ ...
```

### Q: Pruningì´ ë™ì‘í•˜ì§€ ì•ŠìŒ
- ì›ì¸: `trial.report()` í˜¸ì¶œ ëˆ„ë½ ë˜ëŠ” Multi-objectiveì—ì„œ Pruning ì‚¬ìš©
- í•´ê²°:
  - Single-objectiveì—ì„œë§Œ Pruning ì‚¬ìš© ê°€ëŠ¥
  - ë§¤ epochë§ˆë‹¤ `trial.report(value, step)` í˜¸ì¶œ
  - `trial.should_prune()` ì²´í¬ í›„ `raise optuna.TrialPruned()`
