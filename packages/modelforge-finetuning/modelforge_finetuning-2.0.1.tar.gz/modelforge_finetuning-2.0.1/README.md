# ModelForge üîß‚ö°

[![PyPI Downloads](https://static.pepy.tech/personalized-badge/modelforge-finetuning?period=total&units=INTERNATIONAL_SYSTEM&left_color=BLACK&right_color=BLUE&left_text=downloads)](https://pepy.tech/projects/modelforge-finetuning)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/)
[![Version](https://img.shields.io/badge/version-2.0.1-blue)](https://github.com/RETR0-OS/ModelForge)

**Fine-tune LLMs on your laptop's GPU‚Äîno code, no PhD, no hassle.**

ModelForge v2.0 is a complete architectural overhaul bringing **2x faster training**, modular providers, advanced strategies, and production-ready code quality.

![logo](https://github.com/user-attachments/assets/12b3545d-0e8b-4460-9291-d0786c9cb0fa)

## ‚ú® What's New in v2.0

- üöÄ **2x Faster Training** with Unsloth provider
- üß© **Multiple Providers**: HuggingFace, Unsloth (more coming!)
- üéØ **Advanced Strategies**: SFT, QLoRA, RLHF, DPO
- üìä **Built-in Evaluation** with task-specific metrics
- üèóÔ∏è **Modular Architecture** for easy extensibility
- üîí **Production-Ready** with proper error handling and logging

**[See What's New in v2.0 ‚Üí](docs/getting-started/whats-new.md)**

## üöÄ Features

- **GPU-Powered Fine-Tuning**: Optimized for NVIDIA GPUs (even 4GB VRAM)
- **One-Click Workflow**: Upload data ‚Üí Configure ‚Üí Train ‚Üí Test
- **Hardware-Aware**: Auto-detects GPU and recommends optimal models
- **No-Code UI**: Beautiful React interface, no CLI or notebooks
- **Multiple Providers**: HuggingFace (standard) or Unsloth (2x faster)
- **Advanced Strategies**: SFT, QLoRA, RLHF, DPO support
- **Automatic Evaluation**: Built-in metrics for all tasks

## üìñ Supported Tasks

- **Text Generation**: Chatbots, instruction following, code generation, creative writing
- **Summarization**: Document condensing, article summarization, meeting notes
- **Question Answering**: RAG systems, document search, FAQ bots

## üéØ Quick Start

### Prerequisites

- **Python 3.11.x** (Python 3.12 not yet supported)
- **NVIDIA GPU** with 4GB+ VRAM (6GB+ recommended)
- **CUDA** installed and configured
- **HuggingFace Account** with access token ([Get one here](https://huggingface.co/settings/tokens))
- **Linux or Windows** operating system

> **‚ö†Ô∏è macOS is NOT supported.** ModelForge requires NVIDIA CUDA which is not available on macOS. Use Linux or Windows with NVIDIA GPU.
> 
> **Windows Users**: See [Windows Installation Guide](docs/installation/windows.md) for platform-specific instructions, especially for Unsloth support.

### Installation

```bash
# Install ModelForge
pip install modelforge-finetuning

# Install PyTorch with CUDA support
# Visit https://pytorch.org/get-started/locally/ for your CUDA version
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

### Set HuggingFace Token

**Linux:**
```bash
export HUGGINGFACE_TOKEN=your_token_here
```

**Windows PowerShell:**
```powershell
$env:HUGGINGFACE_TOKEN="your_token_here"
```

**Or use .env file:**
```bash
echo "HUGGINGFACE_TOKEN=your_token_here" > .env
```

### Run ModelForge

```bash
modelforge run
```

Open your browser to **http://localhost:8000** and start training!

**[Full Quick Start Guide ‚Üí](docs/getting-started/quickstart.md)**

## üìö Documentation

### Getting Started
- **[Quick Start Guide](docs/getting-started/quickstart.md)** - Get up and running in 5 minutes
- **[What's New in v2.0](docs/getting-started/whats-new.md)** - Major features and improvements

### Installation
- **[Windows Installation](docs/installation/windows.md)** - Complete Windows setup (including WSL and Docker)
- **[Linux Installation](docs/installation/linux.md)** - Linux setup guide
- **[Post-Installation](docs/installation/post-installation.md)** - Initial configuration

### Configuration & Usage
- **[Configuration Guide](docs/configuration/configuration-guide.md)** - All configuration options
- **[Dataset Formats](docs/configuration/dataset-formats.md)** - Preparing your training data
- **[Training Tasks](docs/configuration/training-tasks.md)** - Understanding different tasks
- **[Hardware Profiles](docs/configuration/hardware-profiles.md)** - Optimizing for your GPU

### Providers
- **[Provider Overview](docs/providers/overview.md)** - Understanding providers
- **[HuggingFace Provider](docs/providers/huggingface.md)** - Standard HuggingFace models
- **[Unsloth Provider](docs/providers/unsloth.md)** - 2x faster training

### Training Strategies
- **[Strategy Overview](docs/strategies/overview.md)** - Understanding strategies
- **[SFT Strategy](docs/strategies/sft.md)** - Standard supervised fine-tuning
- **[QLoRA Strategy](docs/strategies/qlora.md)** - Memory-efficient training
- **[RLHF Strategy](docs/strategies/rlhf.md)** - Reinforcement learning
- **[DPO Strategy](docs/strategies/dpo.md)** - Direct preference optimization

### API Reference
- **[REST API](docs/api-reference/rest-api.md)** - Complete API documentation
- **[Training Config Schema](docs/api-reference/training-config.md)** - Configuration options

### Troubleshooting
- **[Common Issues](docs/troubleshooting/common-issues.md)** - Frequently encountered problems
- **[Windows Issues](docs/troubleshooting/windows-issues.md)** - Windows-specific troubleshooting
- **[FAQ](docs/troubleshooting/faq.md)** - Frequently asked questions

### Contributing
- **[Contributing Guide](docs/contributing/contributing.md)** - How to contribute
- **[Architecture](docs/contributing/architecture.md)** - Understanding the codebase
- **[Model Configurations](docs/contributing/model-configs.md)** - Adding model recommendations

**[üìñ Full Documentation Index ‚Üí](docs/README.md)**

## üîß Platform Support

| Platform | HuggingFace Provider | Unsloth Provider | Notes |
|----------|---------------------|------------------|-------|
| **Linux** | ‚úÖ Full support | ‚úÖ Full support | Recommended |
| **Windows (Native)** | ‚úÖ Full support | ‚ùå Not supported | Use WSL or Docker for Unsloth |
| **WSL 2** | ‚úÖ Full support | ‚úÖ Full support | Recommended for Windows users |
| **Docker** | ‚úÖ Full support | ‚úÖ Full support | With NVIDIA runtime |

**[Platform-Specific Installation Guides ‚Üí](docs/installation/)**

## ‚ö†Ô∏è Important Notes

### Windows Users

**Unsloth provider is NOT supported on native Windows.** For 2x faster training with Unsloth:

1. **Option 1: WSL (Recommended)** - [WSL Installation Guide](docs/installation/windows.md#option-2-wsl-installation-recommended)
2. **Option 2: Docker** - [Docker Installation Guide](docs/installation/windows.md#option-3-docker-installation)

The HuggingFace provider works perfectly on native Windows.

### Unsloth Constraints

When using Unsloth provider, you **MUST** specify a fixed `max_sequence_length`:

```json
{
  "provider": "unsloth",
  "max_seq_length": 2048  // ‚úÖ Required - cannot be -1
}
```

Auto-inference (`max_seq_length: -1`) is **NOT supported** with Unsloth.

**[Learn more about Unsloth ‚Üí](docs/providers/unsloth.md)**

## üìÇ Dataset Format

ModelForge uses JSONL format. Each task has specific fields:

**Text Generation:**
```jsonl
{"input": "What is AI?", "output": "AI stands for Artificial Intelligence..."}
{"input": "Explain ML", "output": "Machine Learning is a subset of AI..."}
```

**Summarization:**
```jsonl
{"input": "Long article text...", "output": "Short summary."}
```

**Question Answering:**
```jsonl
{"context": "Document text...", "question": "What is X?", "answer": "X is..."}
```

**[Complete Dataset Format Guide ‚Üí](docs/configuration/dataset-formats.md)**

## ü§ù Contributing

We welcome contributions! ModelForge v2.0's modular architecture makes it easy to:

- **Add new providers** - Just 2 files needed
- **Add new strategies** - Just 2 files needed
- **Add model recommendations** - Simple JSON configs
- **Improve documentation**
- **Fix bugs and add features**

**[Contributing Guide ‚Üí](docs/contributing/contributing.md)**

### Adding Model Recommendations

ModelForge uses modular configuration files for model recommendations. See the **[Model Configuration Guide](docs/contributing/model-configs.md)** for instructions on adding new recommended models.

## üõ† Tech Stack

- **Backend**: Python, FastAPI, SQLAlchemy
- **Frontend**: React.js
- **ML**: PyTorch, Transformers, PEFT, TRL
- **Training**: LoRA, QLoRA, bitsandbytes
- **Providers**: HuggingFace Hub, Unsloth

*Results on NVIDIA RTX 3090. Your results may vary.*

## üìú License

MIT License - see [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- HuggingFace for Transformers and model hub
- Unsloth AI for optimized training kernels
- The open-source ML community

## üìß Support

- **Documentation**: [docs/](docs/)
- **Issues**: [GitHub Issues](https://github.com/RETR0-OS/ModelForge/issues)
- **Discussions**: [GitHub Discussions](https://github.com/RETR0-OS/ModelForge/discussions)
- **PyPI**: [modelforge-finetuning](https://pypi.org/project/modelforge-finetuning/)

---

**ModelForge v2.0 - Making LLM fine-tuning accessible to everyone** üöÄ

**[Get Started ‚Üí](docs/getting-started/quickstart.md)** | **[Documentation ‚Üí](docs/)** | **[GitHub ‚Üí](https://github.com/RETR0-OS/ModelForge)**
