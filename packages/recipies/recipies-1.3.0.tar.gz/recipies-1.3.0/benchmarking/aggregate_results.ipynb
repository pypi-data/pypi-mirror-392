{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "from datetime import datetime, MINYEAR\n",
    "from recipies import Ingredients, Recipe\n",
    "from recipies.selector import all_predictors\n",
    "from recipies.constants import Accumulator\n",
    "from recipies.steps import StepHistorical, StepSklearn\n",
    "from sklearn.impute import MissingIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up random state for reproducible results\n",
    "rand_state = np.random.RandomState(42)\n",
    "\n",
    "# Create time columns for two different groups\n",
    "timecolumn = pl.concat(\n",
    "    [\n",
    "        pl.datetime_range(datetime(MINYEAR, 1, 1, 0), datetime(MINYEAR, 1, 1, 5), \"1h\", eager=True),\n",
    "        pl.datetime_range(datetime(MINYEAR, 1, 1, 0), datetime(MINYEAR, 1, 1, 3), \"1h\", eager=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create sample DataFrame\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"id\": [1] * 6 + [2] * 4,\n",
    "        \"time\": timecolumn,\n",
    "        \"y\": rand_state.normal(size=(10,)),\n",
    "        \"x1\": rand_state.normal(loc=10, scale=5, size=(10,)),\n",
    "        \"x2\": rand_state.binomial(n=1, p=0.3, size=(10,)),\n",
    "        \"x3\": pl.Series([\"a\", \"b\", \"c\", \"a\", \"c\", \"b\", \"c\", \"a\", \"b\", \"c\"], dtype=pl.Categorical),\n",
    "        \"x4\": pl.Series([\"x\", \"y\", \"y\", \"x\", \"y\", \"y\", \"x\", \"x\", \"y\", \"x\"], dtype=pl.Categorical),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Introduce some missing values\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.int_range(pl.len()).is_in([1, 2, 4, 7])).then(None).otherwise(pl.col(\"x1\")).alias(\"x1\")\n",
    ")\n",
    "\n",
    "# Create Ingredients and Recipe\n",
    "ing = Ingredients(df)\n",
    "rec = Recipe(ing, outcomes=[\"y\"], predictors=[\"x1\", \"x2\", \"x3\", \"x4\"], groups=[\"id\"], sequences=[\"time\"])\n",
    "rec.add_step(StepSklearn(MissingIndicator(features=\"all\"), sel=all_predictors()))\n",
    "rec.add_step(\"impute\", \"x1\", method=\"mean\")\n",
    "rec.add_step(StepHistorical(sel=all_predictors(), fun=Accumulator.MEAN, suffix=\"mean_hist\"))\n",
    "\n",
    "# Apply the recipe to the ingredients\n",
    "df = rec.prep()\n",
    "df2 = df.copy()\n",
    "# Apply the recipe to a new DataFrame (e.g., test set)\n",
    "df2 = rec.bake(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the benchmark results\n",
    "results = pd.read_csv(\n",
    "    \"/Users/robin/Downloads/results_datasizes_[50, 100, 1000, 10000, 100000, 1000000]_seeds_[1, 2, 3, 4, 5]_datetime_2025-07-09_12-27-28.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include steps containing \"Historical\"\n",
    "results = results[results[\"step\"].str.contains(\"Historical\", case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Filtered dataset shape: {results.shape}\")\n",
    "print(f\"Steps after filtering: {results['step'].unique()}\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info about the dataset\n",
    "print(\"Dataset shape:\", results.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(results.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(results.head())\n",
    "print(\"\\nUnique data sizes:\", sorted(results[\"data_size\"].unique()))\n",
    "print(\"\\nUnique steps:\", results[\"step\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate performance by data size (across all steps)\n",
    "# Since your data is already aggregated by step, we'll aggregate further by data_size\n",
    "\n",
    "summary = (\n",
    "    results.groupby(\"data_size\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"duration_mean_Polars\": \"mean\",\n",
    "            \"duration_mean_Pandas\": \"mean\",\n",
    "            \"duration_std_Polars\": \"mean\",\n",
    "            \"duration_std_Pandas\": \"mean\",\n",
    "            \"memory_mean_Polars\": \"mean\",\n",
    "            \"memory_mean_Pandas\": \"mean\",\n",
    "            \"memory_std_Polars\": \"mean\",\n",
    "            \"memory_std_Pandas\": \"mean\",\n",
    "            \"speedup\": \"mean\",\n",
    "        }\n",
    "    )\n",
    "    .round(4)\n",
    ")\n",
    "\n",
    "# Reset index to make data_size a column\n",
    "summary = summary.reset_index()\n",
    "\n",
    "print(\"Aggregated Performance by Data Size:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional performance metrics\n",
    "summary[\"duration_ratio_pandas_vs_polars\"] = (\n",
    "    summary[\"duration_mean_Pandas\"] / summary[\"duration_mean_Polars\"]\n",
    ").round(2)\n",
    "summary[\"memory_ratio_pandas_vs_polars\"] = (\n",
    "    summary[\"memory_mean_Pandas\"] / summary[\"memory_mean_Polars\"]\n",
    ").round(2)\n",
    "\n",
    "# Calculate coefficient of variation for each backend\n",
    "summary[\"duration_cv_polars\"] = (\n",
    "    summary[\"duration_std_Polars\"] / summary[\"duration_mean_Polars\"] * 100\n",
    ").round(2)\n",
    "summary[\"duration_cv_pandas\"] = (\n",
    "    summary[\"duration_std_Pandas\"] / summary[\"duration_mean_Pandas\"] * 100\n",
    ").round(2)\n",
    "summary[\"memory_cv_polars\"] = (summary[\"memory_std_Polars\"] / summary[\"memory_mean_Polars\"] * 100).round(2)\n",
    "summary[\"memory_cv_pandas\"] = (summary[\"memory_std_Pandas\"] / summary[\"memory_mean_Pandas\"] * 100).round(2)\n",
    "\n",
    "print(\"\\nEnhanced Performance Summary:\")\n",
    "print(\n",
    "    summary[\n",
    "        [\n",
    "            \"data_size\",\n",
    "            \"duration_ratio_pandas_vs_polars\",\n",
    "            \"memory_ratio_pandas_vs_polars\",\n",
    "            \"duration_cv_polars\",\n",
    "            \"duration_cv_pandas\",\n",
    "            \"memory_cv_polars\",\n",
    "            \"memory_cv_pandas\",\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "plt.style.use(\"default\")\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Duration comparison with error bars\n",
    "ax1 = axes[0, 0]\n",
    "ax1.errorbar(\n",
    "    summary[\"data_size\"],\n",
    "    summary[\"duration_mean_Polars\"],\n",
    "    yerr=summary[\"duration_std_Polars\"],\n",
    "    label=\"Polars\",\n",
    "    marker=\"o\",\n",
    "    capsize=5,\n",
    "    color=\"blue\",\n",
    ")\n",
    "ax1.errorbar(\n",
    "    summary[\"data_size\"],\n",
    "    summary[\"duration_mean_Pandas\"],\n",
    "    yerr=summary[\"duration_std_Pandas\"],\n",
    "    label=\"Pandas\",\n",
    "    marker=\"s\",\n",
    "    capsize=5,\n",
    "    color=\"orange\",\n",
    ")\n",
    "ax1.set_xscale(\"log\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlabel(\"Data Size\")\n",
    "ax1.set_ylabel(\"Duration (seconds)\")\n",
    "ax1.set_title(\"Performance Comparison: Duration vs Data Size\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Memory usage comparison with error bars\n",
    "ax2 = axes[0, 1]\n",
    "ax2.errorbar(\n",
    "    summary[\"data_size\"],\n",
    "    summary[\"memory_mean_Polars\"],\n",
    "    yerr=summary[\"memory_std_Polars\"],\n",
    "    label=\"Polars\",\n",
    "    marker=\"o\",\n",
    "    capsize=5,\n",
    "    color=\"blue\",\n",
    ")\n",
    "ax2.errorbar(\n",
    "    summary[\"data_size\"],\n",
    "    summary[\"memory_mean_Pandas\"],\n",
    "    yerr=summary[\"memory_std_Pandas\"],\n",
    "    label=\"Pandas\",\n",
    "    marker=\"s\",\n",
    "    capsize=5,\n",
    "    color=\"orange\",\n",
    ")\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_xlabel(\"Data Size\")\n",
    "ax2.set_ylabel(\"Memory Usage (MB)\")\n",
    "ax2.set_title(\"Memory Usage Comparison vs Data Size\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Speed ratio (Pandas/Polars - higher means Polars is faster)\n",
    "ax3 = axes[0, 2]\n",
    "ax3.plot(summary[\"data_size\"], summary[\"duration_ratio_pandas_vs_polars\"], \"go-\", linewidth=2, markersize=8)\n",
    "ax3.axhline(y=1, color=\"r\", linestyle=\"--\", alpha=0.7, label=\"Equal performance\")\n",
    "ax3.set_xscale(\"log\")\n",
    "ax3.set_xlabel(\"Data Size\")\n",
    "ax3.set_ylabel(\"Speed Ratio (Pandas/Polars)\")\n",
    "ax3.set_title(\"Speed Advantage: Pandas vs Polars\\n(>1 means Polars is faster)\")\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Memory ratio (Pandas/Polars - higher means Polars uses less memory)\n",
    "ax4 = axes[1, 0]\n",
    "ax4.plot(summary[\"data_size\"], summary[\"memory_ratio_pandas_vs_polars\"], \"bo-\", linewidth=2, markersize=8)\n",
    "ax4.axhline(y=1, color=\"r\", linestyle=\"--\", alpha=0.7, label=\"Equal memory usage\")\n",
    "ax4.set_xscale(\"log\")\n",
    "ax4.set_xlabel(\"Data Size\")\n",
    "ax4.set_ylabel(\"Memory Ratio (Pandas/Polars)\")\n",
    "ax4.set_title(\"Memory Efficiency: Pandas vs Polars\\n(>1 means Polars uses less memory)\")\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Coefficient of Variation comparison for Duration\n",
    "ax5 = axes[1, 1]\n",
    "ax5.plot(\n",
    "    summary[\"data_size\"], summary[\"duration_cv_polars\"], \"b^-\", linewidth=2, markersize=8, label=\"Polars CV\"\n",
    ")\n",
    "ax5.plot(\n",
    "    summary[\"data_size\"], summary[\"duration_cv_pandas\"], \"ro-\", linewidth=2, markersize=8, label=\"Pandas CV\"\n",
    ")\n",
    "ax5.set_xscale(\"log\")\n",
    "ax5.set_xlabel(\"Data Size\")\n",
    "ax5.set_ylabel(\"Coefficient of Variation (%)\")\n",
    "ax5.set_title(\"Duration Variability: CV Comparison\")\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Speedup over data sizes\n",
    "ax6 = axes[1, 2]\n",
    "ax6.plot(summary[\"data_size\"], summary[\"speedup\"], \"mo-\", linewidth=2, markersize=8)\n",
    "ax6.axhline(y=1, color=\"r\", linestyle=\"--\", alpha=0.7, label=\"No speedup\")\n",
    "ax6.set_xscale(\"log\")\n",
    "ax6.set_xlabel(\"Data Size\")\n",
    "ax6.set_ylabel(\"Speedup Factor\")\n",
    "ax6.set_title(\"Average Speedup Across All Steps\")\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed summary report\n",
    "print(\"=\" * 100)\n",
    "print(\"COMPREHENSIVE BENCHMARK RESULTS SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for _, row in summary.iterrows():\n",
    "    data_size = int(row[\"data_size\"])\n",
    "    print(f\"\\nData Size: {data_size:,} rows\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Duration results\n",
    "    polars_duration = row[\"duration_mean_Polars\"]\n",
    "    pandas_duration = row[\"duration_mean_Pandas\"]\n",
    "    polars_duration_std = row[\"duration_std_Polars\"]\n",
    "    pandas_duration_std = row[\"duration_std_Pandas\"]\n",
    "    duration_ratio = row[\"duration_ratio_pandas_vs_polars\"]\n",
    "\n",
    "    print(\"PERFORMANCE (Duration):\")\n",
    "    print(\n",
    "        f\"  Polars:  {polars_duration:.4f} ± {polars_duration_std:.4f} seconds (CV: {row['duration_cv_polars']:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Pandas:  {pandas_duration:.4f} ± {pandas_duration_std:.4f} seconds (CV: {row['duration_cv_pandas']:.1f}%)\"\n",
    "    )\n",
    "    print(f\"  Ratio:   {duration_ratio:.2f}x ({'Polars faster' if duration_ratio > 1 else 'Pandas faster'})\")\n",
    "\n",
    "    # Memory results\n",
    "    polars_memory = row[\"memory_mean_Polars\"]\n",
    "    pandas_memory = row[\"memory_mean_Pandas\"]\n",
    "    polars_memory_std = row[\"memory_std_Polars\"]\n",
    "    pandas_memory_std = row[\"memory_std_Pandas\"]\n",
    "    memory_ratio = row[\"memory_ratio_pandas_vs_polars\"]\n",
    "\n",
    "    print(\"\\nMEMORY USAGE:\")\n",
    "    print(f\"  Polars:  {polars_memory:.2f} ± {polars_memory_std:.2f} MB (CV: {row['memory_cv_polars']:.1f}%)\")\n",
    "    print(f\"  Pandas:  {pandas_memory:.2f} ± {pandas_memory_std:.2f} MB (CV: {row['memory_cv_pandas']:.1f}%)\")\n",
    "    print(\n",
    "        f\"  Ratio:   {memory_ratio:.2f}x ({'Polars more efficient' if memory_ratio > 1 else 'Pandas more efficient'})\"\n",
    "    )\n",
    "\n",
    "    # Overall speedup\n",
    "    speedup = row[\"speedup\"]\n",
    "    print(f\"\\nOVERALL SPEEDUP: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by step analysis\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PERFORMANCE BY STEP ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "step_analysis = (\n",
    "    results.groupby(\"step\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"duration_mean_Polars\": \"mean\",\n",
    "            \"duration_mean_Pandas\": \"mean\",\n",
    "            \"memory_mean_Polars\": \"mean\",\n",
    "            \"memory_mean_Pandas\": \"mean\",\n",
    "            \"speedup\": \"mean\",\n",
    "        }\n",
    "    )\n",
    "    .round(4)\n",
    ")\n",
    "\n",
    "step_analysis[\"duration_ratio\"] = (\n",
    "    step_analysis[\"duration_mean_Pandas\"] / step_analysis[\"duration_mean_Polars\"]\n",
    ").round(2)\n",
    "step_analysis[\"memory_ratio\"] = (\n",
    "    step_analysis[\"memory_mean_Pandas\"] / step_analysis[\"memory_mean_Polars\"]\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nAverage Performance by Step (across all data sizes):\")\n",
    "print(step_analysis)\n",
    "\n",
    "# Find best and worst performing steps for each backend\n",
    "print(f\"\\nFastest steps for Polars: {step_analysis.nsmallest(3, 'duration_mean_Polars').index.tolist()}\")\n",
    "print(f\"Fastest steps for Pandas: {step_analysis.nsmallest(3, 'duration_mean_Pandas').index.tolist()}\")\n",
    "print(\n",
    "    f\"Steps where Polars has biggest advantage: {step_analysis.nlargest(3, 'duration_ratio').index.tolist()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Most memory efficient steps (Polars): {step_analysis.nsmallest(3, 'memory_mean_Polars').index.tolist()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV files\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Export aggregated summary by data size\n",
    "summary_file = f\"performance_summary_by_datasize_{timestamp}.csv\"\n",
    "summary.to_csv(summary_file, index=False)\n",
    "print(f\"\\nData size performance summary exported to: {summary_file}\")\n",
    "\n",
    "# Export step analysis\n",
    "step_file = f\"performance_summary_by_step_{timestamp}.csv\"\n",
    "step_analysis.to_csv(step_file, index=True)\n",
    "print(f\"Step performance summary exported to: {step_file}\")\n",
    "\n",
    "# Export detailed comparison table\n",
    "comparison_df = summary[\n",
    "    [\"data_size\", \"duration_ratio_pandas_vs_polars\", \"memory_ratio_pandas_vs_polars\", \"speedup\"]\n",
    "].copy()\n",
    "comparison_df.columns = [\n",
    "    \"data_size\",\n",
    "    \"speed_ratio_pandas_vs_polars\",\n",
    "    \"memory_ratio_pandas_vs_polars\",\n",
    "    \"speedup\",\n",
    "]\n",
    "comparison_file = f\"performance_comparison_{timestamp}.csv\"\n",
    "comparison_df.to_csv(comparison_file, index=False)\n",
    "print(f\"Performance comparison exported to: {comparison_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap showing performance across data sizes and steps\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Pivot the data to create a matrix for heatmap\n",
    "duration_heatmap_data = results.pivot(index=\"step\", columns=\"data_size\", values=\"speedup\")\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    duration_heatmap_data,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"RdYlBu_r\",\n",
    "    center=1,\n",
    "    cbar_kws={\"label\": \"Speedup (Polars vs Pandas)\"},\n",
    ")\n",
    "plt.title(\"Speedup Heatmap: Polars vs Pandas\\nAcross Data Sizes and Steps\")\n",
    "plt.xlabel(\"Data Size\")\n",
    "plt.ylabel(\"Processing Step\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OVERALL BENCHMARK STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\n",
    "    f\"Data sizes tested: {len(summary)} ({min(summary['data_size']):,} to {max(summary['data_size']):,} rows)\"\n",
    ")\n",
    "print(f\"Processing steps analyzed: {len(step_analysis)}\")\n",
    "print(f\"Total benchmark combinations: {len(results)}\")\n",
    "\n",
    "print(\"\\nOverall Performance Summary:\")\n",
    "print(f\"Average speedup across all tests: {results['speedup'].mean():.2f}x\")\n",
    "print(f\"Best speedup achieved: {results['speedup'].max():.2f}x\")\n",
    "print(f\"Worst speedup: {results['speedup'].min():.2f}x\")\n",
    "\n",
    "print(\"\\nDuration Performance:\")\n",
    "print(f\"Average Polars duration: {summary['duration_mean_Polars'].mean():.4f} seconds\")\n",
    "print(f\"Average Pandas duration: {summary['duration_mean_Pandas'].mean():.4f} seconds\")\n",
    "print(\n",
    "    f\"Overall speed ratio: {(summary['duration_mean_Pandas'].mean() / summary['duration_mean_Polars'].mean()):.2f}x\"\n",
    ")\n",
    "\n",
    "print(\"\\nMemory Performance:\")\n",
    "print(f\"Average Polars memory: {summary['memory_mean_Polars'].mean():.2f} MB\")\n",
    "print(f\"Average Pandas memory: {summary['memory_mean_Pandas'].mean():.2f} MB\")\n",
    "print(\n",
    "    f\"Overall memory ratio: {(summary['memory_mean_Pandas'].mean() / summary['memory_mean_Polars'].mean()):.2f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
