@inproceedings{10.1145/3641525,
  title = {{{ACM REP}} '24: {{Proceedings}} of the 2nd {{ACM}} Conference on Reproducibility and Replicability},
  booktitle = {{{ACM REP}} '24: {{Proceedings}} of the 2nd {{ACM}} Conference on Reproducibility and Replicability},
  author = {Various, Authors},
  date = {2024},
  publisher = {Association for Computing Machinery},
  location = {Rennes, France and New York, NY, USA},
  doi = {10.1145/3641525},
  isbn = {979-8-4007-0530-4}
}

@article{galliFeatureenginePythonPackage2021,
  title = {Feature-Engine: {{A Python}} Package for Feature Engineering for Machine Learning},
  shorttitle = {Feature-Engine},
  author = {Galli, Soledad},
  date = {2021-09-22},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {6},
  number = {65},
  pages = {3642},
  publisher = {The Open Journal},
  issn = {2475-9066},
  doi = {10.21105/joss.03642},
  url = {https://joss.theoj.org/papers/10.21105/joss.03642},
  urldate = {2025-07-22},
  abstract = {Feature-engine is an open source Python library with the most exhaustive battery of transformations to engineer and select features for use in machine learning. Feature-engine supports several techniques to impute missing data, encode categorical variables, transform variables mathematically, perform discretization, remove or censor outliers, and combine variables into new features. Feature-engine also hosts an array of algorithms for feature selection.},
  langid = {english},
  file = {/Users/robin/Zotero/storage/V3LYVWF4/Galli - 2021 - Feature-engine A Python package for feature engineering for machine learning.pdf}
}

@inproceedings{j.PyjanitorCleanerAPI2019,
  title = {Pyjanitor: {{A Cleaner API}} for {{Cleaning Data}}},
  shorttitle = {Pyjanitor},
  booktitle = {Proceedings of the {{Python}} in {{Science Conference}}},
  author = {J., Eric and Barry, Zachary and Zuckerman, Sam and Sailer, Zachary},
  date = {2019},
  pages = {50--53},
  publisher = {SciPy},
  location = {Austin, Texas},
  issn = {2575-9752},
  doi = {10.25080/majora-7ddc1dd1-007},
  url = {https://doi.curvenote.com/10.25080/Majora-7ddc1dd1-007},
  urldate = {2025-07-22},
  abstract = {The pandas library has become the de facto library for data wrangling in the Python programming language. However, inconsistencies in the pandas application programming interface (API), while idiomatic due to historical use, prevent use of expressive, fluent programming idioms that enable self-documenting pandas code. Here, we introduce pyjanitor, an open source Python package that extends the pandas API with such idioms. We describe its design and implementation of the package, provide usage examples from a variety of domains, and discuss the ways that the pyjanitor project has enabled the inclusion of first-time contributors to open source projects.},
  eventtitle = {Python in {{Science Conference}}},
  langid = {english},
  file = {/Users/robin/Zotero/storage/KFHKGQJY/J. et al. - 2019 - pyjanitor A Cleaner API for Cleaning Data.pdf}
}

@article{johnsonMIMICIVFreelyAccessible2023,
  title = {{{MIMIC-IV}}, a Freely Accessible Electronic Health Record Dataset},
  author = {Johnson, Alistair E. W. and Bulgarelli, Lucas and Shen, Lu and Gayles, Alvin and Shammout, Ayad and Horng, Steven and Pollard, Tom J. and Moody, Benjamin and Gow, Brian and Lehman, Li-wei H. and Celi, Leo A. and Mark, Roger G.},
  date = {2023-01-03},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {10},
  number = {1},
  pages = {1},
  issn = {2052-4463},
  doi = {10.1038/s41597-022-01899-x},
  url = {https://www.nature.com/articles/s41597-022-01899-x},
  urldate = {2023-04-13},
  abstract = {Abstract             Digital data collection during routine clinical practice is now ubiquitous within hospitals. The data contains valuable information on the care of patients and their response to treatments, offering exciting opportunities for research. Typically, data are stored within archival systems that are not intended to support research. These systems are often inaccessible to researchers and structured for optimal storage, rather than interpretability and analysis. Here we present MIMIC-IV, a publicly available database sourced from the electronic health record of the Beth Israel Deaconess Medical Center. Information available includes patient measurements, orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. MIMIC-IV is intended to support a wide array of research studies and educational material, helping to reduce barriers to conducting clinical research.},
  langid = {english},
  file = {/Users/robin/Zotero/storage/ZTI6MGCU/Johnson et al_2023_MIMIC-IV, a freely accessible electronic health record dataset.pdf}
}

@inproceedings{johnsonReproducibilityCriticalCare2017a,
  title = {Reproducibility in Critical Care: A Mortality Prediction Case Study},
  shorttitle = {Reproducibility in Critical Care},
  booktitle = {Proceedings of the 2nd {{Machine Learning}} for {{Healthcare Conference}}},
  author = {Johnson, Alistair E. W. and Pollard, Tom J. and Mark, Roger G.},
  date = {2017-11-06},
  pages = {361--376},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v68/johnson17a.html},
  urldate = {2025-07-23},
  abstract = {Mortality prediction of intensive care unit (ICU) patients facilitates hospital benchmarking and has the opportunity to provide caregivers with useful summaries of patient health at the bedside. The development of novel models for mortality prediction is a popular task in machine learning, with researchers typically seeking to maximize measures such as the area under the receiver operator characteristic curve (AUROC). The number of â€™researcher degrees of freedomâ€™ that contribute to the performance of a model, however, presents a challenge when seeking to compare reported performance of such models. In this study, we review publications that have reported performance of mortality prediction models based on the Medical Information Mart for Intensive Care (MIMIC) database and attempt to reproduce the cohorts used in their studies. We then compare the performance reported in the studies against gradient boosting and logistic regression models using a simple set of features extracted from MIMIC. We demonstrate the large heterogeneity in studies that purport to conduct the single task of â€™mortality predictionâ€™, highlighting the need for improvements in the way that prediction tasks are reported to enable fairer comparison between models. We reproduced datasets for 38 experiments corresponding to 28 published studies using MIMIC. In half of the experiments, the sample size we acquired was 25\% greater or smaller than the sample size reported. The highest discrepancy was 11,767 patients. While accurate reproduction of each study cannot be guaranteed, we believe that these results highlight the need for more consistent reporting of model design and methodology to allow performance improvements to be compared. We discuss the challenges in reproducing the cohorts used in the studies, highlighting the importance of clearly reported methods (e.g. data cleansing, variable selection, cohort selection) and the need for open code and publicly available benchmarks.},
  eventtitle = {Machine {{Learning}} for {{Healthcare Conference}}},
  langid = {english},
  doi = {10.1038/s41597-022-01899-x},
  file = {/Users/robin/Zotero/storage/5C74RYC5/Johnson et al. - 2017 - Reproducibility in critical care a mortality prediction case study.pdf}
}

@article{kellyKeyChallengesDelivering2019a,
  title = {Key Challenges for Delivering Clinical Impact with Artificial Intelligence},
  author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
  date = {2019-12},
  journaltitle = {BMC Medicine},
  shortjournal = {BMC Med},
  volume = {17},
  number = {1},
  pages = {195},
  issn = {1741-7015},
  doi = {10.1186/s12916-019-1426-2},
  url = {https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1426-2},
  urldate = {2023-04-12},
  abstract = {Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful postmarket surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.},
  langid = {english},
  file = {/Users/robin/Zotero/storage/IL456PGP/Kelly et al. - 2019 - Key challenges for delivering clinical impact with.pdf}
}

@software{kuhnRecipesPreprocessingFeature2024,
  title = {Recipes: {{Preprocessing}} and {{Feature Engineering Steps}} for {{Modeling}}},
  shorttitle = {Recipes},
  author = {Kuhn, Max and Wickham, Hadley and Hvitfeldt, Emil and Software, Posit and PBC},
  date = {2024-07-04},
  url = {https://cloud.r-project.org/web/packages/recipes/index.html},
  urldate = {2024-07-09},
  abstract = {A recipe prepares your data for modeling. We provide an extensible framework for pipeable sequences of feature engineering steps provides preprocessing tools to be applied to data. Statistical parameters for the steps can be estimated from an initial data set and then applied to other data sets. The resulting processed output can then be used as inputs for statistical or machine learning models.},
  version = {1.1.0},
  annotation = {10.32614/CRAN.package.recipes},
  doi = {10.32614/CRAN.package.recipes},
}

@inproceedings{mckinney-proc-scipy-2010,
  title = {Data {{Structures}} for {{Statistical Computing}} in {{Python}}},
  booktitle = {Proceedings of the 9th {{Python}} in {{Science Conference}}},
  author = {McKinney, Wes},
  editor = {family=Walt, given=StÃ©fan, prefix=van der, useprefix=true and Millman, Jarrod},
  date = {2010},
  pages = {56--61},
  doi = {10.25080/Majora-92bf1922-00a}
}

@online{mozzilloEvaluationDataframeLibraries2024,
  title = {Evaluation of {{Dataframe Libraries}} for {{Data Preparation}} on a {{Single Machine}}},
  author = {Mozzillo, Angelo and Zecchini, Luca and Gagliardelli, Luca and Aslam, Adeel and Bergamaschi, Sonia and Simonini, Giovanni},
  date = {2024-06-10},
  eprint = {2312.11122},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2312.11122},
  doi = {10.48786/edbt.2025.27},
  urldate = {2024-07-09},
  abstract = {Data preparation is a trial-and-error process that typically involves countless iterations over the data to define the best pipeline of operators for a given task. With tabular data, practitioners often perform that burdensome activity on local machines by writing ad hoc scripts with libraries based on the Pandas dataframe API and testing them on samples of the entire datasetâ€”the faster the library, the less idle time its users have.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/robin/Zotero/storage/B2KUGHJ3/Mozzillo et al. - 2024 - Evaluation of Dataframe Libraries for Data Prepara.pdf}
}

@inproceedings{paszkePyTorchImperativeStyle2019,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  doi = {10.48550/arXiv.1912.01703},
  url = {https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html},
  urldate = {2023-04-18},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.},
  file = {/Users/robin/Zotero/storage/DBZHEP84/Paszke et al_2019_PyTorch.pdf}
}

@article{pedregosa_scikit-learn_2011,
  title = {Scikit-Learn: {{Machine}} Learning in Python},
  shorttitle = {Scikit-Learn},
  author = {Pedregosa, Fabian and Varoquaux, GaÃ«l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Ã‰douard},
  date = {2011},
  journaltitle = {Journal of Machine Learning Research},
  volume = {12},
  number = {85},
  pages = {2825--2830},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v12/pedregosa11a.html},
  urldate = {2022-12-21},
  doi = {10.48550/arXiv.1201.0490},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.}
}

@inproceedings{shenDataAdditionDilemma2024b,
  title = {The Data Addition Dilemma},
  booktitle = {Proceedings of the 9th Machine Learning for Healthcare Conference},
  author = {Shen, Judy Hanwen and Raji, Inioluwa Deborah and Chen, Irene Y.},
  editor = {Deshpande, Kaivalya and Fiterau, Madalina and Joshi, Shalmali and Lipton, Zachary and Ranganath, Rajesh and Urteaga, IÃ±igo},
  date = {2024-08-16/2024-08-17},
  series = {Proceedings of Machine Learning Research},
  volume = {252},
  publisher = {PMLR},
  doi = {10.48550/arXiv.2408.04154},
  url = {https://proceedings.mlr.press/v252/shen24a.html},
  abstract = {In many machine learning for healthcare tasks, standard datasets are constructed by amassing data across many, often fundamentally dissimilar, sources. But when does adding more data help, and when does it hinder progress on desired model outcomes in real-world settings? We identify this situation as the Data Addition Dilemma, demonstrating that adding training data in this multi-source scaling context can at times result in reduced overall accuracy, uncertain fairness outcomes and reduced worst-subgroup performance. We find that this possibly arises from an empirically observed trade-off between model performance improvements due to data scaling and model deterioration from distribution shift. We thus establish baseline strategies for navigating this dilemma, introducing distribution shift heuristics to guide decision-making for which data sources to add in order to yield the expected model performance improvements. We conclude with a discussion of the required considerations for data collection and suggestions for studying data composition and scale in the age of increasingly larger models.}
}

@online{Proceedings2ndACM,
  title = {Proceedings of the 2nd {{ACM Conference}} on {{Reproducibility}} and {{Replicability}}},
  url = {https://dl.acm.org/doi/proceedings/10.1145/3641525},
  urldate = {2025-07-23},
  langid = {english},
  organization = {ACM Conferences},
  doi = {10.1145/3641525},
  file = {/Users/robin/Zotero/storage/DCPUI73M/3641525.html}
}

@inproceedings{rahmanWhatQuestionsProgrammers2018,
  title = {What Questions Do Programmers Ask about Configuration as Code?},
  booktitle = {Proceedings of the 4th {{International Workshop}} on {{Rapid Continuous Software Engineering}}},
  author = {Rahman, Akond and Partho, Asif and Morrison, Patrick and Williams, Laurie},
  date = {2018-05-29},
  series = {{{RCoSE}} '18},
  pages = {16--22},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3194760.3194769},
  url = {https://dl.acm.org/doi/10.1145/3194760.3194769},
  urldate = {2024-11-05},
  abstract = {Configuration as code (CaC) tools, such as Ansible and Puppet, help software teams to implement continuous deployment and deploy software changes rapidly. CaC tools are growing in popularity, yet what challenges programmers encounter about CaC tools, have not been characterized. A systematic investigation on what questions are asked by programmers, can help us identify potential technical challenges about CaC, and can aid in successful use of CaC tools. The goal of this paper is to help current and potential configuration as code (CaC) adoptees in identifying the challenges related to CaC through an analysis of questions asked by programmers on a major question and answer website. We extract 2,758 Puppet-related questions asked by programmers from January 2010 to December 2016, posted on Stack Overflow. We apply qualitative analysis to identify the questions programmers ask about Puppet. We also investigate the trends in questions with unsatisfactory answers, and changes in question categories over time. From our empirical study, we synthesize 16 major categories of questions. The three most common question categories are: (i) syntax errors, (ii) provisioning instances; and (iii) assessing Puppet's feasibility to accomplish certain tasks. Three categories of questions that yield the most unsatisfactory answers are (i) installation, (ii) security, and (iii) data separation.},
  isbn = {978-1-4503-5745-6},
  file = {/Users/robin/Zotero/storage/NPUTS3V9/Rahman et al_2018_What questions do programmers ask about configuration as code.pdf}
}

@online{santosImprovingRepresentationLearning2025,
  title = {Improving {{Representation Learning}} of {{Complex Critical Care Data}} with {{ICU-BERT}}},
  author = {Santos, Ricardo and Carreiro, AndrÃ© V. and Peng, Xi and Gamboa, Hugo and FrÃ¶hlich, Holger},
  date = {2025-02-26},
  eprint = {2502.19593},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.19593},
  url = {http://arxiv.org/abs/2502.19593},
  urldate = {2025-04-24},
  abstract = {The multivariate, asynchronous nature of real-world clinical data, such as that generated in Intensive Care Units (ICUs), challenges traditional AI-based decision-support systems. These often assume data regularity and feature independence and frequently rely on limited data scopes and manual feature engineering. The potential of generative AI technologies has not yet been fully exploited to analyze clinical data. We introduce ICU-BERT, a transformer-based model pre-trained on the MIMIC-IV database using a multi-task scheme to learn robust representations of complex ICU data with minimal preprocessing. ICU-BERT employs a multi-token input strategy, incorporating dense embeddings from a biomedical Large Language Model to learn a generalizable representation of complex and multivariate ICU data. With an initial evaluation of five tasks and four additional ICU datasets, ICU-BERT results indicate that ICU-BERT either compares to or surpasses current performance benchmarks by leveraging fine-tuning. By integrating structured and unstructured data, ICU-BERT advances the use of foundational models in medical informatics, offering an adaptable solution for clinical decision support across diverse applications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/robin/Zotero/storage/XDHVFWNA/Santos et al. - 2025 - Improving Representation Learning of Complex Critical Care Data with ICU-BERT.pdf;/Users/robin/Zotero/storage/87X4T6R4/2502.html}
}

@article{sarwarSecondaryUseElectronic2023,
  title = {The {{Secondary Use}} of {{Electronic Health Records}} for {{Data Mining}}: {{Data Characteristics}} and {{Challenges}}},
  shorttitle = {The {{Secondary Use}} of {{Electronic Health Records}} for {{Data Mining}}},
  author = {Sarwar, Tabinda and Seifollahi, Sattar and Chan, Jeffrey and Zhang, Xiuzhen and Aksakalli, Vural and Hudson, Irene and Verspoor, Karin and Cavedon, Lawrence},
  date = {2023-03-31},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {55},
  number = {2},
  pages = {1--40},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3490234},
  url = {https://dl.acm.org/doi/10.1145/3490234},
  urldate = {2022-05-02},
  abstract = {The primary objective of implementing Electronic Health Records (EHRs) is to improve the management of patientsâ€™ health-related information. However, these records have also been extensively used for the secondary purpose of clinical research and to improve healthcare practice. EHRs provide a rich set of information that includes demographics, medical history, medications, laboratory test results, and diagnosis. Data mining and analytics techniques have extensively exploited EHR information to study patient cohorts for various clinical and research applications, such as phenotype extraction, precision medicine, intervention evaluation, disease prediction, detection, and progression. But the presence of diverse data types and associated characteristics poses many challenges to the use of EHR data. In this article, we provide an overview of information found in EHR systems and their characteristics that could be utilized for secondary applications. We first discuss the different types of data stored in EHRs, followed by the data transformations necessary for data analysis and mining. Later, we discuss the data quality issues and characteristics of the EHRs along with the relevant methods used to address them. Moreover, this survey also highlights the usage of various data types for different applications. Hence, this article can serve as a primer for researchers to understand the use of EHRs for data mining and analytics purposes.},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/robin/Zotero/storage/TJYEISKX/Sarwar et al_2023_The Secondary Use of Electronic Health Records for Data Mining.pdf}
}

@article{semmelrockReproducibilityMachinelearningbasedResearch2025,
  title = {Reproducibility in Machine-Learning-Based Research: {{Overview}}, Barriers, and Drivers},
  shorttitle = {Reproducibility in Machine-Learning-Based Research},
  author = {Semmelrock, Harald and Ross-Hellauer, Tony and Kopeinik, Simone and Theiler, Dieter and Haberl, Armin and Thalmann, Stefan and Kowald, Dominik},
  date = {2025},
  journaltitle = {AI Magazine},
  volume = {46},
  number = {2},
  pages = {e70002},
  issn = {2371-9621},
  doi = {10.1002/aaai.70002},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aaai.70002},
  urldate = {2025-07-23},
  abstract = {Many research fields are currently reckoning with issues of poor levels of reproducibility. Some label it a â€œcrisis,â€ and research employing or building machine learning (ML) models is no exception. Issues including lack of transparency, data or code, poor adherence to standards, and the sensitivity of ML training conditions mean that many papers are not even reproducible in principle. Where they are, though, reproducibility experiments have found worryingly low degrees of similarity with original results. Despite previous appeals from ML researchers on this topic and various initiatives from conference reproducibility tracks to the ACM's new Emerging Interest Group on Reproducibility and Replicability, we contend that the general community continues to take this issue too lightly. Poor reproducibility threatens trust in and integrity of research results. Therefore, in this article, we lay out a new perspective on the key barriers and drivers (both procedural and technical) to increased reproducibility at various levels (methods, code, data, and experiments). We then map the drivers to the barriers to give concrete advice for strategies for researchers to mitigate reproducibility issues in their own work, to lay out key areas where further research is needed in specific areas, and to further ignite discussion on the threat presented by these urgent issues.},
  langid = {english},
  file = {/Users/robin/Zotero/storage/MPE2A5NV/Semmelrock et al. - 2025 - Reproducibility in machine-learning-based research Overview, barriers, and drivers.pdf;/Users/robin/Zotero/storage/LIUDAM67/aaai.html}
}

@inproceedings{vandewaterAnotherICUBenchmark2024a,
  title = {Yet {{Another ICU Benchmark}}: {{A Flexible Multi-Center Framework}} for {{Clinical ML}}},
  shorttitle = {Yet {{Another ICU Benchmark}}},
  booktitle = {Proceedings of {{The Twelfth International Conference}} on {{Learning Representations}}},
  author = {Van de Water, Robin and Schmidt, Hendrik Nils Aurel and Elbers, Paul and Thoral, Patrick and Arnrich, Bert and Rockenschaub, Patrick},
  date = {2024-05-07},
  doi = {10.48550/arXiv.2306.05109},
  url = {https://openreview.net/forum?id=ox2ATRM90I},
  urldate = {2025-01-31},
  abstract = {Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. Given the abundance of available data from electronic health records, the intensive care unit (ICU) is a natural habitat for ML. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transparent preprocessing pipeline and extensible training code for multiple ML and deep learning models, YAIB enables unified model development, transfer, and evaluation. Our benchmark comes with five predefined established prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and length of stay) developed in collaboration with clinicians. Adding further tasks is straightforward by design. Using YAIB, we demonstrate that the choice of dataset, cohort definition, and preprocessing have a major impact on the prediction performance â€” often more so than model class â€” indicating an urgent need for YAIB as a holistic benchmarking tool. We provide our work to the clinical ML community to accelerate method development and enable real-world clinical implementations.},
  eventtitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {/Users/robin/Zotero/storage/4VNZA8JF/Water et al. - 2023 - Yet Another ICU Benchmark A Flexible Multi-Center Framework for Clinical ML.pdf}
}

@software{vinkPolarsPolarsPython2024,
  title = {Pola-Rs/Polars: {{Python Polars}} 1.0.0},
  shorttitle = {Pola-Rs/Polars},
  author = {Vink, Ritchie and family=Gooijer, given=Stijn, prefix=de, useprefix=false and Beedie, Alexander and Gorelli, Marco Edward and Guo, Weijie and family=Zundert, given=J., prefix=van, useprefix=false and Peters, Orson and Hulselmans, Gert and Grinstead, Cory and {nameexhaustion} and Marshall and {chielP} and Burghoorn, Gijs and Turner-Trauring, Itamar and Santamaria, Matteo and Heres, DaniÃ«l and Magarick, Josh and {ibENPC} and Wilksch, Moritz and Leitao, Jorge and Genockey, Karl and family=Gelderen, given=Mick, prefix=van, useprefix=false and Barbagiannis, Petros and Haag, Jonas and Mitchell, Lawrence and Borchert, Oliver and Brannigan, Liam and family=Heerden, given=Marc, prefix=van, useprefix=false and Koutsouris, Ion},
  date = {2024-07-01},
  doi = {10.5281/zenodo.12606903},
  url = {https://zenodo.org/records/12606903},
  urldate = {2025-10-15},
  abstract = {ðŸ’¥ Breaking changes Change default engine for read\_excel to "calamine" (\#17263) Implement binary serialization of LazyFrame/DataFrame/Expr and set it as the default format (\#17223) Streamline optional dependency definitions in pyproject.toml (\#17168) Update read/scan\_parquet to disable Hive partitioning by default for file inputs (\#17106) Split replace functionality into two separate methods (\#16921) Default to writing binview data to IPC, mark compression argument as keyword-only (\#17084) Remove re-export of type aliases (\#17032) Rename ModuleUpgradeRequired and PolarsPanicError error, remove InvalidAssert error (\#17033) Change data orientation inference logic for DataFrame construction and warn when row orientation is inferred (\#16976) Properly apply strict parameter in Series constructor (\#16939) Remove supertype definition of List and non-List types (\#16918) Consistently convert to given time zone in Series constructor  (\#16828) Update reshape to return Array types instead of List types (\#16825) Default to raising on out-of-bounds indices in all get/gather operations (\#16841) Native selector XOR set operation, guarantee consistent selector column-order (\#16833) Set infer\_schema\_length as keyword-only argument in str.json\_decode (\#16835) Update set\_sorted to only accept a single column (\#16800) Remove deprecated parameters in Series.cut/qcut and update struct field names (\#16741) Expedited removal of certain deprecated functionality (\#16754) Update some error types to more appropriate variants (\#15030) Scheduled removal of deprecated functionality (\#16715) Change default offset in group\_by\_dynamic from 'negative every' to 'zero' (\#16658) Constrain access to globals from DataFrame.sql in favor of top-level pl.sql (\#16598) Read 2D NumPy arrays as Array type instead of List (\#16710) Update clip to no longer propagate nulls in the given bounds (\#14413) Change str.to\_datetime to default to microsecond precision for format specifiers "\%f" and "\%.f" (\#13597) Update resulting column names in pivot when pivoting by multiple values (\#16439) Preserve nulls in ewm\_mean, ewm\_std, and ewm\_var (\#15503) Restrict casting for temporal data types (\#14142) Support Decimal types by default when converting from Arrow (\#15324) Remove serde functionality from pl.read\_json and DataFrame.write\_json (\#16550) Update function signature of nth to allow positional input of indices, remove columns parameter (\#16510) Rename struct fields of rle output to len/value and update data type of len field (\#15249) Remove class variables from some DataTypes (\#16524) Add check\_names parameter to Series.equals and default to False (\#16610) âš ï¸ Deprecations Deprecate LazyFrame.fetch (\#17278) Deprecate size parameter in parametric testing strategies in favor of min\_size/max\_size (\#17128) Split replace functionality into two separate methods (\#16921) Rename DataFrame.melt to unpivot and make parameters consistent with pivot (\#17095) Remove re-export of exceptions at top-level (\#17059) Deprecate dt.mean/dt.median in favor of mean/median (\#16888) Deprecate LazyFrame.with\_context in favor of horizontal concatenation (\#16860) Rename parameter descending to reverse in top\_k methods (\#16817) Rename str.concat to str.join and update default delimiter (\#16790) Deprecate arctan2d in favor of arctan2(...).degrees() (\#16786) ðŸš€ Performance improvements Rechunk before group\_by `iteration (\#17302) Improve unique performance by adding RangedUniqueKernel for primitive arrays (\#17166) Improve unique performance by creating UniqueKernel and improve bool implementation (\#17160) Default to writing binview data to IPC, mark compression argument as keyword-only (\#17084) Parallelize arrow conversion if binview -{$>$} large\_bin (\#17083) Garbage collect buffers in if-then-else view kernel (\#16993) Desugar AND filter into multiple nodes (\#16992) Optimize generic arg\_sort of row-encoding (\#16894) Improve rle\_id iteration performance and set sorted flags (\#16893) Optimize sort for String and Binary types (\#16871) Use split\_at in split (\#16865) Use split\_at instead of double slice in chunk splits. (\#16856) Don't rechunk in align\_ if arrays are aligned (\#16850) Don't create small chunks in parallel collect. (\#16845) Add dedicated no-null branch in arg\_sort (\#16808) Speed up dt.offset\_by 2x for constant durations (\#16728) Toggle coalesce in join if non-coalesced key isn't projected (\#16677) Make dt.truncate 1.5x faster when every is just a single duration (and not an expression) (\#16666) Always prune unused columns in semi/anti join (\#16665) âœ¨ Enhancements Add SQL support for NATURAL joins and the COLUMNS function (\#17295) Add str.extract\_many expression (\#17304) Change default engine for read\_excel to "calamine" (\#17263) Deprecate LazyFrame.fetch (\#17278) Support '\%' in pathnames for async scan (\#17271) Support SQL Struct/JSON field access operators (\#17226) Exclude directories from glob expansion result (\#17174) Support SQL ORDER BY ALL syntax (\#17212) Support PostgreSQL \textasciicircum @ ("starts with"), and \textasciitilde\textasciitilde,\textasciitilde\textasciitilde *,!\textasciitilde\textasciitilde,!\textasciitilde\textasciitilde * ("like", "ilike") string-matching operators (\#17251) Support SQL SELECT * ILIKE wildcard syntax (\#17169) Support SQL temporal functions STRFTIME and STRPTIME, and typed literal syntax (\#17245) Support date/datetime for hive parts (\#17256) Implement binary serialization of LazyFrame/DataFrame/Expr and set it as the default format (\#17223) Allow no-op round/ceil/floor on integer types (\#17241) Support loading from datasets where the hive columns are also stored in the file (\#17203) Implement serde for Null columns (\#17218) Support Decimal types in write\_csv/write\_json (\#14209) Add optional "default" to get\_column DataFrame method (\#17176) Improve SQL support for array indexing, increase test coverage (\#16972) Support reading byte stream split encoded floats and doubles in parquet (\#17099) Add float\_scientific option to write\_csv/sink\_csv (\#17111) Support Struct field selection in the SQL engine, RENAME and REPLACE select wildcard options (\#17109) Update DataFrame.pivot to allow index=None when values is set (\#17126) Update read/scan\_parquet to disable Hive partitioning by default for file inputs (\#17106) Improve ipython autocomplete for LazyFrame and DataFrame (\#17091) Split replace functionality into two separate methods (\#16921) Improve schema inference for hive partitions (\#17079) Rename DataFrame.melt to unpivot and make parameters consistent with pivot (\#17095) Print row index in explain and show\_graph (\#17074) Support top-level pl.col autocompletion for iPython (\#17080) Remove re-export of exceptions at top-level (\#17059) Implement predicate and projection pushdown for read\_ndjson (\#17068) Allow (non-)coalescing in join\_asof (\#17066) Turn of coalescing and fix mutation of join on expressions (\#17061) Expand NDJson glob into one SCAN (\#17063) Do not parse hive partitions from user provided base directory path (\#17055) Support directory paths in scans for Parquet, IPC and CSV (\#17017) Implement general array equality checks (\#17043) Add strict parameter to DataFrame/LazyFrame.drop and fix behavior to default to True (\#17044) Rename ModuleUpgradeRequired and PolarsPanicError error, remove InvalidAssert error (\#17033) Add rechunk parameter to read\_delta (\#16991) allow experimental metadata use on release (\#17005) Add simple version of json\_normalize (\#17015) Change data orientation inference logic for DataFrame construction and warn when row orientation is inferred (\#16976) Desugar AND filter into multiple nodes (\#16992) Handle textio even if not correct (\#16971) Properly apply strict parameter in Series constructor (\#16939) Add SQL support for INTERSECT and EXCEPT ops (\#16960) Add PerformanceWarning to LazyFrame properties (\#16964) Add collect\_schema method to LazyFrame and DataFrame (\#16929) Allow setting file cache TTL on a per-file basis (\#16891) Support Decimal inputs for lit (\#16950) Implement multiply and division for lhs duration (\#16948) Raise on invalid temporal arithmetic (\#16934) Always end with a in-memory sink on collect (\#16928) Add DataFrame.style namespace (\#16809) Add Schema class (\#16873) Normalize value\_counts (\#16917) Implement equality for more Array types (\#16902) Set up some of the infrastructure for new streaming engine (\#16900) Cache downloaded cloud IPC files (\#16892) Consistently convert to given time zone in Series constructor  (\#16828) Improve read\_csv SQL table reading function defaults (better handle dates) (\#16866) Support SQL VALUES clause and inline renaming of columns in CTE \& derived table definitions (\#16851) Support Python Enum values in lit (\#16858) Convert to given time zone in .str.to\_datetime when values are offset-aware (\#16742) Update reshape to return Array types instead of List types (\#16825) Default to raising on out-of-bounds indices in all get/gather operations (\#16841) Support SQL "SELECT" with no tables, optimise registration of globals (\#16836) Native selector XOR set operation, guarantee consistent selector column-order (\#16833) Extend recognised EXTRACT and DATE\_PART SQL part abbreviations (\#16767) Improve error message when raising integers to negative integers, improve docs (\#16827) Return datetime for mean/median of Date colum (\#16795) Update set\_sorted to only accept a single column (\#16800) Expose overflowing cast (\#16805) Update group\_by iteration and partition\_by to always return tuple keys (\#16793) Support array arithmetic for equally sized shapes (\#16791) Expedited removal of certain deprecated functionality (2) (\#16779) Removal of read\_database\_uri passthrough from read\_database (\#16783) Remove pyxlsb engine from read\_database (\#16784) Add check\_order parameter to assert\_series\_equal (\#16778) Enforce deprecation of keyword arguments as positional (\#16755) Support cloud storage in scan\_csv (\#16674) Streamline SQL INTERVAL handling and improve related error messages, update sqlparser-rs lib (\#16744) Support use of ordinal values in SQL ORDER BY clause (\#16745) Support executing polars SQL against pandas and pyarrow objects (\#16746) Remove deprecated parameters in Series.cut/qcut and update struct field names (\#16741) Expedited removal of certain deprecated functionality (\#16754) Remove deprecated functionality from rolling methods (\#16750) Update date\_range to no longer produce datetime ranges (\#16734) Mark min\_periods as keyword-only for rolling methods (\#16738) Remove deprecated top\_k parameters nulls\_last, maintain\_order, and multithreaded (\#16599) Support order-by in window functions (\#16743) Add SQL support for NULLS FIRST/LAST ordering (\#16711) Update some error types to more appropriate variants (\#15030) Initial SQL support for INTERVAL strings (\#16732) Scheduled removal of deprecated functionality (2) (\#16724) Scheduled removal of deprecated functionality (\#16715) Enforce deprecation of offset arg in truncate and round (\#16655) Change default offset in group\_by\_dynamic from 'negative every' to 'zero' (\#16658) Constrain access to globals from DataFrame.sql in favor of top-level pl.sql (\#16598) Read 2D NumPy arrays as Array type instead of List (\#16710) Update clip to no longer propagate nulls in the given bounds (\#14413) Change str.to\_datetime to default to microsecond precision for format specifiers "\%f" and "\%.f" (\#13597) Update resulting column names in pivot when pivoting by multiple values (\#16439) Preserve nulls in ewm\_mean, ewm\_std, and ewm\_var (\#15503) Restrict casting for temporal data types (\#14142) Add many more auto-inferable datetime formats for str.to\_datetime (\#16634) Support Decimal types by default when converting from Arrow (\#15324) Remove serde functionality from pl.read\_json and DataFrame.write\_json (\#16550) Update function signature of nth to allow positional input of indices, remove columns parameter (\#16510) Rename struct fields of rle output to len/value and update data type of len field (\#15249) Remove class variables from some DataTypes (\#16524) Add check\_names parameter to Series.equals and default to False (\#16610) Dedicated SQLInterface and SQLSyntax errors (\#16635) Add DIV function support to the SQL interface (\#16678) Support non-coalescing streaming left join (\#16672) Allow wildcard and exclude before struct expansions (\#16671) ðŸž Bug fixes Raise on invalid shape dataframe arithmetic (\#17322) Fix panic in window case (\#17320) Raise errors instead of panicking when sink\_csv fails (\#17313) Raise if join keys are passed to cross join (\#17305) Ensure we don't close extant adbc connections in write\_database (\#17298) Don't null on oob in list.get for column index (\#17276) Fix issue where sliced PyArrow record batches were not handled correctly (\#17058) Don't oob on nulls in list.get (\#17262) Fix list getter with nulls (\#17261) Respect nulls\_last parameter in aggregate sort\_by (\#17249) Fix literal slice in group by (\#17242) Fix DataFrame.top\_k not handling nulls correctly (\#17239) Update implementation of Enum support in lit to address spurious test failure (\#17187) Use explicit turbofish to help rustc (\#17159) Raise on invalid set dtypes (\#17157) Fix corrupted reads for hive parts from cloud and projection pushdown failure on hive parts (\#17152) Set intersection supertype (\#17154) ChainedWhen should not inherit Expr (\#17142) Fix decompress\_impl for csv with n\_rows set (\#17118) Fix incorrect window std for chunked series (\#17110) Fix panic when using fold in certain situations (\#17114) Fix melt panic (\#17088) Fix expression autocomplete in IPython (\#17072) Exclude index from expansion in rolling/group\_by\_dynamic (\#17086) Update some Series dunder method type signatures (\#17053) Fix oob of join with literals and empty table (\#17047) Don't silently accept multi-table FROM clauses (implicit JOIN syntax) (\#17028) Don't split up ANDed filters that are group-aware (\#17031) Harden "async" check for users with out-of-date sqlalchemy libraries (\#17029) Error when sort\_by of unequal length (\#17026) Properly catch not found explode cols (\#17020) Correctly convert data frames to NumPy for C index order (\#17000) Raise on invalid arithmetic shapes (\#16986) Don't pushdown predicates in cross join if the refer to both tables (\#16983) Fix projection pushdown with literal joins (\#16981) Fix edge case in DataFrame constructor data orientation inference (\#16975) Raise on list of objects (\#16959) Handle strictness for Decimal Series construction (\#15309) Don't panic in object to anyvalue (\#16957) Properly set FAST\_EXPLODE\_LIST metadata (\#16951) Raise informative error when writing object to file (\#16954) Remove supertype definition of List and non-List types (\#16918) Remove unwrap in extend() (\#16890) Fix should\_rechunk check (\#16852) Ensure read\_excel and read\_ods return identical frames across all engines when given empty spreadsheet tables (\#16802) Consistent behaviour when "infer\_schema\_length=0" for read\_excel (\#16840) Standardised additional SQL interface errors (\#16829) Ensure that splitted ChunkedArray also flattens chunks (\#16837) Reduce needless panics in comparisons (\#16831) Reset if next caller clones inner series (\#16812) Raise on non-positive json schema inference (\#16770) Rewrite implementation of top\_k/bottom\_k and fix a variety of bugs (\#16804) Fix comparison of UInt64 with zero (\#16799) Fix incorrect parquet statistics written for UInt64 values {$>$} Int64::MAX (\#16766) Fix boolean distinct (\#16765) DATE\_PART SQL syntax/parsing, improve some error messages (\#16761) Include pl. qualifier for inner dtypes in to\_init\_repr (\#16235) Column selection wasn't applied when reading CSV with no rows (\#16739) Panic on empty df / null List(Categorical) (\#16730) Only flush if operator can flush in streaming outer join (\#16723) Raise unsupported cat array (\#16717) Assert SQLInterfaceError is raised (\#16713) Restrict casting for temporal data types (\#14142) Handle nested categoricals in assert\_series\_equal when categorical\_as\_str=True (\#16700) Improve read\_database check for SQLAlchemy async Session objects (\#16680) Reduce scope of multi-threaded numpy conversion (\#16686) Full null on dyn int (\#16679) Fix filter shape on empty null (\#16670) ðŸ“– Documentation Update version switcher for 1.0.0 final release (\#16848) Finish upgrade guide for 1.0.0 (\#17257) Minor layout/terminology improvement for selector set ops (\#17299) Mark hypothesis testing functionality as unstable (\#17258) Add SQL docs for the CAST and TRY\_CAST functions (\#17214) Mark plot namespace as unstable (\#17205) Bump docs dependencies (\#17199) More accurate and helpful docs for user defined functions (\#15194) Add doc examples to concat\_list (\#17127) Add "coming from pandas" note to DataFrame.unique docstring (\#17119) Fix some warnings during doc build (\#17077) Properly expose InProcessQuery in docs, mark as unstable (\#17097) Add upgrade guide for Python Polars 1.0.0 (\#16914) Lots of additions to the SQL reference docs (\#16990) Minor doctest fixes (\#17002) Include a doc entry for every exception type (\#17001) Fixup bullet points in write\_parquet docstring (\#16909) Update version switcher for 1.0.0 prereleases (\#16847) Update link from Python API reference to user guide (\#16849) Update docstring/test/etc usage of select and with\_columns to idiomatic form (\#16801) Update versioning docs for 1.0.0 (\#16757) Add docstring example for DataFrame.limit (\#16753) Fix incorrect stated value of include\_nulls in DataFrame.update docstring (\#16701) Update deprecation docs in the user guide (\#14315) Add example for index count in DataFrame.rolling (\#16600) Improve docstring of Expr/Series.map\_elements (\#16079) Add missing polars.sql docs entry and small docstring update (\#16656) ðŸ“¦ Build system Update Cargo.lock (\#17284) Streamline optional dependency definitions in pyproject.toml (\#17168) Update rustc 2024-06-23 (\#17135) Do not set environment variable on import (\#17101) Fix config flag for Tracemalloc (\#17098) Pin optional NumPy dependency to {$<$} 2.0.0 for now (\#17060) ðŸ› ï¸ Other improvements Fix typo in join validation error message (\#17296) Fix linting issue in docs (\#17292) Use typed iter in list.get (\#17286) Rename type\_aliases module to \_typing (\#17282) add ability to have pipeline blockers in new streaming engine (\#17247) Support date/datetime for hive parts (\#17256) Refactor serde tests, add hypothesis tests (\#17216) Refactor parsing of data type inputs to Polars data types (\#17164) Skip all moto AWS tests for now (\#17178) Add missing spaces in cargo.toml (\#17145) Minor test refactor for concat\_list (\#17120) Remove re-export of data type groups (\#17073) Add pivot test \#17081 (\#17090) Minor cleanup to better define boundaries of public API (\#17051) Support directory paths in scans for Parquet, IPC and CSV (\#17017) Remove re-export of type aliases (\#17032) Remove file cache test (\#17038) Update exception imports in test suite (\#17035) Point polars-stream to crates/ again (\#17024) Fix failing file cache test in CI (\#17014) Add some parametric tests for sort functionality (\#17008) Pin NumPy to {$<$}2.0 for now (\#16999) Use proper join type in test (\#16994) Fix file cache verbose logging leakage during pytest (\#16984) Skip another intermitently failing AWS test (\#16980) Update test suite to explicitly use orient="row" in DataFrame constructor when applicable (\#16977) Remove redundant projection attribute in IR::DataFrameScan (\#16952) Factor out some apply calls in duration namespace (\#16941) Skip intermittently failing AWS test (\#16908) Refactor expression parsing utils (\#16906) Set up some of the infrastructure for new streaming engine (\#16900) Refactor parts of IR. (\#16899) Add fundamentals for new async-based streaming execution engine (\#16884) Move around some existing tests (\#16877) Remove inner Arc from FileCacheEntry (\#16870) Do not update stable API reference on prerelease (\#16846) Update links to API references (\#16843) Prepare update of API reference URLs (\#16816) Rename allow\_overflow to wrap\_numerical (\#16807) Set infer\_schema\_length as keyword-only argument in str.json\_decode (\#16835) Don't enter streaming engine for groupby-{$>$} agg mean/median â€¦ (\#16810) Improve safety of amortized\_iter (\#16820) Remove needless inner type clone (\#16718) Fix incorrect debug assertion in ChunkedArray::from\_chunks\_and\_dtype (\#16697) Update version resolver for 1.0.0 release (\#16705) Avoid AWS pinning to outdated crc32c version (\#16681) Thank you to all our contributors for making this release possible! @IvanIsCoding, @JamesCE2001, @JulianCologne, @KDruzhkin, @Kylea650, @MarcoGorelli, @Mottl, @Object905, @SeanTater, @adamreeve, @alexander-beedie, @bertiewooster, @borchero, @c-peters, @coastalwhite, @datapythonista, @datenzauberai, @dependabot, @dependabot[bot], @eitsupi, @flisky, @henryharbeck, @itamarst, @jqnatividad, @lukeshingles, @machow, @marenwestermann, @mcrumiller, @montanarograziano, @nameexhaustion, @orlp, @p3i0t, @ritchie46, @sherlockbeard, @stinodego, @tkellogg, @universalmind303 and @wence-},
  organization = {Zenodo},
  file = {/Users/robin/Zotero/storage/P2GHEQ96/12606903.html}
}

@software{warmerdamKoaningScikitlegoV0952025,
  title = {Koaning/Scikit-Lego: V0.9.5},
  shorttitle = {Koaning/Scikit-Lego},
  author = {family=Warmerdam, given=Vincent, prefix=D, useprefix=false and Bruzzesi, Francesco and MBrouns and Collot, StÃ©phane and family=Boer, given=Josko, prefix=de, useprefix=false and KÃ¼bler, Robert and family=hoeven, prefix=pim-, useprefix=true and {mkalimeri} and Paulino, Arthur and Gorelli, Marco Edward and Verheijen, Peter and Borry, Maxime and Hoogland, Kay and Masip, David and Kowalczuk, Magdalena and {ktiamur} and AminaZ and Sharma, Gaurav and Lepelaars, Carlo and Rens and Cor and Hermans, Frits and Borrella, Tomas and Rose, Stephen Anthony and family=Dorsten, given=Sander, prefix=van, useprefix=false and Levitski, Hleb and Keromnes, Jan and PÃ©rez-Lozao, Sergio CalderÃ³n and Payne, Skylar},
  date = {2025-04-30},
  doi = {10.5281/zenodo.15313097},
  url = {https://zenodo.org/records/15313097},
  urldate = {2025-07-22},
  abstract = {Minor bugfix release, mainly for https://github.com/koaning/scikit-lego/pull/742},
  organization = {Zenodo},
  file = {/Users/robin/Zotero/storage/Y2T2RU6L/15313097.html}
}
@article{reynaEarlyPredictionSepsis2020a,
  title = {Early {{Prediction}} of {{Sepsis From Clinical Data}}: {{The PhysioNet}}/{{Computing}} in {{Cardiology Challenge}} 2019},
  shorttitle = {Early {{Prediction}} of {{Sepsis From Clinical Data}}},
  author = {Reyna, Matthew A. and Josef, Christopher S. and Jeter, Russell and Shashikumar, Supreeth P. and Westover, M. Brandon and Nemati, Shamim and Clifford, Gari D. and Sharma, Ashish},
  date = {2020-02},
  journaltitle = {Critical Care Medicine},
  shortjournal = {Crit Care Med},
  volume = {48},
  number = {2},
  eprint = {31939789},
  eprinttype = {pubmed},
  pages = {210--217},
  issn = {1530-0293},
  doi = {10.1097/CCM.0000000000004145},
  langid = {english},
  pmcid = {PMC6964870},
  keywords = {Algorithms,Early Diagnosis,Electronic Health Records,Female,Humans,Intensive Care Units,Male,Sepsis,Severity of Illness Index,Time Factors,United States},
  file = {/Users/robin/Zotero/storage/GDGXT3SK/Reyna et al. - 2020 - Early Prediction of Sepsis From Clinical Data The PhysioNetComputing in Cardiology Challenge 2019.pdf}
}
