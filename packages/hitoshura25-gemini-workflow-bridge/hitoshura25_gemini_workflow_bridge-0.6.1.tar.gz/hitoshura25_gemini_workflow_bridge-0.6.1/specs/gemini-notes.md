Me: I would like to use the Gemini CLI from Claude Code. What are some ideal use cases for how the two work together

Gemini:
Using the Gemini CLI and Claude Code together allows you to create a powerful, multi-agent development workflow right in your terminal. Instead of using them as separate, competing tools, the ideal approach is to use Claude Code as the main "orchestrator" that calls the Gemini CLI as a specialized "subagent" for specific tasks.

This "best of both worlds" approach lets you leverage Claude's strengths in agentic planning and refactoring while tapping into Gemini's massive context window and free tier.

Here are the ideal use cases for how they work together.

1. üß† Large-Scale Codebase Analysis
This is the most common and powerful use case. The Gemini CLI (with Gemini 2.5 Pro) has a 1 million token context window, which is far larger than what you might typically use with Claude Code.

You can instruct Claude Code to delegate "big picture" analysis to the Gemini CLI. This keeps Claude's context window free to focus on the immediate task.

How it works: You'd prompt Claude Code: "Use the Gemini CLI to analyze the entire @src/ directory and explain the main data flow for our authentication service."

Why it's ideal: Claude Code doesn't need to load thousands of lines of code into its own context. It simply calls the gemini -p "..." command and gets a summary back, which it can then use to plan its next steps.

2. üßê "Second Opinion" Peer Reviews
You can use the Gemini CLI as an unbiased "peer reviewer" for code generated by you or by Claude Code.

How it works: After implementing a new feature with Claude Code, you can ask it: "This looks good. Now, please use the Gemini CLI to review these changes for any potential bugs, style issues, or missed edge cases."

Why it's ideal: This simulates a team environment where one developer (Claude) implements a feature and another (Gemini) reviews it. It's excellent for catching errors and improving code quality.

3. üí∏ Cost and Token Optimization
If you're using a paid plan for Claude Code, you can strategically offload token-intensive but simpler tasks to the Gemini CLI, which has a very generous free tier (e.g., 1,000 requests/day).

How it works: You can configure Claude Code's CLAUDE.md (its "memory" file) to default to using the Gemini CLI for tasks like generating documentation, writing unit tests, or summarizing files.

Why it's ideal: You save your more "expensive" Claude tokens for complex reasoning, planning, and multi-step refactoring, while using the free Gemini CLI for bulk-generation tasks.

4. üõ†Ô∏è Creating Specialized Subagents
For a more advanced workflow, you can formally define the Gemini CLI as a "subagent" tool within Claude Code's configuration. This makes the integration seamless.

How it works: You'd create a prompt for Claude Code that defines a new tool, like gemini-analyzer. This tool's job is to take a natural language request, format it into a gemini -p "..." command, execute it, and return the output.

Why it's ideal: You can create a whole suite of custom tools. For example, you could have:

gemini-security-scan: "Use your gemini-analyzer tool to scan the @api/ directory for potential security vulnerabilities."

gemini-feature-trace: "Use gemini-analyzer to trace the 'user-profile-update' feature across the entire codebase and list all relevant files."

üèÅ How to Get Started
The simplest way to start is by having both CLIs installed. Then, you can simply tell Claude Code to use the Gemini CLI in its non-interactive mode.

Example Prompt for Claude Code:

"I need to understand this project. Please use the Gemini CLI (gemini -p "prompt") to summarize the purpose of the files in the @src/utils/ directory and also to explain the project's overall architecture from the README.md."


Me: I have setup a mcp server for Claude Code to use Gemini CLI, it currently has tools for spec creation and analyzing the codebase. The spec creation tool will automatically use the analyze codebase tool to take advantage of Gemini's large context window. However, the spec document that comes back often misses details, and when I ask Claude to review it finds missing info or inaccurate specifications. This may mean it may more effective to utilize the "Cost and Token Optimization", where Claude does the actual planning and Gemini assists. What are some ways I can update the MCP server for this sort of workflow?

Gemini:
You've hit on the exact right insight. This is a classic "agentic workflow" challenge. Your spec-creation tool is trying to do two distinct cognitive tasks at once: analysis (what's there) and synthesis/planning (what should be there).Gemini's strength is the analysis on a massive context. Claude's strength is the synthesis and reasoning to create a detailed plan. Your observation is correct: it's more effective to have Claude do the planning using Gemini's analysis as a "raw material" rather than asking Gemini to deliver the final, planned-out spec.Here are concrete ways you can update your MCP server to support this "Claude-as-Planner, Gemini-as-Analyst" workflow.1. Deconstruct Your spec-creation ToolThe root of the issue is that your spec-creation tool is too "smart." It's trying to do Claude's job. The fix is to break it apart.You should deprecate or remove the spec-creation tool from your MCP server entirely. Claude Code itself will now be responsible for creating the spec. Instead, you will provide it with a "dumber," more focused tool that just provides the raw context it needs.2. Sharpen the analyze-codebase Tool's PurposeThis tool (powered by the Gemini CLI) is your new workhorse. Its sole purpose should be to provide raw facts, not to create a spec. You need to update its prompt on the MCP server to be very strict about its output.Update the analyze-codebase tool's system prompt on your MCP server to something like this:Your Role: You are a codebase analysis engine. Your only job is to answer questions about the provided codebase.Output Format:Respond only with factual information.List relevant files, functions, data structures, and class definitions.Trace data flow as requested.CRITICAL: DO NOT create a software spec. DO NOT suggest new features. DO NOT make creative inferences. Your job is to report what exists, not what should exist. Just provide the raw analysis.This change is critical. Now, when Claude calls this tool, it won't get a "half-baked" spec. It will get a "bag of facts" (e.g., "File auth.go has a Login function that takes User struct. User struct is defined in models.go...").3. Let Claude Code Do the "Thinking" (The New Workflow)With your new, focused analyze-codebase tool, the workflow now shifts responsibility to Claude. Instead of a one-shot request, the conversation becomes a two-step process (which Claude can often handle in one turn):Claude (Planner): "I need to write a spec. To do this, I must first understand the existing code."Claude (Tool User): "I will now call the analyze-codebase tool to get information on the @src/api/ and @src/services/ directories."Gemini (via MCP): (Returns the raw, factual analysis.)Claude (Planner): "Great. I have the user's request (...) and the codebase analysis (from the tool). I will now synthesize these two pieces of information to create a detailed spec."This workflow ensures Claude's superior reasoning and planning capabilities are applied to the raw, large-scale context provided by Gemini.4. (Optional) Add a "Spec Reviewer" ToolIf you still find gaps, you can add a new tool to your MCP server that acts as a dedicated reviewer. This is different from your old spec-creation tool.Tool Name: review-spec-for-gapsEngine: Claude (or even Gemini, just for a "second opinion")Prompt: "You are a senior solutions architect. You will be given a [User Request], a [Codebase Analysis], and a [Draft Spec]. Your job is to compare the [Draft Spec] against the other two documents and return a list of only the missing details, inaccuracies, or unhandled edge cases."How Claude Code would use this:"I have drafted a spec. I will now use the review-spec-for-gaps tool to get a second opinion before I show it to the user."Summary of MCP Server ChangesChangeOld Way (Problematic)New Way (Recommended)ToolingOne "smart" spec-creation tool that does analysis + planning.One "dumb" analyze-codebase tool that only does analysis.Gemini's RoleTries to analyze the code and write the final spec. (Misses details)Provides a raw, factual summary of a massive codebase. (High accuracy)Claude's RoleAsks for the spec and then has to re-do the work by reviewing it.Does the planning. It calls the tool for "facts" and then writes the spec itself.MCP Promptspec-creation prompt: "Analyze this code and write a spec..."analyze-codebase prompt: "Analyze this code and report only the facts..."By making your analyze-codebase tool a "dumb" (but powerful) fact-provider, you perfectly leverage the "Cost and Token Optimization" model. Gemini handles the massive token analysis, and Claude performs the high-value reasoning to turn that analysis into a high-quality plan.

Me: can you provide an example of the interactions of Claude Code with the MCP Server (that uses gemini) when it comes to planning a feature/change? Can you also explain how token/cost is actually optimized?

Gemini:
Here is a practical example of that interaction, followed by a clear explanation of how the tokens and costs are being optimized.Example: Planning a Feature ChangeLet's imagine you have a project and you want to refactor your simple string-based error handling to use a more robust, centralized Error class.Your Goal: "I want to stop using throw new Error("...") everywhere. I want to create a new AppError class in @src/utils/errors.js and refactor all @src/services/ files to use it. Create a spec for this."Here is the step-by-step interaction flow:[USER IN CLAUDE CODE]claude I need to plan a refactor. I want to create a new AppError class in @src/utils/errors.js that takes a message and a statusCode. Then, I need a plan to update all files in @src/services/ that currently use throw new Error(...) to use this new AppError class instead. Please create a specification for this change.[CLAUDE CODE (Internal Monologue)]"Okay, this is a planning task. The user wants a spec.Goal: Create AppError class and refactor @src/services/ to use it.Unknowns: I don't know how many files in @src/services/ use throw new Error. I don't know what kind of errors they are throwing (e.g., "Not Found", "Invalid Input", "Auth Failed"). If I just write a spec, I'll be guessing.Plan: I must first analyze the codebase to get the raw facts. I will use the analyze-codebase tool (which uses Gemini) to scan the entire @src/services/ directory for all instances of throw new Error.Step 2: Once I have that list of facts, I will use it and the user's request to write the final, detailed spec."[CLAUDE CODE (Executing Tool Call)]Calling MCP Server Tool: analyze-codebasePrompt to Gemini: "You are a code analysis engine. Scan all files in the @src/services/ directory. Find and list every single instance where throw new Error(...) is used. For each instance, provide the file path, line number, and the full error message string. DO NOT write a spec. Only return this list of facts."[MCP SERVER (Gemini) (Returning Tool Output)](Gemini ingests all 25 files and 50,000 tokens in @src/services/...)Tool Output:JSON{
  "analysis_summary": "Found 4 instances of 'throw new Error' in @src/services/",
  "instances": [
    {
      "file": "src/services/userService.js",
      "line": 42,
      "usage": "throw new Error('User not found')"
    },
    {
      "file": "src/services/userService.js",
      "line": 91,
      "usage": "throw new Error('Invalid email address')"
    },
    {
      "file": "src/services/projectService.js",
      "line": 25,
      "usage": "throw new Error('Project not found')"
    },
    {
      "file": "src/services/projectService.js",
      "line": 150,
      "usage": "throw new Error('You do not have permission')"
    }
  ]
}
[CLAUDE CODE (Internal Monologue)]"Excellent. The analysis is complete. I have 4 specific instances to refactor. I see 'Not Found' errors, a validation error, and a permission error. This is enough information to write a high-quality spec."[CLAUDE CODE (Final Response to User)]Hello! I've analyzed the @src/services/ directory and found 4 instances that need to be refactored.Based on this analysis, here is the detailed implementation specification for creating and adopting the new AppError class:1. Create New AppError ClassFile: src/utils/errors.jsJavaScript// New file: @src/utils/errors.js
class AppError extends Error {
  constructor(message, statusCode) {
    super(message);
    this.statusCode = statusCode;
    this.status = `${statusCode}`.startsWith('4') ? 'fail' : 'error';
    this.isOperational = true;
Error.captureStackTrace(this, this.constructor);
}}export default AppError;
### 2\. Refactor `userService.js`
Import: Add import AppError from '../utils/errors.js'; at the top of the file.Line 42: Change throw new Error('User not found') to throw new AppError('User not found', 404).Line 91: Change throw new Error('Invalid email address') to throw new AppError('Invalid email address', 400).3. Refactor projectService.jsImport: Add import AppError from '../utils/errors.js'; at the top of the file.Line 25: Change throw new Error('Project not found') to throw new AppError('Project not found', 404).Line 150: Change throw new Error('You do not have permission') to throw new AppError('You do not have permission', 403).This plan covers the creation of the new class and precisely updates all existing usages.How This Optimizes Tokens and CostThis "specialist" workflow is far more efficient than the alternatives. Let's compare the token usage:WorkflowInput Tokens (The "Cost")Reasoning Quality (The "Result")Old Way (Gemini-Only Spec)50,000 tokens of code + 100-token prompt.(User's original problem)Low. Gemini tries to analyze 50k tokens and write a spec at the same time. It's "lossy" and misses details, as you saw.Old Way (Claude-Only Spec)50,000 tokens of code + 100-token prompt.(Requires claude add @src/services/)High... but Expensive. Claude can do this, but you are paying for 50,000+ tokens to be processed in its context window just to find 4 lines.New Way (Gemini + Claude)Claude: 100-token user prompt.Gemini: 50,000 tokens of code (free tier)....Claude: 300-token analysis (from Gemini) + 100-token prompt.Total "Paid" Context for Claude: ~400 tokens.Very High. You use the free, large-context tool (Gemini) for the bulk analysis (needle-in-a-haystack search). Then, you use the paid, high-reasoning tool (Claude) on a tiny, high-signal context (just the results) to do the planning.The optimization is simple:You are "compressing" 50,000 tokens of low-signal codebase context into a 300-token, high-signal summary using Gemini's free, large-context window.You then feed only that valuable 300-token summary to Claude, which uses its (paid) superior reasoning on a tiny context window. You are substituting free, bulk-analysis tokens for expensive, high-reasoning tokens.