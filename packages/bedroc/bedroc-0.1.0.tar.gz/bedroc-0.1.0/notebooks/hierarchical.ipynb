{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf616bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "\n",
    "from bedroc import debug_logger\n",
    "from bedroc.hierarchical import (\n",
    "    Analyzer,\n",
    "    SyntheticDataGenerator,\n",
    "    hierarchical_difference_model,\n",
    "    zero_difference_model,\n",
    ")\n",
    "\n",
    "logger = debug_logger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e3551",
   "metadata": {},
   "source": [
    "# Hierarchical Bayesian analysis for multi-feature data\n",
    "\n",
    "We apply a hierarchical Bayesian modeling framework to multi-feature data in order to infer systematic differences between two groups, A and B. Each data point contains multiple measured features, and these features may vary widely in scale, noise level, or informativeness. A hierarchical formulation allows the model to borrow statistical strength across features, leading to more stable and interpretable inferences.\n",
    "\n",
    "In the model, each feature has its own mean in group A and an associated mean difference describing how group B deviates from group A. These per-feature differences are not estimated independently; instead, they are linked through a higher-level distribution controlled by a global scale parameter. This induces partial pooling, which automatically shrinks poorly constrained differences toward zero while allowing genuinely strong signals to stand out.\n",
    "\n",
    "This approach provides coherent uncertainty quantification, posterior estimates of feature-level effect sizes, and a principled comparison against a simpler zero-difference model. The hierarchical model is therefore well suited for high-dimensional problems where features differ in variability or sample support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5b156",
   "metadata": {},
   "source": [
    "## Generate and plot synthetic data\n",
    "\n",
    "Set a random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee3f5b",
   "metadata": {},
   "source": [
    "We begin by generating synthetic data to explore the behaviour of the hierarchical model. The parameters below control the separation between the two groups, the variability of feature means, and the underlying noise levels. You are encouraged to modify these settings to observe how changes in effect size, noise, or feature-level variability influence the inference and model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311654a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = SyntheticDataGenerator(\n",
    "    100,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    # difference_scale=0.5,\n",
    "    # type_a_std_of_mean=1.0,\n",
    "    # type_b_std_of_mean=1.5,\n",
    "    # sigma_min=0.5,\n",
    "    # sigma_max=2.0,\n",
    ")\n",
    "data_generator.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167cd707",
   "metadata": {},
   "source": [
    "We next plot the synthetic dataset to visualise the underlying structure of the two groups. The figure displays the raw feature distributions for Types A and B alongside the true parameters used to generate them, allowing us to verify the intended separation and noise characteristics before fitting any models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56962a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data_generator.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea9e44",
   "metadata": {},
   "source": [
    "This line calls the helper function ``hierarchical_difference_model``, which builds and samples the hierarchical Bayesian model. It returns both the constructed PyMC model object (``model``) and the posterior samples stored in an InferenceData object (``idata``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd48fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, idata = hierarchical_difference_model(\n",
    "    data_generator.X_A, data_generator.X_B, random_seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a4f75",
   "metadata": {},
   "source": [
    "# Analyze the inference\n",
    "\n",
    "After running the hierarchical Bayesian model and obtaining posterior samples in ``idata``, we create a data analyzer object. This analyzer helps us inspect and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Analyzer(model, idata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86684a",
   "metadata": {},
   "source": [
    "Use the data analyzer to visualize the results of the hierarchical Bayesian inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ae8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyzer.plot_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyzer.plot_posterior_predictive(thinning_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyzer.plot_posterior(var_names=[\"mu_A\", \"mu_B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyzer.plot_posterior_differences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyzer.plot_posterior_effect_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ef3b6",
   "metadata": {},
   "source": [
    "For the confusion matrix, we generate some out-of-sample data. The goal is to evaluate the model's classification performance on new data that was not seen during training. This allows us to test generalization, avoiding overly optimistic metrics that could arise if we only measured accuracy on the training set.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Generate new synthetic samples for both Type A and Type B using the same data generator, but ensuring they are independent of the training data.\n",
    "2. Stack the new samples together to form a single dataset for prediction.\n",
    "3. Create the corresponding true labels array to compare against model predictions.\n",
    "4. Pass this dataset to the analyzer's `plot_confusion_matrix` method to visualize how well the model separates Type A and Type B in previously unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_A_new, X_B_new = data_generator.generate_out_of_sample_data(n_samples=1000)\n",
    "X_new = np.vstack([X_A_new, X_B_new])\n",
    "true_labels = np.array([\"A\"] * len(X_A_new) + [\"B\"] * len(X_B_new))\n",
    "\n",
    "_ = analyzer.plot_confusion_matrix(X_new, true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5b55a",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "\n",
    "We can compare the hierarchical model with a zero-difference model to assess whether the data support feature-wise mean differences between types A and B. A \"zero difference\" model acts as a baseline or null hypothesis: there are no systematic differences between the two groups beyond noise.\n",
    "\n",
    "To compare these models, we use Leave-One-Out cross-validation (LOO) based on the pointwise log-likelihood. LOO evaluates how well each model predicts unseen data and automatically penalizes model complexity.\n",
    "\n",
    "If the hierarchical model shows a higher ELPD (less negative LOO), this supports the existence of feature-level differences between the two groups. If not, the data may not justify the additional hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_model, zero_idata = zero_difference_model(\n",
    "    data_generator.X_A, data_generator.X_B, random_seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "with model:\n",
    "    pm.compute_log_likelihood(idata)\n",
    "\n",
    "with zero_model:\n",
    "    pm.compute_log_likelihood(zero_idata)\n",
    "\n",
    "hierarchical_loo = az.loo(idata, var_name=\"X_obs\")\n",
    "zero_loo = az.loo(zero_idata, var_name=\"X_obs\")\n",
    "\n",
    "logger.debug(\"Hierarchical model LOO:\\n%s\", hierarchical_loo)\n",
    "logger.debug(\"Zero-difference model LOO:\\n%s\", zero_loo)\n",
    "\n",
    "df_comp_loo = az.compare(\n",
    "    {\"hierarchical\": idata, \"zero difference\": zero_idata},\n",
    "    ic=\"loo\",\n",
    "    var_name=\"X_obs\",\n",
    ")\n",
    "\n",
    "# Format DataFrame nicely for logging\n",
    "loo_str = df_comp_loo.to_string(\n",
    "    float_format=\"{:.6f}\".format,  # round floats to 3 decimals\n",
    "    justify=\"right\",  # right-align columns\n",
    "    col_space=10,  # minimum column width\n",
    ")\n",
    "\n",
    "logger.info(\"LOO model comparison:\\n%s\", loo_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9812ba",
   "metadata": {},
   "source": [
    "There is a convenient function to visualize model comparison results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afaaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = az.plot_compare(df_comp_loo, insample_dev=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedroc (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
