from math import log
from typing import List, Dict, Any

from .ai_helpers import get_enabled_tools_openai_format, process_tool_calls, requires_user_confirmation, needs_tool_call
from .plan_executor import PlanExecutor
from ..widgets import ChatHistoryWidget, ModelSelectorWidget, ChatInputWidget
from ketacli.sdk.textual_chart.utils.history_utils import build_user_history_summary, build_user_raw_inputs_summary
import logging
import json
import hashlib
logger = logging.getLogger("ketacli.textual")

# æ–°å¢ï¼šåŸºäºå†…å®¹æŒ‡çº¹çš„å»é‡ï¼Œé¿å…é‡å¤çš„å¤§å—æ–‡æœ¬è¿›å…¥ä¸Šä¸‹æ–‡

def _fingerprint_text(text: str) -> str:
    try:
        return hashlib.sha256(text.encode("utf-8", "ignore")).hexdigest()[:16]
    except Exception:
        return str(len(text) or 0)


def _dedup_messages_by_content(existing: list, new_msgs: list, min_len: int = 400) -> list:
    """åœ¨è¿½åŠ æ–°æ¶ˆæ¯å‰è¿›è¡Œå»é‡ï¼š
    - ä»…é’ˆå¯¹é•¿åº¦è¾ƒå¤§çš„æ¶ˆæ¯ï¼ˆé»˜è®¤>=400å­—ç¬¦ï¼‰ï¼Œé¿å…å°æç¤ºè¢«è¯¯æ€
    - æ¯”å¯¹ existing ä¸­å·²å­˜åœ¨å†…å®¹çš„æŒ‡çº¹ï¼Œè·³è¿‡é‡å¤
    """
    try:
        seen = set()
        for m in existing or []:
            c = (m.get("content") or "")
            if len(c) >= min_len:
                seen.add(_fingerprint_text(c))
        filtered = []
        for m in new_msgs or []:
            c = (m.get("content") or "")
            if len(c) < min_len:
                filtered.append(m)
                continue
            fp = _fingerprint_text(c)
            if fp in seen:
                logger.debug(f"[dedup] è·³è¿‡é‡å¤æ¶ˆæ¯ role={m.get('role')} len={len(c)} fp={fp}")
                continue
            seen.add(fp)
            filtered.append(m)
        return filtered
    except Exception:
        return new_msgs


# ç»Ÿä¸€æ ‡è®°å¸¸é‡ä¸åˆ¤å®šåŠ©æ‰‹ï¼ˆé‡æ„ï¼‰
# æ–°ç‰ˆæ ‡ç­¾ï¼ˆå”¯ä¸€é€‰æ‹©ã€è¯­ä¹‰æ¸…æ™°ï¼‰ï¼š
# - [STEP_NEXT]ï¼šå½“å‰æ­¥éª¤å·²å®Œæˆï¼Œå¹¶æ˜ç¡®ç»™å‡ºä¸‹ä¸€æ­¥è®¡åˆ’ï¼ˆæ¨è¿›ï¼‰
# - [STEP_WAIT]ï¼šå½“å‰æ­¥éª¤æœªå®Œæˆï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤/è¡¥å……ä¿¡æ¯ï¼ˆæš‚åœï¼‰
# - [STEP_BLOCKED]ï¼šå¤–éƒ¨ç³»ç»Ÿ/æƒé™/èµ„æºé—®é¢˜å¯¼è‡´æ— æ³•ç»§ç»­ï¼ˆç»ˆæ­¢è¯¥æ­¥ï¼‰
# - [TASK_DONE]ï¼šæ•´ä¸ªä»»åŠ¡å·²å®Œæˆï¼ˆç»“æŸä¼šè¯ï¼‰
NEW_STEP_NEXT_MARKERS = {"[STEP_NEXT]", "[step_next]"}
NEW_STEP_WAIT_MARKERS = {"[STEP_WAIT]", "[step_wait]"}
NEW_STEP_BLOCKED_MARKERS = {"[STEP_BLOCKED]", "[step_blocked]"}
NEW_TASK_DONE_MARKERS = {"[TASK_DONE]", "[task_done]"}

# å…¼å®¹æ—§æ ‡ç­¾ï¼ˆä¿ç•™è¯†åˆ«ï¼Œä¸åœ¨æç¤ºä¸­å†ä½¿ç”¨ï¼‰ï¼š
DONE_MARKERS = {"[STEP_DONE]", "[step_done]", "æ­¥éª¤å®Œæˆ", "å®Œæˆè¯¥æ­¥éª¤", "å·²å®Œæˆè¯¥æ­¥éª¤"} | NEW_STEP_NEXT_MARKERS
CONTINUE_MARKERS = {"[STEP_CONTINUE]", "[step_continue]", "ç»§ç»­ä¸‹ä¸€æ­¥", "éœ€è¦ç»§ç»­", "ç»§ç»­æ‰§è¡Œ", "ç»§ç»­"}
REQUIRE_USER_MARKERS = {"[STEP_REQUIRE_USER]", "[step_require_user]"} | NEW_STEP_WAIT_MARKERS

# ä¼šè¯ç»“æŸæ ‡è®°ï¼šæ‰©å±•åŒ…å«å®Œæˆç±»ä¸­æ–‡çŸ­è¯­ä¸æ–°ä»»åŠ¡å®Œæˆæ ‡ç­¾
SESSION_DONE_MARKERS = {
    "[SESSION_DONE]", "[session_done]", "ä¼šè¯ç»“æŸ", "ç»“æŸä¼šè¯",
    "ä»»åŠ¡å·²å®Œæˆ", "ä»»åŠ¡å®Œæˆ", "å¯¹è¯å®Œæˆ",  "å·²å®Œæˆä»»åŠ¡"
} | NEW_TASK_DONE_MARKERS

# å®Œæˆç±»æ–‡æœ¬æ ‡è®°ï¼ˆç”¨äºæ— å·¥å…·è°ƒç”¨æ—¶çš„æ—©åœè¯†åˆ«ï¼‰
COMPLETE_MARKERS = {"ä»»åŠ¡å·²å®Œæˆ", "ä»»åŠ¡å®Œæˆ", "å¯¹è¯å®Œæˆ", "å·²å®Œæˆä»»åŠ¡"} | NEW_TASK_DONE_MARKERS


 

def safe_notify(app, message: str, severity: str = None, timeout: int = None, **kwargs) -> None:
    """å®‰å…¨é€šçŸ¥åŒ…è£…ï¼šç»Ÿä¸€æ•è·é€šçŸ¥å¼‚å¸¸ï¼Œå‡å°‘è§†è§‰å™ªéŸ³ã€‚"""
    try:
        notify = getattr(app, "notify", None)
        if callable(notify):
            if severity is not None:
                kwargs["severity"] = severity
            if timeout is not None:
                kwargs["timeout"] = timeout
            notify(message, **kwargs)
    except Exception:
        pass


def has_marker(text: str, markers: set) -> bool:
    try:
        lower = (text or "").lower()
    except Exception:
        lower = ""
    if not lower:
        return False
    return any((m or "").lower() in lower for m in (markers or set()))

# æ–°å¢ï¼šæ˜¯å¦ç»“æŸä¼šè¯åˆ¤å®š
def should_end_session(text: str, has_tool_calls: bool = False) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”ç»“æŸå½“å‰ä¼šè¯ï¼š
    - è‹¥åŒ…å«ä¼šè¯ç»“æŸæ ‡è®°ï¼Œç›´æ¥ç»“æŸï¼›
    - è‹¥å­˜åœ¨å·¥å…·è°ƒç”¨ï¼Œä¼˜å…ˆæ‰§è¡Œå·¥å…·ï¼Œä¸ä»¥ STEP_DONE ç»“æŸä¼šè¯ï¼›
    - è‹¥æ˜ç¡®å®Œæˆä¸”æœªå¸¦ç»§ç»­æ ‡è®°ï¼Œåˆ™ç»“æŸä¼šè¯ã€‚
    """
    try:
        # 1) æ˜¾å¼ä¼šè¯ç»“æŸæ ‡è®°
        if has_marker(text, SESSION_DONE_MARKERS):
            return True
        # 2) è‹¥æ— å·¥å…·è°ƒç”¨ï¼Œä¸”æ–‡æœ¬å‘½ä¸­å®Œæˆç±»æ ‡è®°ï¼ŒåŒæ—¶ä¸åŒ…å«ç»§ç»­/ç”¨æˆ·ç¡®è®¤æ ‡è®°ï¼Œåˆ™æ—©åœ
        if (not has_tool_calls) and has_marker(text, COMPLETE_MARKERS):
            if (not has_marker(text, CONTINUE_MARKERS)) and (not should_pause_for_user(text)):
                return True
        return False
    except Exception:
        return False

def should_pause_for_user(text: str) -> bool:
    return bool(
        requires_user_confirmation(text)
        or has_marker(text, REQUIRE_USER_MARKERS)
        or has_marker(text, NEW_STEP_WAIT_MARKERS)
    )


def should_force_tool_call(app: Any, messages: List[Dict[str, Any]], user_text: str) -> bool:
    """ç»Ÿä¸€çš„å·¥å…·åˆ†æ”¯å¼ºåˆ¶åˆ¤å®šï¼š
    - è‹¥ç”¨æˆ·æ–‡æœ¬å«â€œç»§ç»­â€è¯­ä¹‰æ ‡è®°ï¼Œåˆ™å¼ºåˆ¶èµ°å·¥å…·åˆ†æ”¯ï¼›
    - è‹¥æœ€è¿‘å†å²ä¸­å­˜åœ¨ tool è§’è‰²æ¶ˆæ¯ï¼ˆè¡¨ç¤ºå·¥å…·ä¸Šä¸‹æ–‡ä»åœ¨è¿›è¡Œï¼‰ï¼Œä¹Ÿè¿›å…¥å·¥å…·åˆ†æ”¯ï¼›
    - è‹¥æœ€è¿‘ assistant/user/system æ–‡æœ¬å‡ºç°ç»§ç»­è¯­ä¹‰ï¼Œä¹Ÿè¿›å…¥å·¥å…·åˆ†æ”¯ã€‚
    """
    try:
        if has_marker(user_text, CONTINUE_MARKERS):
            return True
        recent = messages[-6:] if messages else []
        for m in recent:
            if (m or {}).get("role") == "tool":
                return True
        for m in messages[-3:] if messages else []:
            if (m or {}).get("role") in ("assistant", "user", "system"):
                if has_marker((m or {}).get("content") or "", CONTINUE_MARKERS):
                    return True
    except Exception:
        return False
    return False


async def execute_task_steps(app: Any, steps: List[str], original_user_text: str) -> None:
    """æ‰§è¡Œä»»åŠ¡æ­¥éª¤çš„é€šç”¨æµç¨‹ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ä¸æ€»ç»“æ ‡è®°ã€‚

    å‚æ•°:
        app: æºå¸¦ UI/çŠ¶æ€/AI å®¢æˆ·ç«¯çš„åº”ç”¨å®ä¾‹
        steps: å·²è§„åˆ’çš„æ­¥éª¤åˆ—è¡¨
        original_user_text: åŸå§‹ç”¨æˆ·è¾“å…¥æ–‡æœ¬ï¼ˆç”¨äºä¸Šä¸‹æ–‡æç¤ºï¼‰
    """
    logger.debug(f"[steps] å¯åŠ¨æ­¥éª¤æ‰§è¡Œï¼šæ•°é‡={len(steps)}ï¼ŒåŸå§‹æ–‡æœ¬é•¿åº¦={len(original_user_text or '')}")
    # æ ‡è®°è®¡åˆ’çŠ¶æ€ä¸ºè¿è¡Œä¸­
    try:
        setattr(app, "plan_status", "running")
    except Exception:
        pass

    # ä¿æŠ¤æ€§æ£€æŸ¥
    if not getattr(app, "ai_client", None):
        safe_notify(app, "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–", severity="error")
        return

    # è·å– UI ç»„ä»¶ï¼ˆå®¹é”™ï¼‰
    try:
        chat_history = app.query_one("#chat-history", None)
        model_selector = app.query_one("#model-selector", None)
    except Exception:
        chat_history = None
        model_selector = None

    # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹åˆ·æ–°å®¢æˆ·ç«¯ï¼ˆå®¹é”™ï¼‰
    try:
        selected_model = model_selector.get_selected_model() if model_selector else None
        if selected_model:
            app.ai_client = app.ai_client.__class__(
                system_prompt=getattr(app.ai_client, "system_prompt", ""),
                model_name=selected_model,
            )
        logger.debug(f"[steps] å½“å‰é€‰å®šæ¨¡å‹={selected_model}ï¼›ç³»ç»Ÿæç¤ºè¯é•¿åº¦={len(getattr(app.ai_client, 'system_prompt', '') or '')}")
    except Exception:
        pass

    # æ¯æ­¥è¿­ä»£ä¸Šé™ï¼ˆè¯»å–é…ç½®å¹¶é™æµï¼‰
    try:
        max_step_iterations = getattr(app.ai_client.model_config, "max_iterations", 8) or 8
        if not isinstance(max_step_iterations, int) or max_step_iterations <= 0:
            max_step_iterations = 8
        max_step_iterations = min(max_step_iterations, 8)
        logger.debug(f"[steps] æ¯æ­¥è¿­ä»£ä¸Šé™={max_step_iterations}")
    except Exception:
        max_step_iterations = 8

    # å®Œæˆ/ç»§ç»­æ ‡è®°ï¼ˆç»Ÿä¸€å¸¸é‡ï¼‰
    done_markers = DONE_MARKERS
    continue_markers = CONTINUE_MARKERS

    # è·å–å·¥å…·åˆ—è¡¨ï¼ˆå®¹é”™ï¼‰
    try:
        tools = get_enabled_tools_openai_format(getattr(app, "enabled_tools", {}))
        try:
            tool_names = [t.get("function", {}).get("name") for t in (tools or [])]
            logger.debug(f"[tools] æ­¥éª¤æ‰§è¡Œå·¥å…·ï¼šæ•°é‡={len(tools)}ï¼›åç§°={tool_names}")
        except Exception:
            pass
    except Exception:
        tools = []
    # æ–°å¢ï¼šç”¨äºè·¨è¿­ä»£å»é‡å·¥å…·è°ƒç”¨çš„ç­¾åé›†åˆ
    executed_tool_signatures = set()
    # é€æ­¥æ‰§è¡Œ
    for idx, step in enumerate(steps, start=1):
        try:
            if chat_history:
                chat_history.add_message("assistant", f"â–¶ï¸ å¼€å§‹æ‰§è¡Œç¬¬ {idx} æ­¥ï¼š{step}")
            logger.debug(f"[step] å¼€å§‹ç¬¬{idx}æ­¥ï¼šå†…å®¹é•¿åº¦={len(step or '')}")


            # åŸºç¡€æ¶ˆæ¯ï¼ˆå«ä¸¥æ ¼æ ‡è®°æç¤ºï¼‰
            base_messages: List[Dict[str, Any]] = list(getattr(app, "conversation_history", []))
            # ä»…æ”¶é›†ç”¨æˆ·æ›¾ç»è¾“å…¥è¿‡çš„ä¿¡æ¯ï¼ˆå…¬å…±æ–¹æ³•è§£ææ‘˜è¦ï¼‰ï¼Œæ’é™¤å½“å‰è¾“å…¥ä¸åˆæˆæ¶ˆæ¯
            # ä¼˜å…ˆä½¿ç”¨åŸå§‹è¾“å…¥æ‘˜è¦ï¼Œå…¶æ¬¡å›é€€åˆ°ä¼šè¯å†å²
            try:
                _user_history_text = build_user_raw_inputs_summary(
                    getattr(app, "user_raw_inputs", []),
                    current_task_text=original_user_text,
                )
                if _user_history_text == "æ— ":
                    _user_history_text = build_user_history_summary(
                        getattr(app, "conversation_history", []),
                        current_task_text=original_user_text,
                        exclude_synthetic=True,
                    )
            except Exception:
                _user_history_text = build_user_history_summary(
                    getattr(app, "conversation_history", []),
                    current_task_text=original_user_text,
                    exclude_synthetic=True,
                )
            logger.debug(f"[step] ä¸Šä¸‹æ–‡å‡†å¤‡ï¼šå†å²æ¶ˆæ¯={len(base_messages)}ï¼›ç”¨æˆ·å†å²æ‘˜è¦é•¿åº¦={len(_user_history_text or '')}")

            base_messages.append({
                "role": "user",
                "synthetic": True,
                "content": (
                    f"ç”¨æˆ·å½“å‰ä»»åŠ¡ï¼š{original_user_text}\n"
                    f"ç”¨æˆ·å†å²è¾“å…¥ï¼š{_user_history_text}\n"
                    f"è¯·ä¸¥æ ¼æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼ˆç¬¬ {idx} æ­¥ï¼‰ï¼š{step}\n"
                    f"åœ¨å›å¤æœ€åä¸€è¡Œæ·»åŠ ä¸€ä¸ªæ ‡ç­¾ï¼ˆä¸è¦åŒæ—¶è¾“å‡ºå¤šä¸ªï¼Œä¹Ÿä¸è¦ä½¿ç”¨æ—§æ ‡ç­¾ï¼‰ï¼š\n"
                    f"- è‹¥æœ¬æ­¥å·²å®Œæˆï¼šæ·»åŠ æ ‡ç­¾ [STEP_NEXT]\n"
                    f"- è‹¥æœ¬æ­¥éœ€è¦ç»§ç»­æ‰§è¡Œï¼šæ·»åŠ æ ‡ç­¾ [STEP_CONTINUE]\n"
                    f"- è‹¥æœ¬æ­¥éœ€è¦ç”¨æˆ·ç¡®è®¤æˆ–è¡¥å……å‚æ•°ï¼šæ·»åŠ æ ‡ç­¾ [STEP_WAIT]\n"
                    f"- è‹¥å¤–éƒ¨ç³»ç»Ÿä¸å¯ç”¨/æƒé™ä¸è¶³/èµ„æºç¼ºå¤±å¯¼è‡´æ— æ³•ç»§ç»­ï¼šæ·»åŠ æ ‡ç­¾ [STEP_BLOCKED]\n"
                    f"- è‹¥æ•´ä¸ªä»»åŠ¡å·²å®Œæˆï¼šæ·»åŠ æ ‡ç­¾ [TASK_DONE]\n"
                ),
            })
            try:
                _lim = 1200
                _synthetic_content = (base_messages[-1].get("content") or "")
                _preview = _synthetic_content if len(_synthetic_content) <= _lim else _synthetic_content[:_lim] + f"...[truncated {len(_synthetic_content)-_lim}]"
                logger.debug(f"[send][step {idx}] è¿½åŠ synthetic useræ¶ˆæ¯ï¼šé¢„è§ˆ={_preview}")
            except Exception:
                logger.debug(f"[send][step {idx}] è¿½åŠ synthetic useræ¶ˆæ¯å¤±è´¥")

            logger.debug(f"[step] å¼€å§‹ç¬¬{idx}æ­¥ï¼šå†…å®¹é•¿åº¦={len(step or '')}")

            # æ­¥å†…è¿­ä»£
            confirm_tried = False
            escalate_tried = False
            cont_streak = 0
            # è®°å½•ä¸Šä¸€è½®summaryæŒ‡çº¹ï¼Œç”¨äºé‡å¤å†…å®¹æ—©åœ
            prev_summary_fp = ""
            for it in range(1, max_step_iterations + 1):
                logger.debug(f"[iter] ç¬¬{idx}æ­¥è¿­ä»£ {it}/{max_step_iterations}")

                # åœ¨å‘èµ·è¯·æ±‚å‰ï¼Œè§„èŒƒåŒ–å¹¶æ¸…æ´—å·¥å…·æ¶ˆæ¯ï¼Œé¿å…OpenAI 400
                try:
                    base_messages, _ra, _rt = await app._process_tool_sequence(base_messages)
                    logger.debug(f"[tools][step {idx} iter {it}] åºåˆ—è§„èŒƒåŒ–ï¼šç§»é™¤assistant={_ra}ï¼Œç§»é™¤tool={_rt}ï¼Œæ¶ˆæ¯æ•°={len(base_messages)}")
                    try:
                        provider = getattr(app.ai_client.model_config, "provider", "")
                        base_messages = app._sanitize_tool_messages(base_messages, provider)
                    except Exception:
                        logger.error(f"[tools][step {idx} iter {it}] åºåˆ—æ¸…æ´—å¤±è´¥")
                except Exception:
                    logger.error(f"[tools][step {idx} iter {it}] åºåˆ—è§„èŒƒåŒ–å¤±è´¥")

                # åŠ©æ‰‹å“åº”ï¼ˆå«å·¥å…·ï¼‰
                try:
                    # å‘é€å‰è®°å½•è¯·æ±‚æ¶ˆæ¯é¢„è§ˆï¼ˆå–æœ€è¿‘10æ¡ï¼‰
                    try:
                        _lim = 800
                        _payload_preview = []
                        for m in base_messages[-10:]:
                            _c = (m.get("content") or "")
                            _payload_preview.append({
                                "role": m.get("role"),
                                "content_preview": _c if len(_c) <= _lim else _c[:_lim] + f"...[truncated {len(_c)-_lim}]",
                            })
                        logger.debug(f"[send][step {idx} iter {it}] è¯·æ±‚æ¶ˆæ¯é¢„è§ˆï¼š{json.dumps(_payload_preview, ensure_ascii=False, indent=2)}")
                    except Exception:
                        logger.error(f"[send][step {idx} iter {it}] è¯·æ±‚æ¶ˆæ¯é¢„è§ˆå¤±è´¥")
                    response = await app.ai_client.chat_with_tools_async(
                        messages=base_messages,
                        tools=tools,
                        tool_choice="auto",
                    )
                except Exception as e:
                    if chat_history:
                        chat_history.add_message("assistant", f"âŒ å·¥å…·é˜¶æ®µå‡ºé”™ï¼š{e}")
                    logger.error(f"[iter] å·¥å…·é˜¶æ®µè°ƒç”¨å¼‚å¸¸ï¼š{e}")
                    break

                assistant_msg = getattr(response, "content", "")
                tool_calls = getattr(response, "tool_calls", []) or []
 
                if assistant_msg:
                    if chat_history:
                        chat_history.add_message("assistant", assistant_msg)
                    # è¿½åŠ å‰å»é‡ï¼Œé¿å…é‡å¤çš„é•¿æ–‡æœ¬assistantæ¶ˆæ¯è¿›å…¥ä¸Šä¸‹æ–‡
                    _new_assistant = _dedup_messages_by_content(base_messages, [{"role": "assistant", "content": assistant_msg}], min_len=600)
                    if _new_assistant:
                        base_messages.extend(_new_assistant)
                    # è‹¥assistantæ¶ˆæ¯å·²æ˜ç¡®åŒ…å«ä¸‹ä¸€æ­¥æ ‡è®°ï¼Œåˆ™ç›´æ¥åˆ¤å®šå½“å‰æ­¥éª¤å®Œæˆï¼Œè·³è¿‡å·¥å…·æ‰§è¡Œä¸æ€»ç»“
                    try:
                        assistant_next_hit = has_marker(assistant_msg, NEW_STEP_NEXT_MARKERS)
                        assistant_wait_hit = has_marker(assistant_msg, NEW_STEP_WAIT_MARKERS)
                        assistant_block_hit = has_marker(assistant_msg, NEW_STEP_BLOCKED_MARKERS)
                    except Exception:
                        assistant_next_hit = False
                        assistant_wait_hit = False
                        assistant_block_hit = False
                    if assistant_next_hit:
                        if chat_history:
                            chat_history.add_message("assistant", f"âœ… ç¬¬ {idx} æ­¥`({step})`å®Œæˆï¼ˆassistantæ–°æ ‡ç­¾ï¼‰")
                        logger.debug(f"[step] ç¬¬{idx}æ­¥å®Œæˆï¼ˆassistantæ–°æ ‡ç­¾ï¼‰ï¼Œé€€å‡ºè¯¥æ­¥è¿­ä»£")
                        cont_streak = 0
                        # ä¿å­˜ä¼šè¯å†å²åç»“æŸè¯¥æ­¥è¿­ä»£
                        try:
                            app.conversation_history = base_messages
                            app._save_current_session()
                            logger.debug(f"[step] ç¬¬{idx}æ­¥ä¼šè¯å†å²å·²ä¿å­˜ï¼šæ¶ˆæ¯æ€»æ•°={len(base_messages)}")
                        except Exception:
                            logger.error(f"[step] ç¬¬{idx}æ­¥ä¼šè¯å†å²ä¿å­˜å¤±è´¥")
                        break
                    # æ–°å¢ï¼šassistantç›´æ¥æŒ‡ç¤ºæš‚åœæˆ–é˜»å¡æ—¶ï¼Œç«‹å³æš‚åœæµç¨‹ï¼Œç­‰å¾…ç”¨æˆ·äº¤äº’
                    if assistant_wait_hit:
                        logger.debug(f"[step] ç¬¬{idx}æ­¥æš‚åœï¼ˆassistantæ–°æ ‡ç­¾ [STEP_WAIT]ï¼‰")
                        safe_notify(app, "â¸ï¸ æš‚åœï¼šéœ€è¦ä½ çš„è¾“å…¥æˆ–ç¡®è®¤åç»§ç»­ã€‚", timeout=4)
                        try:
                            app.conversation_history = base_messages
                            app._save_current_session()
                        except Exception:
                            logger.error(f"[step] ç¬¬{idx}æ­¥ä¼šè¯å†å²ä¿å­˜å¤±è´¥")
                        try:
                            setattr(app, "plan_status", "paused")
                        except Exception:
                            logger.error(f"[step] ç¬¬{idx}æ­¥è®¾ç½®æš‚åœçŠ¶æ€å¤±è´¥")
                        return
                    if assistant_block_hit:
                        logger.debug(f"[step] ç¬¬{idx}æ­¥é˜»å¡ï¼ˆassistantæ–°æ ‡ç­¾ [STEP_BLOCKED]ï¼‰")
                        safe_notify(app, "ğŸ›‘ é˜»å¡ï¼šå¤–éƒ¨æ¡ä»¶é™åˆ¶ï¼Œæš‚æ— æ³•ç»§ç»­ã€‚", severity="error", timeout=4)
                        try:
                            app.conversation_history = base_messages
                            app._save_current_session()
                        except Exception:
                            logger.error(f"[step] ç¬¬{idx}æ­¥ä¼šè¯å†å²ä¿å­˜å¤±è´¥")
                        try:
                            setattr(app, "plan_status", "paused")
                        except Exception:
                            logger.error(f"[step] ç¬¬{idx}æ­¥è®¾ç½®æš‚åœçŠ¶æ€å¤±è´¥")
                        return
                elif not tool_calls:
                    # è®°å½•ç©ºå“åº”ä»¥ä¾¿è§¦å‘æé†’è¿”å›æ ‡ç­¾
                    logger.debug(f"[iter] æ¨¡å‹assistantè¿”å›ä¸ºç©ºï¼Œå°†è¿½åŠ æç¤ºè¦æ±‚è¿”å›æ ‡ç­¾")
                    empty_assistant_response = True
 
                # è¿‡æ»¤ä»…å¯ç”¨çš„å·¥å…·è°ƒç”¨
                # è¿‡æ»¤å¹¶å»é‡å·¥å…·è°ƒç”¨ï¼ˆæŒ‰å¯ç”¨å·¥å…· + å‚æ•°ç­¾åï¼‰ï¼Œé¿å…é‡å¤è°ƒç”¨å¯¼è‡´æ— æ•ˆå¾ªç¯
                try:
                    filtered_tool_calls, disabled_called_names, skipped_duplicates = await filter_and_deduplicate_tool_calls(app, tool_calls, executed_tool_signatures)
                    logger.debug(f"[tools][step {idx} iter {it}] è¿‡æ»¤ä¸å»é‡ï¼šä¿ç•™={len(filtered_tool_calls)}ï¼Œå¿½ç•¥æœªå¯ç”¨={len(disabled_called_names)}")
                except Exception:
                    # å›é€€ï¼šä»…æŒ‰å¯ç”¨å·¥å…·åè¿‡æ»¤
                    enabled_attr = getattr(app, "enabled_tools", None)
                    if isinstance(enabled_attr, dict):
                        enabled_names = set(enabled_attr.keys())
                    elif isinstance(enabled_attr, (set, list, tuple)):
                        enabled_names = set(enabled_attr)
                    else:
                        enabled_names = set()
                    filtered_tool_calls = [
                        tc for tc in (tool_calls or []) if tc.get("function", {}).get("name") in enabled_names
                    ]
                    disabled_called_names = []

                # å°†é‡å¤è°ƒç”¨è·³è¿‡ä¿¡æ¯åé¦ˆåˆ°ä¸Šä¸‹æ–‡ï¼ŒæŒ‡å¯¼æ¨¡å‹é¿å…é‡å¤
                try:
                    if locals().get("skipped_duplicates"):
                        dup_preview = ", ".join([(d or {}).get("name") or "" for d in (skipped_duplicates or []) if (d or {}).get("name")][:6])
                        if dup_preview.strip():
                            base_messages.append({
                                "role": "user",
                                "synthetic": True,
                                "content": (
                                    f"æç¤ºï¼šé‡å¤çš„å·¥å…·è°ƒç”¨å·²è¢«è·³è¿‡ï¼ˆæŒ‰å‚æ•°ç­¾åå»é‡ï¼‰ï¼š{dup_preview}ã€‚"
                                    f"è¯·é¿å…å¯¹åŒä¸€å‚æ•°é‡å¤è°ƒç”¨ï¼Œä¼˜å…ˆè°ƒæ•´å‚æ•°æˆ–ç»§ç»­æ€è€ƒå†å°è¯•ã€‚"
                                ),
                            })
                            logger.debug(f"[tools][step {idx} iter {it}] é‡å¤è°ƒç”¨æç¤ºå·²è¿½åŠ åˆ°ä¸Šä¸‹æ–‡ï¼š{dup_preview}")
                except Exception:
                    logger.error(f"[tools][step {idx} iter {it}] å¤„ç†é‡å¤è°ƒç”¨æç¤ºå¼‚å¸¸")

                # ç¡®ä¿æŒ‰ OpenAI è§„èŒƒï¼šè‹¥å­˜åœ¨å·¥å…·è°ƒç”¨ï¼Œå‰ç½® assistant æ¶ˆæ¯å¿…é¡»æºå¸¦ tool_calls
                if filtered_tool_calls:
                    if base_messages and (base_messages[-1].get("role") == "assistant"):
                        # å°†æœ€è¿‘çš„ assistant æ¶ˆæ¯è¡¥å……ä¸Š tool_calls
                        base_messages[-1]["tool_calls"] = filtered_tool_calls
                        # è‹¥æ— æ–‡æœ¬å†…å®¹ï¼Œä¿æŒä¸ºç©ºå­—ç¬¦ä¸²å³å¯
                        if "content" not in base_messages[-1]:
                            base_messages[-1]["content"] = assistant_msg or ""
                    else:
                        base_messages.append({
                            "role": "assistant",
                            "content": assistant_msg or "",
                            "tool_calls": filtered_tool_calls,
                        })

                # æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶é™„åŠ æ¶ˆæ¯
                tool_messages = []
                try:
                    tool_messages = await process_tool_calls(
                        filtered_tool_calls,
                        chat_history_widget=chat_history,
                        add_to_base_messages=True,
                    )
                except Exception as e:
                    if chat_history:
                        chat_history.add_message("assistant", f"âš ï¸ å¤„ç†å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{e}")
                    logger.exception(f"[tools] å·¥å…·è°ƒç”¨å¤„ç†å¼‚å¸¸ï¼š{e}")
                # å·¥å…·æ‰§è¡Œåçš„é¢„è§ˆä¸ç»Ÿè®¡æ—¥å¿—
                try:
                    _lim = 1500
                    _tm_preview = [{
                        "role": tm.get("role"),
                        "content_preview": (tm.get("content") or "") if len(tm.get("content") or "") <= _lim else (tm.get("content") or "")[:_lim] + f"...[truncated {len(tm.get('content') or '')-_lim}]",
                    } for tm in (tool_messages or [])]
                    logger.debug(f"[recv][step {idx} iter {it}] toolæ¶ˆæ¯ï¼š{_tm_preview}")
                except Exception:
                    logger.error(f"[recv][step {idx} iter {it}] å¤„ç†toolæ¶ˆæ¯å¼‚å¸¸")
                logger.debug(f"[tools] å·¥å…·æ‰§è¡Œå®Œæˆï¼šè¿½åŠ æ¶ˆæ¯æ•°={len(tool_messages or [])}")
                # åœ¨è¿½åŠ å‰è¿›è¡Œå†…å®¹å»é‡ï¼Œé¿å…é‡å¤çš„æ–‡æ¡£/é•¿æ–‡æœ¬åå¤è¿›å…¥ä¸Šä¸‹æ–‡
                tool_messages = _dedup_messages_by_content(base_messages, tool_messages, min_len=600)
                base_messages.extend(tool_messages or [])
                

            # æ€»ç»“ä¸å®Œæˆåˆ¤å®šï¼ˆæ— è®ºå·¥å…·æ˜¯å¦å¼‚å¸¸ï¼Œå‡è¿›å…¥æ€»ç»“é˜¶æ®µï¼‰
            # å‘é€å‰è®°å½•æ€»ç»“è¯·æ±‚æ¶ˆæ¯é¢„è§ˆï¼ˆå–æœ€è¿‘10æ¡ï¼‰
            try:
                _lim = 800
                _payload_preview = []
                for m in base_messages[-10:]:
                    _c = (m.get("content") or "")
                    _payload_preview.append({
                        "role": m.get("role"),
                        "content_preview": _c if len(_c) <= _lim else _c[:_lim] + f"...[truncated {len(_c)-_lim}]",
                    })
                logger.debug(f"[send][step {idx} iter {it}] æ€»ç»“è¯·æ±‚æ¶ˆæ¯é¢„è§ˆï¼š{json.dumps(_payload_preview, ensure_ascii=False, indent=2)}")
            except Exception:
                logger.error(f"[send][step {idx} iter {it}] æ€»ç»“è¯·æ±‚æ¶ˆæ¯é¢„è§ˆå¼‚å¸¸")
            # è‹¥ä¸Šä¸€è½®assistantä¸ºç©ºï¼Œåˆ™ç›´æ¥æé†’æ¨¡å‹è¿”å›æ ‡ç­¾
            try:
                if 'empty_assistant_response' in locals() and empty_assistant_response:
                    synth_prompt = {
                        "role": "user",
                        "synthetic": True,
                        "content": (
                            f"åˆšæ‰ä½ çš„å›å¤ä¸ºç©ºã€‚è¯·è¾“å‡ºæ€»ç»“å¹¶åˆ¤æ–­ç¬¬ {idx} æ­¥çŠ¶æ€ï¼š\n"
                            f"å·²å®Œæˆåœ¨æ–‡æœ¬æœ«æ·»åŠ  [STEP_DONE]ï¼Œæœªå®Œæˆæ·»åŠ  [STEP_CONTINUE]ï¼Œè‹¥æ•´ä½“ä»»åŠ¡å®Œæˆæ·»åŠ  [SESSION_DONE]ã€‚\n"
                            f"å¦‚å·¥å…·æ‰§è¡Œæœªè¿”å›é¢„æœŸç»“æœï¼Œè¯·é‡æ–°æ•´ç†å·¥å…·éœ€è¦çš„å‚æ•°åç»§ç»­æ‰§è¡Œï¼›å¹¶åœ¨æ€»ç»“ç»“å°¾æ·»åŠ [STEP_CONTINUE]"
                        ),
                    }
                    base_messages.append(synth_prompt)
                    confirm_tried = True
                    logger.debug(f"[send][step {idx} iter {it}] è¿½åŠ æ ‡ç­¾æé†’æç¤ºï¼š{synth_prompt.get('content')}")
                    empty_assistant_response = False
            except Exception:
                logger.error(f"[send][step {idx} iter {it}] è¿½åŠ æ ‡ç­¾æé†’æç¤ºå¼‚å¸¸")
            try:
                logger.debug(f"[send][step {idx} iter {it}] å‘é€æ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼š{json.dumps(base_messages, ensure_ascii=False, indent=2)}")
                summary = await app.ai_client.chat_async(base_messages)
                
            except Exception as e:
                if chat_history:
                    chat_history.add_message("assistant", f"âŒ æ€»ç»“é˜¶æ®µå‡ºé”™ï¼š{e}")
                logger.exception(f"[send][step {idx} iter {it}] æ€»ç»“é˜¶æ®µå‡ºé”™ï¼š{e}")
                break

            summary_text = getattr(summary, "content", "") or ""
            logger.debug(f"[recv][step {idx} iter {it}] æ¨¡å‹å›å¤ï¼š{json.dumps(summary_text, ensure_ascii=False, indent=2)}")
            try:
                _lim = 2000
                _sum_preview = summary_text if len(summary_text or "") <= _lim else summary_text[:_lim] + f"...[truncated {len(summary_text)-_lim}]"
                logger.debug(f"[recv][step {idx} iter {it}] summary/confirmï¼šé¢„è§ˆ={_sum_preview}")
            except Exception:
                logger.error(f"[recv][step {idx} iter {it}] å¤„ç†summary/confirmå¼‚å¸¸")
            logger.debug(f"[summary] é•¿åº¦={len(summary_text or '')}ï¼›éœ€ç”¨æˆ·ç¡®è®¤={requires_user_confirmation(summary_text)}")
            # è‹¥éœ€è¦ç”¨æˆ·ç¡®è®¤/è¡¥å…¨ï¼Œç¡®ä¿è¿½åŠ æ ‡è®°
            if requires_user_confirmation(summary_text) and not has_marker(summary_text, REQUIRE_USER_MARKERS):
                sep = "\n\n" if not summary_text.endswith("\n") else "\n"
                summary_text = summary_text + sep + "[STEP_REQUIRE_USER]"
            # å°†æ€»ç»“åŠ å…¥å†å²ä¸åŸºæ¶ˆæ¯
            if chat_history and summary_text:
                chat_history.add_message("assistant", summary_text)
            base_messages.append({"role": "assistant", "content": summary_text})

            # éœ€è¦ç”¨æˆ·ç¡®è®¤æ—¶æš‚åœä¼šè¯
            if should_pause_for_user(summary_text):
                logger.debug(f"[step] ç¬¬{idx}æ­¥æš‚åœï¼šç­‰å¾…ç”¨æˆ·è¾“å…¥/ç¡®è®¤")
                safe_notify(app, "â¸ï¸ æš‚åœï¼šç­‰å¾…ä½ çš„è¾“å…¥æˆ–ç¡®è®¤åç»§ç»­ã€‚", timeout=4)
                try:
                    app.conversation_history = base_messages
                    app._save_current_session()
                except Exception:
                    logger.error(f"[send][step {idx} iter {it}] ä¿å­˜ä¼šè¯å¼‚å¸¸")
                # è®°å½•è®¡åˆ’çŠ¶æ€ä¸ºæš‚åœ
                try:
                    setattr(app, "plan_status", "paused")
                except Exception:
                    logger.error(f"[send][step {idx} iter {it}] è®¾ç½®è®¡åˆ’çŠ¶æ€å¼‚å¸¸")
                return

            # ä¼šè¯ç»“æŸæ ‡è®°ï¼ˆå«æ–°æ—§ä»»åŠ¡å®Œæˆæ ‡ç­¾ï¼‰
            # é˜²æ­¢åœ¨éæœ«æ­¥æ”¶åˆ° [TASK_DONE] / [SESSION_DONE] å¯¼è‡´æå‰ç»“æŸæ•´ä¸ªä¼šè¯
            force_continue = False
            try:
                total_steps = len(steps)
            except Exception:
                total_steps = 0
            try:
                # éæœ«æ­¥ï¼šå½“å‰æ­¥åºå·å°äºæ€»æ­¥æ•°ï¼ˆä¾‹å¦‚æ€»5æ­¥ï¼Œåˆ™1~4ä¸ºéæœ«æ­¥ï¼‰
                is_mid_step = idx < total_steps
            except Exception:
                is_mid_step = False
            try:
                # è‹¥åœ¨éæœ«æ­¥å‡ºç°â€œä»»åŠ¡å®Œæˆâ€ç›¸å…³æ ‡è®°æˆ–çŸ­è¯­ï¼Œå¼ºåˆ¶ç»§ç»­åç»­æ­¥éª¤ï¼Œé¿å…æå‰ç»“æŸæ•´ä¸ªä¼šè¯
                task_done_midway = is_mid_step and (
                    has_marker(summary_text, NEW_TASK_DONE_MARKERS)
                    or has_marker(summary_text, SESSION_DONE_MARKERS)
                    or has_marker(summary_text, COMPLETE_MARKERS)
                )
            except Exception:
                task_done_midway = False

            if task_done_midway:
                # éæœ«æ­¥æ”¶åˆ°ä»»åŠ¡å®Œæˆæ ‡ç­¾/çŸ­è¯­â€”â€”æŒ‰æ¨è¿›å¤„ç†ï¼Œç»§ç»­åç»­æ­¥éª¤
                force_continue = True
                logger.debug(f"[step] éæœ«æ­¥æ”¶åˆ°ä»»åŠ¡å®Œæˆç›¸å…³æ ‡è®°ï¼ŒæŒ‰ [STEP_NEXT] ç»§ç»­åˆ°ç¬¬{idx+1}æ­¥")
                if chat_history:
                    chat_history.add_message("assistant", f"â„¹ï¸ æ”¶åˆ°ä»»åŠ¡å®Œæˆç›¸å…³æ ‡è®°ä½†å°šæœ‰åç»­æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œç¬¬ {idx+1} æ­¥ã€‚")

            # è‹¥åˆšæ‰§è¡Œè¿‡å·¥å…·æˆ–å¤„äºéæœ«æ­¥ï¼Œåˆ™ä¸åº”å› å®ŒæˆçŸ­è¯­æå‰ç»“æŸä¼šè¯
            try:
                _has_tool_calls = bool(locals().get("tool_executed", False))
            except Exception:
                _has_tool_calls = False
            # ä»…åœ¨â€œæœ€åä¸€æ­¥â€ä¸”å‘½ä¸­ä¼šè¯ç»“æŸæ ‡è®°æ—¶æ‰å…è®¸ç»“æŸä¼šè¯ï¼›
            # åœ¨éæœ«æ­¥ä¸€å¾‹ä¸å› å®ŒæˆçŸ­è¯­/æ ‡è®°è€Œæ—©åœã€‚
            try:
                is_last_step = idx >= total_steps and total_steps > 0
            except Exception:
                is_last_step = False
            if (not force_continue) and is_last_step and should_end_session(summary_text, has_tool_calls=_has_tool_calls):
                logger.debug("[step] ä¼šè¯ç»“æŸæ ‡è®°å‘½ä¸­ï¼Œé€€å‡ºæ­¥éª¤æ‰§è¡Œ")
                safe_notify(app, "âœ… ä¼šè¯å®Œæˆ", timeout=4)
                try:
                    app.conversation_history = base_messages
                    app._save_current_session()
                except Exception:
                    logger.error(f"[send][step {idx} iter {it}] ä¿å­˜ä¼šè¯å¼‚å¸¸")
                # æ ‡è®°è®¡åˆ’çŠ¶æ€ä¸ºå®Œæˆ
                try:
                    setattr(app, "plan_status", "completed")
                except Exception:
                    logger.error(f"[send][step {idx} iter {it}] è®¾ç½®è®¡åˆ’çŠ¶æ€å¼‚å¸¸")
                return

            # é¢å¤–æ£€æµ‹ï¼šä»…è¿”å›æ ‡è®°ä¸å¤–éƒ¨ç³»ç»Ÿé˜»å¡
            stripped = (summary_text or "").strip()
            only_marker = stripped in (
                "[STEP_NEXT]", "[STEP_WAIT]", "[STEP_BLOCKED]", "[TASK_DONE]",
                "[STEP_DONE]", "[STEP_CONTINUE]", "[SESSION_DONE]", "[STEP_REQUIRE_USER]"
            )
            blocked_keywords = [
                "ç³»ç»Ÿä¸å¯ç”¨", "å¹³å°è¶…æ—¶", "æŒç»­è¶…æ—¶", "è¶…æ—¶", "æƒé™ä¸è¶³", "æ²¡æœ‰æƒé™", "æ— æƒé™",
                "èµ„æºç¼ºå¤±", "èµ„æºä¸å­˜åœ¨", "ä¸å¯è®¿é—®", "æ— æ³•æ‰§è¡Œ", "æ‰§è¡Œå¤±è´¥", "å¤±è´¥",
                "æœåŠ¡ä¸å¯ç”¨", "ä¸å¯ç”¨", "å—é™", "é™åˆ¶", "quota", "rate limit", "è¿æ¥é”™è¯¯",
            ]
            blocked_by_system = any(k in (summary_text or "") for k in blocked_keywords)

            # åŸå§‹æ ‡è®°åˆ¤å®š
            done_hit = has_marker(summary_text, DONE_MARKERS)
            cont_hit = has_marker(summary_text, CONTINUE_MARKERS)
            # æ”¾å®½å¯å‘å¼å®Œæˆï¼šåªè¦æ˜ç¡®æŒ‡å‘ä¸‹ä¸€æ­¥ï¼Œåˆ™è§†ä¸ºå½“å‰æ­¥å®Œæˆ
            auto_done = mentions_next_step(summary_text, idx)
            logger.debug(f"[step] æ ‡è®°çŠ¶æ€ï¼šDONE={done_hit} CONTINUE={cont_hit} AUTO_DONE={auto_done}")

            # è‹¥å·²æ‰§è¡Œå·¥å…·ä¸”æ€»ç»“æ˜ç¡®ç»™å‡ºä¸‹ä¸€æ­¥/è‡ªç„¶é˜»å¡ï¼Œä¹Ÿè§†ä¸ºæœ¬æ­¥å®Œæˆï¼ˆé¿å…åŒä¸€æ­¥åå¤é‡è¯•ï¼‰
            try:
                tool_executed = bool(locals().get("tool_messages")) and len(locals().get("tool_messages") or []) > 0
            except Exception:
                logger.error(f"[send][step {idx} iter {it}] æ£€æŸ¥å·¥å…·æ‰§è¡Œå¼‚å¸¸")
                tool_executed = False

            # æ–°æ ‡ç­¾å‘½ä¸­ä¸æ—§æ ‡ç­¾å…¼å®¹
            next_hit = has_marker(summary_text, NEW_STEP_NEXT_MARKERS)
            blocked_hit = has_marker(summary_text, NEW_STEP_BLOCKED_MARKERS)
            task_done_hit = has_marker(summary_text, NEW_TASK_DONE_MARKERS) or has_marker(summary_text, SESSION_DONE_MARKERS)

            if task_done_hit and not (locals().get("force_continue", False)):
                # ä»»åŠ¡å®Œæˆï¼šåœ¨ä¸Šæ–¹ should_end_session å·²å¤„ç†ï¼›æ­¤å¤„é˜²å¾¡æ€§è¡¥å……
                logger.debug(f"[step] æ£€æµ‹åˆ°ä»»åŠ¡å®Œæˆæ ‡ç­¾ï¼Œè§¦å‘ä¼šè¯ç»“æŸ")
                safe_notify(app, "âœ… ä¼šè¯å®Œæˆ", timeout=4)
                try:
                    app.conversation_history = base_messages
                    app._save_current_session()
                except Exception:
                    logger.error(f"[send][step {idx} iter {it}] ä¿å­˜ä¼šè¯å¼‚å¸¸")
                try:
                    setattr(app, "plan_status", "completed")
                except Exception:
                    logger.error(f"[send][step {idx} iter {it}] è®¾ç½®è®¡åˆ’çŠ¶æ€å¼‚å¸¸")
                return

            # è‹¥æ£€æµ‹åˆ°å·¥å…·å¤±è´¥ï¼Œåˆ™ç¦æ­¢è¿›å…¥ä¸‹ä¸€æ­¥ï¼Œå¼ºåˆ¶åœ¨æœ¬æ­¥ç»§ç»­ï¼ˆå¿½ç•¥ [STEP_NEXT] ä¸å¯å‘å¼å®Œæˆï¼‰
            if locals().get("tool_failed", False):
                logger.debug(f"[step] æ£€æµ‹åˆ°å·¥å…·å¤±è´¥ï¼Œå¿½ç•¥ä¸‹ä¸€æ­¥æ ‡è®°ï¼Œç»§ç»­å½“å‰æ­¥éª¤")
                # è¿½åŠ ä¸€æ¬¡æ˜ç¡®çš„é‡è¯•æç¤ºï¼Œé¿å…æ¨¡å‹è¯¯åˆ¤æœ¬æ­¥å·²å®Œæˆ
                retry_prompt = {
                    "role": "user",
                    "synthetic": True,
                    "content": (
                        f"è¯·åœ¨å½“å‰æ­¥éª¤ä¸­å…ˆè·å–å¿…è¦çš„æ–‡æ¡£ä¸ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚å­—æ®µç»“æ„ã€SPLè¯­æ³•è§„èŒƒã€å‚æ•°ç¤ºä¾‹ï¼‰ï¼Œç„¶åä¿®æ­£å‚æ•°å¹¶é‡è¯•å·¥å…·è°ƒç”¨ã€‚\n"
                        f"å®Œæˆè¿™äº›æ“ä½œåï¼Œåœ¨æ€»ç»“çš„æœ€åä¸€è¡Œä»…è¾“å‡º [STEP_CONTINUE]ã€‚"
                    ),
                }
                base_messages.append(retry_prompt)
                cont_streak = 0
                # ä¸é€€å‡ºè¯¥æ­¥è¿­ä»£ï¼Œç»§ç»­å‘æ¨¡å‹è¯·æ±‚æ›´å…·ä½“çš„æ“ä½œ
            elif next_hit or (done_hit and not cont_hit) or auto_done:
                if chat_history:
                    chat_history.add_message("assistant", f"âœ… ç¬¬ {idx} æ­¥`({step})`å®Œæˆ")
                logger.debug(f"[step] ç¬¬{idx}æ­¥å®Œæˆï¼ˆ{'æ–°æ ‡ç­¾' if next_hit else ('æ˜¾å¼' if done_hit else 'å¯å‘å¼')}ï¼‰ï¼Œé€€å‡ºè¯¥æ­¥è¿­ä»£")
                cont_streak = 0
                break
            elif blocked_hit and blocked_by_system:
                # å¤–éƒ¨é˜»å¡ï¼šç»ˆæ­¢è¯¥æ­¥å¹¶æç¤º
                if chat_history:
                    chat_history.add_message("assistant", f"â›” ç¬¬ {idx} æ­¥`({step})`å› å¤–éƒ¨é˜»å¡è€Œç»ˆæ­¢ï¼ˆ[STEP_BLOCKED]ï¼‰")
                logger.debug(f"[step] ç¬¬{idx}æ­¥å¤–éƒ¨é˜»å¡ï¼Œç»ˆæ­¢è¯¥æ­¥è¿­ä»£")
                cont_streak = 0
                break
            elif tool_executed and (mentions_next_step(summary_text, idx)):
                # å·¥å…·æ‰§è¡Œåæ˜ç¡®è¿›å…¥ä¸‹ä¸€æ­¥ï¼Œç›´æ¥åˆ¤å®šä¸ºå®Œæˆ
                if chat_history:
                    chat_history.add_message("assistant", f"âœ… ç¬¬ {idx} æ­¥`({step})`å®Œæˆï¼ˆå·¥å…·å·²æ‰§è¡Œå¹¶ç»™å‡ºä¸‹ä¸€æ­¥ï¼‰")
                logger.debug(f"[step] ç¬¬{idx}æ­¥å®Œæˆï¼ˆå·¥å…·åå¯å‘å¼ï¼‰")
                cont_streak = 0
                break
            else:
                # è‹¥é¦–è½®æœªå‘½ä¸­æ ‡è®°ï¼Œè¿½åŠ ä¸€æ¬¡æœ€å°ç¡®è®¤ä»¥è·å–æ˜¾å¼æ ‡è®°
                if not confirm_tried and it == 1:
                    confirm_msg = {
                        "role": "user",
                        "synthetic": True,
                        "content": (
                            f"è¯·åœ¨å›å¤æœ€åä¸€è¡Œä»…è¾“å‡ºä¸€ä¸ªæ ‡ç­¾ï¼Œä¸è¦åŒæ—¶è¾“å‡ºå¤šä¸ªï¼š\n"
                            f"- ç¬¬ {idx} æ­¥å·²å®Œæˆå¹¶ç»™å‡ºä¸‹ä¸€æ­¥ï¼šä»…è¾“å‡º [STEP_NEXT]\n"
                            f"- éœ€è¦ä½ çš„ç¡®è®¤æˆ–è¡¥å……å‚æ•°ï¼šä»…è¾“å‡º [STEP_WAIT]\n"
                            f"- å¤–éƒ¨ç³»ç»Ÿä¸å¯ç”¨/æƒé™ä¸è¶³/èµ„æºç¼ºå¤±ï¼šä»…è¾“å‡º [STEP_BLOCKED]\n"
                            f"- æ•´ä¸ªä»»åŠ¡å·²å®Œæˆï¼šä»…è¾“å‡º [TASK_DONE]"
                        ),
                    }
                    base_messages.append(confirm_msg)
                    logger.debug(f"[send][step {idx} iter {it}] è¿½åŠ ç¡®è®¤æ ‡è®°è¯·æ±‚")
                    try:
                        confirm_resp = await app.ai_client.chat_async(base_messages)
                        confirm_text = getattr(confirm_resp, "content", "") or ""
                        _lim = 200
                        _cprev = confirm_text if len(confirm_text) <= _lim else confirm_text[:_lim] + f"...[truncated {len(confirm_text)-_lim}]"
                        logger.debug(f"[recv][step {idx} iter {it}] confirmï¼š{_cprev}")
                    except Exception:
                        confirm_text = ""
                        logger.error(f"[send][step {idx} iter {it}] ç¡®è®¤æ ‡è®°è¯·æ±‚å¼‚å¸¸")
                    if chat_history and confirm_text.strip():
                        chat_history.add_message("assistant", confirm_text)
                    base_messages.append({"role": "assistant", "content": confirm_text})
                    confirm_tried = True
                    # é‡æ–°åˆ¤å®šæ ‡è®°
                    done_hit = has_marker(confirm_text, DONE_MARKERS)
                    cont_hit = has_marker(confirm_text, CONTINUE_MARKERS)
                    logger.debug(f"[step] æ ‡è®°ç¡®è®¤ï¼šDONE={done_hit} CONTINUE={cont_hit}")
                    if done_hit and not cont_hit:
                        if chat_history:
                            chat_history.add_message("assistant", f"âœ… ç¬¬ {idx} æ­¥`({step})`å®Œæˆ")
                        cont_streak = 0
                        break
                    # è‹¥æ˜ç¡®ç»§ç»­åˆ™è¿›å…¥ä¸‹ä¸€è½®
                    if cont_hit:
                        cont_streak += 1
                        if chat_history:
                            chat_history.add_message("assistant", f"â†» ç¬¬ {idx} æ­¥`({step})`ç»§ç»­è¿­ä»£ï¼ˆ{it}/{max_step_iterations}ï¼‰")
                        logger.debug(f"[step] ç¬¬{idx}æ­¥ç»§ç»­è¿­ä»£ï¼ˆ{it}/{max_step_iterations}ï¼‰ï¼Œstreak={cont_streak}")
                        continue
                # é»˜è®¤ç»§ç»­è¿­ä»£ï¼ˆéé¦–è½®æˆ–ç¡®è®¤åä»éœ€ç»§ç»­ï¼‰
                # è®¡ç®—å½“å‰summaryæŒ‡çº¹ï¼ŒåŸºäºé‡å¤å†…å®¹è¿›è¡Œæ—©åœä¿æŠ¤
                try:
                    cur_fp = _fingerprint_text(summary_text)
                except Exception:
                    cur_fp = ""
                if cont_hit:
                    cont_streak += 1
                else:
                    cont_streak = 0
                # è¿­ä»£ä¿æŠ¤ï¼šè‹¥è¿ç»­ä¸¤è½®ç»§ç»­ä¸”æ€»ç»“å†…å®¹æœªå˜åŒ–ï¼Œä¸”æ–‡æœ¬æ˜ç¡®è¿›å…¥ä¸‹ä¸€æ­¥ï¼Œåˆ™è§†ä¸ºå®Œæˆ
                try:
                    if cont_streak >= 2 and prev_summary_fp and (cur_fp == prev_summary_fp) and mentions_next_step(summary_text, idx):
                        if chat_history:
                            chat_history.add_message("assistant", f"âœ… ç¬¬ {idx} æ­¥`({step})`å®Œæˆï¼ˆé‡å¤è¿­ä»£ä¿æŠ¤è§¦å‘ï¼‰")
                        logger.debug(f"[step] ç¬¬{idx}æ­¥é‡å¤è¿­ä»£ä¿æŠ¤æ—©åœï¼šstreak={cont_streak}")
                        cont_streak = 0
                        break
                except Exception:
                    logger.error(f"[step] é‡å¤è¿­ä»£ä¿æŠ¤æ—©åœå¼‚å¸¸")
                prev_summary_fp = cur_fp
                if chat_history:
                    chat_history.add_message("assistant", f"â†» ç¬¬ {idx} æ­¥`({step})`ç»§ç»­è¿­ä»£ï¼ˆ{it}/{max_step_iterations}ï¼‰")
                logger.debug(f"[step] ç¬¬{idx}æ­¥ç»§ç»­è¿­ä»£ï¼ˆ{it}/{max_step_iterations}ï¼‰ï¼Œstreak={cont_streak}")
                
                continue

            # æ›´æ–°å¯¹è¯å†å²å¹¶ä¿å­˜
            try:
                app.conversation_history = base_messages
                app._save_current_session()
                logger.debug(f"[step] ç¬¬{idx}æ­¥ä¼šè¯å†å²å·²ä¿å­˜ï¼šæ¶ˆæ¯æ€»æ•°={len(base_messages)}")
            except Exception:
                logger.error(f"[step] ç¬¬{idx}æ­¥ä¼šè¯å†å²ä¿å­˜å¼‚å¸¸")

        except Exception as e:
            if chat_history:
                chat_history.add_message("assistant", f"âŒ æ‰§è¡Œç¬¬ {idx} æ­¥å¤±è´¥ï¼š{e}")
            logger.exception(f"[step] æ‰§è¡Œç¬¬{idx}æ­¥å¤±è´¥ï¼š{e}")
            continue

    # å®Œæˆæç¤º
    safe_notify(app, f"ğŸ§­ {len(steps)} ä¸ªæ­¥éª¤æ‰§è¡Œç»“æŸ", timeout=3)
    logger.debug(f"[steps] æ­¥éª¤æ‰§è¡Œç»“æŸï¼šæ€»æ­¥éª¤æ•°={len(steps)}")
    # æ ‡è®°è®¡åˆ’çŠ¶æ€ä¸ºå®Œæˆ
    try:
        setattr(app, "plan_status", "completed")
    except Exception:
        logger.error(f"[steps] æ­¥éª¤æ‰§è¡Œç»“æŸæ ‡è®°å¼‚å¸¸")


async def process_ai_response(app: Any, user_message: str, streaming: bool = None) -> None:
    """é€šç”¨çš„ AI å“åº”å¤„ç†æµç¨‹ï¼šå‡†å¤‡ä¸Šä¸‹æ–‡ã€è§„åˆ’æ­¥éª¤ã€å·¥å…·è¿­ä»£ä¸æ”¶å°¾ã€‚"""
    if not getattr(app, "ai_client", None):
        safe_notify(app, "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–", severity="error")
        return

    # è‹¥æœªæ˜¾å¼ä¼ å…¥ï¼Œåˆ™ä»åº”ç”¨æˆ–æ¨¡å‹é…ç½®è¯»å–ï¼Œé»˜è®¤å¯ç”¨æµå¼
    if streaming is None:
        try:
            streaming = getattr(app, "enable_streaming", None)
        except Exception:
            streaming = None
        if streaming is None:
            try:
                # å…ˆè¯»å–ç›´æ¥å­—æ®µ
                streaming = bool(getattr(app.ai_client.model_config, "streaming", False))
                # å†å°è¯• extra_params ä¸­çš„ streaming / enable_streaming / stream
                extra = getattr(app.ai_client.model_config, "extra_params", {}) or {}
                for key in ("streaming", "enable_streaming", "stream"):
                    if key in extra:
                        streaming = bool(extra.get(key))
                        break
            except Exception:
                safe_notify(app, "è¯»å–æµå¼é…ç½®å¤±è´¥ï¼Œé»˜è®¤å¯ç”¨æµå¼", severity="warning")
                streaming = False
                logger.error(f"[flow] è¯»å–æµå¼é…ç½®å¼‚å¸¸ï¼Œé»˜è®¤å¯ç”¨æµå¼")

    try:
        if getattr(app, "force_non_streaming", False):
            streaming = False
    except Exception:
        pass
    logger.debug(f"[flow] streamingé…ç½®ï¼š{streaming}")
    try:
        setattr(app, "_last_streaming_mode", bool(streaming))
    except Exception:
        pass
    # æ ‡è®°è¿›ç¨‹è¿›è¡Œä¸­
    app._chat_in_progress = True
    try:
        chat_history = app.query_one("#chat-history", ChatHistoryWidget)
        model_selector = app.query_one("#model-selector", ModelSelectorWidget)
    except Exception:
        chat_history = None
        model_selector = None
        logger.error(f"[flow] æŸ¥è¯¢å¯¹è¯å†å²æˆ–æ¨¡å‹é€‰æ‹©å™¨å¼‚å¸¸")

    try:
        # å¢å¼ºç³»ç»Ÿæç¤ºè¯
        try:
            app.ai_client.system_prompt = app._augment_system_prompt(app.ai_client.system_prompt)
            logger.debug(f"[prompt] ç³»ç»Ÿæç¤ºè¯é•¿åº¦={len(app.ai_client.system_prompt or '')}")
        except Exception:
            logger.error(f"[prompt] ç³»ç»Ÿæç¤ºè¯å¢å¼ºå¼‚å¸¸")

        # å‡†å¤‡æ¶ˆæ¯
        messages = app._prepare_messages(user_message)
        logger.debug(f"[context] å‡†å¤‡å®Œæˆï¼šæ¶ˆæ¯æ•°={len(messages)}")

        # è‹¥å­˜åœ¨è®¡åˆ’æ‰§è¡Œä¸­ï¼Œåˆ™è·³è¿‡é‡æ–°è§„åˆ’ï¼Œè½¬å…¥æ™®é€šå›å¤æµç¨‹
        try:
            if getattr(app, "plan_execution_in_progress", False) or getattr(app, "planning_locked", False):
                logger.debug("[plan] ä¼šè¯è§„åˆ’å·²é”å®šæˆ–æ‰§è¡Œä¸­ï¼Œè·³è¿‡æ–°çš„è§„åˆ’ã€‚")
            else:
                # è‡ªåŠ¨ä»»åŠ¡è§„åˆ’ï¼ˆè¿”å› dictï¼ŒåŒ…æ‹¬ type ä¸ stepsï¼‰
                try:
                    logger.debug(f"[plan] åŸå§‹éœ€æ±‚={user_message}")
                    plan = await app._plan_task_steps(user_message)
                    logger.debug(f"[plan] è‡ªåŠ¨è§„åˆ’={plan}")
                except Exception as e:
                    logger.error(f"ç”Ÿæˆä»»åŠ¡æ­¥éª¤å¤±è´¥ï¼š{e}ã€‚åŸå§‹éœ€æ±‚ï¼š{user_message}")
                    safe_notify(app, f"ç”Ÿæˆä»»åŠ¡æ­¥éª¤å¤±è´¥ã€‚åŸå§‹éœ€æ±‚ï¼š{user_message}", severity="error")
                    plan = {"type": "task", "complexity": "low", "steps": [user_message]}

                # è‹¥ä¸ºä»»åŠ¡ä¸”æœ‰æ­¥éª¤ï¼Œå…ˆå±•ç¤ºè§„åˆ’å¹¶å§”æ‰˜æ­¥éª¤æ‰§è¡Œï¼›é—®é¢˜ç±»å‹åˆ™ç›´æ¥ç»§ç»­æ­£å¸¸å“åº”æµç¨‹
                steps = (plan.get("steps") or []) if isinstance(plan, dict) else []
                # æ³¨å…¥è§„åˆ’ç”Ÿæˆçš„ç³»ç»Ÿæç¤ºï¼ˆè‹¥æœ‰ï¼‰ï¼Œç”¨äºå¼•å¯¼åç»­æ‰§è¡Œé˜¶æ®µ
                try:
                    custom_sys_prompt = str((plan.get("system_prompt") or "").strip()) if isinstance(plan, dict) else ""
                except Exception:
                    custom_sys_prompt = ""
                    logger.error(f"[plan] æå–è§„åˆ’system_promptå¼‚å¸¸")
                if custom_sys_prompt:
                    try:
                        base_prompt = app.ai_client.system_prompt or ""
                        merged_prompt = f"{base_prompt}\n\n{custom_sys_prompt}".strip()
                        app.ai_client.system_prompt = app._augment_system_prompt(merged_prompt)
                        logger.debug(f"[prompt] å·²æ³¨å…¥è§„åˆ’system_promptï¼Œé•¿åº¦={len(app.ai_client.system_prompt or '')}")
                        # å±•ç¤ºå½“å‰ä»»åŠ¡çš„ç³»ç»Ÿæç¤ºè¯åˆ°å³ä¾§ä»»åŠ¡æ 
                        try:
                            setattr(app, "current_task_system_prompt", custom_sys_prompt)
                        except Exception:
                            logger.error(f"[plan] æ³¨å…¥è§„åˆ’system_promptå¼‚å¸¸")
                        try:
                            task_manager = app.query_one("#task-manager", None)
                        except Exception:
                            task_manager = None
                            logger.error(f"[plan] æŸ¥è¯¢ä»»åŠ¡ç®¡ç†å™¨å¼‚å¸¸")
                        try:
                            if task_manager and hasattr(task_manager, "set_system_prompt"):
                                task_manager.set_system_prompt(custom_sys_prompt)
                        except Exception:
                            logger.error(f"[plan] æ³¨å…¥è§„åˆ’system_promptå¼‚å¸¸")
                    except Exception:
                        logger.error(f"[plan] æ³¨å…¥è§„åˆ’system_promptå¼‚å¸¸")
                if isinstance(plan, dict) and (plan.get("type") == "task") and len(steps) > 0:
                    try:
                        plan_text = "\n".join([f"{i+1}. {s}" for i, s in enumerate(steps)])
                        if chat_history:
                            chat_history.add_message("assistant", f"ğŸ§­ å·²æ‹†åˆ†ä¸º{len(steps)}ä¸ªæ­¥éª¤ï¼š\n{plan_text}")
                    except Exception:
                        logger.error(f"[plan] å±•ç¤ºä»»åŠ¡è§„åˆ’å¼‚å¸¸")
                    # è®¾ç½®è§„åˆ’æ‰§è¡ŒçŠ¶æ€å¹¶é”å®šæœ¬ä¼šè¯è§„åˆ’ï¼Œé˜²æ­¢æ–°çš„æ¶ˆæ¯è§¦å‘é‡å¤è§„åˆ’
                    try:
                        setattr(app, "planning_locked", True)
                        setattr(app, "plan_execution_in_progress", True)
                        logger.debug("[plan] å·²é”å®šä¼šè¯è§„åˆ’ï¼Œå¹¶æ ‡è®°æ‰§è¡Œä¸­=True")
                    except Exception:
                        logger.error(f"[plan] è®¾ç½®è§„åˆ’æ‰§è¡ŒçŠ¶æ€å¼‚å¸¸")
                    try:
                        setattr(app, "_current_plan_steps", list(steps or []))
                        setattr(app, "_current_plan_task_text", user_message)
                        setattr(app, "_current_plan_index", 0)
                        logger.debug("[plan] å·²é¢„ä¿å­˜è®¡åˆ’ä¸Šä¸‹æ–‡ï¼Œæ”¯æŒåœæ­¢åæ¢å¤")
                    except Exception:
                        logger.error(f"[plan] é¢„ä¿å­˜è®¡åˆ’ä¸Šä¸‹æ–‡å¼‚å¸¸")
                    try:
                        executor = PlanExecutor()
                        await executor.run(app, steps, user_message)
                    finally:
                        try:
                            status = getattr(app, "plan_status", None)
                            if status == "completed":
                                setattr(app, "plan_execution_in_progress", False)
                            else:
                                # ä»å¤„äºæš‚åœæˆ–è¿è¡Œä¸­ï¼Œä¿æŒé”ä»¥é¿å…é‡å¤è§„åˆ’
                                setattr(app, "plan_execution_in_progress", True)
                        except Exception:
                            logger.error(f"[plan] è®¾ç½®è§„åˆ’æ‰§è¡ŒçŠ¶æ€å¼‚å¸¸")
                    return
        except Exception:
            # è‹¥çŠ¶æ€åˆ¤å®šæµç¨‹å¼‚å¸¸ï¼Œä¸é˜»æ–­åç»­æ™®é€šå›å¤é€»è¾‘
            logger.error(f"[plan] è§„åˆ’æ‰§è¡Œå¼‚å¸¸")

        # è§„èŒƒåŒ–å·¥å…·æ¶ˆæ¯é¡ºåº
        messages, removed_assistant, removed_tool = app._enforce_openai_tool_sequence(messages)
        logger.debug(f"[tools] åºåˆ—è§„èŒƒåŒ–ï¼šç§»é™¤assistant={removed_assistant}ï¼Œç§»é™¤tool={removed_tool}ï¼Œæ¶ˆæ¯æ•°={len(messages)}")
        if removed_assistant or removed_tool:
            safe_notify(
                app,
                f"ğŸ§¹ å·²è§„èŒƒåŒ–å·¥å…·æ¶ˆæ¯ï¼šç§»é™¤ä¸å®Œæ•´assistant {removed_assistant} æ¡/å­¤ç«‹tool {removed_tool} æ¡",
                severity="warning",
                timeout=4,
            )

        # è·å–å¯ç”¨å·¥å…·
        tools = app._get_enabled_tools_openai_format()
        logger.debug(f"[tools] å¯ç”¨å·¥å…·æ•°é‡={len(tools)}")
        try:
            provider = getattr(app.ai_client.model_config, "provider", "")
            current_model = app.ai_client.get_current_model() if hasattr(app.ai_client, "get_current_model") else ""
            safe_notify(app, f"ğŸ”§ å½“å‰æ¨¡å‹: {current_model} / æä¾›æ–¹: {provider}ï¼Œå¯ç”¨å·¥å…·: {len(tools)}", timeout=3)
            force_tools_branch = should_force_tool_call(app, messages, user_message)
            if force_tools_branch:
                safe_notify(app, "â¡ï¸ å·²å› â€˜ç»§ç»­â€™ä¸å†å²å·¥å…·è°ƒç”¨ï¼Œå¼ºåˆ¶èµ°å·¥å…·åˆ†æ”¯", timeout=4)
        except Exception:
            safe_notify(app, "ğŸ”§ è·å–å¯ç”¨å·¥å…·å¤±è´¥ï¼Œé»˜è®¤ä½¿ç”¨20æ¬¡è¿­ä»£", severity="warning", timeout=3)
            logger.error(f"[tools] è·å–å¯ç”¨å·¥å…·å¼‚å¸¸")


        # æ–°å¢ï¼šåœ¨è¿›å…¥å·¥å…·åˆ†æ”¯å‰è¿›è¡Œ needs_tool_call åˆ¤å®šï¼Œé¿å…æ— æ„ä¹‰è¿­ä»£
        try:
            if not force_tools_branch and not needs_tool_call(user_message):
                # èµ°æ™®é€šå¯¹è¯è·¯å¾„ï¼Œé¿å…å·¥å…·è¿­ä»£
                from .chat_stream import stream_chat_async
                from ..token_calculator import calculate_token_stats
                # æµå¼æˆ–éæµå¼å¤„ç†
                if streaming:
                    try:
                        chat_history = app.query_one("#chat-history", ChatHistoryWidget)
                    except Exception:
                        chat_history = None
                    streaming_widget = chat_history.start_streaming_message("assistant") if chat_history else None
                    accumulated = ""
                    try:
                        async for chunk in stream_chat_async(app, messages):
                            content = chunk if isinstance(chunk, str) else (chunk.get("content") if isinstance(chunk, dict) else str(chunk))
                            content = content or ""
                            accumulated += content
                            try:
                                if streaming_widget:
                                    streaming_widget.append_content(content)
                            except Exception:
                                pass
                    except Exception:
                        # å›é€€åˆ°éæµå¼
                        try:
                            resp = await app.ai_client.chat_async(messages)
                            accumulated = getattr(resp, "content", "") or ""
                        except Exception:
                            accumulated = ""
                            logger.error(f"[tools] éæµå¼è·å–å›å¤å¼‚å¸¸")
                    # å®Œæˆå¹¶è¿½åŠ æ¶ˆæ¯
                    assistant_msg_dict = {"role": "assistant", "content": accumulated}
                    messages.append(assistant_msg_dict)
                    if chat_history:
                        message_added = chat_history.finish_streaming_message(accumulated)
                        if not message_added:
                            context_for_assistant = messages[:-1] if messages else []
                            token_stats = calculate_token_stats(current_message=assistant_msg_dict, context_messages=context_for_assistant)
                            chat_history.add_message("assistant", accumulated, token_stats=token_stats)
                    app.conversation_history = messages
                    return
                else:
                    try:
                        resp = await app.ai_client.chat_async(messages)
                        content = getattr(resp, "content", "") or ""
                    except Exception:
                        content = ""
                    assistant_msg_dict = {"role": "assistant", "content": content}
                    messages.append(assistant_msg_dict)
                    try:
                        chat_history = app.query_one("#chat-history", ChatHistoryWidget)
                    except Exception:
                        chat_history = None
                    if chat_history:
                        context_for_assistant = messages[:-1] if messages else []
                        token_stats = calculate_token_stats(current_message=assistant_msg_dict, context_messages=context_for_assistant)
                        chat_history.add_message("assistant", content, token_stats=token_stats)
                    app.conversation_history = messages
                    return
        except Exception:
            # åˆ¤å®šå¤±è´¥ä¸å½±å“åç»­å·¥å…·æµç¨‹
            logger.error(f"[tools] åˆ¤å®šæ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨å¼‚å¸¸")

        # è¿­ä»£ä¸Šé™ï¼ˆç”¨äºæµæ§ä¿¡æ¯å±•ç¤ºï¼‰
        try:
            max_iterations = getattr(app.ai_client.model_config, "max_iterations", 20) or 20
            if not isinstance(max_iterations, int) or max_iterations <= 0:
                max_iterations = 20
        except Exception:
            max_iterations = 20

        # è¿è¡Œå·¥å…·è¿­ä»£ï¼ˆå§”æ‰˜åˆ°å…¬å…±å®ç°ï¼‰
        logger.debug(f"[iteration] å‡†å¤‡è¿­ä»£ï¼šstreaming={streaming}ï¼Œä¸Šé™={max_iterations}ï¼Œæ¶ˆæ¯æ•°={len(messages)}ï¼Œå·¥å…·æ•°={len(tools)}")
        result = await run_tool_iterations(app, messages, tools, user_message, streaming=streaming)
        messages = result.get("messages", messages)
        app.conversation_history = messages
        return

    except Exception as e:
        logger.exception(f"[flow] å¤„ç†è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {e}")
        try:
            if chat_history:
                chat_history.add_message("assistant", f"âŒ å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
        except Exception:
            logger.error(f"[flow] æ·»åŠ é”™è¯¯æ¶ˆæ¯å¼‚å¸¸")
    finally:
        app._chat_in_progress = False
        app._current_ai_task = None
        try:
            chat_input = app.query_one("#chat-input", ChatInputWidget)
            chat_input.set_loading(False)
            chat_input.set_processing(False)
        except Exception:
            logger.error(f"[flow] è®¾ç½®èŠå¤©è¾“å…¥çŠ¶æ€å¼‚å¸¸")
        # è‡ªåŠ¨ä¿å­˜ä¼šè¯
        try:
            app._save_current_session()
        except Exception:
            logger.error(f"[flow] è‡ªåŠ¨ä¿å­˜ä¼šè¯å¼‚å¸¸")


async def filter_and_deduplicate_tool_calls(app, tool_calls: list, executed_tool_signatures: set) -> tuple:
    """è¿‡æ»¤å’Œå»é‡å·¥å…·è°ƒç”¨ï¼Œè¿”å›(è¿‡æ»¤åçš„è°ƒç”¨åˆ—è¡¨, è¢«å¿½ç•¥çš„æœªå¯ç”¨å·¥å…·ååˆ—è¡¨, è·³è¿‡çš„é‡å¤è°ƒç”¨ä¿¡æ¯åˆ—è¡¨)ã€‚"""
    filtered_tool_calls = []
    disabled_called_names = []
    skipped_duplicates = []
    try:
        enabled = set(getattr(app, "enabled_tools", set()) or set())
        # åªä¿ç•™å¯ç”¨å·¥å…·çš„è°ƒç”¨
        filtered_tool_calls = [
            tc for tc in (tool_calls or [])
            if ((tc or {}).get("function", {}).get("name") in enabled)
        ]
        # æ ¹æ®å‡½æ•°å+è§„èŒƒåŒ–å‚æ•°åšå»é‡
        try:
            import json
            dedup = []
            for tc in filtered_tool_calls:
                fn = (tc or {}).get("function", {})
                nm = fn.get("name")
                args = fn.get("arguments", "{}")
                try:
                    if isinstance(args, (dict, list)):
                        args_norm = json.dumps(args, ensure_ascii=False, sort_keys=True)
                    else:
                        args_norm = str(args)
                except Exception:
                    args_norm = str(args)
                sig = f"{nm}:{args_norm}"
                if sig in executed_tool_signatures:
                    safe_notify(app, f"â™»ï¸ è·³è¿‡é‡å¤å·¥å…·è°ƒç”¨: {nm}", severity="warning", timeout=3)
                    # è®°å½•é‡å¤è°ƒç”¨ä¿¡æ¯ç”¨äºåç»­è¿½åŠ åˆ°ä¸Šä¸‹æ–‡
                    try:
                        skipped_duplicates.append({
                            "name": nm or "",
                            "arguments": args_norm,
                            "tool_call_id": (tc or {}).get("id") or "",
                        })
                    except Exception:
                        pass
                    continue
                executed_tool_signatures.add(sig)
                dedup.append(tc)
            filtered_tool_calls = dedup
        except Exception:
            pass
        # æ”¶é›†æœªå¯ç”¨å·¥å…·å
        try:
            disabled_called_names = [
                (tc or {}).get("function", {}).get("name")
                for tc in (tool_calls or [])
                if ((tc or {}).get("function", {}).get("name") not in enabled)
            ]
            if disabled_called_names:
                try:
                    preview = ", ".join([n for n in disabled_called_names if n][:6])
                    safe_notify(
                        app,
                        f"ğŸš« æ£€æµ‹åˆ°æœªå¯ç”¨çš„å·¥å…·è°ƒç”¨å·²è¢«å¿½ç•¥ï¼š{preview}",
                        severity="warning",
                        timeout=4,
                    )
                except Exception:
                    logger.error(f"[flow] é€šçŸ¥æœªå¯ç”¨å·¥å…·è°ƒç”¨å¼‚å¸¸")
        except Exception:
            logger.error(f"[flow] æ”¶é›†æœªå¯ç”¨å·¥å…·åå¼‚å¸¸")
    except Exception:
        filtered_tool_calls = []
    return filtered_tool_calls, disabled_called_names, skipped_duplicates


async def run_tool_iterations(app, messages: list, tools: list, user_message: str, streaming: bool = True) -> dict:
    """è¿è¡Œå·¥å…·è°ƒç”¨è¿­ä»£ï¼ˆå…¬å…±å®ç°ï¼‰ï¼Œæ”¯æŒæµå¼/éæµå¼ä¸¤ç§æ¨¡å¼ã€‚"""
    iteration = 0
    block_tool_retry_for_current_query = False
    executed_tool_signatures = set()
    # æ–°å¢ï¼šè®°å½•ä¸Šä¸€è½®åŠ©æ‰‹æ–‡æœ¬ï¼Œç”¨äºé‡å¤å†…å®¹æ—©åœ
    previous_assistant_text = ""

    # è¿­ä»£ä¸Šé™
    try:
        max_iterations = getattr(app.ai_client.model_config, "max_iterations", 20) or 20
        if not isinstance(max_iterations, int) or max_iterations <= 0:
            max_iterations = 20
    except Exception:
        max_iterations = 20

    # UI ç»„ä»¶
    try:
        from ..widgets import ChatHistoryWidget
        chat_history = app.query_one("#chat-history", ChatHistoryWidget)
    except Exception:
        chat_history = None
    streaming_widget = chat_history.start_streaming_message("assistant") if (chat_history and streaming) else None

    # ä¾èµ–å‡½æ•°ï¼ˆé¿å…é¡¶éƒ¨æ”¹åŠ¨ï¼Œå†…éƒ¨å¯¼å…¥ï¼‰
    from .chat_stream import process_tool_sequence, stream_and_process_response
    from ..token_calculator import calculate_token_stats
    from ketacli.sdk.ai.function_call import function_executor
    from ketacli.sdk.ai.tool_output_compressor import compress_if_large
    from textual.widget import Widget
    from .ai_helpers import plan_task_steps, requires_user_confirmation

    while iteration < max_iterations:
        iteration += 1
        safe_notify(app, f"â¡ï¸ ç¬¬{iteration}è½®å·¥å…·è¯·æ±‚ï¼Œä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°: {len(messages)}", timeout=2)

        # å¤„ç†å·¥å…·è°ƒç”¨åºåˆ—ï¼Œè§„èŒƒåŒ–æ¶ˆæ¯å†å²
        messages, ra, rt = await process_tool_sequence(app, messages)

        # è·å–AIå“åº”ï¼šæ ¹æ®æ¨¡å¼é€‰æ‹©æµå¼æˆ–éæµå¼
        if streaming:
            response, _ = await stream_and_process_response(app, messages, tools, streaming_widget)
        else:
            try:
                response = await app.ai_client.chat_with_tools_async(messages=messages, tools=tools)
            except Exception:
                # å›é€€åˆ°æ™®é€šå›ç­”
                try:
                    response = await app.ai_client.chat_async(messages)
                except Exception:
                    class _EmptyResp:
                        content = ""
                        tool_calls = []
                    response = _EmptyResp()

        # æ„é€ åŠ©æ‰‹æ¶ˆæ¯
        assistant_message = {"role": "assistant", "content": getattr(response, "content", "")}
        _resp_content_len = len(getattr(response, "content", "") or "")
        _resp_tool_calls_len = len(getattr(response, "tool_calls", []) or [])
        logger.debug(f"[iteration] æ¨¡å‹å“åº”ï¼šcontent_len={_resp_content_len}ï¼Œtool_calls={_resp_tool_calls_len}")

        # è¿‡æ»¤ä¸å»é‡å·¥å…·è°ƒç”¨
        filtered_tool_calls, disabled_called_names, skipped_duplicates = await filter_and_deduplicate_tool_calls(
            app, (getattr(response, "tool_calls", None) or []), executed_tool_signatures
        )
        logger.debug(f"[iteration] å·¥å…·è°ƒç”¨è¿‡æ»¤ï¼šä¿ç•™={len(filtered_tool_calls)}ï¼Œå¿½ç•¥æœªå¯ç”¨={len(disabled_called_names)}")

        # å¤„ç†ç¦ç”¨å·¥å…·æç¤ºä¸ç©ºå†…å®¹å›é€€
        try:
            if disabled_called_names:
                try:
                    preview = ", ".join([n for n in disabled_called_names if n][:6])
                    guidance = (
                        f"âš ï¸ æ£€æµ‹åˆ°æ¨¡å‹å°è¯•è°ƒç”¨æœªå¯ç”¨çš„å·¥å…·ï¼š{preview}ã€‚è¯¥è°ƒç”¨å·²è¢«å¿½ç•¥ã€‚\n"
                        "è¯·æŒ‰ `T` æˆ– `Ctrl+T` æ‰“å¼€å·¥å…·åˆ—è¡¨å¯ç”¨æ‰€éœ€å·¥å…·ï¼Œæˆ–ç»§ç»­è¾“å…¥è®©æˆ‘åœ¨ä¸ä½¿ç”¨å·¥å…·çš„æƒ…å†µä¸‹å›ç­”ã€‚"
                    )
                    existing = (assistant_message.get("content") or "")
                    if existing.strip():
                        sep = "\n\n" if not existing.endswith("\n") else "\n"
                        assistant_message["content"] = existing + sep + guidance
                    else:
                        assistant_message["content"] = guidance
                except Exception:
                    pass
            if (not filtered_tool_calls) and disabled_called_names and not (assistant_message.get("content") or "").strip():
                disabled_preview = ", ".join([n for n in disabled_called_names if n][:6])
                fallback_text = (
                    f"âš ï¸ æ£€æµ‹åˆ°æ¨¡å‹å°è¯•è°ƒç”¨æœªå¯ç”¨çš„å·¥å…·ï¼š{disabled_preview}ã€‚è¯¥è°ƒç”¨å·²è¢«å¿½ç•¥ã€‚\n"
                    "è¯·æŒ‰ `Ctrl+T` æ‰“å¼€å·¥å…·åˆ—è¡¨å¯ç”¨æ‰€éœ€å·¥å…·ï¼Œæˆ–ç»§ç»­è¾“å…¥è®©æˆ‘åœ¨ä¸ä½¿ç”¨å·¥å…·çš„æƒ…å†µä¸‹å›ç­”ã€‚"
                )
                assistant_message["content"] = fallback_text
        except Exception:
            pass

        # å‘ä¸Šä¸‹æ–‡åé¦ˆé‡å¤è°ƒç”¨è·³è¿‡ä¿¡æ¯ï¼Œå¸®åŠ©æ¨¡å‹é¿å…é‡å¤
        try:
            if locals().get("skipped_duplicates"):
                dup_preview = ", ".join([(d or {}).get("name") or "" for d in (skipped_duplicates or []) if (d or {}).get("name")][:6])
                if dup_preview.strip():
                    messages.append({
                        "role": "user",
                        "synthetic": True,
                        "content": (
                            f"æç¤ºï¼šæ£€æµ‹åˆ°é‡å¤çš„å·¥å…·è°ƒç”¨å·²è¢«è·³è¿‡ï¼š{dup_preview}ã€‚"
                            f"è¯·é¿å…å¯¹ç›¸åŒå‚æ•°é‡å¤è°ƒç”¨ï¼Œä¼˜å…ˆåˆ†æåŸå› å¹¶è°ƒæ•´å‚æ•°åå†è¯•ã€‚"
                        ),
                    })
        except Exception:
            pass

        # é™åˆ¶æ¯è½®åªæ‰§è¡Œä¸€ä¸ªå·¥å…·è°ƒç”¨
        if filtered_tool_calls:
            try:
                filtered_tool_calls = filtered_tool_calls[:1]
                safe_notify(app, "ğŸ¯ ä¸ºæå‡ç²¾å‡†åº¦ï¼šæœ¬è½®ä»…æ‰§è¡Œ1æ¬¡å·¥å…·è°ƒç”¨å¹¶éšåè¿›è¡Œæ€è€ƒ", severity="success", timeout=3)
            except Exception:
                pass
            assistant_message["tool_calls"] = filtered_tool_calls
            try:
                names = []
                for tc in filtered_tool_calls:
                    fn = (tc or {}).get("function", {})
                    nm = fn.get("name")
                    if nm:
                        names.append(nm)
                if names:
                    safe_notify(app, f"ğŸ› ï¸ å°†æ‰§è¡Œå·¥å…·: {', '.join(names[:5])}", timeout=3)
            except Exception:
                pass

        # è‹¥éœ€è¦ç”¨æˆ·ç¡®è®¤/è¡¥å…¨ï¼Œç¡®ä¿è¿½åŠ æ ‡è®°
        try:
            cur = (assistant_message.get("content") or "")
            if requires_user_confirmation(cur) and not has_marker(cur, REQUIRE_USER_MARKERS):
                sep = "\n\n" if not cur.endswith("\n") else "\n"
                assistant_message["content"] = cur + sep + "[STEP_REQUIRE_USER]"
        except Exception:
            pass

        # é™„åŠ åŠ©æ‰‹æ¶ˆæ¯
        messages.append(assistant_message)
        _assistant_preview = (assistant_message.get("content") or "").strip().replace("\n", " ")[:120]
        _assistant_tool_names = [((tc or {}).get("function", {}).get("name")) for tc in (assistant_message.get("tool_calls") or [])]
        _assistant_tool_names = [n for n in _assistant_tool_names if n][:5]
        logger.debug(f"[iteration] é™„åŠ åŠ©æ‰‹æ¶ˆæ¯ï¼šcontent_preview='{_assistant_preview}', tool_calls={_assistant_tool_names}")

        # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯ï¼ˆæ ¹æ®æ¨¡å¼ï¼‰
        try:
            assistant_content = (assistant_message.get("content") or "")
            if assistant_content.strip() and chat_history:
                if streaming:
                    message_added = chat_history.finish_streaming_message(assistant_content)
                    if not message_added:
                        assistant_msg_dict = {"role": "assistant", "content": assistant_content}
                        context_for_assistant = messages[:-1] if messages else []
                        assistant_token_stats = calculate_token_stats(
                            current_message=assistant_msg_dict,
                            context_messages=context_for_assistant,
                        )
                        chat_history.add_message("assistant", assistant_content, token_stats=assistant_token_stats)
                else:
                    assistant_msg_dict = {"role": "assistant", "content": assistant_content}
                    context_for_assistant = messages[:-1] if messages else []
                    assistant_token_stats = calculate_token_stats(
                        current_message=assistant_msg_dict,
                        context_messages=context_for_assistant,
                    )
                    chat_history.add_message("assistant", assistant_content, token_stats=assistant_token_stats)
            # # è§„åˆ’/ç¡®è®¤æ—©åœåˆ¤æ–­
            # try:
            #     if has_marker(assistant_content, PLAN_READY_MARKERS):
            #         context_hint = ""
            #         for idx in range(len(messages) - 2, -1, -1):
            #             if messages[idx].get("role") == "tool":
            #                 ctx = (messages[idx].get("content") or "").strip()
            #                 if ctx:
            #                     context_hint = ctx[:800]
            #                     break
            #         plan_input = assistant_content
            #         if context_hint:
            #             plan_input = f"{assistant_content}\n\n[å·²è¯†åˆ«ä¸Šä¸‹æ–‡æ‘˜è¦]\n{context_hint}"
            #         plan = await app._plan_task_steps(plan_input)
            #         steps = (plan.get("steps") or []) if isinstance(plan, dict) else []
            #         if isinstance(plan, dict) and (plan.get("type") == "task") and len(steps) > 1:
            #             plan_text = "\n".join([f"{i+1}. {s}" for i, s in enumerate(steps)])
            #             chat_history.add_message("assistant", f"ğŸ§­ å·²æ‹†åˆ†ä¸º{len(steps)}ä¸ªæ­¥éª¤ï¼š\n{plan_text}")
            #             await execute_task_steps(app, steps, user_message)
            #             return {"messages": messages, "stop": True}
            # except Exception:
            #     pass
            if should_pause_for_user(assistant_content):
                logger.debug("[iteration] æ—©åœï¼šç­‰å¾…ç”¨æˆ·ç¡®è®¤/è¾“å…¥")
                safe_notify(app, "â¸ï¸ æš‚åœï¼šç­‰å¾…ä½ çš„è¾“å…¥æˆ–ç¡®è®¤åç»§ç»­ã€‚", timeout=4)
                return {"messages": messages, "stop": True}
            # æ–°å¢ï¼šä¼šè¯ç»“æŸæˆ–æ­¥éª¤å®Œæˆæ—©åœ
            if should_end_session(assistant_content, has_tool_calls=bool(filtered_tool_calls)):
                logger.debug("[iteration] æ—©åœï¼šä¼šè¯ç»“æŸæ ‡è®°å‘½ä¸­")
                safe_notify(app, "âœ… ä¼šè¯å·²ç»“æŸï¼Œåœæ­¢ç»§ç»­è¿­ä»£ã€‚", timeout=4)
                return {"messages": messages, "stop": True}
        except Exception:
            pass

        # æ–°å¢ï¼šè‹¥æ— å·¥å…·è°ƒç”¨ä¸”æœ¬è½®åŠ©æ‰‹æ–‡æœ¬ä¸ä¸Šä¸€è½®ç›¸åŒï¼Œç›´æ¥æ—©åœï¼Œé¿å…é‡å¤è¿­ä»£
        if (not filtered_tool_calls):
            cur_text = (assistant_message.get("content") or "").strip()
            if cur_text and previous_assistant_text.strip() and (cur_text == previous_assistant_text.strip()):
                logger.debug("[iteration] æ—©åœï¼šè¿ç»­ç›¸åŒæ–‡æœ¬ä¸”æ— å·¥å…·è°ƒç”¨")
                safe_notify(app, "ğŸ›‘ æ£€æµ‹åˆ°é‡å¤å“åº”ä¸”æ— å·¥å…·è°ƒç”¨ï¼Œæå‰ç»“æŸã€‚", timeout=5)
                return {"messages": messages, "stop": True}
        # æ›´æ–°ä¸Šä¸€è½®æ–‡æœ¬
        previous_assistant_text = (assistant_message.get("content") or "")

        # æ‰§è¡Œå·¥å…·æˆ–è€…ç»“æŸ
        if filtered_tool_calls:
            tool_results = await function_executor.execute_from_tool_calls_async(filtered_tool_calls)
            import json
            for i, tool_result in enumerate(tool_results):
                tool_call = filtered_tool_calls[i]
                func_data = tool_call.get("function", {})
                func_name = func_data.get("name")
                func_args = func_data.get("arguments", "{}")
                if tool_result.get("success"):
                    result_val = tool_result.get("result", "")
                    if isinstance(result_val, Widget):
                        result_str = "(å›¾è¡¨å¯è§†åŒ–ç»“æœ)"
                        result_obj_for_ui = result_val
                    elif isinstance(result_val, (dict, list)):
                        try:
                            result_str = json.dumps(result_val, ensure_ascii=False)
                        except Exception:
                            result_str = str(result_val)
                        result_obj_for_ui = result_val if isinstance(result_val, dict) else None
                    else:
                        result_str = str(result_val) if result_val is not None else ""
                        result_obj_for_ui = None
                    if not result_str.strip():
                        result_str = "(ç»“æœä¸ºç©º)"
                    compressed_text, was_compressed = compress_if_large(result_str, threshold=8000)
                    no_data = False
                    try:
                        txt_chk = result_str or ""
                        if txt_chk.strip() == "(ç»“æœä¸ºç©º)" or ("æœªæŸ¥è¯¢åˆ°æ•°æ®" in txt_chk):
                            no_data = True
                    except Exception:
                        no_data = False
                    if chat_history:
                        chat_history.add_tool_call(
                            func_name,
                            func_args,
                            compressed_text if was_compressed else result_str,
                            False if (no_data and func_name == "search_data") else True,
                            result_obj=result_obj_for_ui,
                        )
                    tool_message = {
                        "role": "tool",
                        "tool_call_id": tool_call.get("id", f"call_{func_name}"),
                        "content": compressed_text if was_compressed else result_str,
                    }
                    messages.append(tool_message)
                    try:
                        if no_data and func_name == "search_data":
                            safe_notify(app, f"âš ï¸ å·¥å…· {func_name} æ‰§è¡Œå®Œæˆä½†æ— æ•°æ®", severity="warning", timeout=4)
                        else:
                            safe_notify(app, f"âœ… å·¥å…· {func_name} æ‰§è¡ŒæˆåŠŸ", timeout=2)
                    except Exception:
                        pass
                    try:
                        txt = result_str or ""
                        if (txt.strip() == "(ç»“æœä¸ºç©º)" or ("æœªæŸ¥è¯¢åˆ°æ•°æ®" in txt)) and func_name == "search_data":
                            import json as _json
                            aobj = {}
                            try:
                                if isinstance(func_args, str):
                                    aobj = _json.loads(func_args)
                                elif isinstance(func_args, dict):
                                    aobj = func_args
                            except Exception:
                                aobj = {}
                            orig = str(aobj.get("spl") or "")
                            if orig:
                                from ..widgets.modal_widgets import ToolArgsEditDialog
                                try:
                                    app.push_screen(ToolArgsEditDialog(tool_name=func_name, original_args=aobj or func_args, error_summary=txt))
                                    safe_notify(app, "æç¤ºï¼šæŸ¥è¯¢ä¸ºç©ºï¼Œå·²æ‰“å¼€å‚æ•°ç¼–è¾‘å¼¹çª—", timeout=5)
                                except Exception:
                                    pass
                    except Exception:
                        pass
                else:
                    error_msg = tool_result.get("error", "æ‰§è¡Œå¤±è´¥")
                    if not (error_msg or "").strip():
                        error_msg = "(é”™è¯¯ä¿¡æ¯ä¸ºç©º)"
                    if chat_history:
                        chat_history.add_tool_call(func_name, func_args, error_msg, False)
                    tool_message = {
                        "role": "tool",
                        "tool_call_id": tool_call.get("id", f"call_{func_name}"),
                        "content": error_msg or "",
                    }
                    messages.append(tool_message)
                    block_tool_retry_for_current_query = True
                    try:
                        safe_notify(app, f"âŒ å·¥å…· {func_name} æ‰§è¡Œå¤±è´¥ï¼š{error_msg}", severity="warning", timeout=4, markup=False)
                    except Exception:
                        pass
                    try:
                        if func_name == "search_data":
                            import json as _json
                            orig_spl = ""
                            try:
                                if isinstance(func_args, str):
                                    aobj = _json.loads(func_args)
                                else:
                                    aobj = func_args if isinstance(func_args, dict) else {}
                                orig_spl = str(aobj.get("spl") or "")
                            except Exception:
                                orig_spl = ""
                            if orig_spl:
                                from ..widgets.modal_widgets import ToolArgsEditDialog
                                try:
                                    app.push_screen(ToolArgsEditDialog(tool_name=func_name, original_args=aobj or func_args, error_summary=error_msg))
                                    safe_notify(app, "æç¤ºï¼šå·²æ‰“å¼€å‚æ•°ç¼–è¾‘å¼¹çª—ï¼Œå¯ç¼–è¾‘åç«‹å³é‡è¯•", timeout=5)
                                except Exception:
                                    pass
                    except Exception:
                        pass
                continue
        else:
            # ä»…åœ¨æµå¼æ¨¡å¼ä¸‹æ‰§è¡Œéæµå¼å›é€€å°è¯•ï¼Œé¿å…é‡å¤
            if streaming:
                try:
                    import re
                    provider = getattr(app.ai_client.model_config, "provider", "")
                    current_model = app.ai_client.get_current_model() if hasattr(app.ai_client, "get_current_model") else ""
                    tools_names = []
                    for t in tools:
                        fn = (t or {}).get("function", {})
                        nm = fn.get("name")
                        if nm:
                            tools_names.append(nm)
                    markers = re.findall(r"<\|\s*tool_call_begin\s*\|>(.*?)<\|\s*tool_call_end\s*\|>", getattr(response, "content", "") or "", flags=re.DOTALL)
                    snippet = (getattr(response, "content", "") or "").strip().replace("\n", " ")[:300]
                    last_user = ""
                    for idx in range(len(messages) - 1, -1, -1):
                        if messages[idx].get("role") == "user":
                            last_user = (messages[idx].get("content") or "").strip().replace("\n", " ")[:120]
                            break
                    safe_notify(
                        app,
                        f"ğŸ§ª è°ƒè¯•ï¼šæ¨¡å‹æœªè¿”å›ç»“æ„åŒ–å·¥å…·è°ƒç”¨ | æ¨¡å‹: {current_model}/{provider} | å·¥å…·æ•°: {len(tools)} | æ ‡è®°æ®µ: {len(markers)}",
                        severity="warning",
                        timeout=5,
                        markup=False,
                    )
                    if tools_names:
                        safe_notify(app, f"ğŸ§ª å¯ç”¨å·¥å…·: {', '.join(tools_names[:6])}", timeout=4, markup=False)
                    if last_user:
                        safe_notify(app, f"ğŸ§ª æœ€è¿‘ç”¨æˆ·è¾“å…¥ç‰‡æ®µ: {last_user}", timeout=4, markup=False)
                    if snippet:
                        safe_notify(app, f"ğŸ§ª å“åº”ç‰‡æ®µ: {snippet}", timeout=5, markup=False)
                except Exception:
                    pass

                # æ–°å¢ï¼šéæµå¼ä¸€æ¬¡æ€§å›é€€å°è¯•ï¼Œå°½é‡æ‹¿åˆ°ç»“æ„åŒ–å·¥å…·è°ƒç”¨
                try:
                    fallback_resp = await app.ai_client.chat_with_tools_async(messages, tools=tools)
                    fallback_calls = getattr(fallback_resp, "tool_calls", []) or []
                except Exception:
                    fallback_calls = []
                if fallback_calls:
                    filtered_fallback_calls, _, _ = await filter_and_deduplicate_tool_calls(app, fallback_calls, executed_tool_signatures)
                    if filtered_fallback_calls:
                        safe_notify(app, "ğŸ” éæµå¼å›é€€è·å–åˆ°å·¥å…·è°ƒç”¨ï¼Œç»§ç»­æ‰§è¡Œ", timeout=4)
                        assistant_message["tool_calls"] = filtered_fallback_calls[:1]
                        messages.append(assistant_message)
                        # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯ï¼ˆä¸æµå¼ç»„ä»¶å¯¹é½ï¼‰
                        try:
                            assistant_content = (assistant_message.get("content") or "")
                            if assistant_content.strip() and chat_history:
                                message_added = chat_history.finish_streaming_message(assistant_content)
                                if not message_added:
                                    assistant_msg_dict = {"role": "assistant", "content": assistant_content}
                                    context_for_assistant = messages[:-1] if messages else []
                                    assistant_token_stats = calculate_token_stats(
                                        current_message=assistant_msg_dict,
                                        context_messages=context_for_assistant,
                                    )
                                    chat_history.add_message("assistant", assistant_content, token_stats=assistant_token_stats)
                        except Exception:
                            pass
                        # æ‰§è¡Œå·¥å…·å¹¶å°†ç»“æœè¿½åŠ åˆ°æ¶ˆæ¯
                        try:
                            tool_messages = await process_tool_calls(filtered_fallback_calls[:1], chat_history_widget=chat_history, add_to_base_messages=True)
                            messages.extend(tool_messages or [])
                        except Exception:
                            pass
                        continue
            # è‹¥å›é€€ä»æœªæ‹¿åˆ°å·¥å…·è°ƒç”¨ï¼Œåˆ™ç»§ç»­ä¸‹ä¸€è½®ï¼Œè®©æ¨¡å‹æ€è€ƒ
            safe_notify(app, "â­ï¸ æœªè¿”å›ç»“æ„åŒ–å·¥å…·è°ƒç”¨ï¼Œæœ¬è½®ç»§ç»­ä¸‹ä¸€è½®å°è¯•", timeout=4)
            logger.debug("[iteration] æœ¬è½®æœªè¿”å›ç»“æ„åŒ–tool_callsï¼Œç»§ç»­ä¸‹ä¸€è½®")
            continue

    if iteration >= max_iterations:
        logger.debug(f"[iteration] è¾¾åˆ°è¿­ä»£ä¸Šé™ï¼š{max_iterations}")
        safe_notify(app, f"âš ï¸ å·¥å…·æ‰§è¡Œæ¬¡æ•°å·²è¾¾åˆ°ä¸Šé™ï¼ˆ{max_iterations}ï¼‰ï¼Œå·²åœæ­¢ç»§ç»­ã€‚", severity="warning", timeout=5)
        try:
            if chat_history:
                chat_history.add_message(
                    "assistant",
                    (
                        f"å·¥å…·æ‰§è¡Œæ¬¡æ•°å·²è¾¾åˆ°ä¸Šé™ï¼ˆ{max_iterations}ï¼‰ã€‚"
                        "å¦‚éœ€ç»§ç»­ï¼Œè¯·è¾“å…¥â€œç»§ç»­â€è®©æˆ‘æ¥ç€æ‰§è¡Œï¼Œ"
                        "æˆ–æŒ‰ Ctrl+T æ‰“å¼€å·¥å…·åˆ—è¡¨å¯ç”¨/è°ƒæ•´æ‰€éœ€å·¥å…·åå†è¯•ã€‚"
                    ),
                )
        except Exception:
            pass
    return {"messages": messages, "stop": False}


def mentions_next_step(text: str, current_idx: int) -> bool:
    """å¯å‘å¼åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ˜ç¡®æŒ‡å‘â€œä¸‹ä¸€æ­¥â€
    - å‘½ä¸­â€œä¸‹ä¸€æ­¥â€ã€â€œæ¥ä¸‹æ¥â€ç­‰ä¸­æ–‡æç¤º
    - å‘½ä¸­â€œNextâ€æˆ–â€œnext stepâ€ç­‰è‹±æ–‡æç¤º
    - æ˜ç¡®å‡ºç°â€œç¬¬{idx+1}æ­¥â€ç¼–å·
    """
    try:
        if not text:
            return False
        t = (text or "").lower()
    except Exception:
        t = ""
    if not t.strip():
        return False
    if ("ä¸‹ä¸€æ­¥" in t) or ("æ¥ä¸‹æ¥" in t):
        return True
    try:
        import re
        nxt = current_idx + 1
        if re.search(rf"ç¬¬\s*{nxt}\s*æ­¥", text):
            return True
        if re.search(r"\bnext\b", t) or re.search(r"\bnext\s+step\b", t):
            return True
        if re.search(rf"\bstep\s*{nxt}\b", t):
            return True
    except Exception:
        pass
    return False
