name: Run Tests

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:
    # Allow manual triggering

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: ["unit", "integration"]
        include:
          - test-type: "unit"
            pytest-args: "-m 'unit'"
          - test-type: "integration"
            pytest-args: "-m 'integration'"


    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Set up Docker Buildx
        if: matrix.test-type == 'integration'
        uses: docker/setup-buildx-action@v3

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-mock pytest-asyncio pytest-xdist pytest-rerunfailures

      - name: Install package in development mode
        run: |
          pip install -e .

      - name: Build Docker images for integration tests
        if: matrix.test-type == 'integration'
        run: |
          # Build the shell server image needed for Docker tests
          docker build -f src/microbots/environment/local_docker/image_builder/Dockerfile -t kavyasree261002/shell_server:latest .

      - name: Run ${{ matrix.test-type }} tests
        env:
          # OpenAI API Configuration
          OPEN_AI_KEY: ${{ secrets.OPEN_AI_KEY }}
          OPEN_AI_DEPLOYMENT_NAME: ${{ secrets.OPEN_AI_DEPLOYMENT_NAME }}
          OPEN_AI_END_POINT: ${{ secrets.OPEN_AI_END_POINT }}
          # Azure OpenAI API Configuration
          AZURE_OPENAI_API_VERSION: ${{ secrets.AZURE_OPENAI_API_VERSION }}
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          BROWSER_USE_LLM_MODEL: "gpt-5"
          BROWSER_USE_LLM_TEMPERATURE: 1
        run: |
          python -m pytest ${{ matrix.pytest-args }} \
            -n auto \
            --dist loadgroup \
            --reruns 1 \
            --reruns-delay 5 \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=test-results-${{ matrix.test-type }}.xml \
            -v \
            -o log_cli=true \
            -o log_cli_level=DEBUG \
            -o log_cli_format="%(asctime)s [%(levelname)s] %(name)s: %(message)s" \
            -o log_cli_date_format="%Y-%m-%d %H:%M:%S"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test-type }}
          path: test-results-*.xml

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-${{ matrix.test-type }}
          path: coverage.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: always()
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: ${{ matrix.test-type }}
          name: codecov-${{ matrix.test-type }}
          fail_ci_if_error: false

  test-summary:
    runs-on: ubuntu-latest
    needs: [test]
    if: always()
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          merge-multiple: true

      - name: Test Summary
        if: always()
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.test.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.test.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY