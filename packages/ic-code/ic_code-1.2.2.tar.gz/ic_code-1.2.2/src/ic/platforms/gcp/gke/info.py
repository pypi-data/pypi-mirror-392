#!/usr/bin/env python3
import argparse
import json
import os
from typing import Dict, List, Optional, Any
from google.cloud.container_v1 import ClusterManagerClient
from google.cloud.container_v1.types import ListClustersRequest, GetClusterRequest
from google.api_core import exceptions as gcp_exceptions
from rich.console import Console
from rich.table import Table
from rich import box
from rich.rule import Rule
from rich.tree import Tree

try:
    from ....common.gcp_utils import (
        GCPAuthManager, GCPProjectManager, GCPResourceCollector,
    create_gcp_client, format_gcp_output, get_gcp_resource_labels
    )
except ImportError:
    from common.gcp_utils import (
        GCPAuthManager, GCPProjectManager, GCPResourceCollector,
    create_gcp_client, format_gcp_output, get_gcp_resource_labels
    )
try:
    from ....common.log import log_info, log_error, log_exception
except ImportError:
    from common.log import log_info, log_error, log_exception

# Import MCP integration
try:
    from mcp.gcp_connector import MCPGCPService
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False

console = Console()


def fetch_gke_clusters_via_mcp(mcp_connector, project_id: str, location_filter: str = None) -> List[Dict]:
    """
    MCP ì„œë²„ë¥¼ í†µí•´ GCP GKE í´ëŸ¬ìŠ¤í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        mcp_connector: MCP GCP ì»¤ë„¥í„°
        project_id: GCP í”„ë¡œì íŠ¸ ID
        location_filter: ìœ„ì¹˜ í•„í„° (ì¡´ ë˜ëŠ” ì§€ì—­, ì„ íƒì‚¬í•­)
    
    Returns:
        GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    try:
        params = {
            'project_id': project_id,
            'location_filter': location_filter
        }
        
        response = mcp_connector.execute_gcp_query('gke', 'list_clusters', params)
        if response.success:
            return response.data.get('clusters', [])
        else:
            log_error(f"MCP GKE clusters query failed: {response.error}")
            return []
            
    except Exception as e:
        log_error(f"MCP GKE clusters fetch failed: {e}")
        return []


def fetch_gke_clusters_direct(project_id: str, location_filter: str = None) -> List[Dict]:
    """
    ì§ì ‘ APIë¥¼ í†µí•´ GCP GKE í´ëŸ¬ìŠ¤í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        project_id: GCP í”„ë¡œì íŠ¸ ID
        location_filter: ìœ„ì¹˜ í•„í„° (ì¡´ ë˜ëŠ” ì§€ì—­, ì„ íƒì‚¬í•­)
    
    Returns:
        GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    try:
        auth_manager = GCPAuthManager()
        credentials = auth_manager.get_credentials()
        if not credentials:
            log_error(f"GCP ì¸ì¦ ì‹¤íŒ¨: {project_id}")
            return []
        
        cluster_client = ClusterManagerClient(credentials=credentials)
        
        all_clusters = []
        
        # ëª¨ë“  ìœ„ì¹˜ì—ì„œ í´ëŸ¬ìŠ¤í„° ì¡°íšŒ (location_filterê°€ ì—†ëŠ” ê²½ìš°)
        if not location_filter:
            # í”„ë¡œì íŠ¸ì˜ ëª¨ë“  í´ëŸ¬ìŠ¤í„° ê°€ì ¸ì˜¤ê¸° (ëª¨ë“  ìœ„ì¹˜)
            parent = f"projects/{project_id}/locations/-"
        else:
            # íŠ¹ì • ìœ„ì¹˜ì˜ í´ëŸ¬ìŠ¤í„°ë§Œ ê°€ì ¸ì˜¤ê¸°
            parent = f"projects/{project_id}/locations/{location_filter}"
        
        try:
            request = ListClustersRequest(parent=parent)
            response = cluster_client.list_clusters(request=request)
            
            for cluster in response.clusters:
                cluster_data = collect_cluster_details(
                    cluster_client, project_id, cluster
                )
                if cluster_data:
                    all_clusters.append(cluster_data)
                    
        except gcp_exceptions.Forbidden:
            log_error(f"í”„ë¡œì íŠ¸ {project_id}ì— ëŒ€í•œ GKE ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
            return []
        except Exception as e:
            log_error(f"GKE í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì‹¤íŒ¨: {project_id}, Error={e}")
            return []
        
        log_info(f"í”„ë¡œì íŠ¸ {project_id}ì—ì„œ {len(all_clusters)}ê°œ GKE í´ëŸ¬ìŠ¤í„° ë°œê²¬")
        return all_clusters
        
    except gcp_exceptions.PermissionDenied:
        log_error(f"í”„ë¡œì íŠ¸ {project_id}ì— ëŒ€í•œ Container Engine ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
        return []
    except Exception as e:
        log_error(f"GKE í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì‹¤íŒ¨: {project_id}, Error={e}")
        return []


def fetch_gke_clusters(project_id: str, location_filter: str = None) -> List[Dict]:
    """
    GCP GKE í´ëŸ¬ìŠ¤í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (MCP ìš°ì„ , ì§ì ‘ API í´ë°±).
    
    Args:
        project_id: GCP í”„ë¡œì íŠ¸ ID
        location_filter: ìœ„ì¹˜ í•„í„° (ì¡´ ë˜ëŠ” ì§€ì—­, ì„ íƒì‚¬í•­)
    
    Returns:
        GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    # MCP ì„œë¹„ìŠ¤ ì‚¬ìš© ì‹œë„
    if MCP_AVAILABLE:
        try:
            mcp_service = MCPGCPService('gke')
            return mcp_service.execute_with_fallback(
                'list_clusters',
                {'project_id': project_id, 'location_filter': location_filter},
                lambda project_id, location_filter: fetch_gke_clusters_direct(project_id, location_filter)
            )
        except Exception as e:
            log_error(f"MCP service failed, using direct API: {e}")
    
    # ì§ì ‘ API ì‚¬ìš©
    return fetch_gke_clusters_direct(project_id, location_filter)


def collect_cluster_details(cluster_client: ClusterManagerClient, 
                          project_id: str, cluster) -> Optional[Dict]:
    """
    í´ëŸ¬ìŠ¤í„°ì˜ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        cluster_client: Container í´ëŸ¬ìŠ¤í„° í´ë¼ì´ì–¸íŠ¸
        project_id: GCP í”„ë¡œì íŠ¸ ID
        cluster: í´ëŸ¬ìŠ¤í„° ê°ì²´
    
    Returns:
        í´ëŸ¬ìŠ¤í„° ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° ì •ë³´
        cluster_data = {
            'project_id': project_id,
            'name': cluster.name,
            'location': cluster.location,
            'location_type': cluster.location_type.name if hasattr(cluster, 'location_type') else 'UNKNOWN',
            'status': cluster.status.name if hasattr(cluster, 'status') else 'UNKNOWN',
            'description': cluster.description or '',
            'initial_cluster_version': cluster.initial_cluster_version,
            'current_master_version': cluster.current_master_version,
            'current_node_version': cluster.current_node_version,
            'create_time': cluster.create_time,
            'endpoint': cluster.endpoint,
            'initial_node_count': cluster.initial_node_count,
            'current_node_count': cluster.current_node_count,
            'labels': get_gcp_resource_labels(cluster),
            'node_pools': [],
            'addons_config': {},
            'network_config': {},
            'master_auth': {},
            'logging_config': {},
            'monitoring_config': {},
            'maintenance_policy': {},
            'autopilot': {}
        }
        
        # ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ì •ë³´
        if hasattr(cluster, 'network_config') and cluster.network_config:
            network_config = cluster.network_config
            cluster_data['network_config'] = {
                'network': network_config.network if hasattr(network_config, 'network') else '',
                'subnetwork': network_config.subnetwork if hasattr(network_config, 'subnetwork') else '',
                'enable_intra_node_visibility': getattr(network_config, 'enable_intra_node_visibility', False),
                'default_snat_status': getattr(network_config, 'default_snat_status', {}),
                'enable_l4_ilb_subsetting': getattr(network_config, 'enable_l4_ilb_subsetting', False)
            }
        
        # ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ì •ë³´ (legacy)
        if hasattr(cluster, 'network') and cluster.network:
            cluster_data['network'] = cluster.network
        if hasattr(cluster, 'subnetwork') and cluster.subnetwork:
            cluster_data['subnetwork'] = cluster.subnetwork
        if hasattr(cluster, 'cluster_ipv4_cidr') and cluster.cluster_ipv4_cidr:
            cluster_data['cluster_ipv4_cidr'] = cluster.cluster_ipv4_cidr
        if hasattr(cluster, 'services_ipv4_cidr') and cluster.services_ipv4_cidr:
            cluster_data['services_ipv4_cidr'] = cluster.services_ipv4_cidr
        
        # ë…¸ë“œ í’€ ì •ë³´ ìˆ˜ì§‘
        if hasattr(cluster, 'node_pools') and cluster.node_pools:
            cluster_data['node_pools'] = get_node_pool_details(cluster.node_pools)
        
        # ì• ë“œì˜¨ êµ¬ì„± ì •ë³´
        if hasattr(cluster, 'addons_config') and cluster.addons_config:
            addons = cluster.addons_config
            cluster_data['addons_config'] = {
                'http_load_balancing': getattr(addons.http_load_balancing, 'disabled', True) if hasattr(addons, 'http_load_balancing') else True,
                'horizontal_pod_autoscaling': getattr(addons.horizontal_pod_autoscaling, 'disabled', True) if hasattr(addons, 'horizontal_pod_autoscaling') else True,
                'kubernetes_dashboard': getattr(addons.kubernetes_dashboard, 'disabled', True) if hasattr(addons, 'kubernetes_dashboard') else True,
                'network_policy_config': getattr(addons.network_policy_config, 'disabled', True) if hasattr(addons, 'network_policy_config') else True,
                'istio_config': getattr(addons.istio_config, 'disabled', True) if hasattr(addons, 'istio_config') else True,
                'cloud_run_config': getattr(addons.cloud_run_config, 'disabled', True) if hasattr(addons, 'cloud_run_config') else True
            }
        
        # ë§ˆìŠ¤í„° ì¸ì¦ ì •ë³´
        if hasattr(cluster, 'master_auth') and cluster.master_auth:
            master_auth = cluster.master_auth
            cluster_data['master_auth'] = {
                'username': getattr(master_auth, 'username', ''),
                'client_certificate_config': getattr(master_auth, 'client_certificate_config', {}),
                'cluster_ca_certificate': bool(getattr(master_auth, 'cluster_ca_certificate', ''))
            }
        
        # ë¡œê¹… êµ¬ì„±
        if hasattr(cluster, 'logging_config') and cluster.logging_config:
            logging_config = cluster.logging_config
            cluster_data['logging_config'] = {
                'component_config': getattr(logging_config, 'component_config', {})
            }
        elif hasattr(cluster, 'logging_service') and cluster.logging_service:
            cluster_data['logging_service'] = cluster.logging_service
        
        # ëª¨ë‹ˆí„°ë§ êµ¬ì„±
        if hasattr(cluster, 'monitoring_config') and cluster.monitoring_config:
            monitoring_config = cluster.monitoring_config
            cluster_data['monitoring_config'] = {
                'component_config': getattr(monitoring_config, 'component_config', {})
            }
        elif hasattr(cluster, 'monitoring_service') and cluster.monitoring_service:
            cluster_data['monitoring_service'] = cluster.monitoring_service
        
        # ìœ ì§€ë³´ìˆ˜ ì •ì±…
        if hasattr(cluster, 'maintenance_policy') and cluster.maintenance_policy:
            maintenance_policy = cluster.maintenance_policy
            cluster_data['maintenance_policy'] = {
                'window': getattr(maintenance_policy, 'window', {}),
                'resource_version': getattr(maintenance_policy, 'resource_version', '')
            }
        
        # Autopilot ì •ë³´
        if hasattr(cluster, 'autopilot') and cluster.autopilot:
            autopilot = cluster.autopilot
            cluster_data['autopilot'] = {
                'enabled': getattr(autopilot, 'enabled', False)
            }
        
        # ë³´ì•ˆ ê´€ë ¨ ì •ë³´
        if hasattr(cluster, 'master_authorized_networks_config'):
            cluster_data['master_authorized_networks_enabled'] = bool(cluster.master_authorized_networks_config)
        
        if hasattr(cluster, 'private_cluster_config'):
            cluster_data['private_cluster'] = bool(cluster.private_cluster_config)
        
        if hasattr(cluster, 'ip_allocation_policy'):
            cluster_data['ip_alias_enabled'] = bool(cluster.ip_allocation_policy)
        
        # í†µê³„ ì •ë³´ ì¶”ê°€
        cluster_data['node_pools_count'] = len(cluster_data['node_pools'])
        cluster_data['total_nodes'] = sum(pool.get('node_count', 0) for pool in cluster_data['node_pools'])
        
        return cluster_data
        
    except Exception as e:
        log_error(f"í´ëŸ¬ìŠ¤í„° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {cluster.name}, Error={e}")
        return None


def get_node_pool_details(node_pools) -> List[Dict]:
    """
    ë…¸ë“œ í’€ì˜ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Args:
        node_pools: ë…¸ë“œ í’€ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ë…¸ë“œ í’€ ìƒì„¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    node_pool_details = []
    
    try:
        for pool in node_pools:
            pool_info = {
                'name': pool.name,
                'status': pool.status.name if hasattr(pool, 'status') else 'UNKNOWN',
                'initial_node_count': pool.initial_node_count,
                'node_count': getattr(pool, 'node_count', pool.initial_node_count),
                'version': pool.version,
                'config': {},
                'autoscaling': {},
                'management': {},
                'max_pods_constraint': {},
                'conditions': [],
                'locations': []
            }
            
            # ë…¸ë“œ êµ¬ì„± ì •ë³´
            if hasattr(pool, 'config') and pool.config:
                config = pool.config
                pool_info['config'] = {
                    'machine_type': getattr(config, 'machine_type', ''),
                    'disk_size_gb': getattr(config, 'disk_size_gb', 0),
                    'disk_type': getattr(config, 'disk_type', ''),
                    'image_type': getattr(config, 'image_type', ''),
                    'labels': dict(getattr(config, 'labels', {})),
                    'tags': list(getattr(config, 'tags', [])),
                    'preemptible': getattr(config, 'preemptible', False),
                    'spot': getattr(config, 'spot', False),
                    'oauth_scopes': list(getattr(config, 'oauth_scopes', [])),
                    'service_account': getattr(config, 'service_account', ''),
                    'metadata': dict(getattr(config, 'metadata', {})),
                    'local_ssd_count': getattr(config, 'local_ssd_count', 0),
                    'boot_disk_kms_key': getattr(config, 'boot_disk_kms_key', ''),
                    'min_cpu_platform': getattr(config, 'min_cpu_platform', '')
                }
                
                # íƒ€ì¸íŠ¸ ì •ë³´
                if hasattr(config, 'taints') and config.taints:
                    pool_info['config']['taints'] = []
                    for taint in config.taints:
                        pool_info['config']['taints'].append({
                            'key': getattr(taint, 'key', ''),
                            'value': getattr(taint, 'value', ''),
                            'effect': getattr(taint, 'effect', '')
                        })
                
                # ìƒŒë“œë°•ìŠ¤ êµ¬ì„±
                if hasattr(config, 'sandbox_config') and config.sandbox_config:
                    pool_info['config']['sandbox_config'] = {
                        'type': getattr(config.sandbox_config, 'type', '')
                    }
                
                # ë…¸ë“œ ê·¸ë£¹ ì •ë³´
                if hasattr(config, 'node_group') and config.node_group:
                    pool_info['config']['node_group'] = getattr(config, 'node_group', '')
                
                # ë¦¬ì†ŒìŠ¤ ë¼ë²¨
                if hasattr(config, 'resource_labels') and config.resource_labels:
                    pool_info['config']['resource_labels'] = dict(config.resource_labels)
            
            # ìë™ ìŠ¤ì¼€ì¼ë§ ì •ë³´
            if hasattr(pool, 'autoscaling') and pool.autoscaling:
                autoscaling = pool.autoscaling
                pool_info['autoscaling'] = {
                    'enabled': getattr(autoscaling, 'enabled', False),
                    'min_node_count': getattr(autoscaling, 'min_node_count', 0),
                    'max_node_count': getattr(autoscaling, 'max_node_count', 0),
                    'total_min_node_count': getattr(autoscaling, 'total_min_node_count', 0),
                    'total_max_node_count': getattr(autoscaling, 'total_max_node_count', 0),
                    'location_policy': getattr(autoscaling, 'location_policy', '')
                }
            
            # ê´€ë¦¬ ì •ë³´
            if hasattr(pool, 'management') and pool.management:
                management = pool.management
                pool_info['management'] = {
                    'auto_upgrade': getattr(management, 'auto_upgrade', False),
                    'auto_repair': getattr(management, 'auto_repair', False),
                    'upgrade_options': getattr(management, 'upgrade_options', {})
                }
            
            # ìµœëŒ€ íŒŒë“œ ì œì•½
            if hasattr(pool, 'max_pods_constraint') and pool.max_pods_constraint:
                max_pods = pool.max_pods_constraint
                pool_info['max_pods_constraint'] = {
                    'max_pods_per_node': getattr(max_pods, 'max_pods_per_node', 0)
                }
            
            # ì¡°ê±´ ì •ë³´
            if hasattr(pool, 'conditions') and pool.conditions:
                for condition in pool.conditions:
                    pool_info['conditions'].append({
                        'code': getattr(condition, 'code', ''),
                        'message': getattr(condition, 'message', ''),
                        'canonical_code': getattr(condition, 'canonical_code', '')
                    })
            
            # ìœ„ì¹˜ ì •ë³´
            if hasattr(pool, 'locations') and pool.locations:
                pool_info['locations'] = list(pool.locations)
            
            node_pool_details.append(pool_info)
    
    except Exception as e:
        log_error(f"ë…¸ë“œ í’€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: Error={e}")
    
    return node_pool_details


def load_mock_data():
    """Mock ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    dir_path = os.path.dirname(os.path.realpath(__file__))
    mock_file = os.path.join(dir_path, 'mock_data.json')

    try:
        with open(mock_file, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        console.print(f"[bold red]ì—ëŸ¬: Mock ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mock_file}[/bold red]")
        return []
    except json.JSONDecodeError:
        console.print(f"[bold red]ì—ëŸ¬: Mock ë°ì´í„° íŒŒì¼ì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {mock_file}[/bold red]")
        return []


def format_table_output(clusters: List[Dict]) -> None:
    """
    GCP GKE í´ëŸ¬ìŠ¤í„° ëª©ë¡ì„ Rich í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        clusters: GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    if not clusters:
        console.print("[yellow]í‘œì‹œí•  GCP GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
        return

    # í”„ë¡œì íŠ¸, ìœ„ì¹˜, í´ëŸ¬ìŠ¤í„° ì´ë¦„ ìˆœìœ¼ë¡œ ì •ë ¬
    clusters.sort(key=lambda x: (x.get("project_id", ""), x.get("location", ""), x.get("name", "")))

    table = Table(box=box.HORIZONTALS, expand=False, show_header=True, header_style="bold")
    
    table.add_column("Project", style="bold magenta")
    table.add_column("Location", style="bold cyan")
    table.add_column("Cluster Name", style="bold white")
    table.add_column("Status", justify="center")
    table.add_column("Version", style="dim")
    table.add_column("Node Pools", justify="center", style="blue")
    table.add_column("Total Nodes", justify="center", style="green")
    table.add_column("Endpoint", style="cyan")
    table.add_column("Autopilot", justify="center", style="yellow")
    table.add_column("Labels", style="dim")

    last_project = None
    last_location = None
    
    for i, cluster in enumerate(clusters):
        project_changed = cluster.get("project_id") != last_project
        location_changed = cluster.get("location") != last_location

        # í”„ë¡œì íŠ¸ê°€ ë°”ë€” ë•Œ êµ¬ë¶„ì„  ì¶”ê°€
        if i > 0 and project_changed:
            table.add_row("", "", "", "", "", "", "", "", "", "", end_section=True)

        # ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒ ì ìš©
        status = cluster.get('status', 'UNKNOWN')
        if status == "RUNNING":
            status_colored = f"[green]{status}[/green]"
        elif status == "ERROR":
            status_colored = f"[red]{status}[/red]"
        elif status == "PROVISIONING":
            status_colored = f"[yellow]{status}[/yellow]"
        elif status == "STOPPING":
            status_colored = f"[orange1]{status}[/orange1]"
        else:
            status_colored = f"[dim]{status}[/dim]"
        
        # ë²„ì „ ì •ë³´
        master_version = cluster.get('current_master_version', 'N/A')
        if master_version != 'N/A':
            # ë²„ì „ì—ì„œ ì£¼ìš” ë¶€ë¶„ë§Œ í‘œì‹œ (ì˜ˆ: 1.27.3-gke.100 -> 1.27.3)
            version_parts = master_version.split('-')
            version_display = version_parts[0] if version_parts else master_version
        else:
            version_display = master_version
        
        # ë…¸ë“œ í’€ ë° ë…¸ë“œ ìˆ˜
        node_pools_count = cluster.get('node_pools_count', 0)
        total_nodes = cluster.get('total_nodes', 0)
        
        # ì—”ë“œí¬ì¸íŠ¸ (IPë§Œ í‘œì‹œ)
        endpoint = cluster.get('endpoint', 'N/A')
        if endpoint and endpoint != 'N/A':
            # HTTPS URLì—ì„œ IPë§Œ ì¶”ì¶œ
            if endpoint.startswith('https://'):
                endpoint = endpoint.replace('https://', '')
        
        # Autopilot ì—¬ë¶€
        autopilot_enabled = cluster.get('autopilot', {}).get('enabled', False)
        autopilot_display = "âœ“" if autopilot_enabled else "-"
        
        # ë¼ë²¨ ì •ë³´ (ìµœëŒ€ 2ê°œë§Œ í‘œì‹œ)
        labels = cluster.get('labels', {})
        if labels:
            label_items = list(labels.items())[:2]
            label_text = ", ".join([f"{k}={v}" for k, v in label_items])
            if len(labels) > 2:
                label_text += f" (+{len(labels)-2})"
        else:
            label_text = "-"
        
        display_values = [
            cluster.get("project_id", "") if project_changed else "",
            cluster.get("location", "") if project_changed or location_changed else "",
            cluster.get("name", "N/A"),
            status_colored,
            version_display,
            str(node_pools_count) if node_pools_count > 0 else "-",
            str(total_nodes) if total_nodes > 0 else "-",
            endpoint,
            autopilot_display,
            label_text
        ]
        
        table.add_row(*display_values)

        last_project = cluster.get("project_id")
        last_location = cluster.get("location")
    
    console.print(table)


def format_tree_output(clusters: List[Dict]) -> None:
    """
    GCP GKE í´ëŸ¬ìŠ¤í„° ëª©ë¡ì„ íŠ¸ë¦¬ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤ (í”„ë¡œì íŠ¸/ìœ„ì¹˜/í´ëŸ¬ìŠ¤í„° ê³„ì¸µ).
    
    Args:
        clusters: GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    if not clusters:
        console.print("[yellow]í‘œì‹œí•  GCP GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
        return

    # í”„ë¡œì íŠ¸ë³„ë¡œ ê·¸ë£¹í™”
    projects = {}
    for cluster in clusters:
        project_id = cluster.get("project_id", "unknown")
        location = cluster.get("location", "unknown")
        
        if project_id not in projects:
            projects[project_id] = {}
        if location not in projects[project_id]:
            projects[project_id][location] = []
        
        projects[project_id][location].append(cluster)

    # íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
    tree = Tree("ğŸš¢ [bold blue]GCP GKE Clusters[/bold blue]")
    
    for project_id in sorted(projects.keys()):
        project_node = tree.add(f"ğŸ“ [bold magenta]{project_id}[/bold magenta]")
        
        for location in sorted(projects[project_id].keys()):
            location_clusters = projects[project_id][location]
            location_node = project_node.add(
                f"ğŸŒ [bold cyan]{location}[/bold cyan] ({len(location_clusters)} clusters)"
            )
            
            for cluster in sorted(location_clusters, key=lambda x: x.get("name", "")):
                # ìƒíƒœ ì•„ì´ì½˜
                status = cluster.get('status', 'UNKNOWN')
                if status == "RUNNING":
                    status_icon = "ğŸŸ¢"
                elif status == "ERROR":
                    status_icon = "ğŸ”´"
                elif status == "PROVISIONING":
                    status_icon = "ğŸŸ¡"
                elif status == "STOPPING":
                    status_icon = "ğŸŸ "
                else:
                    status_icon = "âšª"
                
                # Autopilot ì•„ì´ì½˜
                autopilot_enabled = cluster.get('autopilot', {}).get('enabled', False)
                autopilot_icon = "ğŸ¤–" if autopilot_enabled else "âš™ï¸"
                
                # í´ëŸ¬ìŠ¤í„° ì •ë³´
                cluster_name = cluster.get("name", "N/A")
                master_version = cluster.get("current_master_version", "N/A")
                node_pools_count = cluster.get("node_pools_count", 0)
                total_nodes = cluster.get("total_nodes", 0)
                
                # ë²„ì „ ë‹¨ìˆœí™”
                if master_version != "N/A":
                    version_parts = master_version.split('-')
                    version_display = version_parts[0] if version_parts else master_version
                else:
                    version_display = master_version
                
                cluster_info = (
                    f"{status_icon} {autopilot_icon} [bold white]{cluster_name}[/bold white] "
                    f"(v{version_display}) - "
                    f"Pools: [blue]{node_pools_count}[/blue], "
                    f"Nodes: [green]{total_nodes}[/green]"
                )
                
                cluster_node = location_node.add(cluster_info)
                
                # ë„¤íŠ¸ì›Œí¬ ì •ë³´
                network = cluster.get('network', cluster.get('network_config', {}).get('network', ''))
                subnetwork = cluster.get('subnetwork', cluster.get('network_config', {}).get('subnetwork', ''))
                if network or subnetwork:
                    network_info = f"ğŸ”— Network: {network.split('/')[-1] if network else 'default'}"
                    if subnetwork:
                        network_info += f", Subnet: {subnetwork.split('/')[-1]}"
                    cluster_node.add(network_info)
                
                # ë…¸ë“œ í’€ ìƒì„¸ ì •ë³´
                if cluster.get('node_pools'):
                    pools_node = cluster_node.add(f"ğŸ”§ [bold blue]Node Pools ({len(cluster['node_pools'])})[/bold blue]")
                    for pool in cluster['node_pools'][:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                        pool_name = pool.get('name', 'N/A')
                        machine_type = pool.get('config', {}).get('machine_type', 'N/A')
                        node_count = pool.get('node_count', 0)
                        preemptible = pool.get('config', {}).get('preemptible', False)
                        spot = pool.get('config', {}).get('spot', False)
                        
                        pool_type = ""
                        if spot:
                            pool_type = " (Spot)"
                        elif preemptible:
                            pool_type = " (Preemptible)"
                        
                        pool_info = (
                            f"ğŸ’» {pool_name} - "
                            f"{machine_type}{pool_type} "
                            f"({node_count} nodes)"
                        )
                        pools_node.add(pool_info)
                        
                        # ìë™ ìŠ¤ì¼€ì¼ë§ ì •ë³´
                        autoscaling = pool.get('autoscaling', {})
                        if autoscaling.get('enabled'):
                            min_nodes = autoscaling.get('min_node_count', 0)
                            max_nodes = autoscaling.get('max_node_count', 0)
                            pools_node.add(f"ğŸ“ˆ Autoscaling: {min_nodes}-{max_nodes} nodes")
                    
                    if len(cluster['node_pools']) > 3:
                        pools_node.add(f"... and {len(cluster['node_pools']) - 3} more pools")
                
                # ì• ë“œì˜¨ ì •ë³´
                addons = cluster.get('addons_config', {})
                enabled_addons = []
                if not addons.get('http_load_balancing', True):
                    enabled_addons.append("HTTP LB")
                if not addons.get('horizontal_pod_autoscaling', True):
                    enabled_addons.append("HPA")
                if not addons.get('network_policy_config', True):
                    enabled_addons.append("Network Policy")
                if not addons.get('istio_config', True):
                    enabled_addons.append("Istio")
                if not addons.get('cloud_run_config', True):
                    enabled_addons.append("Cloud Run")
                
                if enabled_addons:
                    cluster_node.add(f"ğŸ”Œ Addons: {', '.join(enabled_addons)}")
                
                # ë¼ë²¨ ì •ë³´
                if cluster.get('labels'):
                    labels_text = ", ".join([f"{k}={v}" for k, v in cluster['labels'].items()])
                    cluster_node.add(f"ğŸ·ï¸  Labels: {labels_text}")

    console.print(tree)


def format_output(clusters: List[Dict], output_format: str = 'table') -> str:
    """
    GKE í´ëŸ¬ìŠ¤í„° ë°ì´í„°ë¥¼ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ í¬ë§·í•©ë‹ˆë‹¤.
    
    Args:
        clusters: GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
        output_format: ì¶œë ¥ í˜•ì‹ ('table', 'tree', 'json', 'yaml')
    
    Returns:
        í¬ë§·ëœ ì¶œë ¥ ë¬¸ìì—´ (table/treeì˜ ê²½ìš° ì§ì ‘ ì¶œë ¥í•˜ê³  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜)
    """
    if output_format == 'table':
        format_table_output(clusters)
        return ""
    elif output_format == 'tree':
        format_tree_output(clusters)
        return ""
    elif output_format == 'json':
        return format_gcp_output(clusters, 'json')
    elif output_format == 'yaml':
        return format_gcp_output(clusters, 'yaml')
    else:
        # ê¸°ë³¸ê°’ì€ í…Œì´ë¸”
        format_table_output(clusters)
        return ""


def print_cluster_table(clusters):
    """GCP GKE í´ëŸ¬ìŠ¤í„° ëª©ë¡ì„ ê³„ì¸µì  í…Œì´ë¸”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼)"""
    format_table_output(clusters)


def main(args):
    """
    ë©”ì¸ í•¨ìˆ˜ - GCP GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ ì¡°íšŒí•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        args: CLI ì¸ì ê°ì²´
    """
    try:
        log_info("GCP GKE í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì‹œì‘")
        
        # GCP ì¸ì¦ ë° í”„ë¡œì íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”
        auth_manager = GCPAuthManager()
        if not auth_manager.validate_credentials():
            console.print("[bold red]GCP ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¸ì¦ ì •ë³´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.[/bold red]")
            return
        
        project_manager = GCPProjectManager(auth_manager)
        resource_collector = GCPResourceCollector(auth_manager)
        
        # í”„ë¡œì íŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        if args.project:
            # íŠ¹ì • í”„ë¡œì íŠ¸ ì§€ì •ëœ ê²½ìš°
            projects = [args.project]
        else:
            # ëª¨ë“  ì ‘ê·¼ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ ì‚¬ìš©
            projects = project_manager.get_projects()
        
        if not projects:
            console.print("[yellow]ì ‘ê·¼ ê°€ëŠ¥í•œ GCP í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
            return
        
        log_info(f"ì¡°íšŒí•  í”„ë¡œì íŠ¸: {len(projects)}ê°œ")
        
        # ë³‘ë ¬ë¡œ GKE í´ëŸ¬ìŠ¤í„° ìˆ˜ì§‘
        all_clusters = resource_collector.parallel_collect(
            projects, 
            fetch_gke_clusters,
            args.location if hasattr(args, 'location') else None
        )
        
        if not all_clusters:
            console.print("[yellow]ì¡°íšŒëœ GKE í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
            return
        
        # í•„í„° ì ìš©
        filters = {}
        if hasattr(args, 'cluster') and args.cluster:
            filters['name'] = args.cluster
        if hasattr(args, 'project') and args.project:
            filters['project'] = args.project
        if hasattr(args, 'location') and args.location:
            filters['zone'] = args.location  # locationì„ zone í•„í„°ë¡œ ì‚¬ìš©
        
        filtered_clusters = resource_collector.apply_filters(all_clusters, filters)
        
        # ì¶œë ¥ í˜•ì‹ ê²°ì •
        output_format = getattr(args, 'output', 'table')
        
        # ê²°ê³¼ ì¶œë ¥
        if output_format in ['json', 'yaml']:
            output_text = format_output(filtered_clusters, output_format)
            console.print(output_text)
        else:
            format_output(filtered_clusters, output_format)
        
        log_info(f"ì´ {len(filtered_clusters)}ê°œ GKE í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì™„ë£Œ")
        
    except KeyboardInterrupt:
        console.print("\n[yellow]ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.[/yellow]")
    except Exception as e:
        log_exception(e)
        console.print(f"[bold red]ì˜¤ë¥˜ ë°œìƒ: {e}[/bold red]")


def add_arguments(parser):
    """
    CLI ì¸ìë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        parser: argparse.ArgumentParser ê°ì²´
    """
    parser.add_argument(
        '-p', '--project', 
        help='GCP í”„ë¡œì íŠ¸ IDë¡œ í•„í„°ë§ (ì˜ˆ: my-project-123)'
    )
    parser.add_argument(
        '-c', '--cluster', 
        help='í´ëŸ¬ìŠ¤í„° ì´ë¦„ìœ¼ë¡œ í•„í„°ë§ (ë¶€ë¶„ ì¼ì¹˜)'
    )
    parser.add_argument(
        '-l', '--location', 
        help='ìœ„ì¹˜ë¡œ í•„í„°ë§ (ì¡´ ë˜ëŠ” ì§€ì—­, ì˜ˆ: us-central1-a ë˜ëŠ” us-central1)'
    )
    parser.add_argument(
        '-o', '--output', 
        choices=['table', 'tree', 'json', 'yaml'],
        default='table',
        help='ì¶œë ¥ í˜•ì‹ ì„ íƒ (ê¸°ë³¸ê°’: table)'
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="GCP GKE í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¡°íšŒ")
    add_arguments(parser)
    args = parser.parse_args()
    main(args)