#!/usr/bin/env python3
import os
import sys
import argparse
import json
from concurrent.futures import ThreadPoolExecutor, as_completed

from azure.mgmt.containerservice import ContainerServiceClient
from dotenv import load_dotenv
from rich.console import Console
from rich.table import Table
from rich import box
from rich.tree import Tree

try:
    from ....common.log import log_info, log_error
except ImportError:
    from common.log import log_info, log_error
try:
    from ....common.azure_utils import (
        get_azure_subscriptions,
    create_azure_client,
    get_resource_groups,
    format_azure_output,
    get_azure_resource_tags,
    parallel_azure_operation
    )
except ImportError:
    from common.azure_utils import (
        get_azure_subscriptions,
    create_azure_client,
    get_resource_groups,
    format_azure_output,
    get_azure_resource_tags,
    parallel_azure_operation
    )

load_dotenv()
console = Console()

def fetch_aks_info(subscription_id, location_filter=None, resource_group_filter=None, cluster_name_filter=None):
    """Azure AKS í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    log_info(f"Azure AKS ì •ë³´ ìˆ˜ì§‘ ì‹œì‘: Subscription={subscription_id}")
    
    aks_client = create_azure_client(ContainerServiceClient, subscription_id)
    if not aks_client:
        return []
    
    try:
        aks_info_list = []
        
        # ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ë³„ë¡œ AKS í´ëŸ¬ìŠ¤í„° ì¡°íšŒ
        resource_groups = get_resource_groups(subscription_id)
        
        for rg in resource_groups:
            rg_name = rg['name']
            
            # ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ í•„í„° ì ìš©
            if resource_group_filter and resource_group_filter.lower() not in rg_name.lower():
                continue
            
            try:
                # AKS í´ëŸ¬ìŠ¤í„° ëª©ë¡ ì¡°íšŒ
                clusters = aks_client.managed_clusters.list_by_resource_group(resource_group_name=rg_name)
                
                for cluster in clusters:
                    # í´ëŸ¬ìŠ¤í„° ì´ë¦„ í•„í„° ì ìš©
                    if cluster_name_filter and cluster_name_filter.lower() not in cluster.name.lower():
                        continue
                    
                    # ìœ„ì¹˜ í•„í„° ì ìš©
                    if location_filter and location_filter.lower() not in cluster.location.lower():
                        continue
                    
                    # AKS í´ëŸ¬ìŠ¤í„° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                    cluster_detail = collect_aks_details(aks_client, rg_name, cluster, subscription_id)
                    if cluster_detail:
                        aks_info_list.append(cluster_detail)
                        
            except Exception as e:
                log_error(f"ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ {rg_name}ì˜ AKS í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
                continue
        
        return aks_info_list
        
    except Exception as e:
        log_error(f"Azure AKS ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: Subscription={subscription_id}, Error={e}")
        return []

def collect_aks_details(aks_client, resource_group_name, cluster, subscription_id):
    """AKS í´ëŸ¬ìŠ¤í„°ì˜ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    try:
        # ë…¸ë“œ í’€ ì •ë³´
        node_pools_info = []
        if cluster.agent_pool_profiles:
            for pool in cluster.agent_pool_profiles:
                pool_detail = {
                    'name': pool.name,
                    'count': pool.count,
                    'vm_size': pool.vm_size,
                    'os_type': str(pool.os_type) if pool.os_type else 'Linux',
                    'os_disk_size_gb': pool.os_disk_size_gb,
                    'max_pods': pool.max_pods,
                    'provisioning_state': str(pool.provisioning_state) if pool.provisioning_state else 'Unknown',
                    'availability_zones': list(pool.availability_zones) if pool.availability_zones else [],
                    'enable_auto_scaling': pool.enable_auto_scaling if hasattr(pool, 'enable_auto_scaling') else False,
                    'min_count': pool.min_count if hasattr(pool, 'min_count') else None,
                    'max_count': pool.max_count if hasattr(pool, 'max_count') else None,
                    'node_taints': list(pool.node_taints) if hasattr(pool, 'node_taints') and pool.node_taints else [],
                    'node_labels': dict(pool.node_labels) if hasattr(pool, 'node_labels') and pool.node_labels else {}
                }
                
                # ìŠ¤ì¼€ì¼ë§ ëª¨ë“œ
                if hasattr(pool, 'mode'):
                    pool_detail['mode'] = str(pool.mode)
                
                node_pools_info.append(pool_detail)
        
        # ë„¤íŠ¸ì›Œí¬ í”„ë¡œí•„
        network_profile = {}
        if cluster.network_profile:
            network_profile = {
                'network_plugin': str(cluster.network_profile.network_plugin) if cluster.network_profile.network_plugin else 'kubenet',
                'network_policy': str(cluster.network_profile.network_policy) if cluster.network_profile.network_policy else None,
                'pod_cidr': cluster.network_profile.pod_cidr,
                'service_cidr': cluster.network_profile.service_cidr,
                'dns_service_ip': cluster.network_profile.dns_service_ip,
                'docker_bridge_cidr': cluster.network_profile.docker_bridge_cidr,
                'load_balancer_sku': str(cluster.network_profile.load_balancer_sku) if cluster.network_profile.load_balancer_sku else 'Standard'
            }
        
        # ì• ë“œì˜¨ í”„ë¡œí•„
        addon_profiles = {}
        if cluster.addon_profiles:
            for addon_name, addon_config in cluster.addon_profiles.items():
                addon_profiles[addon_name] = {
                    'enabled': addon_config.enabled,
                    'config': dict(addon_config.config) if addon_config.config else {}
                }
        
        # ì„œë¹„ìŠ¤ ì£¼ì²´ ë˜ëŠ” ê´€ë¦¬ ID
        identity_info = {}
        if cluster.service_principal_profile:
            identity_info['type'] = 'ServicePrincipal'
            identity_info['client_id'] = cluster.service_principal_profile.client_id
        elif cluster.identity:
            identity_info['type'] = str(cluster.identity.type)
            if cluster.identity.user_assigned_identities:
                identity_info['user_assigned_identities'] = list(cluster.identity.user_assigned_identities.keys())
        
        # API ì„œë²„ ì ‘ê·¼ í”„ë¡œí•„
        api_server_profile = {}
        if hasattr(cluster, 'api_server_access_profile') and cluster.api_server_access_profile:
            api_server_profile = {
                'enable_private_cluster': cluster.api_server_access_profile.enable_private_cluster,
                'authorized_ip_ranges': list(cluster.api_server_access_profile.authorized_ip_ranges) if cluster.api_server_access_profile.authorized_ip_ranges else []
            }
        
        # AKS í´ëŸ¬ìŠ¤í„° ì •ë³´ êµ¬ì„±
        aks_data = {
            'subscription_id': subscription_id,
            'resource_group': resource_group_name,
            'cluster': {
                'name': cluster.name,
                'id': cluster.id,
                'location': cluster.location,
                'provisioning_state': str(cluster.provisioning_state),
                'kubernetes_version': cluster.kubernetes_version,
                'dns_prefix': cluster.dns_prefix,
                'fqdn': cluster.fqdn,
                'private_fqdn': cluster.private_fqdn if hasattr(cluster, 'private_fqdn') else None,
                'enable_rbac': cluster.enable_rbac if hasattr(cluster, 'enable_rbac') else True,
                'tags': get_azure_resource_tags(cluster),
                'node_pools': node_pools_info,
                'network_profile': network_profile,
                'addon_profiles': addon_profiles,
                'identity': identity_info,
                'api_server_access_profile': api_server_profile,
                'node_pool_count': len(node_pools_info),
                'total_node_count': sum(pool.get('count', 0) for pool in node_pools_info)
            }
        }
        
        # ìë™ ìŠ¤ì¼€ì¼ëŸ¬ í”„ë¡œí•„
        if hasattr(cluster, 'auto_scaler_profile') and cluster.auto_scaler_profile:
            aks_data['cluster']['auto_scaler_profile'] = {
                'balance_similar_node_groups': cluster.auto_scaler_profile.balance_similar_node_groups,
                'expander': str(cluster.auto_scaler_profile.expander) if cluster.auto_scaler_profile.expander else None,
                'max_empty_bulk_delete': cluster.auto_scaler_profile.max_empty_bulk_delete,
                'max_graceful_termination_sec': cluster.auto_scaler_profile.max_graceful_termination_sec,
                'max_node_provision_time': cluster.auto_scaler_profile.max_node_provision_time,
                'max_total_unready_percentage': cluster.auto_scaler_profile.max_total_unready_percentage,
                'new_pod_scale_up_delay': cluster.auto_scaler_profile.new_pod_scale_up_delay,
                'ok_total_unready_count': cluster.auto_scaler_profile.ok_total_unready_count,
                'scale_down_delay_after_add': cluster.auto_scaler_profile.scale_down_delay_after_add,
                'scale_down_delay_after_delete': cluster.auto_scaler_profile.scale_down_delay_after_delete,
                'scale_down_delay_after_failure': cluster.auto_scaler_profile.scale_down_delay_after_failure,
                'scale_down_unneeded_time': cluster.auto_scaler_profile.scale_down_unneeded_time,
                'scale_down_unready_time': cluster.auto_scaler_profile.scale_down_unready_time,
                'scale_down_utilization_threshold': cluster.auto_scaler_profile.scale_down_utilization_threshold,
                'scan_interval': cluster.auto_scaler_profile.scan_interval,
                'skip_nodes_with_local_storage': cluster.auto_scaler_profile.skip_nodes_with_local_storage,
                'skip_nodes_with_system_pods': cluster.auto_scaler_profile.skip_nodes_with_system_pods
            }
        
        return aks_data
        
    except Exception as e:
        log_error(f"AKS í´ëŸ¬ìŠ¤í„° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {cluster.name}, Error={e}")
        return None

def format_output(aks_info_list, output_format):
    """ì¶œë ¥ í˜•ì‹ì— ë”°ë¼ ë°ì´í„°ë¥¼ í¬ë§·í•©ë‹ˆë‹¤."""
    if output_format == 'json':
        return format_azure_output(aks_info_list, 'json')
    elif output_format == 'yaml':
        return format_azure_output(aks_info_list, 'yaml')
    elif output_format == 'tree':
        return format_tree_output(aks_info_list)
    else:
        return format_table_output(aks_info_list)

def format_tree_output(aks_info_list):
    """íŠ¸ë¦¬ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not aks_info_list:
        console.print("[yellow]í‘œì‹œí•  Azure AKS í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
        return
    
    # êµ¬ë…ë³„ë¡œ ê·¸ë£¹í™”
    subscriptions = {}
    for aks_info in aks_info_list:
        subscription_id = aks_info['subscription_id']
        if subscription_id not in subscriptions:
            subscriptions[subscription_id] = {}
        
        resource_group = aks_info['resource_group']
        if resource_group not in subscriptions[subscription_id]:
            subscriptions[subscription_id][resource_group] = []
        
        subscriptions[subscription_id][resource_group].append(aks_info)
    
    tree = Tree("â˜¸ï¸ [bold blue]Azure Kubernetes Service (AKS)[/bold blue]")
    
    for subscription_id, resource_groups in subscriptions.items():
        sub_tree = tree.add(f"ğŸ“‹ Subscription: {subscription_id}")
        
        for rg_name, clusters in resource_groups.items():
            rg_tree = sub_tree.add(f"ğŸ“ Resource Group: [magenta]{rg_name}[/magenta]")
            
            for aks_info in clusters:
                cluster = aks_info['cluster']
                cluster_tree = rg_tree.add(f"â˜¸ï¸ [cyan]{cluster['name']}[/cyan] (v{cluster['kubernetes_version']})")
                
                # ê¸°ë³¸ ì •ë³´
                cluster_tree.add(f"ğŸ“ Location: [green]{cluster['location']}[/green]")
                cluster_tree.add(f"ğŸ“Š State: {format_provisioning_state_simple(cluster['provisioning_state'])}")
                cluster_tree.add(f"ğŸŒ FQDN: {cluster['fqdn']}")
                cluster_tree.add(f"ğŸ” RBAC: {'âœ…' if cluster['enable_rbac'] else 'âŒ'}")
                
                # ë…¸ë“œ í’€
                if cluster['node_pools']:
                    pool_tree = cluster_tree.add(f"ğŸ–¥ï¸ Node Pools ({len(cluster['node_pools'])})")
                    for pool in cluster['node_pools']:
                        pool_node = pool_tree.add(f"ğŸ”§ {pool['name']} ({pool['vm_size']})")
                        pool_node.add(f"ğŸ“Š Nodes: {pool['count']}")
                        pool_node.add(f"ğŸ§ OS: {pool['os_type']}")
                        if pool['enable_auto_scaling']:
                            pool_node.add(f"ğŸ“ˆ Auto Scaling: {pool['min_count']}-{pool['max_count']}")
                        if pool['availability_zones']:
                            pool_node.add(f"ğŸŒ Zones: {', '.join(pool['availability_zones'])}")
                
                # ë„¤íŠ¸ì›Œí¬
                if cluster['network_profile']:
                    net_tree = cluster_tree.add("ğŸŒ Network")
                    net_tree.add(f"ğŸ”Œ Plugin: {cluster['network_profile']['network_plugin']}")
                    if cluster['network_profile']['network_policy']:
                        net_tree.add(f"ğŸ›¡ï¸ Policy: {cluster['network_profile']['network_policy']}")
                    if cluster['network_profile']['service_cidr']:
                        net_tree.add(f"ğŸ  Service CIDR: {cluster['network_profile']['service_cidr']}")
                
                # ì• ë“œì˜¨
                if cluster['addon_profiles']:
                    addon_tree = cluster_tree.add("ğŸ”§ Add-ons")
                    for addon_name, addon_config in cluster['addon_profiles'].items():
                        status = "âœ…" if addon_config['enabled'] else "âŒ"
                        addon_tree.add(f"{status} {addon_name}")
    
    console.print(tree)

def format_table_output(aks_info_list):
    """í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not aks_info_list:
        console.print("[yellow]í‘œì‹œí•  Azure AKS í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
        return
    
    # êµ¬ë…ë³„ë¡œ ê·¸ë£¹í™”
    subscriptions = {}
    for aks_info in aks_info_list:
        subscription_id = aks_info['subscription_id']
        if subscription_id not in subscriptions:
            subscriptions[subscription_id] = []
        subscriptions[subscription_id].append(aks_info)
    
    for subscription_id, subscription_clusters in subscriptions.items():
        console.print(f"\n[bold blue]ğŸ”¹ Subscription: {subscription_id}[/bold blue]")
        
        # AKS í´ëŸ¬ìŠ¤í„° ìš”ì•½ í…Œì´ë¸”
        console.print(f"\n[bold]â˜¸ï¸ AKS Clusters ({len(subscription_clusters)} clusters)[/bold]")
        summary_table = Table(box=box.HORIZONTALS, show_header=True, header_style="bold")
        summary_table.add_column("Cluster Name", style="cyan")
        summary_table.add_column("Resource Group", style="magenta")
        summary_table.add_column("Location", style="green")
        summary_table.add_column("K8s Version", style="yellow")
        summary_table.add_column("Node Pools", justify="center")
        summary_table.add_column("Total Nodes", justify="center")
        summary_table.add_column("State", justify="center")
        summary_table.add_column("RBAC", justify="center")
        
        for aks_info in subscription_clusters:
            cluster = aks_info['cluster']
            
            summary_table.add_row(
                cluster.get('name', '-'),
                aks_info.get('resource_group', '-'),
                cluster.get('location', '-'),
                cluster.get('kubernetes_version', '-'),
                str(cluster.get('node_pool_count', 0)),
                str(cluster.get('total_node_count', 0)),
                format_provisioning_state(cluster.get('provisioning_state', 'Unknown')),
                'âœ…' if cluster.get('enable_rbac', False) else 'âŒ'
            )
        
        console.print(summary_table)
        
        # ë…¸ë“œ í’€ ìƒì„¸ ì •ë³´
        for aks_info in subscription_clusters:
            cluster = aks_info['cluster']
            if cluster.get('node_pools'):
                console.print(f"\n[bold]ğŸ–¥ï¸ Node Pools for {cluster['name']}[/bold]")
                pool_table = Table(box=box.HORIZONTALS, show_header=True, header_style="bold")
                pool_table.add_column("Pool Name", style="cyan")
                pool_table.add_column("VM Size", style="yellow")
                pool_table.add_column("OS Type", style="green")
                pool_table.add_column("Node Count", justify="center")
                pool_table.add_column("Auto Scaling", justify="center")
                pool_table.add_column("Max Pods", justify="center")
                pool_table.add_column("Zones", style="blue")
                pool_table.add_column("State", justify="center")
                
                for pool in cluster['node_pools']:
                    auto_scaling = "âŒ"
                    if pool.get('enable_auto_scaling'):
                        auto_scaling = f"âœ… ({pool.get('min_count', 0)}-{pool.get('max_count', 0)})"
                    
                    zones = ', '.join(pool.get('availability_zones', [])) if pool.get('availability_zones') else '-'
                    
                    pool_table.add_row(
                        pool.get('name', '-'),
                        pool.get('vm_size', '-'),
                        pool.get('os_type', '-'),
                        str(pool.get('count', 0)),
                        auto_scaling,
                        str(pool.get('max_pods', '-')),
                        zones,
                        format_provisioning_state(pool.get('provisioning_state', 'Unknown'))
                    )
                
                console.print(pool_table)
        
        # ìœ„ì¹˜ë³„ í†µê³„
        location_stats = {}
        for aks_info in subscription_clusters:
            location = aks_info['cluster'].get('location', 'Unknown')
            if location not in location_stats:
                location_stats[location] = {'clusters': 0, 'total_nodes': 0, 'node_pools': 0}
            location_stats[location]['clusters'] += 1
            location_stats[location]['total_nodes'] += aks_info['cluster'].get('total_node_count', 0)
            location_stats[location]['node_pools'] += aks_info['cluster'].get('node_pool_count', 0)
        
        if len(location_stats) > 1:
            console.print(f"\n[bold]ğŸ“Š Location Statistics[/bold]")
            stats_table = Table(box=box.HORIZONTALS, show_header=True, header_style="bold")
            stats_table.add_column("Location", style="green")
            stats_table.add_column("Clusters", justify="center")
            stats_table.add_column("Total Nodes", justify="center")
            stats_table.add_column("Node Pools", justify="center")
            
            for location, stats in sorted(location_stats.items()):
                stats_table.add_row(
                    location,
                    str(stats['clusters']),
                    str(stats['total_nodes']),
                    str(stats['node_pools'])
                )
            
            console.print(stats_table)

def format_provisioning_state(state):
    """í”„ë¡œë¹„ì €ë‹ ìƒíƒœì— ë”°ë¼ ìƒ‰ìƒì„ ì ìš©í•©ë‹ˆë‹¤."""
    state_lower = state.lower()
    if 'succeeded' in state_lower:
        return f"[bold green]{state}[/bold green]"
    elif 'failed' in state_lower:
        return f"[bold red]{state}[/bold red]"
    elif 'updating' in state_lower or 'creating' in state_lower:
        return f"[bold yellow]{state}[/bold yellow]"
    else:
        return state

def format_provisioning_state_simple(state):
    """íŠ¸ë¦¬ìš© ê°„ë‹¨í•œ ìƒíƒœ í¬ë§·"""
    state_lower = state.lower()
    if 'succeeded' in state_lower:
        return f"[green]{state}[/green]"
    elif 'failed' in state_lower:
        return f"[red]{state}[/red]"
    else:
        return state

def main(args):
    """ë©”ì¸ í•¨ìˆ˜"""
    subscriptions = args.subscription.split(",") if args.subscription else get_azure_subscriptions()
    
    if not subscriptions:
        log_error("Azure êµ¬ë…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. AZURE_SUBSCRIPTIONS í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ Azure CLIë¡œ ë¡œê·¸ì¸í•˜ì„¸ìš”.")
        return
    
    all_aks_info = parallel_azure_operation(
        fetch_aks_info,
        subscriptions,
        args.location,
        args.resource_group,
        args.name
    )
    
    # ì¶œë ¥ í˜•ì‹ì— ë”°ë¼ ê²°ê³¼ ì¶œë ¥
    if args.output in ['json', 'yaml']:
        output = format_output(all_aks_info, args.output)
        print(output)
    elif args.output == 'tree':
        format_tree_output(all_aks_info)
    else:
        format_table_output(all_aks_info)

def add_arguments(parser):
    """ëª…ë ¹í–‰ ì¸ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    parser.add_argument('-s', '--subscription', help='íŠ¹ì • Azure êµ¬ë… ID ëª©ë¡(,) (ì—†ìœ¼ë©´ ëª¨ë“  êµ¬ë… ì‚¬ìš©)')
    parser.add_argument('-l', '--location', help='ìœ„ì¹˜ í•„í„° (ë¶€ë¶„ ì¼ì¹˜)')
    parser.add_argument('-g', '--resource-group', help='ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ í•„í„° (ë¶€ë¶„ ì¼ì¹˜)')
    parser.add_argument('-n', '--name', help='AKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ í•„í„° (ë¶€ë¶„ ì¼ì¹˜)')
    parser.add_argument('--output', choices=['table', 'json', 'yaml', 'tree'], default='table',
                       help='ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸ê°’: table)')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”')

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Azure AKS ì •ë³´ ì¡°íšŒ")
    add_arguments(parser)
    args = parser.parse_args()
    main(args)