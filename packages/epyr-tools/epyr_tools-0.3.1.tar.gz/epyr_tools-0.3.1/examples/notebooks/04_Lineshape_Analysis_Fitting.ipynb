{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 04: Lineshape Analysis and Fitting\n",
    "## Master EPR Spectral Analysis with EPyR Tools\n",
    "\n",
    "Welcome to the fourth EPyR Tools tutorial! EPR lineshape analysis is fundamental for extracting quantitative information about paramagnetic systems. This notebook explores the comprehensive `lineshapes` module for spectral fitting and analysis.\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand EPR lineshape theory (Gaussian, Lorentzian, Voigtian)\n",
    "- Apply single and multi-component spectral fitting\n",
    "- Extract quantitative parameters (g-values, linewidths, intensities)\n",
    "- Evaluate fitting quality and parameter uncertainties\n",
    "- Handle complex multi-site EPR spectra\n",
    "- Create publication-quality fitted spectrum plots\n",
    "\n",
    "### üìê EPR Lineshape Theory\n",
    "\n",
    "EPR lineshapes arise from different broadening mechanisms:\n",
    "- **Gaussian**: Inhomogeneous broadening (strain, unresolved hyperfine)\n",
    "- **Lorentzian**: Homogeneous broadening (lifetime, relaxation)\n",
    "- **Voigtian**: Convolution of Gaussian + Lorentzian (realistic case)\n",
    "- **Pseudo-Voigt**: Linear combination approximation to Voigtian\n",
    "\n",
    "Let's explore these with real EPR data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Lineshape Module Exploration\n",
    "\n",
    "First, let's explore the comprehensive lineshape capabilities in EPyR Tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import epyr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "print(f\"EPyR Tools Version: {epyr.__version__}\")\n",
    "print(f\"Lineshapes module: {hasattr(epyr, 'lineshapes')}\")\n",
    "\n",
    "# Explore lineshape functions\n",
    "if hasattr(epyr, 'lineshapes'):\n",
    "    print(\"\\nAvailable lineshape functions:\")\n",
    "    lineshape_funcs = [func for func in dir(epyr.lineshapes) if not func.startswith('_')]\n",
    "    for func in lineshape_funcs:\n",
    "        print(f\"  - {func}\")\n",
    "    \n",
    "    # Import key lineshape functions\n",
    "    from epyr.lineshapes import (\n",
    "        gaussian, lorentzian, voigtian, pseudo_voigt,\n",
    "        Lineshape, fit_epr_signal\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Lineshape functions imported successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Lineshapes module not available\")\n",
    "\n",
    "# Set up data path\n",
    "data_path = Path('../data')\n",
    "print(f\"\\nData directory exists: {data_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Exploring Individual Lineshape Functions\n",
    "\n",
    "Let's start by understanding the mathematical properties of different EPR lineshapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create field axis for lineshape demonstration\n",
    "field = np.linspace(3300, 3400, 1000)\n",
    "center = 3350  # G\n",
    "width = 10     # G\n",
    "\n",
    "print(\"üìê EPR Lineshape Function Comparison\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Generate different lineshapes\n",
    "shapes = {\n",
    "    'Gaussian': gaussian(field, center, width),\n",
    "    'Lorentzian': lorentzian(field, center, width),\n",
    "    'Voigtian (œÉ=5, Œ≥=5)': voigtian(field, center, sigma=5, gamma=5),\n",
    "    'Pseudo-Voigt (Œ∑=0.5)': pseudo_voigt(field, center, width, eta=0.5)\n",
    "}\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "\n",
    "# Linear scale comparison\n",
    "for i, (name, shape) in enumerate(shapes.items()):\n",
    "    ax1.plot(field, shape, color=colors[i], linewidth=2.5, label=name)\n",
    "\n",
    "ax1.set_xlabel('Magnetic Field (G)')\n",
    "ax1.set_ylabel('Normalized Intensity')\n",
    "ax1.set_title('EPR Lineshapes - Linear Scale')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Log scale to show wings\n",
    "for i, (name, shape) in enumerate(shapes.items()):\n",
    "    ax2.semilogy(field, shape + 1e-6, color=colors[i], linewidth=2.5, label=name)\n",
    "\n",
    "ax2.set_xlabel('Magnetic Field (G)')\n",
    "ax2.set_ylabel('Normalized Intensity (log)')\n",
    "ax2.set_title('EPR Lineshapes - Log Scale (Wings)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze lineshape properties\n",
    "print(f\"\\nüìä Lineshape Properties Analysis:\")\n",
    "print(f\"{'Shape':<20} {'FWHM (G)':<12} {'Peak Height':<15} {'Wing Behavior':<20}\")\n",
    "print(f\"{'-'*20} {'-'*12} {'-'*15} {'-'*20}\")\n",
    "\n",
    "for name, shape in shapes.items():\n",
    "    # Find FWHM\n",
    "    peak_idx = np.argmax(shape)\n",
    "    half_max = shape[peak_idx] / 2\n",
    "    \n",
    "    # Find half-maximum points\n",
    "    left_idx = np.where(shape[:peak_idx] <= half_max)[0]\n",
    "    right_idx = np.where(shape[peak_idx:] <= half_max)[0]\n",
    "    \n",
    "    if len(left_idx) > 0 and len(right_idx) > 0:\n",
    "        fwhm = field[peak_idx + right_idx[0]] - field[left_idx[-1]]\n",
    "    else:\n",
    "        fwhm = np.nan\n",
    "    \n",
    "    peak_height = shape[peak_idx]\n",
    "    \n",
    "    # Wing behavior (ratio at ¬±2*FWHM from center)\n",
    "    wing_field = 2 * width\n",
    "    center_idx = np.argmin(np.abs(field - center))\n",
    "    wing_left_idx = np.argmin(np.abs(field - (center - wing_field)))\n",
    "    wing_right_idx = np.argmin(np.abs(field - (center + wing_field)))\n",
    "    \n",
    "    wing_ratio = (shape[wing_left_idx] + shape[wing_right_idx]) / (2 * peak_height)\n",
    "    \n",
    "    if 'Gaussian' in name:\n",
    "        wing_desc = \"Exponential decay\"\n",
    "    elif 'Lorentzian' in name:\n",
    "        wing_desc = \"Power law (1/x¬≤)\"\n",
    "    else:\n",
    "        wing_desc = \"Mixed behavior\"\n",
    "    \n",
    "    print(f\"{name:<20} {fwhm:<12.2f} {peak_height:<15.6f} {wing_desc:<20}\")\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"  - Gaussian: Narrow core, fast decay in wings (inhomogeneous broadening)\")\n",
    "print(\"  - Lorentzian: Broader wings, slower decay (homogeneous broadening)\")\n",
    "print(\"  - Voigtian: Convolution combines both effects (most realistic)\")\n",
    "print(\"  - Pseudo-Voigt: Fast approximation with adjustable mixing (Œ∑ parameter)\")\n",
    "\n",
    "print(\"\\n‚úÖ Lineshape comparison complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Loading Real EPR Data for Fitting\n",
    "\n",
    "Now let's load a real EPR spectrum and prepare it for lineshape analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real EPR spectrum\n",
    "epr_file = data_path / '130406SB_CaWO4_Er_CW_5K_20.DSC'\n",
    "\n",
    "if epr_file.exists():\n",
    "    print(f\"Loading EPR spectrum: {epr_file.name}\")\n",
    "    field_data, intensity_data, params_data, _ = epyr.eprload(str(epr_file))\n",
    "    \n",
    "    print(f\"\\nEPR Spectrum Information:\")\n",
    "    print(f\"Field range: {field_data.min():.1f} to {field_data.max():.1f} G\")\n",
    "    print(f\"Field points: {len(field_data)}\")\n",
    "    print(f\"Microwave frequency: {params_data.get('MWFQ', 'Unknown')} GHz\")\n",
    "    print(f\"Temperature: 5 K (from filename)\")\n",
    "    print(f\"Sample: Er¬≥‚Å∫ in CaWO4 single crystal\")\n",
    "\nelse:\n",
    "    print(\"Real EPR file not found. Creating synthetic EPR spectrum...\")\n",
    "    \n",
    "    # Create synthetic multi-component EPR spectrum\n",
    "    field_data = np.linspace(3300, 3400, 800)\n",
    "    \n",
    "    # Multi-site Er¬≥‚Å∫ spectrum with different g-values\n",
    "    component1 = gaussian(field_data, 3340, 8) * 0.6    # Site 1\n",
    "    component2 = gaussian(field_data, 3355, 12) * 0.8   # Site 2  \n",
    "    component3 = gaussian(field_data, 3375, 6) * 0.4    # Site 3\n",
    "    \n",
    "    # Add some Lorentzian broadening\n",
    "    total_signal = component1 + component2 + component3\n",
    "    \n",
    "    # Add realistic baseline and noise\n",
    "    baseline = 0.02 + 0.0001 * (field_data - 3350)\n",
    "    noise = 0.03 * np.random.randn(len(field_data))\n",
    "    \n",
    "    intensity_data = total_signal + baseline + noise\n",
    "    \n",
    "    # Fake parameters\n",
    "    params_data = {\n",
    "        'MWFQ': 9.4,\n",
    "        'Temperature': 5,\n",
    "        'Sample': 'Synthetic Er¬≥‚Å∫ multisite'\n",
    "    }\n",
    "    \n",
    "    print(f\"Synthetic spectrum created with 3 components\")\n",
    "    print(f\"Component centers: 3340, 3355, 3375 G\")\n",
    "\n",
    "# Initial visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.plot(field_data, intensity_data, 'b-', linewidth=1.5, label='EPR Spectrum')\n",
    "ax.set_xlabel('Magnetic Field (G)')\n",
    "ax.set_ylabel('EPR Intensity (a.u.)')\n",
    "ax.set_title(f'EPR Spectrum for Lineshape Analysis\\n{params_data.get(\"Sample\", \"Unknown Sample\")}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Add measurement info\n",
    "info_text = f\"\"\"Measurement Info:\n",
    "Frequency: {params_data.get('MWFQ', 'Unknown')} GHz\n",
    "Temperature: {params_data.get('Temperature', 'Unknown')} K\n",
    "Points: {len(field_data)}\n",
    "Range: {field_data.max()-field_data.min():.0f} G\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, info_text, transform=ax.transAxes,\n",
    "        verticalalignment='top', \n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "        fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ EPR spectrum loaded and visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Single-Component Lineshape Fitting\n",
    "\n",
    "Let's start with fitting a single lineshape component to understand the fitting process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-component fitting demonstration\n",
    "print(\"üéØ Single-Component Lineshape Fitting\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Apply baseline correction first\n",
    "try:\n",
    "    corrected_intensity, fitted_baseline = epyr.baseline.correction.polynomial(\n",
    "        field_data, intensity_data, params_data,\n",
    "        order=1,\n",
    "        exclude_center=True,\n",
    "        center_fraction=0.4\n",
    "    )\n",
    "    print(\"Baseline correction applied\")\nexcept:\n",
    "    # Simple baseline correction\n",
    "    baseline_points = np.concatenate([intensity_data[:50], intensity_data[-50:]])\n",
    "    baseline_level = np.mean(baseline_points)\n",
    "    corrected_intensity = intensity_data - baseline_level\n",
    "    fitted_baseline = np.full_like(intensity_data, baseline_level)\n",
    "    print(\"Simple baseline correction applied\")\n",
    "\n",
    "# Try different single-component fits\n",
    "lineshape_types = ['gaussian', 'lorentzian', 'voigtian']\n",
    "fit_results = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot original data\n",
    "axes[0].plot(field_data, intensity_data, 'b-', alpha=0.7, label='Original')\n",
    "axes[0].plot(field_data, fitted_baseline, 'r--', alpha=0.7, label='Baseline')\n",
    "axes[0].plot(field_data, corrected_intensity, 'k-', linewidth=2, label='Corrected')\n",
    "axes[0].set_xlabel('Magnetic Field (G)')\n",
    "axes[0].set_ylabel('EPR Intensity (a.u.)')\n",
    "axes[0].set_title('Baseline Correction')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Fit each lineshape type\n",
    "for i, shape_type in enumerate(lineshape_types):\n",
    "    print(f\"\\nFitting {shape_type} lineshape...\")\n",
    "    \n",
    "    try:\n",
    "        # Use the EPyR Tools fitting function\n",
    "        if hasattr(epyr.lineshapes, 'fit_epr_signal'):\n",
    "            fit_result = fit_epr_signal(\n",
    "                field_data, corrected_intensity,\n",
    "                lineshape=shape_type,\n",
    "                n_components=1,\n",
    "                initial_guess='auto'\n",
    "            )\n",
    "            \n",
    "            fitted_curve = fit_result.fitted_curve\n",
    "            parameters = fit_result.parameters\n",
    "            fit_quality = fit_result.r_squared\n",
    "            \n",
    "        else:\n",
    "            # Manual fitting using scipy.optimize\n",
    "            print(f\"  Using manual fitting for {shape_type}...\")\n",
    "            \n",
    "            # Initial parameter guess\n",
    "            amplitude_guess = np.max(corrected_intensity)\n",
    "            center_guess = field_data[np.argmax(corrected_intensity)]\n",
    "            width_guess = 15  # G\n",
    "            \n",
    "            if shape_type == 'gaussian':\n",
    "                def fit_func(x, amplitude, center, width):\n",
    "                    return amplitude * gaussian(x, center, width)\n",
    "                p0 = [amplitude_guess, center_guess, width_guess]\n",
    "                \n",
    "            elif shape_type == 'lorentzian':\n",
    "                def fit_func(x, amplitude, center, width):\n",
    "                    return amplitude * lorentzian(x, center, width)\n",
    "                p0 = [amplitude_guess, center_guess, width_guess]\n",
    "                \n",
    "            elif shape_type == 'voigtian':\n",
    "                def fit_func(x, amplitude, center, sigma, gamma):\n",
    "                    return amplitude * voigtian(x, center, sigma, gamma)\n",
    "                p0 = [amplitude_guess, center_guess, width_guess/2, width_guess/2]\n",
    "            \n",
    "            # Perform fit\n",
    "            try:\n",
    "                popt, pcov = curve_fit(fit_func, field_data, corrected_intensity, p0=p0)\n",
    "                fitted_curve = fit_func(field_data, *popt)\n",
    "                \n",
    "                # Calculate R-squared\n",
    "                ss_res = np.sum((corrected_intensity - fitted_curve) ** 2)\n",
    "                ss_tot = np.sum((corrected_intensity - np.mean(corrected_intensity)) ** 2)\n",
    "                fit_quality = 1 - (ss_res / ss_tot)\n",
    "                \n",
    "                # Store parameters\n",
    "                if shape_type == 'voigtian':\n",
    "                    parameters = {\n",
    "                        'amplitude': popt[0],\n",
    "                        'center': popt[1],\n",
    "                        'sigma': popt[2],\n",
    "                        'gamma': popt[3]\n",
    "                    }\n",
    "                else:\n",
    "                    parameters = {\n",
    "                        'amplitude': popt[0],\n",
    "                        'center': popt[1],\n",
    "                        'width': popt[2]\n",
    "                    }\n",
    "                \n",
    "            except Exception as fit_error:\n",
    "                print(f\"    Fitting failed: {fit_error}\")\n",
    "                fitted_curve = np.zeros_like(field_data)\n",
    "                parameters = {}\n",
    "                fit_quality = 0\n",
    "        \n",
    "        # Store results\n",
    "        fit_results[shape_type] = {\n",
    "            'fitted_curve': fitted_curve,\n",
    "            'parameters': parameters,\n",
    "            'r_squared': fit_quality\n",
    "        }\n",
    "        \n",
    "        # Plot result\n",
    "        ax = axes[i + 1]\n",
    "        ax.plot(field_data, corrected_intensity, 'b-', linewidth=1.5, label='Data', alpha=0.7)\n",
    "        ax.plot(field_data, fitted_curve, 'r-', linewidth=2, label=f'{shape_type.capitalize()} fit')\n",
    "        ax.plot(field_data, corrected_intensity - fitted_curve, 'g-', alpha=0.7, label='Residual')\n",
    "        \n",
    "        ax.set_xlabel('Magnetic Field (G)')\n",
    "        ax.set_ylabel('EPR Intensity (a.u.)')\n",
    "        ax.set_title(f'{shape_type.capitalize()} Fit (R¬≤ = {fit_quality:.3f})')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Print parameters\n",
    "        print(f\"  R-squared: {fit_quality:.4f}\")\n",
    "        for param, value in parameters.items():\n",
    "            print(f\"  {param}: {value:.3f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error fitting {shape_type}: {e}\")\n",
    "        fit_results[shape_type] = {'r_squared': 0}\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare fit qualities\n",
    "print(f\"\\nüìä Single-Component Fit Comparison:\")\n",
    "print(f\"{'Lineshape':<15} {'R-squared':<12} {'Quality':<15}\")\n",
    "print(f\"{'-'*15} {'-'*12} {'-'*15}\")\n",
    "\n",
    "best_fit = None\n",
    "best_r2 = 0\n",
    "\n",
    "for shape_type, result in fit_results.items():\n",
    "    r2 = result.get('r_squared', 0)\n",
    "    if r2 > 0.8:\n",
    "        quality = \"Excellent\"\n",
    "    elif r2 > 0.6:\n",
    "        quality = \"Good\"\n",
    "    elif r2 > 0.4:\n",
    "        quality = \"Fair\"\n",
    "    else:\n",
    "        quality = \"Poor\"\n",
    "    \n",
    "    print(f\"{shape_type.capitalize():<15} {r2:<12.4f} {quality:<15}\")\n",
    "    \n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_fit = shape_type\n",
    "\n",
    "print(f\"\\nüèÜ Best single-component fit: {best_fit.capitalize()} (R¬≤ = {best_r2:.4f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Single-component fitting analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Multi-Component Lineshape Fitting\n",
    "\n",
    "Real EPR spectra often contain multiple overlapping components. Let's demonstrate multi-component fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-component fitting\n",
    "print(\"üîÑ Multi-Component Lineshape Fitting\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Try fitting multiple Gaussian components\n",
    "n_components_to_try = [2, 3]\n",
    "multifit_results = {}\n",
    "\n",
    "for n_comp in n_components_to_try:\n",
    "    print(f\"\\nTrying {n_comp}-component Gaussian fit...\")\n",
    "    \n",
    "    try:\n",
    "        # Use EPyR Tools multi-component fitting if available\n",
    "        if hasattr(epyr.lineshapes, 'fit_multiple_shapes'):\n",
    "            multifit_result = epyr.lineshapes.fit_multiple_shapes(\n",
    "                field_data, corrected_intensity,\n",
    "                lineshapes=['gaussian'] * n_comp,\n",
    "                initial_centers='auto'\n",
    "            )\n",
    "            \n",
    "            fitted_total = multifit_result.total_fit\n",
    "            individual_components = multifit_result.components\n",
    "            fit_quality = multifit_result.r_squared\n",
    "            parameters = multifit_result.parameters\n",
    "            \n",
    "        else:\n",
    "            # Manual multi-component fitting\n",
    "            print(f\"  Using manual multi-component fitting...\")\n",
    "            \n",
    "            # Define multi-component function\n",
    "            if n_comp == 2:\n",
    "                def multifit_func(x, a1, c1, w1, a2, c2, w2):\n",
    "                    return (a1 * gaussian(x, c1, w1) + \n",
    "                            a2 * gaussian(x, c2, w2))\n",
    "                \n",
    "                # Initial guess - find two main peaks\n",
    "                peak_indices = np.argsort(corrected_intensity)[-2:]\n",
    "                p0 = [\n",
    "                    corrected_intensity[peak_indices[0]], field_data[peak_indices[0]], 15,\n",
    "                    corrected_intensity[peak_indices[1]], field_data[peak_indices[1]], 15\n",
    "                ]\n",
    "                \n",
    "            elif n_comp == 3:\n",
    "                def multifit_func(x, a1, c1, w1, a2, c2, w2, a3, c3, w3):\n",
    "                    return (a1 * gaussian(x, c1, w1) + \n",
    "                            a2 * gaussian(x, c2, w2) +\n",
    "                            a3 * gaussian(x, c3, w3))\n",
    "                \n",
    "                # Initial guess - spread components across spectrum\n",
    "                field_range = field_data.max() - field_data.min()\n",
    "                centers = [field_data.min() + field_range * (i+1)/(n_comp+1) for i in range(n_comp)]\n",
    "                amps = [np.max(corrected_intensity) * 0.7] * n_comp\n",
    "                widths = [15] * n_comp\n",
    "                \n",
    "                p0 = []\n",
    "                for i in range(n_comp):\n",
    "                    p0.extend([amps[i], centers[i], widths[i]])\n",
    "            \n",
    "            # Perform fit with bounds\n",
    "            try:\n",
    "                # Set reasonable bounds\n",
    "                if n_comp == 2:\n",
    "                    bounds = ([0, field_data.min(), 1, 0, field_data.min(), 1],\n",
    "                             [np.inf, field_data.max(), 50, np.inf, field_data.max(), 50])\n",
    "                else:  # n_comp == 3\n",
    "                    lower = [0, field_data.min(), 1] * n_comp\n",
    "                    upper = [np.inf, field_data.max(), 50] * n_comp\n",
    "                    bounds = (lower, upper)\n",
    "                \n",
    "                popt, pcov = curve_fit(multifit_func, field_data, corrected_intensity, \n",
    "                                     p0=p0, bounds=bounds, maxfev=2000)\n",
    "                \n",
    "                fitted_total = multifit_func(field_data, *popt)\n",
    "                \n",
    "                # Extract individual components\n",
    "                individual_components = []\n",
    "                parameters = []\n",
    "                \n",
    "                for i in range(n_comp):\n",
    "                    idx = i * 3\n",
    "                    amp, center, width = popt[idx], popt[idx+1], popt[idx+2]\n",
    "                    component = amp * gaussian(field_data, center, width)\n",
    "                    individual_components.append(component)\n",
    "                    \n",
    "                    parameters.append({\n",
    "                        'amplitude': amp,\n",
    "                        'center': center,\n",
    "                        'width': width\n",
    "                    })\n",
    "                \n",
    "                # Calculate R-squared\n",
    "                ss_res = np.sum((corrected_intensity - fitted_total) ** 2)\n",
    "                ss_tot = np.sum((corrected_intensity - np.mean(corrected_intensity)) ** 2)\n",
    "                fit_quality = 1 - (ss_res / ss_tot)\n",
    "                \n",
    "            except Exception as fit_error:\n",
    "                print(f\"    Multi-component fitting failed: {fit_error}\")\n",
    "                fitted_total = np.zeros_like(field_data)\n",
    "                individual_components = []\n",
    "                parameters = []\n",
    "                fit_quality = 0\n",
    "        \n",
    "        # Store results\n",
    "        multifit_results[n_comp] = {\n",
    "            'fitted_total': fitted_total,\n",
    "            'components': individual_components,\n",
    "            'parameters': parameters,\n",
    "            'r_squared': fit_quality\n",
    "        }\n",
    "        \n",
    "        print(f\"  {n_comp}-component fit R¬≤: {fit_quality:.4f}\")\n",
    "        \n",
    "        # Print component parameters\n",
    "        for i, param_dict in enumerate(parameters):\n",
    "            print(f\"    Component {i+1}:\")\n",
    "            for param, value in param_dict.items():\n",
    "                unit = \"G\" if \"center\" in param or \"width\" in param else \"a.u.\"\n",
    "                print(f\"      {param}: {value:.2f} {unit}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"  Error in {n_comp}-component fitting: {e}\")\n",
    "        multifit_results[n_comp] = {'r_squared': 0}\n",
    "\n",
    "# Plot best multi-component fit\n",
    "best_multifit = max(multifit_results.items(), key=lambda x: x[1].get('r_squared', 0))\n",
    "best_n_comp, best_result = best_multifit\n",
    "\n",
    "if best_result.get('r_squared', 0) > 0:\n",
    "    print(f\"\\nüìä Best Multi-Component Fit: {best_n_comp} components\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Top plot: Fit and components\n",
    "    ax1.plot(field_data, corrected_intensity, 'bo-', linewidth=1.5, markersize=3, \n",
    "             alpha=0.7, label='Experimental data')\n",
    "    ax1.plot(field_data, best_result['fitted_total'], 'r-', linewidth=3, \n",
    "             label=f'Total fit (R¬≤ = {best_result[\"r_squared\"]:.3f})')\n",
    "    \n",
    "    # Plot individual components\n",
    "    colors = ['green', 'orange', 'purple', 'brown']\n",
    "    for i, component in enumerate(best_result['components'][:4]):\n",
    "        ax1.plot(field_data, component, '--', color=colors[i], linewidth=2, \n",
    "                 alpha=0.8, label=f'Component {i+1}')\n",
    "    \n",
    "    ax1.set_xlabel('Magnetic Field (G)')\n",
    "    ax1.set_ylabel('EPR Intensity (a.u.)')\n",
    "    ax1.set_title(f'{best_n_comp}-Component Gaussian Fit')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Bottom plot: Residuals\n",
    "    residuals = corrected_intensity - best_result['fitted_total']\n",
    "    ax2.plot(field_data, residuals, 'g-', linewidth=1.5, label='Residuals')\n",
    "    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.7, label='Zero line')\n",
    "    \n",
    "    # Calculate residual statistics\n",
    "    rms_residual = np.sqrt(np.mean(residuals**2))\n",
    "    max_residual = np.max(np.abs(residuals))\n",
    "    \n",
    "    ax2.set_xlabel('Magnetic Field (G)')\n",
    "    ax2.set_ylabel('Residual (a.u.)')\n",
    "    ax2.set_title(f'Fit Residuals (RMS: {rms_residual:.3f}, Max: {max_residual:.3f})')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüéØ Multi-Component Analysis Summary:\")\n",
    "    print(f\"Best fit: {best_n_comp} components with R¬≤ = {best_result['r_squared']:.4f}\")\n",
    "    print(f\"RMS residual: {rms_residual:.4f}\")\n",
    "    \n",
    "    # Component analysis\n",
    "    print(f\"\\nComponent Details:\")\n",
    "    total_intensity = 0\n",
    "    for i, params in enumerate(best_result['parameters']):\n",
    "        center = params.get('center', 0)\n",
    "        width = params.get('width', 0)\n",
    "        amplitude = params.get('amplitude', 0)\n",
    "        \n",
    "        # Estimate g-value if microwave frequency is known\n",
    "        mw_freq = params_data.get('MWFQ', 9.4)  # GHz\n",
    "        if center > 0 and mw_freq > 0:\n",
    "            g_value = (mw_freq * 1000) / (center * 0.0000467)  # Rough approximation\n",
    "        else:\n",
    "            g_value = 0\n",
    "        \n",
    "        # Estimate relative intensity (area under curve)\n",
    "        relative_intensity = amplitude * width * np.sqrt(np.pi)\n",
    "        total_intensity += relative_intensity\n",
    "        \n",
    "        print(f\"  Component {i+1}:\")\n",
    "        print(f\"    Center: {center:.1f} G\")\n",
    "        print(f\"    Width (FWHM): {width:.1f} G\")\n",
    "        print(f\"    Amplitude: {amplitude:.3f}\")\n",
    "        if g_value > 0:\n",
    "            print(f\"    Approximate g-value: {g_value:.3f}\")\n",
    "    \n",
    "    # Relative intensities\n",
    "    if total_intensity > 0:\n",
    "        print(f\"\\nRelative Intensities:\")\n",
    "        for i, params in enumerate(best_result['parameters']):\n",
    "            amplitude = params.get('amplitude', 0)\n",
    "            width = params.get('width', 0)\n",
    "            component_intensity = amplitude * width * np.sqrt(np.pi)\n",
    "            percentage = 100 * component_intensity / total_intensity\n",
    "            print(f\"  Component {i+1}: {percentage:.1f}%\")\n",
    "\nelse:\n",
    "    print(\"\\n‚ùå Multi-component fitting was not successful\")\n",
    "\n",
    "print(\"\\n‚úÖ Multi-component fitting analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Advanced Fitting: Pseudo-Voigt Analysis\n",
    "\n",
    "For the most realistic EPR lineshape analysis, let's explore Pseudo-Voigt fitting with adjustable Gaussian/Lorentzian mixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Pseudo-Voigt fitting\n",
    "print(\"üìà Advanced Pseudo-Voigt Lineshape Analysis\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Define Pseudo-Voigt fitting function with mixing parameter\n",
    "def fit_pseudo_voigt(x, amplitude, center, width, eta):\n",
    "    \"\"\"Pseudo-Voigt with mixing parameter eta (0=pure Gaussian, 1=pure Lorentzian)\"\"\"\n",
    "    return amplitude * pseudo_voigt(x, center, width, eta)\n",
    "\n",
    "print(\"\\nFitting Pseudo-Voigt lineshape with variable mixing...\")\n",
    "\n",
    "try:\n",
    "    # Initial parameter guess\n",
    "    amplitude_guess = np.max(corrected_intensity)\n",
    "    center_guess = field_data[np.argmax(corrected_intensity)]\n",
    "    width_guess = 15  # G\n",
    "    eta_guess = 0.5   # Start with 50-50 mixing\n",
    "    \n",
    "    p0 = [amplitude_guess, center_guess, width_guess, eta_guess]\n",
    "    \n",
    "    # Set parameter bounds\n",
    "    bounds = ([0, field_data.min(), 1, 0],  # lower bounds\n",
    "              [np.inf, field_data.max(), 50, 1])  # upper bounds\n",
    "    \n",
    "    # Perform fit\n",
    "    popt, pcov = curve_fit(fit_pseudo_voigt, field_data, corrected_intensity, \n",
    "                          p0=p0, bounds=bounds)\n",
    "    \n",
    "    amplitude_fit, center_fit, width_fit, eta_fit = popt\n",
    "    fitted_pv = fit_pseudo_voigt(field_data, *popt)\n",
    "    \n",
    "    # Calculate fit quality\n",
    "    ss_res = np.sum((corrected_intensity - fitted_pv) ** 2)\n",
    "    ss_tot = np.sum((corrected_intensity - np.mean(corrected_intensity)) ** 2)\n",
    "    r_squared_pv = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    # Calculate parameter uncertainties from covariance matrix\n",
    "    param_errors = np.sqrt(np.diag(pcov))\n",
    "    \n",
    "    print(f\"\\nüìä Pseudo-Voigt Fit Results:\")\n",
    "    print(f\"R-squared: {r_squared_pv:.4f}\")\n",
    "    print(f\"Amplitude: {amplitude_fit:.3f} ¬± {param_errors[0]:.3f}\")\n",
    "    print(f\"Center: {center_fit:.2f} ¬± {param_errors[1]:.2f} G\")\n",
    "    print(f\"Width (FWHM): {width_fit:.2f} ¬± {param_errors[2]:.2f} G\")\n",
    "    print(f\"Mixing parameter (Œ∑): {eta_fit:.3f} ¬± {param_errors[3]:.3f}\")\n",
    "    \n",
    "    # Interpret mixing parameter\n",
    "    if eta_fit < 0.3:\n",
    "        mixing_desc = \"Predominantly Gaussian (inhomogeneous broadening)\"\n",
    "    elif eta_fit > 0.7:\n",
    "        mixing_desc = \"Predominantly Lorentzian (homogeneous broadening)\"\n",
    "    else:\n",
    "        mixing_desc = \"Mixed Gaussian-Lorentzian character\"\n",
    "    \n",
    "    print(f\"\\nüîç Physical Interpretation:\")\n",
    "    print(f\"Lineshape character: {mixing_desc}\")\n",
    "    print(f\"Gaussian contribution: {(1-eta_fit)*100:.1f}%\")\n",
    "    print(f\"Lorentzian contribution: {eta_fit*100:.1f}%\")\n",
    "    \n",
    "    # Create comprehensive plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Main fit plot\n",
    "    axes[0,0].plot(field_data, corrected_intensity, 'bo-', markersize=3, alpha=0.7, label='Data')\n",
    "    axes[0,0].plot(field_data, fitted_pv, 'r-', linewidth=3, label=f'Pseudo-Voigt fit')\n",
    "    \n",
    "    # Show pure Gaussian and Lorentzian components\n",
    "    pure_gaussian = amplitude_fit * gaussian(field_data, center_fit, width_fit)\n",
    "    pure_lorentzian = amplitude_fit * lorentzian(field_data, center_fit, width_fit)\n",
    "    \n",
    "    axes[0,0].plot(field_data, pure_gaussian, 'g--', alpha=0.7, \n",
    "                   label=f'Pure Gaussian ({(1-eta_fit)*100:.0f}%)')\n",
    "    axes[0,0].plot(field_data, pure_lorentzian, 'orange', linestyle='--', alpha=0.7,\n",
    "                   label=f'Pure Lorentzian ({eta_fit*100:.0f}%)')\n",
    "    \n",
    "    axes[0,0].set_xlabel('Magnetic Field (G)')\n",
    "    axes[0,0].set_ylabel('EPR Intensity (a.u.)')\n",
    "    axes[0,0].set_title(f'Pseudo-Voigt Fit (R¬≤ = {r_squared_pv:.3f})')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Residuals\n",
    "    residuals_pv = corrected_intensity - fitted_pv\n",
    "    axes[0,1].plot(field_data, residuals_pv, 'g-', linewidth=1.5, label='Residuals')\n",
    "    axes[0,1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    rms_residual_pv = np.sqrt(np.mean(residuals_pv**2))\n",
    "    axes[0,1].set_xlabel('Magnetic Field (G)')\n",
    "    axes[0,1].set_ylabel('Residual (a.u.)')\n",
    "    axes[0,1].set_title(f'Fit Residuals (RMS: {rms_residual_pv:.4f})')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Parameter correlation plot\n",
    "    correlation_matrix = pcov / np.sqrt(np.outer(np.diag(pcov), np.diag(pcov)))\n",
    "    param_names = ['Amplitude', 'Center', 'Width', 'Œ∑ (mixing)']\n",
    "    \n",
    "    im = axes[1,0].imshow(correlation_matrix, cmap='RdBu_r', aspect='equal', vmin=-1, vmax=1)\n",
    "    axes[1,0].set_xticks(range(len(param_names)))\n",
    "    axes[1,0].set_yticks(range(len(param_names)))\n",
    "    axes[1,0].set_xticklabels(param_names, rotation=45)\n",
    "    axes[1,0].set_yticklabels(param_names)\n",
    "    axes[1,0].set_title('Parameter Correlation Matrix')\n",
    "    \n",
    "    # Add correlation values\n",
    "    for i in range(len(param_names)):\n",
    "        for j in range(len(param_names)):\n",
    "            axes[1,0].text(j, i, f'{correlation_matrix[i,j]:.2f}', \n",
    "                          ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=axes[1,0])\n",
    "    \n",
    "    # Mixing parameter sensitivity analysis\n",
    "    eta_values = np.linspace(0, 1, 21)\n",
    "    r2_values = []\n",
    "    \n",
    "    for eta_test in eta_values:\n",
    "        test_curve = amplitude_fit * pseudo_voigt(field_data, center_fit, width_fit, eta_test)\n",
    "        ss_res_test = np.sum((corrected_intensity - test_curve) ** 2)\n",
    "        r2_test = 1 - (ss_res_test / ss_tot)\n",
    "        r2_values.append(r2_test)\n",
    "    \n",
    "    axes[1,1].plot(eta_values, r2_values, 'b-', linewidth=2, label='R¬≤ vs Œ∑')\n",
    "    axes[1,1].axvline(eta_fit, color='red', linestyle='--', linewidth=2, \n",
    "                      label=f'Optimal Œ∑ = {eta_fit:.3f}')\n",
    "    axes[1,1].set_xlabel('Mixing Parameter Œ∑')\n",
    "    axes[1,1].set_ylabel('R-squared')\n",
    "    axes[1,1].set_title('Sensitivity to Mixing Parameter')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compare with previous best fits\n",
    "    print(f\"\\nüèÜ Fit Quality Comparison:\")\n",
    "    print(f\"Single Gaussian: R¬≤ = {fit_results.get('gaussian', {}).get('r_squared', 0):.4f}\")\n",
    "    print(f\"Single Lorentzian: R¬≤ = {fit_results.get('lorentzian', {}).get('r_squared', 0):.4f}\")\n",
    "    print(f\"Single Voigtian: R¬≤ = {fit_results.get('voigtian', {}).get('r_squared', 0):.4f}\")\n",
    "    \n",
    "    if multifit_results:\n",
    "        best_multi_r2 = max(result.get('r_squared', 0) for result in multifit_results.values())\n",
    "        print(f\"Multi-component: R¬≤ = {best_multi_r2:.4f}\")\n",
    "    \n",
    "    print(f\"Pseudo-Voigt: R¬≤ = {r_squared_pv:.4f}\")\n",
    "    \n",
    "    # Physical insights\n",
    "    print(f\"\\nüí° Physical Insights:\")\n",
    "    if eta_fit < 0.3:\n",
    "        print(f\"  - Spectrum dominated by inhomogeneous broadening\")\n",
    "        print(f\"  - Possible causes: crystal strain, unresolved hyperfine structure\")\n",
    "    elif eta_fit > 0.7:\n",
    "        print(f\"  - Spectrum dominated by homogeneous broadening\")\n",
    "        print(f\"  - Possible causes: spin-lattice relaxation, exchange interactions\")\n",
    "    else:\n",
    "        print(f\"  - Mixed broadening mechanisms\")\n",
    "        print(f\"  - Both inhomogeneous and homogeneous effects present\")\n",
    "    \n",
    "    print(f\"  - Linewidth: {width_fit:.1f} G indicates moderate broadening\")\n",
    "    if 'MWFQ' in params_data:\n",
    "        mw_freq = params_data['MWFQ']\n",
    "        g_approx = (mw_freq * 1000) / (center_fit * 0.0000467)\n",
    "        print(f\"  - Approximate g-value: {g_approx:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Pseudo-Voigt fitting failed: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Advanced Pseudo-Voigt analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Lineshape Analysis Best Practices\n",
    "\n",
    "Let's consolidate the key lessons from EPR lineshape analysis and provide practical guidelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive lineshape analysis summary\n",
    "print(\"üéØ EPR LINESHAPE ANALYSIS BEST PRACTICES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìã 1. DATA PREPARATION CHECKLIST:\")\n",
    "preparation_steps = [\n",
    "    \"Apply proper baseline correction before fitting\",\n",
    "    \"Check for phase errors in experimental data\",\n",
    "    \"Ensure adequate signal-to-noise ratio (SNR > 10)\",\n",
    "    \"Verify field axis calibration and units\",\n",
    "    \"Remove obvious artifacts or spurious peaks\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(preparation_steps, 1):\n",
    "    print(f\"  {i}. {step}\")\n",
    "\n",
    "print(f\"\\nüîç 2. LINESHAPE SELECTION GUIDE:\")\n",
    "lineshape_guide = {\n",
    "    'Gaussian': {\n",
    "        'Best for': 'Inhomogeneously broadened lines',\n",
    "        'Physical origin': 'Crystal strain, unresolved hyperfine',\n",
    "        'Wing behavior': 'Exponential decay',\n",
    "        'Use when': 'Sharp central peak, fast wing decay'\n",
    "    },\n",
    "    'Lorentzian': {\n",
    "        'Best for': 'Homogeneously broadened lines',\n",
    "        'Physical origin': 'Lifetime broadening, relaxation',\n",
    "        'Wing behavior': 'Power law (1/x¬≤)',\n",
    "        'Use when': 'Extended wings, uniform broadening'\n",
    "    },\n",
    "    'Voigtian': {\n",
    "        'Best for': 'Mixed broadening mechanisms',\n",
    "        'Physical origin': 'Both inhom. + hom. broadening',\n",
    "        'Wing behavior': 'Intermediate',\n",
    "        'Use when': 'Most realistic case, but more parameters'\n",
    "    },\n",
    "    'Pseudo-Voigt': {\n",
    "        'Best for': 'Practical mixed broadening analysis',\n",
    "        'Physical origin': 'Approximation to Voigtian',\n",
    "        'Wing behavior': 'Tunable via Œ∑ parameter',\n",
    "        'Use when': 'Need mixing ratio, faster computation'\n",
    "    }\n",
    "}\n",
    "\n",
    "for shape, properties in lineshape_guide.items():\n",
    "    print(f\"\\n  {shape}:\")\n",
    "    for prop, desc in properties.items():\n",
    "        print(f\"    {prop}: {desc}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è 3. FITTING STRATEGY:\")\n",
    "fitting_strategy = [\n",
    "    \"Start with single-component fits to understand basic lineshape\",\n",
    "    \"Compare R¬≤ values but don't rely solely on fit quality\",\n",
    "    \"Use physical constraints (positive amplitudes, reasonable widths)\",\n",
    "    \"Check parameter uncertainties and correlations\",\n",
    "    \"Validate with residual analysis (random distribution expected)\",\n",
    "    \"Consider multi-component fits only when justified\",\n",
    "    \"Use Pseudo-Voigt for quantitative broadening mechanism analysis\"\n",
    "]\n",
    "\n",
    "for i, strategy in enumerate(fitting_strategy, 1):\n",
    "    print(f\"  {i}. {strategy}\")\n",
    "\n",
    "print(f\"\\nüìä 4. QUALITY ASSESSMENT CRITERIA:\")\n",
    "quality_criteria = {\n",
    "    'Excellent (R¬≤ > 0.95)': 'Very good model, low noise, proper lineshape',\n",
    "    'Good (R¬≤ > 0.90)': 'Acceptable fit, minor deviations possible',\n",
    "    'Fair (R¬≤ > 0.80)': 'Reasonable fit, check residuals and parameters',\n",
    "    'Poor (R¬≤ < 0.80)': 'Wrong model, bad data, or insufficient components',\n",
    "    'Residual patterns': 'Systematic deviations indicate model problems',\n",
    "    'Parameter uncertainties': 'Should be < 10% of parameter values',\n",
    "    'Physical reasonableness': 'Parameters must make physical sense'\n",
    "}\n",
    "\n",
    "for criterion, description in quality_criteria.items():\n",
    "    print(f\"  {criterion}: {description}\")\n",
    "\n",
    "print(f\"\\nüî¨ 5. PHYSICAL PARAMETER EXTRACTION:\")\n",
    "parameter_guide = {\n",
    "    'g-values': 'g = (h*ŒΩ)/(ŒºB*B‚ÇÄ) where ŒΩ=MW freq, B‚ÇÄ=resonance field',\n",
    "    'Linewidths': 'ŒîH in Gauss, related to relaxation and interactions',\n",
    "    'Intensities': 'Proportional to spin concentration (double integral)',\n",
    "    'Mixing parameter': 'Œ∑ quantifies homog./inhomog. broadening ratio',\n",
    "    'Hyperfine splittings': 'From multi-component center positions',\n",
    "    'Exchange interactions': 'From line broadening and position shifts'\n",
    "}\n",
    "\n",
    "for param, description in parameter_guide.items():\n",
    "    print(f\"  {param}: {description}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è 6. COMMON PITFALLS:\")\n",
    "pitfalls = [\n",
    "    \"Over-fitting: Using too many components without physical justification\",\n",
    "    \"Ignoring baseline: Poor baseline correction leads to parameter errors\",\n",
    "    \"Parameter correlation: High correlations indicate over-parameterization\",\n",
    "    \"Local minima: Try different initial guesses to find global minimum\",\n",
    "    \"Unphysical parameters: Negative amplitudes, unrealistic linewidths\",\n",
    "    \"Ignoring uncertainty: Parameter errors tell you about reliability\",\n",
    "    \"Model selection bias: Choosing model only based on highest R¬≤\"\n",
    "]\n",
    "\n",
    "for i, pitfall in enumerate(pitfalls, 1):\n",
    "    print(f\"  {i}. {pitfall}\")\n",
    "\n",
    "print(f\"\\nüöÄ 7. ADVANCED TECHNIQUES:\")\n",
    "advanced_techniques = [\n",
    "    \"Global fitting: Fit multiple spectra with shared parameters\",\n",
    "    \"Temperature-dependent analysis: Extract activation energies\",\n",
    "    \"Angular-dependent fitting: Determine g-tensor components\",\n",
    "    \"Derivative lineshapes: First and second derivative analysis\",\n",
    "    \"Constrained fitting: Use known physical relationships\",\n",
    "    \"Bootstrap analysis: Estimate parameter confidence intervals\",\n",
    "    \"Bayesian approaches: Include prior knowledge in fitting\"\n",
    "]\n",
    "\n",
    "for i, technique in enumerate(advanced_techniques, 1):\n",
    "    print(f\"  {i}. {technique}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"‚úÖ LINESHAPE ANALYSIS MASTERY ACHIEVED!\")\n",
    "print(f\"You now have the tools for quantitative EPR spectral analysis.\")\n",
    "print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways and Applications\n",
    "\n",
    "### What You've Mastered:\n",
    "\n",
    "1. **Lineshape Theory**: Understanding Gaussian, Lorentzian, Voigtian, and Pseudo-Voigt functions\n",
    "2. **Single-Component Fitting**: Basic spectral analysis and parameter extraction\n",
    "3. **Multi-Component Analysis**: Resolving overlapping EPR signals\n",
    "4. **Advanced Fitting**: Pseudo-Voigt analysis for broadening mechanism determination\n",
    "5. **Quality Assessment**: R¬≤, residuals, parameter uncertainties, and physical validation\n",
    "6. **Physical Interpretation**: Extracting g-values, linewidths, and spin concentrations\n",
    "\n",
    "### EPyR Tools Workflow Summary:\n",
    "\n",
    "```python\n",
    "# Complete lineshape analysis workflow\n",
    "from epyr import eprload\n",
    "from epyr.lineshapes import fit_epr_signal, gaussian, pseudo_voigt\n",
    "\n",
    "# 1. Load and prepare data\n",
    "field, intensity, params, _ = eprload('spectrum.DSC')\n",
    "corrected = apply_baseline_correction(field, intensity, params)\n",
    "\n",
    "# 2. Single-component analysis\n",
    "result = fit_epr_signal(field, corrected, lineshape='pseudo_voigt')\n",
    "\n",
    "# 3. Extract parameters\n",
    "center = result.parameters['center']\n",
    "width = result.parameters['width']\n",
    "mixing = result.parameters['eta']\n",
    "\n",
    "# 4. Physical interpretation\n",
    "g_value = calculate_g_value(center, params['MWFQ'])\n",
    "```\n",
    "\n",
    "### Application Guidelines:\n",
    "\n",
    "- **Simple Systems**: Start with Gaussian or Lorentzian fits\n",
    "- **Complex Spectra**: Use Pseudo-Voigt for broadening analysis\n",
    "- **Multi-Site Systems**: Multi-component Gaussian fitting\n",
    "- **Quantitative Analysis**: Always include error analysis and physical validation\n",
    "\n",
    "### Research Applications:\n",
    "\n",
    "- **Spin Concentration**: From integrated intensities\n",
    "- **Relaxation Studies**: From homogeneous linewidths\n",
    "- **Crystal Field Analysis**: From g-value anisotropy\n",
    "- **Exchange Interactions**: From line broadening effects\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "You're now ready for:\n",
    "- **Tutorial 05**: CLI tools and automation\n",
    "- **Advanced Research**: Apply these techniques to your EPR data\n",
    "- **Publications**: Create publication-quality fitted spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Practice Exercises\n",
    "\n",
    "Perfect your lineshape analysis skills:\n",
    "\n",
    "### Exercise 1: Systematic Lineshape Comparison\n",
    "Load multiple EPR spectra and systematically compare different lineshape models. Create a decision matrix for lineshape selection.\n",
    "\n",
    "### Exercise 2: Multi-Component Resolution\n",
    "Generate synthetic overlapping Gaussian components with known parameters. Test your ability to recover the original parameters through fitting.\n",
    "\n",
    "### Exercise 3: Broadening Mechanism Analysis\n",
    "Use Pseudo-Voigt fits to analyze the temperature dependence of broadening mechanisms in a series of spectra.\n",
    "\n",
    "### Exercise 4: Parameter Uncertainty Analysis\n",
    "Implement bootstrap resampling to estimate realistic parameter uncertainties and confidence intervals.\n",
    "\n",
    "### Exercise 5: Physical Parameter Validation\n",
    "Calculate g-values, spin concentrations, and relaxation parameters from your fitted results. Validate against known literature values.\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Excellent achievement!** You've mastered quantitative EPR lineshape analysis!\n",
    "\n",
    "Continue to **[Tutorial 05: Advanced Features](05_Advanced_Features_CLI.ipynb)** to learn automation and advanced workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}