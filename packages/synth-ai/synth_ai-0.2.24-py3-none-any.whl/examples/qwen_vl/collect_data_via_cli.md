# Collect Vision Training Data via synth-ai CLI

Use synth-ai's built-in CLI tools to collect vision traces for SFT training.

## üìã Overview

**Pipeline:**
1. `synth-ai deploy --runtime=uvicorn` ‚Üí Start the Crafter task app locally
2. `synth-ai eval` ‚Üí Run rollouts with GPT-4o Mini or Qwen3-VL and collect traces
3. `synth-ai filter` ‚Üí Filter traces by quality, convert to SFT format

---

## üöÄ Step 1: Serve Crafter Task App

### Option A: Serve Locally

```bash
cd /Users/joshpurtell/Documents/GitHub/synth-ai

# Serve Crafter task app on localhost:8000
uvx synth-ai deploy grpo-crafter-task-app \
  --runtime uvicorn \
  --port 8000 \
  --trace traces/v3
```

**Output:**
```
üöÄ Task app running at http://localhost:8000
üìù Health check: http://localhost:8000/health
```

### Option B: Use Hosted Task App (Modal)

If you already have a deployed Crafter task app on Modal:
```bash
export TASK_APP_URL="https://synth-laboratories--grpo-crafter-task-app.modal.run"
```

---

## üéØ Step 2: Run Eval with Vision Models

### Collect GPT-4o-mini Vision Traces (OpenAI)

Create eval config: `examples/qwen_vl/configs/eval_gpt5nano_vision.toml`

```toml
# Evaluation config for gpt-4o-mini (vision)
# Legacy filename kept for convenience
[eval]
app_id = "grpo-crafter-task-app"
task_app_url = "http://localhost:8000"  # or your hosted URL
model = "gpt-4o-mini-2024-07-18"
seeds = "0-99"
max_turns = 50
concurrency = 5
env_name = "crafter"
policy_name = "crafter-react"
trace_format = "structured"
return_trace = true

[eval.env_config]
env_params = {max_steps_per_episode = 50}

[eval.policy_config]
provider = "openai"
model = "gpt-4o-mini-2024-07-18"
temperature = 0.7
max_tokens = 512
use_vision = true
image_only_mode = false
use_tools = true
```

**Run evaluation:**
```bash
export OPENAI_API_KEY="sk-..."

uvx synth-ai eval \
  --config examples/qwen_vl/configs/eval_gpt5nano_vision.toml \
  --trace-db traces/gpt4omini_vision/rollouts.db
```

**Expected output:**
```
üéÆ Running evaluation: gpt-4o-mini on crafter
üìä Episodes: 100, Max steps: 50
üîç Vision: enabled (auto-detected from model name)
üì¶ Collecting traces to: traces/gpt4omini_vision/rollouts.db

Episode 0/100 (seed=0): 50 steps, 3 achievements ‚úì
Episode 1/100 (seed=1): 48 steps, 2 achievements ‚úì
Episode 2/100 (seed=2): 50 steps, 4 achievements ‚úì
...
Episode 99/100 (seed=99): 50 steps, 3 achievements ‚úì

‚úÖ Evaluation complete!
   Total episodes: 100
   Total steps: 4,923
   Avg achievements: 2.8
   Traces saved to: traces/gpt4omini_vision/rollouts.db
```

---

### Collect Qwen3-VL Traces (Synth hosted inference)

Create eval config: `examples/qwen_vl/configs/eval_qwen3vl_vision.toml`

```toml
# Evaluation config for Qwen3-VL vision rollouts
[eval]
app_id = "grpo-crafter-task-app"
task_app_url = "http://localhost:8000"
model = "Qwen/Qwen3-VL-8B-Instruct"
seeds = "100-199"
max_turns = 50
concurrency = 5
env_name = "crafter"
policy_name = "crafter-react"
trace_format = "structured"
return_trace = true

[eval.env_config]
env_params = {max_steps_per_episode = 50}

[eval.policy_config]
provider = "synth"
model = "Qwen/Qwen3-VL-8B-Instruct"
temperature = 0.7
max_tokens = 512
use_vision = true
image_only_mode = false
use_tools = true
```

**Run evaluation:**
```bash
export SYNTH_API_KEY="sk_live_..."

uvx synth-ai eval \
  --config examples/qwen_vl/configs/eval_qwen3vl_vision.toml \
  --trace-db traces/qwen3vl_vision/rollouts.db
```

---

## üîç Step 3: Filter Traces for SFT

Use `synth-ai filter` to:
1. Remove low-quality episodes (too short, no achievements)
2. Convert to SFT JSONL format
3. Split into train/val sets

### Filter Config

Create `examples/qwen_vl/configs/filter_vision_sft.toml`:

```toml
# Filter vision traces for SFT training
[filter]
input_db = "traces/gpt4omini_vision/rollouts.db"
output_dir = "traces/gpt4omini_vision/sft"

# Quality filters
min_steps_per_episode = 5
min_achievements_per_episode = 1
max_steps_per_episode = 50

# Remove episodes where model got stuck (repeated actions)
detect_loops = true
max_repeated_actions = 5

# Export format
export_format = "sft_jsonl"  # OpenAI-style messages format
include_images = true         # Keep base64 images in messages

# Train/val split
train_val_split = true
val_fraction = 0.1
random_seed = 42

[sft]
# SFT-specific options
max_sequence_length = 2048    # Truncate if longer
deduplicate = true            # Remove duplicate state-action pairs
shuffle = true                # Shuffle samples
```

**Run filter:**
```bash
uvx synth-ai filter \
  --config examples/qwen_vl/configs/filter_vision_sft.toml
```

**Expected output:**
```
üìÇ Loading traces from traces/gpt4omini_vision/rollouts.db
   Total episodes: 100
   Total steps: 4,923

üîç Applying quality filters...
   ‚úì Min steps (5): kept 98 episodes
   ‚úì Min achievements (1): kept 87 episodes
   ‚úì Loop detection: removed 3 episodes
   
   Final: 84 episodes, 4,235 steps

üì¶ Exporting to SFT JSONL format...
   ‚úì Images included (base64 PNG, 64x64)
   ‚úì Deduplication: removed 45 duplicate samples
   ‚úì Final dataset: 4,190 samples

‚úÇÔ∏è Splitting train/val (90%/10%)...
   ‚úì Train: 3,771 samples ‚Üí traces/gpt4omini_vision/sft/train.jsonl
   ‚úì Val: 419 samples ‚Üí traces/gpt4omini_vision/sft/val.jsonl

‚úÖ Filter complete!
```

---

## üìä Verify Dataset

Check the SFT JSONL format:

```bash
# Inspect first sample
head -1 traces/gpt4omini_vision/sft/train.jsonl | jq .
```

**Expected format:**
```json
{
  "messages": [
    {
      "role": "system",
      "content": "You are a Crafter agent. Your goal is to survive and unlock achievements..."
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Observation:\n- Health: 9/9\n- Hunger: 9/9\n- Position: (32, 32)\n..."
        },
        {
          "type": "image_url",
          "image_url": {
            "url": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA..."
          }
        }
      ]
    },
    {
      "role": "assistant",
      "content": null,
      "tool_calls": [
        {
          "id": "call_abc123",
          "type": "function",
          "function": {
            "name": "move",
            "arguments": "{\"direction\": \"forward\"}"
          }
        }
      ]
    }
  ],
  "metadata": {
    "episode_id": "ep0042",
    "step": 12,
    "seed": 42,
    "has_image": true,
    "model": "gpt-4o-mini-2024-07-18"
  }
}
```

---

## üöÄ Step 4: Train Vision SFT

Now use the filtered dataset for SFT training:

```bash
cd /Users/joshpurtell/Documents/GitHub/monorepo

export BACKEND_BASE_URL="https://synth-backend-dev-docker.onrender.com/api"

uvx synth-ai train \
  --type sft \
  --config configs/vision_sft/crafter_qwen3vl_8b_gpt5nano.toml \
  --dataset traces/gpt4omini_vision/sft/train.jsonl \
  --eval-dataset traces/gpt4omini_vision/sft/val.jsonl \
  --env-file backend/.env.dev
```

---

## üîÑ Complete Workflow (One-Liner per Step)

```bash
# Terminal 1: Serve task app
cd /Users/joshpurtell/Documents/GitHub/synth-ai
uvx synth-ai deploy grpo-crafter-task-app \
  --runtime uvicorn \
  --port 8000 \
  --trace traces/v3

# Terminal 2: Collect traces
export OPENAI_API_KEY="sk-..."
uvx synth-ai eval \
  --config examples/qwen_vl/configs/eval_gpt5nano_vision.toml \
  --trace-db traces/gpt4omini_vision/rollouts.db

# Terminal 2: Filter and export
uvx synth-ai filter \
  --config examples/qwen_vl/configs/filter_vision_sft.toml

# Terminal 2: Train SFT
cd /Users/joshpurtell/Documents/GitHub/monorepo
export BACKEND_BASE_URL="https://synth-backend-dev-docker.onrender.com/api"
uvx synth-ai train \
  --type sft \
  --config configs/vision_sft/crafter_qwen3vl_8b_gpt5nano.toml \
  --dataset /Users/joshpurtell/Documents/GitHub/synth-ai/traces/gpt4omini_vision/sft/train.jsonl \
  --eval-dataset /Users/joshpurtell/Documents/GitHub/synth-ai/traces/gpt4omini_vision/sft/val.jsonl \
  --env-file backend/.env.dev
```

---

## üí∞ Cost & Timeline

| Step | Duration | Cost | Notes |
|------|----------|------|-------|
| 1. Serve | Continuous | Free | Local or Modal |
| 2. Eval (100 episodes) | 30-60 min | ~$1-2 | OpenAI gpt-4o-mini |
| 3. Filter | < 5 min | Free | Local processing |
| 4. SFT (2 epochs) | 2-4 hrs | ~$21 | 2x H200 on Modal |

**Total:** ~$22-23, ~3-5 hours

---

## üéØ Advanced: Collect from Multiple Models

Compare teacher quality by collecting from multiple models:

```bash
# Collect from gpt-5-nano
uvx synth-ai eval --config configs/eval_gpt5nano_vision.toml

# Collect from gpt-4o-mini (stronger teacher)
uvx synth-ai eval --config configs/eval_gpt4o_mini_vision.toml

# Collect from Qwen3-VL (for comparison)
uvx synth-ai eval --config configs/eval_qwen3vl_vision.toml

# Merge and filter all traces
uvx synth-ai filter \
  --input-dbs traces/gpt4omini_vision/rollouts.db,traces/qwen3vl_vision/rollouts.db \
  --output-dir traces/merged_vision/sft \
  --config configs/filter_vision_sft.toml
```

---

## üìö Next Steps

1. ‚úÖ Collect traces with `synth-ai eval`
2. ‚úÖ Filter and export with `synth-ai filter`
3. üöÄ Train VLM with `synth-ai train --type sft`
4. üèÜ Fine-tune with RL: `synth-ai train --type rl`
5. üìä Evaluate final model: `synth-ai eval --config configs/eval_trained_vlm.toml`

---

## üîß Troubleshooting

### Vision not detected
Add explicitly in eval config:
```toml
[eval]
use_vision = true
```

### Task app connection failed
Check task app is running:
```bash
curl http://localhost:8000/health
```

### Traces not saving
Ensure you pass `--trace-db` (or accept the default) so traces land in a SQLite/Turso database.

### Filter removes all samples
Lower quality thresholds:
```toml
[filter]
min_steps_per_episode = 3      # Lower from 5
min_achievements_per_episode = 0  # Allow episodes with no achievements
```

---

## üìñ Related Docs

- **synth-ai CLI Reference:** Run `uvx synth-ai --help`
- **Eval Config Schema:** `synth-ai eval --help`
- **Filter Config Schema:** `synth-ai filter --help`
- **Full Pipeline:** See `/Users/joshpurtell/Documents/GitHub/monorepo/vision_sft_rl.txt`
