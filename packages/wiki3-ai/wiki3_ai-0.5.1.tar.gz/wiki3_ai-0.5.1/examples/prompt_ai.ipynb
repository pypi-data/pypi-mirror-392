{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Built-in AI Demo in JupyterLab and JupyterLite Python Notebook\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "https://developer.chrome.com/docs/ai/prompt-api\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab, Jupyter Notebook, or JupyterLite (statically served, all execution locally in browser)\n",
    "\n",
    "## For developers: Using the Prompt API\n",
    "* Open Chrome and go to `chrome://flags`.\n",
    "* Enable the `#prompt-api-for-gemini-nano` flag.\n",
    "* Enable the `#optimization-guide-on-device-model` flag. If you see a \"BypassPerfRequirement\" option, select it.\n",
    "* Restart Chrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anywidget ipywidgets \"wiki3_ai>=0.5.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from wiki3_ai import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294f9f10defa4726a6d1d28f6805ec8f",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModelWidget object at 0xffffa48dea50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LanguageModel.widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API is available\n",
    "await LanguageModel.availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default temperature: 1\n",
      "Max temperature: 2\n",
      "Default top-K: 3\n",
      "Max top-K: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'defaultTopK': 3,\n",
       " 'maxTopK': 128,\n",
       " 'defaultTemperature': 1,\n",
       " 'maxTemperature': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = await LanguageModel.params()\n",
    "\n",
    "if params:\n",
    "    print(f\"Default temperature: {params.get(\"defaultTemperature\")}\")\n",
    "    print(f\"Max temperature: {params.get(\"maxTemperature\")}\")\n",
    "    print(f\"Default top-K: {params.get(\"defaultTopK\")}\")\n",
    "    print(f\"Max top-K: {params.get(\"maxTopK\")}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LanguageModel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModel at 0xffffa47e86e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = await LanguageModel.create()\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean syntax flows free,\n",
      "Logic blooms, a swift design,\n",
      "Code with grace unfolds. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt\n",
    "result = await lm.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    reader = csv.reader(file)\n",
      "    for row in reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "Replace `'your_file.csv'` with the actual filename.  `csv.reader` iterates over each row of the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create(\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Python programming assistant who gives concise answers.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "def read_csv(filename):\n",
      "  \"\"\"\n",
      "  Reads a CSV file and prints each row.\n",
      "\n",
      "  Args:\n",
      "    filename: The name of the CSV file to read.\n",
      "  \"\"\"\n",
      "  try:\n",
      "    # Open the CSV file in read mode ('r'). The 'with' statement ensures the file is automatically closed.\n",
      "    with open(filename, 'r') as file:\n",
      "      # Create a CSV reader object. This object allows you to iterate over the rows of the CSV file.\n",
      "      reader = csv.reader(file)\n",
      "\n",
      "      # Iterate over each row in the CSV file. Each 'row' is a list of strings, representing the values in each column.\n",
      "      for row in reader:\n",
      "        # Print the row to the console. You can replace this with your desired processing logic.\n",
      "        print(row)\n",
      "  except FileNotFoundError:\n",
      "    print(f\"Error: File '{filename}' not found.\")\n",
      "  except Exception as e:\n",
      "    print(f\"An error occurred: {e}\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = await assistant_session.prompt(\"Please return just the code to read a CSV file in Python.  Include detailed comments.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Why was the computer cold? \n",
      "\n",
      "It left its Windows open! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in assistant_session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a longer poem for you. It's a slightly whimsical piece about finding beauty in unexpected places.\n",
      "\n",
      "**Ephemeral Echoes**\n",
      "\n",
      "The dawn arrives, a blush of rose and gray,\n",
      "Painting the slumbering world in gentle sway.\n",
      "A spider's web, a silver, fragile lace,\n",
      "Hangs glistening, a masterpiece in place.\n",
      "\n",
      "Not grand cathedral, nor a sculpted stone,\n",
      "But delicate threads, exquisitely sown.\n",
      "A fleeting marvel, born of dew-kissed night,\n",
      "A whispered echo of the fading light.\n",
      "\n",
      "The city wakes, a rumble and a hum,\n",
      "Steel giants stir, their tireless work begun.\n",
      "A concrete jungle, stark and cold and vast,\n",
      "Yet tiny blossoms push through cracks so fast.\n",
      "\n",
      "A splash of crimson, a vibrant, hopeful hue,\n",
      "A testament to life, forever new.\n",
      "A stubborn dandelion, bold and bright,\n",
      "Defying pavement, bathed in morning light.\n",
      "\n",
      "The wind it sighs, a mournful, ancient tune,\n",
      "Rustling leaves beneath the harvest moon.\n",
      "Each fallen leaf, a story softly told,\n",
      "Of seasons turning, brave and strong and bold.\n",
      "\n",
      "And in the quiet corners, shadows deep,\n",
      "Where forgotten dreams and memories sleep,\n",
      "A single firefly, a pulsing, gentle gleam,\n",
      "A tiny spark within a fading dream.\n",
      "\n",
      "For beauty isn't found in towering heights,\n",
      "Nor gilded grandeur, nor dazzling sights.\n",
      "But in the whispers, subtle and serene,\n",
      "The ephemeral echoes, rarely seen.\n",
      "\n",
      "So open your eyes, to the small and the slight,\n",
      "The fleeting moments, bathed in morning light.\n",
      "For even in darkness, a glimmer can reside,\n",
      "A fragile beauty, nowhere left to hide.\n",
      "\n",
      "\n",
      "\n",
      "I hope you enjoyed that! Let me know if you'd like another one, or a poem on a different topic.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in assistant_session.prompt_streaming(\"Read me a long poem please.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: A list comprehension is a concise way to create lists in Python. It's essentially a shorthand for creating a new list based on an existing iterable.\n",
      "\n",
      "Here's the basic syntax:\n",
      "\n",
      "```python\n",
      "new_list = [expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "*   **expression:** What you want to put in the new list.\n",
      "*   **item:**  A variable representing each element in the iterable.\n",
      "*   **iterable:**  A sequence (like a list, tuple, string, range) to iterate over.\n",
      "*   **condition (optional):** A filter to include only certain items.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "squared_numbers = [x**2 for x in numbers]  # [1, 4, 9, 16, 25]\n",
      "\n",
      "even_squares = [x**2 for x in numbers if x % 2 == 0] # [4, 16]\n",
      "```\n",
      "\n",
      "Essentially, it's a compact `for` loop combined with an `if` statement for filtering. They are often faster and more readable than traditional `for` loops for creating lists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "result1 = await assistant_session.prompt(\"What is a list comprehension?\")\n",
    "print(\"Assistant:\", result1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ```python\n",
      "# Create a list of numbers\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "\n",
      "# Double each number using list comprehension\n",
      "doubled_numbers = [x * 2 for x in numbers]\n",
      "\n",
      "print(doubled_numbers)  # Output: [2, 4, 6, 8, 10]\n",
      "\n",
      "\n",
      "# Create a list of even numbers from the original list\n",
      "even_numbers = [x for x in numbers if x % 2 == 0]\n",
      "\n",
      "print(even_numbers)  # Output: [2, 4]\n",
      "\n",
      "# Convert strings to uppercase\n",
      "words = [\"hello\", \"world\", \"python\"]\n",
      "uppercase_words = [word.upper() for word in words]\n",
      "\n",
      "print(uppercase_words) # Output: ['HELLO', 'WORLD', 'PYTHON']\n",
      "```\n",
      "\n",
      "The examples demonstrate how list comprehensions create new lists based on existing iterables, applying transformations (doubling, converting to uppercase) or filtering elements (selecting even numbers). They're a powerful and elegant feature of Python.\n"
     ]
    }
   ],
   "source": [
    "# Follow-up message (the assistant remembers the context)\n",
    "result2 = await assistant_session.prompt(\"Can you show me an example?\")\n",
    "print(\"Assistant:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: 1051/9216 tokens\n",
      "\n",
      "This prompt would use approximately 13 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await lm.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema},\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Branch 1 ===\n",
      "Once upon a time, there was a dragon named Zephyr. But unlike the fiery behemoths of legend, Zephyr wasn’t known for scorching villages or hoarding gold. Zephyr was known… for collecting lost things, and for his remarkably kind heart.\n",
      "\n",
      "His scales weren’t shimmering emerald or ruby, but a muted, dusty lavender, the color of twilight. He didn't breathe fire, he breathed gentle breezes that carried the scent of lavender and forgotten memories. He resided not in a volcanic mountain, but in a hidden valley nestled between whispering willow trees and a babbling brook.\n",
      "\n",
      "Zephyr's hoard wasn't gold, but a breathtaking collection of lost objects. A single, mismatched sock, a tarnished silver locket containing a faded picture of a laughing child, a chipped porcelain doll missing an arm, a compass that pointed not North, but towards hope. Each item hummed with a silent story, a whisper of a life once lived.\n",
      "\n",
      "He wasn’t just a collector; he was incredibly helpful.  If a villager lost a favorite button, Zephyr would gently search the surrounding fields, using his keen eyesight to find it nestled amongst the wildflowers.  A child who misplaced a beloved stuffed animal? Zephyr would use his breeze to follow the scent of lavender-scented dreams, often leading the child right to it. \n",
      "\n",
      "He’d often use his lavender breeze to soothe a troubled heart, whispering comforting stories gleaned from the objects in his hoard - a forgotten lullaby from a broken music box, a brave tale from a worn-out book.  He'd even help lost travelers find their way back to the path, guiding them with gentle gusts of wind.  He wasn't boastful about his abilities; he simply did what he could to ease the worries of those around him. \n",
      "\n",
      "One day, old Elara, the village elder, came to Zephyr with a heavy heart. Her grandmother's knitting needles, passed down through generations, had been stolen. Zephyr, without hesitation, offered to help. He inhaled the scent of Elara’s grandmother’s yarn, letting the lavender breeze carry him on a gentle hunt. And, true to his nature, Zephyr found the needles, tucked away in a hollow oak, and returned them to a tearful, grateful Elara. \n",
      "\n",
      "\n",
      "\n",
      "Zephyr's helpfulness wasn't born of obligation, but of a deep empathy for others. He understood that even the smallest loss could feel enormous.  And that, dear listener, is where our story truly begins…\n",
      "\n",
      "\n",
      "\n",
      "=== End of 1 ===\n",
      "=== Branch 2 ===\n",
      "Once upon a time, there was a dragon. \n",
      "\n",
      "But not the gentle, lavender-scaled Zephyr we met before. This dragon was a creature of shadow and fury, a terror whispered about in hushed tones around crackling campfires. They called her Nyx, for she was as dark as the deepest night and as unpredictable as a storm.\n",
      "\n",
      "Nyx was a beast forged of obsidian scales, each one sharp as a shard of glass. Smoke, thick and acrid, constantly curled from her nostrils, tasting of sulfur and ancient wrath.  Her eyes burned with a cold, emerald fire that could pierce the thickest darkness and see straight into the hearts of mortals.  She wasn't interested in collecting lost things; she **was** the embodiment of loss – the loss of hope, the loss of dreams, the loss of life itself.\n",
      "\n",
      "Nyx didn't hoard gold, she devoured it. Kingdoms crumbled before her fiery breath, and armies scattered like leaves in a gale. Villages vanished in a blink, leaving behind only scorched earth and chilling silence. Her roars weren't calls of loneliness or yearning, but guttural pronouncements of dominance and despair.  \n",
      "\n",
      "Legends spoke of a terrible curse woven into Nyx's very being – a curse that demanded a constant feeding of sorrow.  The more pain and heartbreak she witnessed, the stronger she became.  She thrived on the despair of others, a living embodiment of their darkest fears.\n",
      "\n",
      "She stalked the land, a phantom of destruction.  No one dared to meet her gaze, for it was said that looking directly into her eyes would steal your joy, leaving you hollow and empty. Knights vowed to slay her, mages conjured powerful spells, but all were met with a terrifying display of power. Swords shattered, magic faltered, and heroes were reduced to whimpering shadows. \n",
      "\n",
      "Nyx wasn’t motivated by malice, not in the way mortals understood it. She was simply a force of nature, a destructive whirlwind fueled by the unending wellspring of sorrow that permeated the world. She was the inevitable consequence of heartbreak, the chilling reminder that even in the brightest of days, darkness lurked just beneath the surface.\n",
      "\n",
      "\n",
      "\n",
      "And that, dear listener, is the terrifying truth about Nyx, the dragon of shadow.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 2 ===\n"
     ]
    }
   ],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create(\n",
    "    {\"initialPrompts\": [{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"}]}\n",
    ")\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "print(\"=== Branch 1 ===\")\n",
    "async for chunk in branch1.prompt_streaming(\"The dragon was friendly and helpful.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"=== End of 1 ===\")\n",
    "\n",
    "print(\"=== Branch 2 ===\")\n",
    "async for chunk in branch2.prompt_streaming(\"The dragon was fierce and terrifying.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"=== End of 2 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sessions destroyed\n"
     ]
    }
   ],
   "source": [
    "await lm.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"✅ All sessions destroyed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
