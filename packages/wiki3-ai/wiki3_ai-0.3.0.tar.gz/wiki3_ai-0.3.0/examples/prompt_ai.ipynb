{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Built-in AI Demo in JupyterLab and JupyterLite Python Notebook\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "https://developer.chrome.com/docs/ai/prompt-api\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab, Jupyter Notebook, or JupyterLite (statically served, all execution locally in browser)\n",
    "\n",
    "## For developers: Using the Prompt API\n",
    "* Open Chrome and go to `chrome://flags`.\n",
    "* Enable the `#prompt-api-for-gemini-nano` flag.\n",
    "* Enable the `#optimization-guide-on-device-model` flag. If you see a \"BypassPerfRequirement\" option, select it.\n",
    "* Restart Chrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anywidget ipywidgets wiki3_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from wiki3_ai import LanguageModel, Availability, LanguageModelWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339d00f57f814bec87754440dd8e2e70",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModelWidget object at 0xffff88bf6a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_widget = LanguageModelWidget()\n",
    "lm_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModel at 0xffff881f8980>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = await LanguageModel.create(lm_widget)\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Availability.AVAILABLE: 'available'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API is available\n",
    "await lm.availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean syntax flows free,\n",
      "Logic blooms, a coded dream,\n",
      "Scripts come alive now. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt\n",
    "result = await lm.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    reader = csv.reader(file)\n",
      "    for row in reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1.  **`import csv`**: Imports the `csv` module.\n",
      "2.  **`with open('your_file.csv', 'r') as file:`**: Opens the CSV file in read mode (`'r'`).  The `with` statement ensures the file is automatically closed. Replace `'your_file.csv'` with the actual file name.\n",
      "3.  **`reader = csv.reader(file)`**: Creates a CSV reader object.\n",
      "4.  **`for row in reader:`**: Iterates through each row in the CSV file.\n",
      "5.  **`print(row)`**: Prints each row (as a list of strings).\n",
      "\n",
      "\n",
      "\n",
      "For more complex CSV files (e.g., with headers, different delimiters), explore `csv.DictReader` and the `csv` module's documentation.\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create(lm_widget,\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Python programming assistant who gives concise answers.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in assistant_session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: A list comprehension is a concise way to create lists in Python. It's a more compact alternative to using a `for` loop and `append()`.  It allows you to generate a new list by applying an expression to each item in an existing iterable (like a list, tuple, or range).\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "# Traditional loop\n",
      "squares = []\n",
      "for i in range(10):\n",
      "  squares.append(i**2)\n",
      "\n",
      "# List comprehension\n",
      "squares = [i**2 for i in range(10)]\n",
      "\n",
      "print(squares)  # Output: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "```\n",
      "\n",
      "In short, it's a shorthand for creating lists based on existing iterables.\n",
      "\n",
      "Assistant: ```python\n",
      "# Example: Extract even numbers from a list\n",
      "\n",
      "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "# List comprehension to get even numbers\n",
      "even_numbers = [num for num in numbers if num % 2 == 0]\n",
      "\n",
      "print(even_numbers)  # Output: [2, 4, 6, 8, 10]\n",
      "\n",
      "# Example: Convert strings to uppercase\n",
      "\n",
      "words = [\"hello\", \"world\", \"python\"]\n",
      "\n",
      "uppercase_words = [word.upper() for word in words]\n",
      "\n",
      "print(uppercase_words) # Output: ['HELLO', 'WORLD', 'PYTHON']\n",
      "```\n",
      "\n",
      "Essentially, a list comprehension follows this pattern:  `[expression for item in iterable if condition]`.  The `if condition` part is optional. If omitted, it creates a list with all items from the iterable.\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "result1 = await assistant_session.prompt(\"What is a list comprehension?\")\n",
    "print(\"Assistant:\", result1)\n",
    "print()\n",
    "\n",
    "# Follow-up message (the assistant remembers the context)\n",
    "result2 = await assistant_session.prompt(\"Can you show me an example?\")\n",
    "print(\"Assistant:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: 691/9216 tokens\n",
      "\n",
      "This prompt would use approximately 13 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModelParams(default_top_k=3, max_top_k=128, default_temperature=1, max_temperature=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = await lm.params()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default temperature: 1\n",
      "Max temperature: 2\n",
      "Default top-K: 3\n",
      "Max top-K: 128\n"
     ]
    }
   ],
   "source": [
    "if params:\n",
    "    print(f\"Default temperature: {params.default_temperature}\")\n",
    "    print(f\"Max temperature: {params.max_temperature}\")\n",
    "    print(f\"Default top-K: {params.default_top_k}\")\n",
    "    print(f\"Max top-K: {params.max_top_k}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await lm.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema},\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 1: Once upon a time, there was a dragon named Zephyr, but he wasn't your typical, fire-breathing, hoard-guarding kind. Zephyr was a collector of lost melodies. Instead of gold, he amassed fragments of songs – a whisper of a lullaby caught on the wind, a single, shimmering chord from a forgotten flute, the echo of a joyous tavern song fading into twilight. \n",
      "\n",
      "Zephyr lived not in a volcanic mountain, but nestled amongst the whispering willows of the Sunken Glade, a place where moonlight always seemed to linger. His scales weren't the usual crimson or emerald, but a soft, iridescent lavender, shifting with the colors of the dawn. And his breath? It wasn’t fire, but a delicate, shimmering mist that could weave forgotten notes back into existence.\n",
      "\n",
      "He wasn’t a fearsome guardian, not at all. Zephyr was incredibly friendly and helpful. He’d happily assist lost travelers, guiding them through tangled forests with a gentle hum that resonated with the path. He'd mend broken instruments with a puff of his melodic mist, restoring their sound to its former glory.  And he always had a soothing melody to ease a troubled heart. \n",
      "\n",
      "He lived amongst the creatures of the glade, offering his unique talents. Squirrels would bring him interesting twigs to add percussive elements to his compositions, and butterflies would pollinate the luminous flowers he nurtured, adding vibrant colors to his soundscapes.  He was a gentle giant, always eager to lend a claw (though he preferred using his snout!) to anyone in need. \n",
      "\n",
      "Zephyr wasn’t a fearsome guardian, because he *didn’t want to be*. He wanted to share the joy of music, to help others find harmony in their lives. He’d often listen intently to the woes of the creatures who sought him out, and then craft a melody specifically designed to uplift their spirits, a tune woven with hope and resilience.\n",
      "\n",
      "But Zephyr felt a deep loneliness. He longed to share the music, to weave a tapestry of forgotten harmonies for the world to hear. He just couldn’t bring himself to leave his Glade, afraid that his gentle nature wouldn’t be understood by the more… wary inhabitants of the world. He worried his kindness would be misinterpreted. \n",
      "\n",
      "One day, a little girl named Elara wandered into the Sunken Glade. She wasn't afraid. She’d heard whispers of a kind dragon who helped those in need. She wasn't intimidated by scales or claws, only drawn to the gentle hum that emanated from within the willow trees.  She carried her worn wooden lute, hoping to find inspiration. \n",
      "\n",
      "She heard a faint hum, like a sigh carried on the breeze, and followed the sound to Zephyr’s shimmering home.  She gasped, not in fear, but in delight. The shelves filled with vials glowed softly, casting dancing shadows.  Zephyr, startled but not alarmed, peeked out from behind a willow branch.  He offered a small, hesitant wave of his iridescent snout. \n",
      "\n",
      "Elara didn't scream or run. She simply knelt, her lute held respectfully in her lap, and whispered, \"That’s beautiful… what are they all?\" \n",
      "\n",
      "And Zephyr, for the first time, felt a glimmer of hope that his melodies might finally be shared. The story, you see, wasn't just about a friendly dragon who collected lost melodies. It was about a girl who saw the kindness in his heart. And that, he realised, was the most beautiful melody of all.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Branch 2: Once upon a time, there was a dragon named Veridian. He wasn't known for gentle sighs or shimmering melodies. Veridian *was* the melody of terror. He was a behemoth of obsidian scales, each one sharper than a shard of glass. Smoke, thick and acrid, constantly curled from his nostrils, smelling of sulfur and scorched earth. \n",
      "\n",
      "He didn’t dwell in quaint glades, but in the jagged peaks of Mount Cinder, a volcanic scar on the land. His hoard wasn't glittering gold, but a terrifying collection of artifacts – the skulls of valiant knights, the rusted swords of forgotten armies, and the petrified remains of those who dared to challenge him. \n",
      "\n",
      "Veridian breathed not a delicate mist, but a torrent of molten fire, capable of melting stone and turning forests to ash. His roar wasn’t a whisper, but a deafening bellow that shook the very foundations of the world, promising only destruction. He *was* the embodiment of fear, a living nightmare etched into the landscape.\n",
      "\n",
      "He wasn’t a collector of lost melodies, but a devourer of sound. He absorbed the joyful laughter of villagers, the hopeful hymns of priests, even the comforting murmur of lovers’ whispers, leaving behind a hollow silence in his wake.  The echoes of those stolen sounds clung to him, twisting into a discordant symphony of despair that permeated Mount Cinder. \n",
      "\n",
      "For centuries, he’d terrorized the kingdom of Eldoria, demanding tribute – livestock, precious jewels, and sometimes, even people.  He reveled in the fear in their eyes, in the crumbling of their courage. He saw himself not as a creature of instinct, but as a rightful ruler, enforcing the harsh order of his fiery domain.\n",
      "\n",
      "One day, a young knight named Lyra, barely a woman grown, decided she'd had enough. Unlike the previous generations who’d fled in terror, Lyra wasn't seeking glory. She sought a way to *end* the terror. Armed with a shield forged from enchanted moonlight and a sword imbued with the spirit of Eldoria’s ancient heroes, she ascended Mount Cinder, not to fight with brute force, but with a desperate, unconventional plan.  She knew she couldn’t defeat Veridian with strength.  She had to find a weakness, something beyond fire and steel, to pierce the obsidian armor of his terrifying heart.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create(lm_widget,\n",
    "    {\"initialPrompts\": [{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"}]}\n",
    ")\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "result1 = await branch1.prompt(\"The dragon was friendly and helpful.\")\n",
    "print(\"Branch 1:\", result1)\n",
    "print()\n",
    "\n",
    "result2 = await branch2.prompt(\"The dragon was fierce and terrifying.\")\n",
    "print(\"Branch 2:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sessions destroyed\n"
     ]
    }
   ],
   "source": [
    "await lm.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"✅ All sessions destroyed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
